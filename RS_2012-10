{"over_18":false,"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/10raf2/machine_learning_dont_like_weka_ive_been_working/","user_reports":[],"id":"10raf2","link_flair_text":null,"edited":false,"is_self":true,"title":"(Machine Learning) Dont like WEKA? I've been working on a new ML library JSAT - Hoping to get some feedback (x-post from programming) ","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For about 2 years now, I have been working on a library in my spare time. Like many of you, I took a Machine learning course in college and enjoyed it. However, I did not like Weka. So I decided I would do something about it. JSAT is my something.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve restricted myself to Classification, Regression, and Clustering - and have been implementing and testing several different algorithms. I&amp;#39;ve also been trying to implement much of it as a multi-threaded library, so you can take advantage of all that delicious processing power in your desktop.&lt;/p&gt;\n\n&lt;p&gt;Its by no means perfect, and there are lots of spelling errors (dyslexia, I have trouble seeing them). But it is getting to a point where I think it may be usefull to others. So I&amp;#39;m trying to get it out a bit, and get feedback from anyone who feels like trying or using it.&lt;/p&gt;\n\n&lt;p&gt;Hopefully I havent violated any horrible internet rules (mostly a lurker of funny pictures).&lt;/p&gt;\n\n&lt;p&gt;I posted this in &lt;a href=\"/r/programming\"&gt;/r/programming&lt;/a&gt; as well. I&amp;#39;ll be able to answer questions periodically throughout the day. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","distinguished":null,"downs":0,"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"ups":12,"secure_media_embed":{},"score":12,"author_flair_text":null,"link_flair_css_class":null,"selftext":"For about 2 years now, I have been working on a library in my spare time. Like many of you, I took a Machine learning course in college and enjoyed it. However, I did not like Weka. So I decided I would do something about it. JSAT is my something.\n\nI've restricted myself to Classification, Regression, and Clustering - and have been implementing and testing several different algorithms. I've also been trying to implement much of it as a multi-threaded library, so you can take advantage of all that delicious processing power in your desktop.\n\nIts by no means perfect, and there are lots of spelling errors (dyslexia, I have trouble seeing them). But it is getting to a point where I think it may be usefull to others. So I'm trying to get it out a bit, and get feedback from anyone who feels like trying or using it.\n\nHopefully I havent violated any horrible internet rules (mostly a lurker of funny pictures).\n\nI posted this in /r/programming as well. I'll be able to answer questions periodically throughout the day. ","subreddit":"MachineLearning","created_utc":1349094927,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"gilded":0,"author":"EdwardRaff","permalink":"/r/MachineLearning/comments/10raf2/machine_learning_dont_like_weka_ive_been_working/","retrieved_on":1413531750,"num_comments":26}
{"title":"Why/how does Gibbs sampling work?","is_self":true,"edited":false,"link_flair_text":null,"id":"10r4j5","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/10r4j5/whyhow_does_gibbs_sampling_work/","mod_reports":[],"media_embed":{},"over_18":false,"num_comments":4,"retrieved_on":1413531975,"author":"nickponline","permalink":"/r/MachineLearning/comments/10r4j5/whyhow_does_gibbs_sampling_work/","gilded":0,"media":null,"report_reasons":null,"created_utc":1349080945,"banned_by":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"I can't find an explanation I understand as to why alternatively sampling from the conditional distributions of each variable asymptotically gives samples from the full joint distribution. Does anyone has an intuitive explanation or link to a a good source?","author_flair_text":null,"score":5,"secure_media_embed":{},"ups":5,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"downs":0,"distinguished":null,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t find an explanation I understand as to why alternatively sampling from the conditional distributions of each variable asymptotically gives samples from the full joint distribution. Does anyone has an intuitive explanation or link to a a good source?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"}
{"is_self":true,"title":"Some questions on Text Analysis","edited":false,"link_flair_text":null,"mod_reports":[],"media_embed":{},"user_reports":[],"id":"10r290","url":"http://www.reddit.com/r/MachineLearning/comments/10r290/some_questions_on_text_analysis/","over_18":false,"gilded":0,"permalink":"/r/MachineLearning/comments/10r290/some_questions_on_text_analysis/","author":"DeusexConstantia","num_comments":4,"retrieved_on":1413532065,"link_flair_css_class":null,"selftext":"Hi, I hope this is the right subreddit.\n\nFor a small project I'd like to sift through a large amount of articles and tag them according to category (Interview, News article etc.) and occurrence of a preset of notable items ( Names, Brands ).\n\nLater on I might want to add some language processing ( figure out if the article is FROM, WITH or ABOUT an item ) or sentiment analysis ( is this article positive or negative in tone ).\n\nI've googled around, and I'm torn between GATE, NTLK and Rapidminer. I also have a couple of questions:\n\n* I couldn't find an Open Source library or Suite  written in C or C++. Why is that? I'd think that it is quite resource hogging and using Java (which seems to be preferred ) or any other interpreter language would unneccesarilly bog down performance.\n* I'm not sure if any of the three tools above are really suited for the job. Especially GATE and Rapidminer seem like a bit of overkill. Your thoughts on that?\n*What are some good books/tutorials that will help me with this project? I've already bookmarked [this](http://www.puffinwarellc.com/index.php/news-and-articles/articles/33.html?showall=1) link which at the time of posting is on the top of this subreddit. It seems to be quite useful for my goal. Other than that I am lost as for example the NTLK examples use tags like NN, NP-BSJ which I guess are shorthand for some grammatical definition (Nominative Noun maybe?) but which don't really help understanding. Any recommendations?\n\nIf you got this far, thanks for reading.","score":1,"author_flair_text":null,"created_utc":1349075399,"report_reasons":null,"subreddit_id":"t5_2r3gv","banned_by":null,"media":null,"subreddit":"MachineLearning","domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"ups":1,"secure_media_embed":{},"stickied":false,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I hope this is the right subreddit.&lt;/p&gt;\n\n&lt;p&gt;For a small project I&amp;#39;d like to sift through a large amount of articles and tag them according to category (Interview, News article etc.) and occurrence of a preset of notable items ( Names, Brands ).&lt;/p&gt;\n\n&lt;p&gt;Later on I might want to add some language processing ( figure out if the article is FROM, WITH or ABOUT an item ) or sentiment analysis ( is this article positive or negative in tone ).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve googled around, and I&amp;#39;m torn between GATE, NTLK and Rapidminer. I also have a couple of questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I couldn&amp;#39;t find an Open Source library or Suite  written in C or C++. Why is that? I&amp;#39;d think that it is quite resource hogging and using Java (which seems to be preferred ) or any other interpreter language would unneccesarilly bog down performance.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m not sure if any of the three tools above are really suited for the job. Especially GATE and Rapidminer seem like a bit of overkill. Your thoughts on that?\n*What are some good books/tutorials that will help me with this project? I&amp;#39;ve already bookmarked &lt;a href=\"http://www.puffinwarellc.com/index.php/news-and-articles/articles/33.html?showall=1\"&gt;this&lt;/a&gt; link which at the time of posting is on the top of this subreddit. It seems to be quite useful for my goal. Other than that I am lost as for example the NTLK examples use tags like NN, NP-BSJ which I guess are shorthand for some grammatical definition (Nominative Noun maybe?) but which don&amp;#39;t really help understanding. Any recommendations?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you got this far, thanks for reading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null}
{"downs":0,"distinguished":null,"stickied":false,"thumbnail":"http://d.thumbs.redditmedia.com/N_XlesLJr_RMRIy3.jpg","selftext_html":null,"secure_media_embed":{},"ups":43,"secure_media":null,"domain":"normaldeviate.wordpress.com","author_flair_css_class":null,"media":null,"subreddit_id":"t5_2r3gv","created_utc":1349067681,"report_reasons":null,"banned_by":null,"subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"author_flair_text":null,"score":43,"num_comments":6,"retrieved_on":1413532265,"permalink":"/r/MachineLearning/comments/10qxgz/the_remarkable_kmeans/","author":"rrenaud","gilded":0,"over_18":false,"id":"10qxgz","user_reports":[],"url":"http://normaldeviate.wordpress.com/2012/09/30/the-remarkable-k-means/","mod_reports":[],"media_embed":{},"edited":false,"link_flair_text":null,"title":"The remarkable k-means++","is_self":false}
{"banned_by":null,"created_utc":1349062800,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","selftext":"Hi all, \n\nI am looking for an intuitive explanation of variational bayes. Does anyone know of an accessible tutorial or a video of someone who explains variational bayes as clearly as Andrew Ng?\n\nThanks in advance :)","link_flair_css_class":null,"score":14,"author_flair_text":null,"num_comments":8,"retrieved_on":1413532434,"permalink":"/r/MachineLearning/comments/10qt8q/looking_for_an_approachable_explanation_of/","gilded":0,"author":"giror","downs":0,"distinguished":null,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I am looking for an intuitive explanation of variational bayes. Does anyone know of an accessible tutorial or a video of someone who explains variational bayes as clearly as Andrew Ng?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","ups":14,"secure_media_embed":{},"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"edited":false,"link_flair_text":null,"title":"Looking for an approachable explanation of Variational Bayes","is_self":true,"over_18":false,"id":"10qt8q","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/10qt8q/looking_for_an_approachable_explanation_of/","mod_reports":[],"media_embed":{}}
{"num_comments":1,"retrieved_on":1413527385,"author":"chumbaz","gilded":0,"permalink":"/r/MachineLearning/comments/10ugig/help_with_eureqa/","created_utc":1349222182,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"I'm just getting started with Eureqa, but even running a session against some predictable demo data is already frustrating.  \n  \nFor example, I have 100 products with sales data for the first 30 days. I would like to see if there is a correlation in the first 5 days of sales what the sales will look like on day 30.  \n  \nHowever, even when I run predictable samples like every day is (prior day + 10) units, I get results back like \"day30 = day5\". I've played with both cumulative figures (d1: 10, d2: 20, d3: 30) and daily values (d1: 10, d2: 11, d3: 12) and neither really find a valuable solution.\n\nAm I completely missing something? I'd just like to understand this better before I throw a big data set at it.\n\n","score":1,"author_flair_text":null,"ups":1,"secure_media_embed":{},"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"downs":0,"distinguished":null,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just getting started with Eureqa, but even running a session against some predictable demo data is already frustrating.  &lt;/p&gt;\n\n&lt;p&gt;For example, I have 100 products with sales data for the first 30 days. I would like to see if there is a correlation in the first 5 days of sales what the sales will look like on day 30.  &lt;/p&gt;\n\n&lt;p&gt;However, even when I run predictable samples like every day is (prior day + 10) units, I get results back like &amp;quot;day30 = day5&amp;quot;. I&amp;#39;ve played with both cumulative figures (d1: 10, d2: 20, d3: 30) and daily values (d1: 10, d2: 11, d3: 12) and neither really find a valuable solution.&lt;/p&gt;\n\n&lt;p&gt;Am I completely missing something? I&amp;#39;d just like to understand this better before I throw a big data set at it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","title":"Help with Eureqa","is_self":true,"edited":false,"link_flair_text":null,"user_reports":[],"id":"10ugig","url":"http://www.reddit.com/r/MachineLearning/comments/10ugig/help_with_eureqa/","mod_reports":[],"media_embed":{},"over_18":false}
{"edited":false,"link_flair_text":null,"title":"What is the state of the art for efficient k-nearest neighbor search?","is_self":true,"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/10u4hq/what_is_the_state_of_the_art_for_efficient/","id":"10u4hq","user_reports":[],"media_embed":{},"mod_reports":[],"subreddit":"MachineLearning","created_utc":1349211188,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"score":10,"author_flair_text":null,"selftext":"What is current the best algorithm/data-structure for efficiently finding the K nearest neighbors of an arbitrary point in a data set (using Euclidean distance)?","link_flair_css_class":null,"retrieved_on":1413527848,"num_comments":23,"gilded":0,"permalink":"/r/MachineLearning/comments/10u4hq/what_is_the_state_of_the_art_for_efficient/","author":"rudyl313","distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is current the best algorithm/data-structure for efficiently finding the K nearest neighbors of an arbitrary point in a data set (using Euclidean distance)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","ups":10,"secure_media_embed":{},"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null}
{"link_flair_text":null,"edited":false,"title":"Oldie but a goodie: Stein's Paradox in statistics and Empirical Bayes (1977)","is_self":false,"over_18":false,"id":"10tm50","user_reports":[],"url":"http://www-stat.stanford.edu/~ckirby/brad/other/Article1977.pdf","mod_reports":[],"media_embed":{},"created_utc":1349194772,"subreddit_id":"t5_2r3gv","banned_by":null,"report_reasons":null,"media":null,"subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"score":19,"author_flair_text":null,"num_comments":1,"retrieved_on":1413528542,"permalink":"/r/MachineLearning/comments/10tm50/oldie_but_a_goodie_steins_paradox_in_statistics/","author":"rrenaud","gilded":0,"downs":0,"distinguished":null,"thumbnail":"default","stickied":false,"selftext_html":null,"ups":19,"secure_media_embed":{},"domain":"www-stat.stanford.edu","secure_media":null,"author_flair_css_class":null}
{"subreddit":"MachineLearning","media":null,"subreddit_id":"t5_2r3gv","created_utc":1349189003,"banned_by":null,"report_reasons":null,"author_flair_text":null,"score":13,"selftext":"I'm guessing you know all about http://en.wikipedia.org/wiki/Conway's_Game_of_Life\n\nedit - I can program and know a thing or two about economics. Just a bit of an AI novice so intro to any basics concepts I should look up are helpful too.","link_flair_css_class":null,"retrieved_on":1413528759,"num_comments":15,"gilded":0,"author":"iron_brew","permalink":"/r/MachineLearning/comments/10tges/does_anyone_know_of_any_economic_studies/","distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m guessing you know all about &lt;a href=\"http://en.wikipedia.org/wiki/Conway&amp;#x27;s_Game_of_Life\"&gt;http://en.wikipedia.org/wiki/Conway&amp;#39;s_Game_of_Life&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;edit - I can program and know a thing or two about economics. Just a bit of an AI novice so intro to any basics concepts I should look up are helpful too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","secure_media_embed":{},"ups":13,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","edited":1349259599,"link_flair_text":null,"title":"Does anyone know of any economic studies involving AI? E.g. using models like Conway's Game of Life","is_self":true,"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/10tges/does_anyone_know_of_any_economic_studies/","user_reports":[],"id":"10tges","media_embed":{},"mod_reports":[]}
{"is_self":true,"title":"You're handed a 5 years worth of ecommerce data from a large site and asked to find \"actionable insights to improve the bottomline\" - what would you look for?","edited":false,"link_flair_text":null,"mod_reports":[],"media_embed":{},"id":"10wkiu","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/10wkiu/youre_handed_a_5_years_worth_of_ecommerce_data/","over_18":false,"permalink":"/r/MachineLearning/comments/10wkiu/youre_handed_a_5_years_worth_of_ecommerce_data/","author":"stevestoe","gilded":0,"num_comments":18,"retrieved_on":1413524340,"selftext":"I'm finding myself in similar corporate situations (this is a bit more general to make it interesting). Part of my work is to supply reports on sales and distribution numbers. Initially they were just interesting graphs, but since I 've got a background with some math and statistics I decided to learn data analysis with the goal of getting it to the level where I could apply it at work and turn it in to something more useful. At this point the biggest challenge is to know what to look for - knowing what to apply &amp; when to apply it. \n\nI'm interested in hearing how someone with experience would approach a problem like this, where you basically have access to all the data you need (You can assume millions of records and full purchase info), but very limited instructions. What kind of analysis would you run first and why did you decide to use it? I would love to learn more about the process of approaching a data analysis problem, but not sure where to look for learning that specifically. \n","link_flair_css_class":null,"author_flair_text":null,"score":23,"media":null,"banned_by":null,"created_utc":1349307668,"subreddit_id":"t5_2r3gv","report_reasons":null,"subreddit":"MachineLearning","secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"secure_media_embed":{},"ups":23,"stickied":false,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m finding myself in similar corporate situations (this is a bit more general to make it interesting). Part of my work is to supply reports on sales and distribution numbers. Initially they were just interesting graphs, but since I &amp;#39;ve got a background with some math and statistics I decided to learn data analysis with the goal of getting it to the level where I could apply it at work and turn it in to something more useful. At this point the biggest challenge is to know what to look for - knowing what to apply &amp;amp; when to apply it. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in hearing how someone with experience would approach a problem like this, where you basically have access to all the data you need (You can assume millions of records and full purchase info), but very limited instructions. What kind of analysis would you run first and why did you decide to use it? I would love to learn more about the process of approaching a data analysis problem, but not sure where to look for learning that specifically. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null}
{"over_18":false,"url":"http://www.quora.com/Comparing-Cities/What-cultural-differences-exist-between-New-York-and-Silicon-Valley","user_reports":[],"id":"10vrpj","media_embed":{},"mod_reports":[],"edited":false,"link_flair_text":null,"title":"Statistical analysis on twitter data: differences between NYC and SF","is_self":false,"distinguished":null,"downs":0,"selftext_html":null,"thumbnail":"http://a.thumbs.redditmedia.com/abceWj1DqURHOoxT.jpg","stickied":false,"secure_media_embed":{},"ups":42,"author_flair_css_class":null,"secure_media":null,"domain":"quora.com","subreddit":"MachineLearning","media":null,"banned_by":null,"created_utc":1349282308,"subreddit_id":"t5_2r3gv","report_reasons":null,"author_flair_text":null,"score":42,"selftext":"","link_flair_css_class":null,"retrieved_on":1413525436,"num_comments":8,"permalink":"/r/MachineLearning/comments/10vrpj/statistical_analysis_on_twitter_data_differences/","gilded":0,"author":"rrenaud"}
{"selftext":"","link_flair_css_class":null,"author_flair_text":null,"score":1,"media":null,"banned_by":null,"created_utc":1349266743,"subreddit_id":"t5_2r3gv","report_reasons":null,"subreddit":"MachineLearning","gilded":0,"author":"glasses1","permalink":"/r/MachineLearning/comments/10vd8f/from_compressive_sensing_to_machine_learning/","num_comments":0,"retrieved_on":1413526140,"stickied":false,"thumbnail":"http://f.thumbs.redditmedia.com/awl2bRKLLJlH7H3_.jpg","selftext_html":null,"downs":0,"distinguished":null,"secure_media":null,"domain":"nuit-blanche.blogspot.de","author_flair_css_class":null,"secure_media_embed":{},"ups":1,"edited":false,"link_flair_text":null,"is_self":false,"title":"From Compressive Sensing to Machine Learning","over_18":false,"mod_reports":[],"media_embed":{},"id":"10vd8f","user_reports":[],"url":"http://nuit-blanche.blogspot.de/2012/09/from-compressive-sensing-to-machine.html"}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. Say I have a very large dataset and I want to built a random forests with 800 trees on it. I think I can split the resulting dataset into four, disjoint, random sampled parts, train 200 trees on them on four separate machines, then combine the resulting forests, and the result will be equivalent in predictive power to a forests trained in one step without spliting. Am I right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"default","stickied":false,"distinguished":null,"downs":0,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","secure_media_embed":{},"ups":1,"author_flair_text":null,"score":1,"selftext":"Hi. Say I have a very large dataset and I want to built a random forests with 800 trees on it. I think I can split the resulting dataset into four, disjoint, random sampled parts, train 200 trees on them on four separate machines, then combine the resulting forests, and the result will be equivalent in predictive power to a forests trained in one step without spliting. Am I right?","link_flair_css_class":null,"subreddit":"MachineLearning","media":null,"created_utc":1349257446,"subreddit_id":"t5_2r3gv","report_reasons":null,"banned_by":null,"permalink":"/r/MachineLearning/comments/10v8wu/random_forest_question/","author":"[deleted]","gilded":0,"retrieved_on":1413526300,"num_comments":0,"over_18":false,"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/10v8wu/random_forest_question/","id":"10v8wu","user_reports":[],"edited":1349259045,"link_flair_text":null,"is_self":true,"title":"Random forest question"}
{"link_flair_css_class":null,"selftext":"I'm doing some experiments in classification of genomic sequences using [Random Forests](http://www.stat.berkeley.edu/~breiman/RandomForests/).\n\nI was wondering if it makes sense to remove trees, which have a high error rate in out-of-bag samples, from the set of generated trees.\nThe reason for this is that I want to save computations in the classification step (there is a huge amount of classifications to be performed).\n\nDoes anyone have any experience in this topic? Do you think it's a good idea or will I be losing too much prediction power? Any hints for a sensible threshold to delete a tree?","score":2,"author_flair_text":null,"created_utc":1349243887,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","author":"folli","permalink":"/r/MachineLearning/comments/10v2bz/deforestation_of_random_forests/","gilded":0,"num_comments":18,"retrieved_on":1413526547,"stickied":false,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m doing some experiments in classification of genomic sequences using &lt;a href=\"http://www.stat.berkeley.edu/%7Ebreiman/RandomForests/\"&gt;Random Forests&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if it makes sense to remove trees, which have a high error rate in out-of-bag samples, from the set of generated trees.\nThe reason for this is that I want to save computations in the classification step (there is a huge amount of classifications to be performed).&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience in this topic? Do you think it&amp;#39;s a good idea or will I be losing too much prediction power? Any hints for a sensible threshold to delete a tree?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null,"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"ups":2,"secure_media_embed":{},"edited":false,"link_flair_text":null,"is_self":true,"title":"Deforestation of Random Forests","over_18":false,"mod_reports":[],"media_embed":{},"id":"10v2bz","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/10v2bz/deforestation_of_random_forests/"}
{"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"secure_media_embed":{},"ups":1,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi -- sorry I didn&amp;#39;t go to grad school so forgive any confusion of vocabulary...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if there has been any research into the potential usage/existence of a visually self-aware system... not quite sure how to formalize this outside a half-baked idea... but let&amp;#39;s say:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A system (with or without human feedback) that generates something visually [a music visualizer, maybe].&lt;/li&gt;\n&lt;li&gt;A video camera watches the output on the screen, and this data stream as fed back into the system and utilized somehow [maybe a user-dependent reward function for current state].&lt;/li&gt;\n&lt;li&gt;... magic ...&lt;/li&gt;\n&lt;li&gt;Thus the system is aware of it&amp;#39;s own visual appearance!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Again, sorry for the lack of appropriate vocabulary -- I&amp;#39;m trying to dive headfirst into the possibilities of the field.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null,"author":"rpiguy","gilded":0,"permalink":"/r/MachineLearning/comments/10uipo/visually_selfaware_systems/","num_comments":3,"retrieved_on":1413527307,"link_flair_css_class":null,"selftext":"Hi -- sorry I didn't go to grad school so forgive any confusion of vocabulary...\n\nI'm wondering if there has been any research into the potential usage/existence of a visually self-aware system... not quite sure how to formalize this outside a half-baked idea... but let's say:\n\n- A system (with or without human feedback) that generates something visually [a music visualizer, maybe].\n- A video camera watches the output on the screen, and this data stream as fed back into the system and utilized somehow [maybe a user-dependent reward function for current state].\n- ... magic ...\n- Thus the system is aware of it's own visual appearance!\n\nAgain, sorry for the lack of appropriate vocabulary -- I'm trying to dive headfirst into the possibilities of the field.","author_flair_text":null,"score":1,"media":null,"subreddit_id":"t5_2r3gv","created_utc":1349224187,"report_reasons":null,"banned_by":null,"subreddit":"MachineLearning","mod_reports":[],"media_embed":{},"user_reports":[],"id":"10uipo","url":"http://www.reddit.com/r/MachineLearning/comments/10uipo/visually_selfaware_systems/","over_18":false,"is_self":true,"title":"Visually self-aware systems?","link_flair_text":null,"edited":false}
{"over_18":false,"media_embed":{},"mod_reports":[],"url":"http://packagingmachineries.blogspot.in/2012/10/nijranggroup-is-packaging-machinery.html","user_reports":[],"id":"10xeur","edited":false,"link_flair_text":null,"is_self":false,"title":"NijrangGroup is Packaging Machinery Manufacturers","selftext_html":null,"thumbnail":"default","stickied":false,"distinguished":null,"downs":0,"author_flair_css_class":null,"secure_media":null,"domain":"packagingmachineries.blogspot.in","secure_media_embed":{},"ups":1,"author_flair_text":null,"score":1,"selftext":"","link_flair_css_class":null,"subreddit":"MachineLearning","media":null,"report_reasons":null,"created_utc":1349340816,"banned_by":null,"subreddit_id":"t5_2r3gv","gilded":0,"permalink":"/r/MachineLearning/comments/10xeur/nijranggroup_is_packaging_machinery_manufacturers/","author":"nijrang","retrieved_on":1413523175,"num_comments":0}
{"id":"110ja0","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/110ja0/weka_get_the_total_number_of_errors_per_fold/","mod_reports":[],"media_embed":{},"over_18":false,"title":"Weka - get the total number of errors per fold","is_self":true,"edited":false,"link_flair_text":null,"secure_media_embed":{},"ups":4,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"downs":0,"distinguished":null,"stickied":false,"thumbnail":"default","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"http://stackoverflow.com/questions/12738658/why-does-wekas-experimenter-not-show-the-results-from-all-10-folds\"&gt;http://stackoverflow.com/questions/12738658/why-does-wekas-experimenter-not-show-the-results-from-all-10-folds&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I asked this question on StackOverflow and haven&amp;#39;t gotten an answer yet so I am expanding out here to see if someone can help me.&lt;/p&gt;\n\n&lt;p&gt;I am looking to see the number of inaccuracies classifications per fold in Weka.  In experimenter it is only showing me 6 of the 10 folds.  In explorer it gives me one long list that I&amp;#39;d really prefer to not manually count.&lt;/p&gt;\n\n&lt;p&gt;So how do I do this and why is it only giving me 6 of the 10 folds at the moment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","num_comments":5,"retrieved_on":1413518649,"gilded":0,"author":"[deleted]","permalink":"/r/MachineLearning/comments/110ja0/weka_get_the_total_number_of_errors_per_fold/","media":null,"created_utc":1349474244,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"http://stackoverflow.com/questions/12738658/why-does-wekas-experimenter-not-show-the-results-from-all-10-folds\n\nI asked this question on StackOverflow and haven't gotten an answer yet so I am expanding out here to see if someone can help me.\n\nI am looking to see the number of inaccuracies classifications per fold in Weka.  In experimenter it is only showing me 6 of the 10 folds.  In explorer it gives me one long list that I'd really prefer to not manually count.\n\nSo how do I do this and why is it only giving me 6 of the 10 folds at the moment?","author_flair_text":null,"score":4}
{"created_utc":1349402103,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"score":0,"author_flair_text":null,"num_comments":9,"retrieved_on":1413520952,"gilded":0,"author":"[deleted]","permalink":"/r/MachineLearning/comments/10yyuw/really_cool_machine_learning_job_at_dwave/","downs":0,"distinguished":null,"thumbnail":"default","stickied":false,"selftext_html":null,"ups":0,"secure_media_embed":{},"domain":"mitacs.ca","secure_media":null,"author_flair_css_class":null,"edited":false,"link_flair_text":null,"title":"Really cool machine learning job at D-wave.","is_self":false,"over_18":false,"user_reports":[],"id":"10yyuw","url":"https://www.mitacs.ca/o/2012/07/cognition-and-creativity-frameworks-engineer-dwave-systems-inc","mod_reports":[],"media_embed":{}}
{"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/111vlv/longtime_programmer_where_to_begin/","user_reports":[],"id":"111vlv","over_18":false,"is_self":true,"title":"Long-time programmer: Where to begin?","edited":false,"link_flair_text":null,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","secure_media_embed":{},"ups":24,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Preface: my apologies if this has already been asked on here (I searched for similar posts and couldn&amp;#39;t find anything really tackling it).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been programming for a number of years and feel fairly confident in my understanding of essential comp sci, as well as being able to understand and implement various algorithms. I&amp;#39;ve had a passing interest in machine learning for quite some time but I can&amp;#39;t seem to find a good place to start. I was looking through some of the stuff at &lt;em&gt;Quora&lt;/em&gt; but nothing there feels like &amp;quot;do this and you&amp;#39;ll start to understand machine learning or at least know where to go.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;So what I&amp;#39;m looking for is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What books/websites/resources would you suggest for getting started?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve seen R being talked about a lot, should I learn to use it?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m currently taking Calculus in college, should I learn any higher level math before continuing?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","stickied":false,"distinguished":null,"downs":0,"permalink":"/r/MachineLearning/comments/111vlv/longtime_programmer_where_to_begin/","gilded":0,"author":"Neurotrace","retrieved_on":1413516658,"num_comments":27,"author_flair_text":null,"score":24,"link_flair_css_class":null,"selftext":"Preface: my apologies if this has already been asked on here (I searched for similar posts and couldn't find anything really tackling it).\n\nI've been programming for a number of years and feel fairly confident in my understanding of essential comp sci, as well as being able to understand and implement various algorithms. I've had a passing interest in machine learning for quite some time but I can't seem to find a good place to start. I was looking through some of the stuff at *Quora* but nothing there feels like \"do this and you'll start to understand machine learning or at least know where to go.\"\n\nSo what I'm looking for is:\n\n* What books/websites/resources would you suggest for getting started?\n* I've seen R being talked about a lot, should I learn to use it?\n* I'm currently taking Calculus in college, should I learn any higher level math before continuing?","subreddit":"MachineLearning","media":null,"created_utc":1349548888,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv"}
{"distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I took Machine Learning course on Coursera. I&amp;#39;m trying to port some of my code to python. I&amp;#39;m specifically programming a 3 layer Neural Network. I realized that there is &lt;em&gt;scipy.optimize.fmin_bfgs&lt;/em&gt; function to do cost function optimization. But, I don&amp;#39;t how to use it? Here is my &lt;a href=\"http://stackoverflow.com/questions/12771441/scipy-optimize-usage\"&gt;question&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","ups":5,"secure_media_embed":{},"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"subreddit":"MachineLearning","created_utc":1349639522,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"score":5,"author_flair_text":null,"link_flair_css_class":null,"selftext":"I took Machine Learning course on Coursera. I'm trying to port some of my code to python. I'm specifically programming a 3 layer Neural Network. I realized that there is *scipy.optimize.fmin_bfgs* function to do cost function optimization. But, I don't how to use it? Here is my [question](http://stackoverflow.com/questions/12771441/scipy-optimize-usage).","retrieved_on":1413514007,"num_comments":15,"permalink":"/r/MachineLearning/comments/113mjw/using_scipyoptimize_to_optimize_a_cost_function/","gilded":0,"author":"leorahul16","over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/113mjw/using_scipyoptimize_to_optimize_a_cost_function/","id":"113mjw","user_reports":[],"media_embed":{},"mod_reports":[],"link_flair_text":null,"edited":false,"title":"using Scipy.optimize to optimize a cost function in Neural Network","is_self":true}
{"gilded":0,"permalink":"/r/MachineLearning/comments/113en3/how_would_you_build_a_system_for_recognizing/","author":"videoj","retrieved_on":1413514331,"num_comments":17,"score":9,"author_flair_text":null,"link_flair_css_class":null,"selftext":"Postage stamp collecting (/r/philately/) is a very popular hobby.  The hobby depends on several large paper catalogs issued to help collectors identify what they have.  But with over 1/2 million different major stamps issued over the last 170 years, and 1,000's more issued every year, identifying stamps is a time consuming task.\n\nSome of the issues faced are:\n\n1) Similar varieties that vary only by price and color, such as the [Machins](http://en.wikipedia.org/wiki/Machin_series) of the UK or [Washington-Franklin](http://en.wikipedia.org/wiki/Washington-Franklin_Issues) issues of the U.S.\n\n2) Cancellations, usually black, but sometimes other colors, can hide portions of the designs. \n\n3) Differences in the number of perforations (the holes between stamps used to  separate them) can indicate different issues.\n\n\nSo, /r/ml, how would you apply machine learning to this problem?   Assume you had access to clean, identified, copies of all the stamps you needed as a training set.","subreddit":"MachineLearning","created_utc":1349630878,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"ups":9,"secure_media_embed":{},"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Postage stamp collecting (&lt;a href=\"/r/philately/\"&gt;/r/philately/&lt;/a&gt;) is a very popular hobby.  The hobby depends on several large paper catalogs issued to help collectors identify what they have.  But with over 1/2 million different major stamps issued over the last 170 years, and 1,000&amp;#39;s more issued every year, identifying stamps is a time consuming task.&lt;/p&gt;\n\n&lt;p&gt;Some of the issues faced are:&lt;/p&gt;\n\n&lt;p&gt;1) Similar varieties that vary only by price and color, such as the &lt;a href=\"http://en.wikipedia.org/wiki/Machin_series\"&gt;Machins&lt;/a&gt; of the UK or &lt;a href=\"http://en.wikipedia.org/wiki/Washington-Franklin_Issues\"&gt;Washington-Franklin&lt;/a&gt; issues of the U.S.&lt;/p&gt;\n\n&lt;p&gt;2) Cancellations, usually black, but sometimes other colors, can hide portions of the designs. &lt;/p&gt;\n\n&lt;p&gt;3) Differences in the number of perforations (the holes between stamps used to  separate them) can indicate different issues.&lt;/p&gt;\n\n&lt;p&gt;So, &lt;a href=\"/r/ml\"&gt;/r/ml&lt;/a&gt;, how would you apply machine learning to this problem?   Assume you had access to clean, identified, copies of all the stamps you needed as a training set.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","distinguished":null,"downs":0,"is_self":true,"title":"How would you build a system for recognizing collectible postage stamps?","edited":false,"link_flair_text":null,"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/113en3/how_would_you_build_a_system_for_recognizing/","user_reports":[],"id":"113en3","over_18":false}
{"title":"Eigenfaces, linear algebra for face recognition: a well done tutorial with proofs and pictures.","is_self":false,"edited":false,"link_flair_text":null,"user_reports":[],"id":"112snv","url":"http://jeremykun.wordpress.com/2011/07/27/eigenfaces/","mod_reports":[],"media_embed":{},"over_18":false,"num_comments":1,"retrieved_on":1413515293,"permalink":"/r/MachineLearning/comments/112snv/eigenfaces_linear_algebra_for_face_recognition_a/","gilded":0,"author":"rrenaud","banned_by":null,"created_utc":1349587875,"subreddit_id":"t5_2r3gv","report_reasons":null,"media":null,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"","score":71,"author_flair_text":null,"ups":71,"secure_media_embed":{},"domain":"jeremykun.wordpress.com","secure_media":null,"author_flair_css_class":null,"downs":0,"distinguished":null,"stickied":false,"thumbnail":"http://b.thumbs.redditmedia.com/ayd7yAzzmr_-tID7.jpg","selftext_html":null}
{"num_comments":12,"retrieved_on":1413511194,"gilded":0,"author":"HAESatEverySize","permalink":"/r/MachineLearning/comments/115du1/trying_to_learn_svms/","banned_by":null,"created_utc":1349720382,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","selftext":"Good Day,\n\nI am trying to learn SVMs.  We went over them in class and I get the general idea of them.  But now I am trying to sit and learn the the math to actually learn the classifier.  \n\nDo you know of any good sources that teach SVMs?  Preferably ones with actual examples?\n\nThanks","link_flair_css_class":null,"score":9,"author_flair_text":null,"ups":9,"secure_media_embed":{},"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"downs":0,"distinguished":null,"stickied":false,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good Day,&lt;/p&gt;\n\n&lt;p&gt;I am trying to learn SVMs.  We went over them in class and I get the general idea of them.  But now I am trying to sit and learn the the math to actually learn the classifier.  &lt;/p&gt;\n\n&lt;p&gt;Do you know of any good sources that teach SVMs?  Preferably ones with actual examples?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","title":"Trying to learn SVMs","is_self":true,"link_flair_text":null,"edited":false,"user_reports":[],"id":"115du1","url":"http://www.reddit.com/r/MachineLearning/comments/115du1/trying_to_learn_svms/","mod_reports":[],"media_embed":{},"over_18":false}
{"over_18":false,"media_embed":{},"mod_reports":[],"url":"http://www.overkillanalytics.net/more-is-always-better-the-power-of-simple-ensembles/","id":"116z4j","user_reports":[],"edited":false,"link_flair_text":null,"is_self":false,"title":"More Is Always Better: The Power Of Simple Ensembles","selftext_html":null,"thumbnail":"http://c.thumbs.redditmedia.com/hagkY2wx_Hq9wQSJ.jpg","stickied":false,"distinguished":null,"downs":0,"author_flair_css_class":null,"domain":"overkillanalytics.net","secure_media":null,"ups":2,"secure_media_embed":{},"score":2,"author_flair_text":null,"selftext":"","link_flair_css_class":null,"subreddit":"MachineLearning","banned_by":null,"created_utc":1349787678,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"permalink":"/r/MachineLearning/comments/116z4j/more_is_always_better_the_power_of_simple/","gilded":0,"author":"ecsibleyjr","retrieved_on":1413508917,"num_comments":0}
{"secure_media_embed":{},"ups":8,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"downs":0,"distinguished":null,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some trouble understanding exactly how one should implement the structured perceptron for part-of-speech tagging. Could you please confirm or correct my thoughts, and/or fill in any gaps missing?&lt;/p&gt;\n\n&lt;p&gt;So, basically the structured perceptron is a variant of the multiclass perceptron, except for how you implement collecting the best score. A first-order Markov assumption is made, saying that the current sequence index only depends on the previous index. The input is an entire sequence of words, instead of just one word as would be in a non-structured case, as well as a vector of all possible labels (y). The function f(x,y) returns a guessed label sequence for the given word sequence.&lt;/p&gt;\n\n&lt;p&gt;In a multiclass perceptron, getting the best score is easily done through iteration since we only deal with classifying one label to one instance. The problem with classifying entire sequences is that it results in an exponential growth of the number of possible labelings. This is where the Viterbi algorithm is needed, which recursively finds the best path using two feature sets; one for determining how likely a given POS tag is to a certain word, and one for determining how likely a certain POS tag is coming directly after another POS tag. The score from each of these feature sets are multiplied with a unique weight for each state. If the chosen path is wrong, each weight in the states of the wrong path are punished, and the weights in the correct path are awarded.&lt;/p&gt;\n\n&lt;p&gt;This is about how far I have (hopefully) understood. My biggest questions right now is how the features are structured (is the previous tag sequence a part of the features?), and how to actually implement the Viterbi algorithm. Also, is there an implementation of a POS tagger using structured perceptron anywhere I could analyze (preferably in Java)?&lt;/p&gt;\n\n&lt;p&gt;I would be very grateful if you could give me some hints or resources to look into!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","num_comments":3,"retrieved_on":1413504527,"permalink":"/r/MachineLearning/comments/119x53/understanding_the_structured_perceptron_for_pos/","gilded":0,"author":"HerrKanin","media":null,"banned_by":null,"created_utc":1349906876,"report_reasons":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","selftext":"I have some trouble understanding exactly how one should implement the structured perceptron for part-of-speech tagging. Could you please confirm or correct my thoughts, and/or fill in any gaps missing?\n\nSo, basically the structured perceptron is a variant of the multiclass perceptron, except for how you implement collecting the best score. A first-order Markov assumption is made, saying that the current sequence index only depends on the previous index. The input is an entire sequence of words, instead of just one word as would be in a non-structured case, as well as a vector of all possible labels (y). The function f(x,y) returns a guessed label sequence for the given word sequence.\n\nIn a multiclass perceptron, getting the best score is easily done through iteration since we only deal with classifying one label to one instance. The problem with classifying entire sequences is that it results in an exponential growth of the number of possible labelings. This is where the Viterbi algorithm is needed, which recursively finds the best path using two feature sets; one for determining how likely a given POS tag is to a certain word, and one for determining how likely a certain POS tag is coming directly after another POS tag. The score from each of these feature sets are multiplied with a unique weight for each state. If the chosen path is wrong, each weight in the states of the wrong path are punished, and the weights in the correct path are awarded.\n\nThis is about how far I have (hopefully) understood. My biggest questions right now is how the features are structured (is the previous tag sequence a part of the features?), and how to actually implement the Viterbi algorithm. Also, is there an implementation of a POS tagger using structured perceptron anywhere I could analyze (preferably in Java)?\n\nI would be very grateful if you could give me some hints or resources to look into!","link_flair_css_class":null,"author_flair_text":null,"score":8,"id":"119x53","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/119x53/understanding_the_structured_perceptron_for_pos/","mod_reports":[],"media_embed":{},"over_18":false,"title":"Understanding the structured perceptron for POS tagging","is_self":true,"edited":false,"link_flair_text":null}
{"edited":false,"link_flair_text":null,"is_self":false,"title":"Machine Repairs Adelaide","over_18":false,"media_embed":{},"mod_reports":[],"url":"http://rushengineering.blog.com/2012/10/09/machine-repairs-adelaide/","user_reports":[],"id":"1190ca","score":1,"author_flair_text":null,"link_flair_css_class":null,"selftext":"","subreddit":"MachineLearning","created_utc":1349874947,"subreddit_id":"t5_2r3gv","banned_by":null,"report_reasons":null,"media":null,"permalink":"/r/MachineLearning/comments/1190ca/machine_repairs_adelaide/","gilded":0,"author":"jadewebber","retrieved_on":1413505856,"num_comments":1,"selftext_html":null,"stickied":false,"thumbnail":"default","distinguished":null,"downs":0,"author_flair_css_class":null,"domain":"rushengineering.blog.com","secure_media":null,"ups":1,"secure_media_embed":{}}
{"ups":3,"secure_media_embed":{},"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"downs":0,"distinguished":null,"stickied":false,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a project I was working on, I made a proof-of-concept text &lt;a href=\"https://github.com/oyiptong/pancake-smarts\"&gt;recommendation engine&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;However, my project got cancelled. That said, I had a lot of fun building it and would like to continue to work on it.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is something like that any useful to anyone else?&lt;/li&gt;\n&lt;li&gt;If so, in what disciplines would something like that be useful?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The basic idea is that documents that have similar &amp;quot;semantic&amp;quot; topic distributions would be similar.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s how it works:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I have implemented an application that will use Latent Dirichlet Allocation to create topic models from a given corpus of data&lt;/li&gt;\n&lt;li&gt;Subsequent document queries will have their topic distribution inferred and matched for similarity via Random Projections and Levenshtein distance&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can find an example running here: &lt;a href=\"http://174.129.217.121/smarts/query/hnlinks/\"&gt;http://174.129.217.121/smarts/query/hnlinks/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you go to hacker news, and pick a url for an article and enter it in the textbox, there is a chance similar content will show up.&lt;/p&gt;\n\n&lt;p&gt;EDIT: formatting&lt;/p&gt;\n\n&lt;p&gt;EDIT2: The training set hasn&amp;#39;t been picked for accuracy, so the recommendation results might be inaccurate unless its articles about education, startup fanboy pieces, nerd-shoe-gaze blog posts and articles about apple and google.&lt;/p&gt;\n\n&lt;p&gt;EDIT3: The demo server now runs on port 80!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","num_comments":5,"retrieved_on":1413501727,"author":"sayhello","permalink":"/r/MachineLearning/comments/11bty2/feedback_on_text_recommendation_engine/","gilded":0,"created_utc":1349987828,"report_reasons":null,"subreddit_id":"t5_2r3gv","banned_by":null,"media":null,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"For a project I was working on, I made a proof-of-concept text [recommendation engine](https://github.com/oyiptong/pancake-smarts)\n\nHowever, my project got cancelled. That said, I had a lot of fun building it and would like to continue to work on it.\n\n* Is something like that any useful to anyone else?\n* If so, in what disciplines would something like that be useful?\n\nThe basic idea is that documents that have similar \"semantic\" topic distributions would be similar.\n\nHere's how it works:\n\n* I have implemented an application that will use Latent Dirichlet Allocation to create topic models from a given corpus of data\n* Subsequent document queries will have their topic distribution inferred and matched for similarity via Random Projections and Levenshtein distance\n\nYou can find an example running here: http://174.129.217.121/smarts/query/hnlinks/\n\nIf you go to hacker news, and pick a url for an article and enter it in the textbox, there is a chance similar content will show up.\n\nEDIT: formatting\n\nEDIT2: The training set hasn't been picked for accuracy, so the recommendation results might be inaccurate unless its articles about education, startup fanboy pieces, nerd-shoe-gaze blog posts and articles about apple and google.\n\nEDIT3: The demo server now runs on port 80!","score":3,"author_flair_text":null,"user_reports":[],"id":"11bty2","url":"http://www.reddit.com/r/MachineLearning/comments/11bty2/feedback_on_text_recommendation_engine/","mod_reports":[],"media_embed":{},"over_18":false,"title":"Feedback on text recommendation engine","is_self":true,"edited":1350066466,"link_flair_text":null}
{"domain":"spectrum.ieee.org","secure_media":null,"author_flair_css_class":null,"ups":18,"secure_media_embed":{},"stickied":false,"thumbnail":"default","selftext_html":null,"downs":0,"distinguished":null,"author":"amair","permalink":"/r/MachineLearning/comments/11bl9i/article_deconstructing_recommender_systems/","gilded":0,"num_comments":1,"retrieved_on":1413502092,"selftext":"","link_flair_css_class":null,"score":18,"author_flair_text":null,"report_reasons":null,"created_utc":1349980132,"subreddit_id":"t5_2r3gv","banned_by":null,"media":null,"subreddit":"MachineLearning","mod_reports":[],"media_embed":{},"id":"11bl9i","user_reports":[],"url":"http://spectrum.ieee.org/computing/software/deconstructing-recommender-systems","over_18":false,"is_self":false,"title":"Article: Deconstructing Recommender Systems","edited":false,"link_flair_text":null}
{"thumbnail":"default","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"secure_media_embed":{},"ups":2,"link_flair_css_class":null,"selftext":"","author_flair_text":null,"score":2,"media":null,"created_utc":1349975292,"subreddit_id":"t5_2r3gv","banned_by":null,"report_reasons":null,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/11bfx3/design_project_using_sensors_bigdata_and_machine/","author":"reddit_quora","gilded":0,"num_comments":2,"retrieved_on":1413502312,"over_18":false,"mod_reports":[],"media_embed":{},"id":"11bfx3","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11bfx3/design_project_using_sensors_bigdata_and_machine/","edited":false,"link_flair_text":null,"is_self":true,"title":"Design project using sensors, bigdata and machine learning."}
{"media":null,"created_utc":1349966958,"banned_by":null,"subreddit_id":"t5_2r3gv","report_reasons":null,"subreddit":"MachineLearning","selftext":"Hello,\n\nHere is an interesting problem I have been thinking about - find a similarity metric over subreddits. E.g., from my subscribed subs, /r/bicycling and /r/motorcycles are closer to each other than either is to /r/machinelearning, which, in turn, is close to /r/maths and /r/programming.\n\nSo, the problem is to find a way to scan the content in the subs (possibly only post titles and maybe text of self posts) and come up with a model that posits a distance.\n\nThis seems like an unsupervised learning problem to me, possibly using something like a bag of words model. But I suppose the models can trained in a supervised manner as well, since most subreddits have a section for related subs in the sidebar. I'm hoping if people more experienced than myself can think of promising models to apply on this problem?\n\nApplications would be many - automatically recommending subreddits for a new post, suggesting related reddits to users and so on.\n\nbtw, I'm not planning to build it or anything right now, since I haven't really looked into which models would be best to use. Just a thought experiment for now.\n\nEdit: changed \"distance metric\" to \"similarity metric\", since the former is a content-free phrase.","link_flair_css_class":null,"author_flair_text":null,"score":6,"num_comments":16,"retrieved_on":1413502657,"gilded":0,"permalink":"/r/MachineLearning/comments/11b7br/learning_the_structure_of_reddit/","author":"ohell","downs":0,"distinguished":null,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Here is an interesting problem I have been thinking about - find a similarity metric over subreddits. E.g., from my subscribed subs, &lt;a href=\"/r/bicycling\"&gt;/r/bicycling&lt;/a&gt; and &lt;a href=\"/r/motorcycles\"&gt;/r/motorcycles&lt;/a&gt; are closer to each other than either is to &lt;a href=\"/r/machinelearning\"&gt;/r/machinelearning&lt;/a&gt;, which, in turn, is close to &lt;a href=\"/r/maths\"&gt;/r/maths&lt;/a&gt; and &lt;a href=\"/r/programming\"&gt;/r/programming&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;So, the problem is to find a way to scan the content in the subs (possibly only post titles and maybe text of self posts) and come up with a model that posits a distance.&lt;/p&gt;\n\n&lt;p&gt;This seems like an unsupervised learning problem to me, possibly using something like a bag of words model. But I suppose the models can trained in a supervised manner as well, since most subreddits have a section for related subs in the sidebar. I&amp;#39;m hoping if people more experienced than myself can think of promising models to apply on this problem?&lt;/p&gt;\n\n&lt;p&gt;Applications would be many - automatically recommending subreddits for a new post, suggesting related reddits to users and so on.&lt;/p&gt;\n\n&lt;p&gt;btw, I&amp;#39;m not planning to build it or anything right now, since I haven&amp;#39;t really looked into which models would be best to use. Just a thought experiment for now.&lt;/p&gt;\n\n&lt;p&gt;Edit: changed &amp;quot;distance metric&amp;quot; to &amp;quot;similarity metric&amp;quot;, since the former is a content-free phrase.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","secure_media_embed":{},"ups":6,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"edited":1350040941,"link_flair_text":null,"title":"Learning the structure of reddit?","is_self":true,"over_18":false,"id":"11b7br","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11b7br/learning_the_structure_of_reddit/","mod_reports":[],"media_embed":{}}
{"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11b5y1/question_on_using_em_algorithm_for_linear/","user_reports":[],"id":"11b5y1","over_18":false,"is_self":true,"title":"Question on using EM algorithm for linear regression and GMM assumption.","edited":false,"link_flair_text":null,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","secure_media_embed":{},"ups":4,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data set which are a mixture of K different Gaussian components. They consist of input data $X \\in R&lt;sup&gt;{mxN}$&lt;/sup&gt; and $Y \\in R&lt;sup&gt;{nxN}$.&lt;/sup&gt; I have to find the regression coefficient (M) for each components, where\nY = M * X + E,\nE is the noise part. Also I have to calculate variance of E.\nI googled that but no success! I am strongly looking for some helps or references.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","distinguished":null,"downs":0,"gilded":0,"permalink":"/r/MachineLearning/comments/11b5y1/question_on_using_em_algorithm_for_linear/","author":"gholfali","retrieved_on":1413502708,"num_comments":4,"author_flair_text":null,"score":4,"link_flair_css_class":null,"selftext":"I have a data set which are a mixture of K different Gaussian components. They consist of input data $X \\in R^{mxN}$ and $Y \\in R^{nxN}$. I have to find the regression coefficient (M) for each components, where\nY = M * X + E,\nE is the noise part. Also I have to calculate variance of E.\nI googled that but no success! I am strongly looking for some helps or references.\n","subreddit":"MachineLearning","media":null,"created_utc":1349965391,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv"}
{"ups":15,"secure_media_embed":{},"domain":"arek-paterek.com","secure_media":null,"author_flair_css_class":null,"downs":0,"distinguished":null,"thumbnail":"http://b.thumbs.redditmedia.com/n0csf-dshWh-Ddy7.jpg","stickied":false,"selftext_html":null,"num_comments":20,"retrieved_on":1413503156,"gilded":0,"permalink":"/r/MachineLearning/comments/11audd/ebook_on_the_netflix_prize_recommender_systems/","author":"arek1337","created_utc":1349944324,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"score":15,"author_flair_text":null,"user_reports":[],"id":"11audd","url":"http://arek-paterek.com/book/","mod_reports":[],"media_embed":{},"over_18":false,"title":"E-book on the Netflix Prize, recommender systems, and machine learning in general","is_self":false,"edited":false,"link_flair_text":null}
{"title":"E-book on the Netflix Prize, recommender systems, and machine learning in general","is_self":false,"edited":false,"link_flair_text":null,"id":"11atyx","user_reports":[],"url":"http://arek-paterek/book/","mod_reports":[],"media_embed":{},"over_18":false,"num_comments":0,"retrieved_on":1413503171,"author":"[deleted]","permalink":"/r/MachineLearning/comments/11atyx/ebook_on_the_netflix_prize_recommender_systems/","gilded":0,"media":null,"banned_by":null,"created_utc":1349943303,"report_reasons":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"author_flair_text":null,"score":1,"secure_media_embed":{},"ups":1,"secure_media":null,"domain":"arek-paterek","author_flair_css_class":null,"downs":0,"distinguished":null,"thumbnail":"default","stickied":false,"selftext_html":null}
{"ups":14,"secure_media_embed":{},"author_flair_css_class":null,"domain":"blog.kaggle.com","secure_media":null,"distinguished":null,"downs":0,"selftext_html":null,"thumbnail":"http://a.thumbs.redditmedia.com/dH0bYbbNBvTkfhFf.jpg","stickied":false,"retrieved_on":1413499156,"num_comments":2,"permalink":"/r/MachineLearning/comments/11dis8/competitive_astronomy_crowdsourcing_the_universe/","gilded":0,"author":"willis77","subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","created_utc":1350063864,"report_reasons":null,"banned_by":null,"media":null,"score":14,"author_flair_text":null,"link_flair_css_class":null,"selftext":"","url":"http://blog.kaggle.com/2012/10/08/competitive-astronomy-crowd-sourcing-the-universe/","user_reports":[],"id":"11dis8","media_embed":{},"mod_reports":[],"over_18":false,"title":"Competitive Astronomy: Crowdsourcing the Universe","is_self":false,"edited":false,"link_flair_text":null}
{"created_utc":1350054328,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"","score":1,"author_flair_text":null,"num_comments":0,"retrieved_on":1413499556,"permalink":"/r/MachineLearning/comments/11d95g/machine_learning_for_your_robotic_army_an/","gilded":0,"author":"smerity","downs":0,"distinguished":null,"stickied":false,"thumbnail":"http://a.thumbs.redditmedia.com/aSpD5Zau2SAnam_N.jpg","selftext_html":null,"ups":1,"secure_media_embed":{},"domain":"smerity.com","secure_media":null,"author_flair_css_class":null,"edited":false,"link_flair_text":null,"title":"Machine Learning for your Robotic Army: An Intuitive Introduction","is_self":false,"over_18":false,"user_reports":[],"id":"11d95g","url":"http://smerity.com/media/talks/ml_for_your_robotic_army/template.html","mod_reports":[],"media_embed":{}}
{"over_18":false,"url":"http://www.leonpalafox.com/home/booklist","user_reports":[],"id":"11cdll","media_embed":{},"mod_reports":[],"edited":false,"link_flair_text":null,"title":"I have the objective of creating the most comprehensive and intuitive ML book list to date, please suggest new titles.","is_self":false,"distinguished":null,"downs":0,"selftext_html":null,"stickied":false,"thumbnail":"http://d.thumbs.redditmedia.com/Zz0agAcZeyLtd_So.jpg","secure_media_embed":{},"ups":33,"author_flair_css_class":null,"secure_media":null,"domain":"leonpalafox.com","subreddit":"MachineLearning","media":null,"created_utc":1350006559,"banned_by":null,"subreddit_id":"t5_2r3gv","report_reasons":null,"author_flair_text":null,"score":33,"selftext":"","link_flair_css_class":null,"retrieved_on":1413500902,"num_comments":20,"author":"leonoel","gilded":0,"permalink":"/r/MachineLearning/comments/11cdll/i_have_the_objective_of_creating_the_most/"}
{"author":"[deleted]","permalink":"/r/MachineLearning/comments/11euno/project_subjects/","gilded":0,"num_comments":0,"retrieved_on":1413497149,"selftext":"Hi, I'm currently taking a ML course and in two weeks we'll have to start a project. We can suggest a subject for the project ourselves. We have about five weeks to do this project with max 3 people. I like working with text (social media), like a simple naive bayes implementation... I was wondering if any of you might have a doable, cool idea for a ML project idea that can be done in 5 weeks by max 3 people.","link_flair_css_class":null,"author_flair_text":null,"score":1,"media":null,"report_reasons":null,"created_utc":1350132533,"banned_by":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"secure_media_embed":{},"ups":1,"stickied":false,"thumbnail":"default","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m currently taking a ML course and in two weeks we&amp;#39;ll have to start a project. We can suggest a subject for the project ourselves. We have about five weeks to do this project with max 3 people. I like working with text (social media), like a simple naive bayes implementation... I was wondering if any of you might have a doable, cool idea for a ML project idea that can be done in 5 weeks by max 3 people.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null,"is_self":true,"title":"Project subjects","edited":false,"link_flair_text":null,"mod_reports":[],"media_embed":{},"id":"11euno","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11euno/project_subjects/","over_18":false}
{"media":null,"banned_by":null,"created_utc":1350240598,"report_reasons":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"","author_flair_text":null,"score":0,"num_comments":4,"retrieved_on":1413494062,"permalink":"/r/MachineLearning/comments/11gyko/regarding_prediction_using_onevsall/","gilded":0,"author":"bge0","downs":0,"distinguished":null,"thumbnail":"default","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","secure_media_embed":{},"ups":0,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"edited":1350246064,"link_flair_text":null,"title":"Regarding Prediction using oneVsAll","is_self":true,"over_18":false,"user_reports":[],"id":"11gyko","url":"http://www.reddit.com/r/MachineLearning/comments/11gyko/regarding_prediction_using_onevsall/","mod_reports":[],"media_embed":{}}
{"over_18":false,"user_reports":[],"id":"11jaud","url":"http://zinkov.com/posts/2012-10-04-ml-book-reviews/","mod_reports":[],"media_embed":{},"link_flair_text":null,"edited":false,"title":"Mini reviews of 10 popular books on Machine Learning","is_self":false,"downs":0,"distinguished":null,"thumbnail":"http://d.thumbs.redditmedia.com/Zz0agAcZeyLtd_So.jpg","stickied":false,"selftext_html":null,"ups":27,"secure_media_embed":{},"domain":"zinkov.com","secure_media":null,"author_flair_css_class":null,"banned_by":null,"created_utc":1350340008,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"score":27,"author_flair_text":null,"num_comments":9,"retrieved_on":1413490580,"gilded":0,"permalink":"/r/MachineLearning/comments/11jaud/mini_reviews_of_10_popular_books_on_machine/","author":"rrenaud"}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At my job, I have years of customer, sales, and demographic data. I&amp;#39;d like to explore options for mining and visualizing this data. Who buys X product but not Y product? Are our products in discrete groups that tend to be purchased together but with little overlap? Does AB marketing message work in one county, while XY marketing message works better in another?&lt;/p&gt;\n\n&lt;p&gt;I want to become an expert in answering these kinds of questions. What software should I use for this? What software does, say, Nate Silver use for his computations? I&amp;#39;m willing to invest time and money to learn, but I don&amp;#39;t know where to start.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","distinguished":null,"downs":0,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","secure_media_embed":{},"ups":28,"author_flair_text":null,"score":28,"link_flair_css_class":null,"selftext":"At my job, I have years of customer, sales, and demographic data. I'd like to explore options for mining and visualizing this data. Who buys X product but not Y product? Are our products in discrete groups that tend to be purchased together but with little overlap? Does AB marketing message work in one county, while XY marketing message works better in another?\n\nI want to become an expert in answering these kinds of questions. What software should I use for this? What software does, say, Nate Silver use for his computations? I'm willing to invest time and money to learn, but I don't know where to start.","subreddit":"MachineLearning","media":null,"created_utc":1350308363,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","gilded":0,"permalink":"/r/MachineLearning/comments/11idgy/what_dataminingmachinelearning_software_should_i/","author":"ashuttl","retrieved_on":1413491929,"num_comments":45,"over_18":false,"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11idgy/what_dataminingmachinelearning_software_should_i/","id":"11idgy","user_reports":[],"edited":1350327499,"link_flair_text":null,"is_self":true,"title":"What data-mining/machine-learning software should I invest in learning?"}
{"edited":false,"link_flair_text":null,"is_self":true,"title":"What fields/jobs use machine/statistical learning on a daily basis?","over_18":false,"mod_reports":[],"media_embed":{},"id":"11hqxu","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11hqxu/what_fieldsjobs_use_machinestatistical_learning/","selftext":"I know machine learning algorithms (although perhaps not under that name) are used in speech/image processing, computational biology, quantitative finance, marketing, and astrophysics (according to a recent /MachineLearning post). I am wondering what other fields you can expect to find people using similar techniques as an integral part of their daily work? \n\n(I am a master's electrical engineering student studying digital signal processing and considering work in fields utilizing statistical learning.) ","link_flair_css_class":null,"score":8,"author_flair_text":null,"created_utc":1350269025,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","author":"[deleted]","gilded":0,"permalink":"/r/MachineLearning/comments/11hqxu/what_fieldsjobs_use_machinestatistical_learning/","num_comments":10,"retrieved_on":1413492860,"stickied":false,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know machine learning algorithms (although perhaps not under that name) are used in speech/image processing, computational biology, quantitative finance, marketing, and astrophysics (according to a recent /MachineLearning post). I am wondering what other fields you can expect to find people using similar techniques as an integral part of their daily work? &lt;/p&gt;\n\n&lt;p&gt;(I am a master&amp;#39;s electrical engineering student studying digital signal processing and considering work in fields utilizing statistical learning.) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null,"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"ups":8,"secure_media_embed":{}}
{"is_self":false,"title":"R at 12,000 Cores!","edited":false,"link_flair_text":null,"media_embed":{},"mod_reports":[],"url":"http://www.r-bloggers.com/r-at-12000-cores/","user_reports":[],"id":"11lhlp","over_18":false,"permalink":"/r/MachineLearning/comments/11lhlp/r_at_12000_cores/","gilded":0,"author":"talgalili","retrieved_on":1413487408,"num_comments":6,"score":22,"author_flair_text":null,"link_flair_css_class":null,"selftext":"","subreddit":"MachineLearning","created_utc":1350428167,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"author_flair_css_class":null,"domain":"r-bloggers.com","secure_media":null,"ups":22,"secure_media_embed":{},"selftext_html":null,"stickied":false,"thumbnail":"http://a.thumbs.redditmedia.com/4gzcFpWHg-eBcR10.jpg","distinguished":null,"downs":0}
{"downs":0,"distinguished":null,"stickied":false,"thumbnail":"default","selftext_html":null,"secure_media_embed":{},"ups":1,"secure_media":null,"domain":"r-bloggers.com","author_flair_css_class":null,"media":null,"report_reasons":null,"created_utc":1350428114,"subreddit_id":"t5_2r3gv","banned_by":null,"subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"author_flair_text":null,"score":1,"num_comments":0,"retrieved_on":1413487410,"author":"[deleted]","permalink":"/r/MachineLearning/comments/11lhjn/r_at_12000_cores/","gilded":0,"over_18":false,"id":"11lhjn","user_reports":[],"url":"http://www.r-bloggers.com/r-at-12000-cores/","mod_reports":[],"media_embed":{},"edited":false,"link_flair_text":null,"title":"R at 12,000 Cores!","is_self":false}
{"over_18":false,"id":"11kyvz","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11kyvz/machine_learning_prerequisites/","mod_reports":[],"media_embed":{},"edited":false,"link_flair_text":null,"title":"Machine Learning Prerequisites","is_self":true,"downs":0,"distinguished":null,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;ve decided to take advantage of the wealth of online materials and learn the basics of machine learning. I&amp;#39;m a self-taught computer programmer who went to art school, and the last math class I took was Algebra II/Trig in high school. So my question is, what are the maths I should study before getting into ML? From what I can gather, I&amp;#39;ll need calculus, probability, and some kind of statistics -- but I&amp;#39;d like to hear from people who know :) Time is not an issue, I want to make sure I have the proper foundation so I can learn the topic well. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","secure_media_embed":{},"ups":15,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"media":null,"banned_by":null,"created_utc":1350411840,"report_reasons":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"Hello, I've decided to take advantage of the wealth of online materials and learn the basics of machine learning. I'm a self-taught computer programmer who went to art school, and the last math class I took was Algebra II/Trig in high school. So my question is, what are the maths I should study before getting into ML? From what I can gather, I'll need calculus, probability, and some kind of statistics -- but I'd like to hear from people who know :) Time is not an issue, I want to make sure I have the proper foundation so I can learn the topic well. Thanks!","author_flair_text":null,"score":15,"num_comments":23,"retrieved_on":1413488157,"author":"whism","gilded":0,"permalink":"/r/MachineLearning/comments/11kyvz/machine_learning_prerequisites/"}
{"title":"Can somebody \"explain like I am 5\", to me the \"no free lunch theorem for supervised machine learning\"?","is_self":true,"link_flair_text":null,"edited":false,"user_reports":[],"id":"11kegx","url":"http://www.reddit.com/r/MachineLearning/comments/11kegx/can_somebody_explain_like_i_am_5_to_me_the_no/","mod_reports":[],"media_embed":{},"over_18":false,"num_comments":45,"retrieved_on":1413488975,"author":"SunnyJapan","gilded":0,"permalink":"/r/MachineLearning/comments/11kegx/can_somebody_explain_like_i_am_5_to_me_the_no/","banned_by":null,"created_utc":1350389594,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"","score":25,"author_flair_text":null,"ups":25,"secure_media_embed":{},"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"downs":0,"distinguished":null,"stickied":false,"thumbnail":"self","selftext_html":null}
{"distinguished":null,"downs":0,"selftext_html":null,"thumbnail":"default","stickied":false,"ups":1,"secure_media_embed":{},"author_flair_css_class":null,"domain":"reddit.com","secure_media":null,"subreddit":"MachineLearning","created_utc":1350504103,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"score":1,"author_flair_text":null,"selftext":"","link_flair_css_class":null,"retrieved_on":1413484658,"num_comments":0,"author":"[deleted]","gilded":0,"permalink":"/r/MachineLearning/comments/11nbgv/david_wolpert_responds_to_question_about_no_free/","over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/11kegx/can_somebody_explain_like_i_am_5_to_me_the_no/c6nwx8u","user_reports":[],"id":"11nbgv","media_embed":{},"mod_reports":[],"edited":false,"link_flair_text":null,"title":"David Wolpert responds to question about No Free Lunch","is_self":false}
{"edited":false,"link_flair_text":null,"title":"How to measure the accuracy of a certain k-means implementation on a certain data set?","is_self":true,"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/11n409/how_to_measure_the_accuracy_of_a_certain_kmeans/","id":"11n409","user_reports":[],"media_embed":{},"mod_reports":[],"subreddit":"MachineLearning","banned_by":null,"created_utc":1350497622,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"score":3,"author_flair_text":null,"link_flair_css_class":null,"selftext":"I've got a k-means implementation, and wondering how can I measure it's effectiveness on my data set.\n\n\nThe details:\n\nMy sample data is from a 12-96 dimension space, have about 1000-100000 samples at every run. The data is not well separated, but outliers can occur.\n\nI use the following initialization:\nI run the k-means N times on different subsamples, and cluster my k*N results with single linkage. I use the means of these clusters as my initial seed. (N is about 10, and the subsamples are the size of my original samples divided by N. I use different subset every time.)\nThis is the initialization method suggested by Arai and Barakbah:\nhttps://portal.dl.saga-u.ac.jp:8443/bitstream/123456789/54922/1/ZR00005460.pdf\nWith the modification of not using the whole sample set for the initialization. (If you have another recommendation, please let me know. I use this because its low memory consumption and I have good control over the calculation time.)","retrieved_on":1413484978,"num_comments":1,"permalink":"/r/MachineLearning/comments/11n409/how_to_measure_the_accuracy_of_a_certain_kmeans/","gilded":0,"author":"mikabast","distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a k-means implementation, and wondering how can I measure it&amp;#39;s effectiveness on my data set.&lt;/p&gt;\n\n&lt;p&gt;The details:&lt;/p&gt;\n\n&lt;p&gt;My sample data is from a 12-96 dimension space, have about 1000-100000 samples at every run. The data is not well separated, but outliers can occur.&lt;/p&gt;\n\n&lt;p&gt;I use the following initialization:\nI run the k-means N times on different subsamples, and cluster my k*N results with single linkage. I use the means of these clusters as my initial seed. (N is about 10, and the subsamples are the size of my original samples divided by N. I use different subset every time.)\nThis is the initialization method suggested by Arai and Barakbah:\n&lt;a href=\"https://portal.dl.saga-u.ac.jp:8443/bitstream/123456789/54922/1/ZR00005460.pdf\"&gt;https://portal.dl.saga-u.ac.jp:8443/bitstream/123456789/54922/1/ZR00005460.pdf&lt;/a&gt;\nWith the modification of not using the whole sample set for the initialization. (If you have another recommendation, please let me know. I use this because its low memory consumption and I have good control over the calculation time.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","stickied":false,"ups":3,"secure_media_embed":{},"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null}
{"author":"arauhala","gilded":0,"permalink":"/r/MachineLearning/comments/11mepe/story_of_reinventing_machine_learning_as_language/","num_comments":2,"retrieved_on":1413486085,"selftext":"","link_flair_css_class":null,"author_flair_text":null,"score":0,"media":null,"created_utc":1350464553,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","secure_media":null,"domain":"blog.futurice.com","author_flair_css_class":null,"secure_media_embed":{},"ups":0,"stickied":false,"thumbnail":"http://d.thumbs.redditmedia.com/yytAnmOd0gOcxbm-.jpg","selftext_html":null,"downs":0,"distinguished":null,"is_self":false,"title":"Story of reinventing machine learning as language learning","edited":false,"link_flair_text":null,"mod_reports":[],"media_embed":{},"user_reports":[],"id":"11mepe","url":"http://blog.futurice.com/how-to-solve-the-unsolvable-a-learning-story","over_18":false}
{"over_18":false,"url":"http://horicky.blogspot.com/2012/02/characteristics-of-machine-learning.html","id":"11lqeb","user_reports":[],"media_embed":{},"mod_reports":[],"link_flair_text":null,"edited":false,"title":"Comparison of different machine learning models.","is_self":false,"distinguished":null,"downs":0,"selftext_html":null,"thumbnail":"http://c.thumbs.redditmedia.com/0JtXs6gx3N_Y_stJ.jpg","stickied":false,"ups":0,"secure_media_embed":{},"author_flair_css_class":null,"domain":"horicky.blogspot.com","secure_media":null,"subreddit":"MachineLearning","banned_by":null,"created_utc":1350436063,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"score":0,"author_flair_text":null,"selftext":"","link_flair_css_class":null,"retrieved_on":1413487063,"num_comments":0,"author":"qkdhfjdjdhd","gilded":0,"permalink":"/r/MachineLearning/comments/11lqeb/comparison_of_different_machine_learning_models/"}
{"downs":0,"distinguished":null,"stickied":false,"thumbnail":"http://f.thumbs.redditmedia.com/etPVaCgQBhv8P_WA.jpg","selftext_html":null,"ups":27,"secure_media_embed":{},"domain":"mathbabe.org","secure_media":null,"author_flair_css_class":null,"created_utc":1350586497,"report_reasons":null,"subreddit_id":"t5_2r3gv","banned_by":null,"media":null,"subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"score":27,"author_flair_text":null,"num_comments":0,"retrieved_on":1413481737,"gilded":0,"author":"rrenaud","permalink":"/r/MachineLearning/comments/11pbz4/data_science_course_notes_on_lecture_by_cto_of/","over_18":false,"user_reports":[],"id":"11pbz4","url":"http://mathbabe.org/2012/10/18/columbia-data-science-course-week-7-hunch-com-recommendation-engines-svd-alternating-least-squares-convexity-filter-bubbles/","mod_reports":[],"media_embed":{},"edited":false,"link_flair_text":null,"title":"Data science course notes on lecture by CTO of Hunch.com about recommendation engines and SVD","is_self":false}
{"title":"[PDF] Bayesian Reasoning and Machine Learning by David Barber","is_self":false,"link_flair_text":null,"edited":false,"url":"http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf","id":"11ofk8","user_reports":[],"media_embed":{},"mod_reports":[],"over_18":false,"retrieved_on":1413483074,"num_comments":2,"gilded":0,"permalink":"/r/MachineLearning/comments/11ofk8/pdf_bayesian_reasoning_and_machine_learning_by/","author":"LADataJunkie","subreddit":"MachineLearning","media":null,"report_reasons":null,"created_utc":1350542683,"banned_by":null,"subreddit_id":"t5_2r3gv","author_flair_text":null,"score":29,"selftext":"","link_flair_css_class":null,"secure_media_embed":{},"ups":29,"author_flair_css_class":null,"secure_media":null,"domain":"web4.cs.ucl.ac.uk","distinguished":null,"downs":0,"selftext_html":null,"stickied":false,"thumbnail":"default"}
{"downs":0,"distinguished":null,"stickied":false,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Keep hearing about sites like amazon using dynamic pricing to change prices based on real time demand, and there are sites like &lt;a href=\"https://ventata.com/\"&gt;this&lt;/a&gt; and &lt;a href=\"http://wisepricer.com/\"&gt;this&lt;/a&gt; offering it as a service. Does anyone have any experience and can shed some light on how they work? Does learning &amp;amp; prediction play a significant part (if so how)? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","secure_media_embed":{},"ups":1,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"media":null,"created_utc":1350671863,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"Keep hearing about sites like amazon using dynamic pricing to change prices based on real time demand, and there are sites like [this](https://ventata.com/) and [this](http://wisepricer.com/) offering it as a service. Does anyone have any experience and can shed some light on how they work? Does learning &amp; prediction play a significant part (if so how)? ","author_flair_text":null,"score":1,"num_comments":0,"retrieved_on":1413478751,"author":"stevestoe","gilded":0,"permalink":"/r/MachineLearning/comments/11rduk/machine_learning_and_dynamic_pricing_how_does_it/","over_18":false,"id":"11rduk","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11rduk/machine_learning_and_dynamic_pricing_how_does_it/","mod_reports":[],"media_embed":{},"edited":false,"link_flair_text":null,"title":"Machine Learning and Dynamic Pricing? How does it work?","is_self":true}
{"subreddit":"MachineLearning","report_reasons":null,"created_utc":1350668114,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"score":0,"author_flair_text":null,"selftext":"","link_flair_css_class":null,"retrieved_on":1413478922,"num_comments":0,"gilded":0,"author":"iospakistan","permalink":"/r/MachineLearning/comments/11r9l4/ghost_in_the_machine_how_every_computer_is_unique/","distinguished":null,"downs":0,"selftext_html":null,"thumbnail":"default","stickied":false,"ups":0,"secure_media_embed":{},"author_flair_css_class":null,"domain":"iospakistan.com","secure_media":null,"edited":false,"link_flair_text":null,"title":"Ghost in the Machine, How every Computer is unique ","is_self":false,"over_18":false,"url":"http://www.iospakistan.com/ghost-in-the-machine-how-every-computer-is-unique/","id":"11r9l4","user_reports":[],"media_embed":{},"mod_reports":[]}
{"over_18":false,"id":"11r3y3","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11r3y3/job_opening_for_a_creative_dataanalysis_job_at/","mod_reports":[],"media_embed":{},"edited":false,"link_flair_text":null,"title":"Job opening for a creative data-analysis job at Lincoln Center in New York","is_self":true,"downs":0,"distinguished":null,"thumbnail":"default","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone lives in New York or knows someone who does, we’re hiring for a data-analysis position at Lincoln Center. Here’s &lt;a href=\"http://about.lincolncenter.org/about/employment/full-time/direct-marketing-manager\"&gt;the job listing itself&lt;/a&gt; and &lt;a href=\"http://ashuttleworth.com/2012/10/wanted-data-mining-geek/\"&gt;a little more information about the job&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","secure_media_embed":{},"ups":1,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"media":null,"created_utc":1350662890,"report_reasons":null,"subreddit_id":"t5_2r3gv","banned_by":null,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"If anyone lives in New York or knows someone who does, we’re hiring for a data-analysis position at Lincoln Center. Here’s [the job listing itself](http://about.lincolncenter.org/about/employment/full-time/direct-marketing-manager) and [a little more information about the job](http://ashuttleworth.com/2012/10/wanted-data-mining-geek/).","author_flair_text":null,"score":1,"num_comments":0,"retrieved_on":1413479155,"permalink":"/r/MachineLearning/comments/11r3y3/job_opening_for_a_creative_dataanalysis_job_at/","author":"[deleted]","gilded":0}
{"title":"Job opening at Lincoln Center in New York for a data-mining geek","is_self":false,"edited":false,"link_flair_text":null,"id":"11qx3a","user_reports":[],"url":"http://ashuttleworth.com/2012/10/wanted-data-mining-geek/","mod_reports":[],"media_embed":{},"over_18":false,"num_comments":0,"retrieved_on":1413479429,"author":"[deleted]","gilded":0,"permalink":"/r/MachineLearning/comments/11qx3a/job_opening_at_lincoln_center_in_new_york_for_a/","media":null,"subreddit_id":"t5_2r3gv","created_utc":1350656065,"report_reasons":null,"banned_by":null,"subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"author_flair_text":null,"score":1,"secure_media_embed":{},"ups":1,"secure_media":null,"domain":"ashuttleworth.com","author_flair_css_class":null,"downs":0,"distinguished":null,"stickied":false,"thumbnail":"default","selftext_html":null}
{"title":"FTC Challenges Innovators to Do Battle with Robocallers","is_self":false,"edited":false,"link_flair_text":null,"url":"http://www.ftc.gov/opa/2012/10/robocalls3.shtm","user_reports":[],"id":"11qflo","media_embed":{},"mod_reports":[],"over_18":false,"retrieved_on":1413480105,"num_comments":9,"permalink":"/r/MachineLearning/comments/11qflo/ftc_challenges_innovators_to_do_battle_with/","gilded":0,"author":"Derpscientist","subreddit":"MachineLearning","media":null,"created_utc":1350624010,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","author_flair_text":null,"score":16,"link_flair_css_class":null,"selftext":"","secure_media_embed":{},"ups":16,"author_flair_css_class":null,"secure_media":null,"domain":"ftc.gov","distinguished":null,"downs":0,"selftext_html":null,"stickied":false,"thumbnail":"http://b.thumbs.redditmedia.com/6ckznQqlqannuYMC.jpg"}
{"is_self":true,"title":"Neyman Pearson with a non parametric model questions","edited":false,"link_flair_text":null,"mod_reports":[],"media_embed":{},"id":"11qa54","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11qa54/neyman_pearson_with_a_non_parametric_model/","over_18":false,"gilded":0,"author":"duckandcover","permalink":"/r/MachineLearning/comments/11qa54/neyman_pearson_with_a_non_parametric_model/","num_comments":0,"retrieved_on":1413480329,"link_flair_css_class":null,"selftext":"I know that NP is optimal but as I understand it, that's with respect to the underlying density function and not some sample drawn from it.  If there is no model, than doing NP apparently corresponds to a something like a brute force search trying all combinations of the parameters (which implies imposing some discretization on continuous ones) and the finding the best best pD for each pFA.  This, in my mind, raises two questions\n\n1) Given some finite data set it may very well be that there may be pFA which are unique though many may be very close.  I imagine that this is handled by binning (e.g. all pFAs rounded to the nearest 0.05 - like a histogram)\nRight?\n\n2) Can NP overfit?  I know it's optimal for the exact underlying densities but how does sampling affect that?   If what I wrote above is correct, than the number of combinations of parameters can be ungodly (10 levels of 10 parameters ==&gt; 10^10).  It's not doing a fitting in the standard machine learning paradigm sense but I would think that as the parameter discretization increases the finer mesh will yield a higher fractional error per bin(like shot noise).\nIn any event, I have no idea how to compare this to a standard classifier (be it boosted trees, svm, etc)","author_flair_text":null,"score":1,"media":null,"created_utc":1350617752,"report_reasons":null,"subreddit_id":"t5_2r3gv","banned_by":null,"subreddit":"MachineLearning","secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"secure_media_embed":{},"ups":1,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that NP is optimal but as I understand it, that&amp;#39;s with respect to the underlying density function and not some sample drawn from it.  If there is no model, than doing NP apparently corresponds to a something like a brute force search trying all combinations of the parameters (which implies imposing some discretization on continuous ones) and the finding the best best pD for each pFA.  This, in my mind, raises two questions&lt;/p&gt;\n\n&lt;p&gt;1) Given some finite data set it may very well be that there may be pFA which are unique though many may be very close.  I imagine that this is handled by binning (e.g. all pFAs rounded to the nearest 0.05 - like a histogram)\nRight?&lt;/p&gt;\n\n&lt;p&gt;2) Can NP overfit?  I know it&amp;#39;s optimal for the exact underlying densities but how does sampling affect that?   If what I wrote above is correct, than the number of combinations of parameters can be ungodly (10 levels of 10 parameters ==&amp;gt; 10&lt;sup&gt;10).&lt;/sup&gt;  It&amp;#39;s not doing a fitting in the standard machine learning paradigm sense but I would think that as the parameter discretization increases the finer mesh will yield a higher fractional error per bin(like shot noise).\nIn any event, I have no idea how to compare this to a standard classifier (be it boosted trees, svm, etc)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null}
{"edited":false,"link_flair_text":null,"title":"Question on protocol for learning user models","is_self":true,"over_18":false,"id":"11q0gp","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11q0gp/question_on_protocol_for_learning_user_models/","mod_reports":[],"media_embed":{},"media":null,"created_utc":1350608415,"report_reasons":null,"subreddit_id":"t5_2r3gv","banned_by":null,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"Please settle this question. I want to authenticate users. If I learn a user model based on some user data only, do I need to divide by user dataset into training and testing? I mean the data from the other users are not used in building the model, so why can't I use the entire dataset in learning a user model? ","author_flair_text":null,"score":0,"num_comments":1,"retrieved_on":1413480713,"gilded":0,"author":"melipone","permalink":"/r/MachineLearning/comments/11q0gp/question_on_protocol_for_learning_user_models/","downs":0,"distinguished":null,"stickied":false,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please settle this question. I want to authenticate users. If I learn a user model based on some user data only, do I need to divide by user dataset into training and testing? I mean the data from the other users are not used in building the model, so why can&amp;#39;t I use the entire dataset in learning a user model? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","secure_media_embed":{},"ups":0,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null}
{"thumbnail":"default","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We collect data from mobile applications, which include the pages viewed and the actions completed within each page. It&amp;#39;s collected across many of the mainstream platforms (e.g. Android, iPhone, iPad, BlackBerry, Mobile Website). We&amp;#39;re trying to understand how the user is interacting with our applications, as well as how the users are connecting with each other. Please help me understand how ML can be applied to these kinds of data sets in a meaningful way.&lt;/p&gt;\n\n&lt;p&gt;EDIT: I am looking for examples of ML being applied to web / mobile applications. I realize that there is no magical formula, I just need a starting point to understand how these algorithms could be applied in the mobile application context.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null,"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"ups":0,"secure_media_embed":{},"link_flair_css_class":null,"selftext":"We collect data from mobile applications, which include the pages viewed and the actions completed within each page. It's collected across many of the mainstream platforms (e.g. Android, iPhone, iPad, BlackBerry, Mobile Website). We're trying to understand how the user is interacting with our applications, as well as how the users are connecting with each other. Please help me understand how ML can be applied to these kinds of data sets in a meaningful way.\n\nEDIT: I am looking for examples of ML being applied to web / mobile applications. I realize that there is no magical formula, I just need a starting point to understand how these algorithms could be applied in the mobile application context.","score":0,"author_flair_text":null,"created_utc":1350758755,"subreddit_id":"t5_2r3gv","banned_by":null,"report_reasons":null,"media":null,"subreddit":"MachineLearning","author":"[deleted]","gilded":0,"permalink":"/r/MachineLearning/comments/11t3ch/what_kind_of_ml_algorithms_are_commonly_applied/","num_comments":3,"retrieved_on":1413476312,"over_18":false,"mod_reports":[],"media_embed":{},"id":"11t3ch","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11t3ch/what_kind_of_ml_algorithms_are_commonly_applied/","edited":1350771992,"link_flair_text":null,"is_self":true,"title":"What kind of ML algorithms are commonly applied to data collected from mobile applications?"}
{"media_embed":{},"mod_reports":[],"url":"http://labrosa.ee.columbia.edu/millionsong/pages/example-track-description","user_reports":[],"id":"11szk9","over_18":false,"is_self":false,"title":"I have just been Rickrolled in data form.","edited":false,"link_flair_text":null,"author_flair_css_class":null,"domain":"labrosa.ee.columbia.edu","secure_media":null,"ups":4,"secure_media_embed":{},"selftext_html":null,"stickied":false,"thumbnail":"http://b.thumbs.redditmedia.com/arIFfmfX7z_c1tVa.jpg","distinguished":null,"downs":0,"gilded":0,"author":"TheShwayze","permalink":"/r/MachineLearning/comments/11szk9/i_have_just_been_rickrolled_in_data_form/","retrieved_on":1413476465,"num_comments":2,"score":4,"author_flair_text":null,"selftext":"","link_flair_css_class":null,"subreddit":"MachineLearning","created_utc":1350754552,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null}
{"over_18":false,"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11rzn2/how_can_i_get_weka_to_do_a_ttest_on_two/","user_reports":[],"id":"11rzn2","edited":false,"link_flair_text":null,"is_self":true,"title":"How can I get Weka to do a t-test on two classifiers built from the same data?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I asked this question on Stack Overflow, I am putting it out there to see if I can get an answer.&lt;/p&gt;\n\n&lt;p&gt;In Weka I can go to the experimenter. In the set-up I can load in an .arff file, and get weka to create a classifier (i.e. J48), then I can run it and then finally I can go to the analyze tab. In this tab it gives me an option to &amp;#39;testing with Paired T-Test&amp;#39; but I cannot figure out how to create a second classifier (i.e. J48 unpruned) and do a T-Test on the two results.&lt;/p&gt;\n\n&lt;p&gt;Google does not lead me to any tutorial or answers.&lt;/p&gt;\n\n&lt;p&gt;How can I get Weka to do a T-Test on the results of two different classifiers, made from the same data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","distinguished":null,"downs":0,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","secure_media_embed":{},"ups":2,"author_flair_text":null,"score":2,"link_flair_css_class":null,"selftext":"I asked this question on Stack Overflow, I am putting it out there to see if I can get an answer.\n\nIn Weka I can go to the experimenter. In the set-up I can load in an .arff file, and get weka to create a classifier (i.e. J48), then I can run it and then finally I can go to the analyze tab. In this tab it gives me an option to 'testing with Paired T-Test' but I cannot figure out how to create a second classifier (i.e. J48 unpruned) and do a T-Test on the two results.\n\nGoogle does not lead me to any tutorial or answers.\n\nHow can I get Weka to do a T-Test on the results of two different classifiers, made from the same data?","subreddit":"MachineLearning","media":null,"banned_by":null,"created_utc":1350693461,"report_reasons":null,"subreddit_id":"t5_2r3gv","gilded":0,"author":"tekesavvy","permalink":"/r/MachineLearning/comments/11rzn2/how_can_i_get_weka_to_do_a_ttest_on_two/","retrieved_on":1413477904,"num_comments":1}
{"selftext":"I have three sets of data, a training set, validation set, and a test set.  The validation set is used to optimize the parameters of the classifier.  \n\nBefore I got the validation set I was using the performance on leave-one-out cross validation on the training set to select my features. \n\nMy question is, is the validation set only used to optimize the parameters of the classifier, like C in a SVM,  or can I also use it to select features? It makes sense to me that I could use it but I have never specifically seen someone select their features at that stage.","link_flair_css_class":null,"score":4,"author_flair_text":null,"created_utc":1350796742,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","author":"[deleted]","gilded":0,"permalink":"/r/MachineLearning/comments/11tzyq/feature_selection_methodology/","num_comments":5,"retrieved_on":1413475081,"stickied":false,"thumbnail":"default","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have three sets of data, a training set, validation set, and a test set.  The validation set is used to optimize the parameters of the classifier.  &lt;/p&gt;\n\n&lt;p&gt;Before I got the validation set I was using the performance on leave-one-out cross validation on the training set to select my features. &lt;/p&gt;\n\n&lt;p&gt;My question is, is the validation set only used to optimize the parameters of the classifier, like C in a SVM,  or can I also use it to select features? It makes sense to me that I could use it but I have never specifically seen someone select their features at that stage.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null,"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"ups":4,"secure_media_embed":{},"edited":false,"link_flair_text":null,"is_self":true,"title":"Feature selection methodology","over_18":false,"mod_reports":[],"media_embed":{},"user_reports":[],"id":"11tzyq","url":"http://www.reddit.com/r/MachineLearning/comments/11tzyq/feature_selection_methodology/"}
{"secure_media_embed":{},"ups":10,"author_flair_css_class":null,"secure_media":null,"domain":"marginhound.com","distinguished":null,"downs":0,"selftext_html":null,"thumbnail":"default","stickied":false,"retrieved_on":1413471480,"num_comments":0,"permalink":"/r/MachineLearning/comments/11wgu0/linkedin_endorsements_how_might_they_affect/","gilded":0,"author":"[deleted]","subreddit":"MachineLearning","media":null,"created_utc":1350923206,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","author_flair_text":null,"score":10,"link_flair_css_class":null,"selftext":"","url":"http://www.marginhound.com/big-data-is-linkedin-building-a-pagerank-algorithm-for-job-hunters/","id":"11wgu0","user_reports":[],"media_embed":{},"mod_reports":[],"over_18":false,"title":"Linkedin Endorsements: How Might They Affect Linkedin’s Search Algorithm?","is_self":false,"edited":false,"link_flair_text":null}
{"distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I do not know if this is the right subreddit to post, but here goes anyways. I posted this previously on &lt;a href=\"/r/datascience\"&gt;/r/datascience&lt;/a&gt;, but I was  suggested to post elsewhere.&lt;/p&gt;\n\n&lt;p&gt;Data science has been my primary interest for a long while now, and I have just graduated with a Masters in Machine learning &amp;amp; Data mining, before which I pursued a bachelors in Software engineering, both with excellent grades and from good schools. I am in the final stages of interviews for my dream job as a data scientist, at a good small-but-popular company. Everything has been good for me so far, fortunately.&lt;/p&gt;\n\n&lt;p&gt;My problem is that I have no idea what to answer when they ask the inevitable question on what I expect to make. I really don&amp;#39;t know what kind of compensation I should be looking for. I understand that this is a relatively new profession, but there just isn&amp;#39;t enough information on the internet on salaries for data scientists. I have very little &amp;quot;real world&amp;quot; experience, except for several software engineering internships, totaling to about a year&amp;#39;s worth, and several ML projects, both academic and personal. This would be my first &amp;quot;real&amp;quot; job. &lt;/p&gt;\n\n&lt;p&gt;Should I expect just as much as a software developer/engineer at the company? What other professional salaries are comparable to an entry level data-scientist? What was your starting salary as a data scientist? Any kind of information would be helpful. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","ups":4,"secure_media_embed":{},"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"subreddit":"MachineLearning","created_utc":1350903214,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"score":4,"author_flair_text":null,"link_flair_css_class":null,"selftext":"I do not know if this is the right subreddit to post, but here goes anyways. I posted this previously on /r/datascience, but I was  suggested to post elsewhere.\n\nData science has been my primary interest for a long while now, and I have just graduated with a Masters in Machine learning &amp; Data mining, before which I pursued a bachelors in Software engineering, both with excellent grades and from good schools. I am in the final stages of interviews for my dream job as a data scientist, at a good small-but-popular company. Everything has been good for me so far, fortunately.\n\nMy problem is that I have no idea what to answer when they ask the inevitable question on what I expect to make. I really don't know what kind of compensation I should be looking for. I understand that this is a relatively new profession, but there just isn't enough information on the internet on salaries for data scientists. I have very little \"real world\" experience, except for several software engineering internships, totaling to about a year's worth, and several ML projects, both academic and personal. This would be my first \"real\" job. \n\nShould I expect just as much as a software developer/engineer at the company? What other professional salaries are comparable to an entry level data-scientist? What was your starting salary as a data scientist? Any kind of information would be helpful. Thanks!","retrieved_on":1413472091,"num_comments":16,"author":"omlettehead","gilded":0,"permalink":"/r/MachineLearning/comments/11w22t/data_scientists_help_me_out_how_much_can_i_expect/","over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/11w22t/data_scientists_help_me_out_how_much_can_i_expect/","user_reports":[],"id":"11w22t","media_embed":{},"mod_reports":[],"edited":false,"link_flair_text":null,"title":"Data scientists, help me out. How much can I expect to make annually as a fresh data scientist?","is_self":true}
{"title":"The distribution of random correlation matrices","is_self":true,"link_flair_text":null,"edited":false,"id":"11ygkk","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11ygkk/the_distribution_of_random_correlation_matrices/","mod_reports":[],"media_embed":{},"over_18":false,"num_comments":5,"retrieved_on":1413468477,"author":"drbabinski","gilded":0,"permalink":"/r/MachineLearning/comments/11ygkk/the_distribution_of_random_correlation_matrices/","media":null,"created_utc":1351014533,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","selftext":"Does anyone know of a way to randomly generate correlation matrices given that the sum of the correlation matrix's elements remains the same?  The motivation is to show that current correlations we have do indeed have structure, as opposed to chance.  However, it is difficult to show what structure there should be by chance.\n\nWe could shuffle the correlations in the matrix: this ensures the sum of the elements remains the same.  However, doing this is computationally unfeasible---millions of shuffles proves not to find valid correlation matrices (positive definite).  Also, this by nature will not yield all possible correlation matrices that sum up to the same value.  For example, -1, 1, and 1 sum to 1 (as will 1, -1, and 1), but you could also have -.5, 1, .5 sum up to 1.  \n\nOther methods for generating covariance matrices include the Wishart distribution and factor analysis methods.  However, these will not fix the sum of the elements, and it's not entirely clear how these methods compare with the true distribution of correlation matrices.\n\nJust wondering if anyone has any experience here and can point me to some good directions!  It's an interesting problem.","link_flair_css_class":null,"author_flair_text":null,"score":5,"secure_media_embed":{},"ups":5,"secure_media":null,"domain":"self.MachineLearning","author_flair_css_class":null,"downs":0,"distinguished":null,"stickied":false,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know of a way to randomly generate correlation matrices given that the sum of the correlation matrix&amp;#39;s elements remains the same?  The motivation is to show that current correlations we have do indeed have structure, as opposed to chance.  However, it is difficult to show what structure there should be by chance.&lt;/p&gt;\n\n&lt;p&gt;We could shuffle the correlations in the matrix: this ensures the sum of the elements remains the same.  However, doing this is computationally unfeasible---millions of shuffles proves not to find valid correlation matrices (positive definite).  Also, this by nature will not yield all possible correlation matrices that sum up to the same value.  For example, -1, 1, and 1 sum to 1 (as will 1, -1, and 1), but you could also have -.5, 1, .5 sum up to 1.  &lt;/p&gt;\n\n&lt;p&gt;Other methods for generating covariance matrices include the Wishart distribution and factor analysis methods.  However, these will not fix the sum of the elements, and it&amp;#39;s not entirely clear how these methods compare with the true distribution of correlation matrices.&lt;/p&gt;\n\n&lt;p&gt;Just wondering if anyone has any experience here and can point me to some good directions!  It&amp;#39;s an interesting problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"}
{"author":"kafka399","gilded":0,"permalink":"/r/MachineLearning/comments/11y963/exploring_parliamentarians_similarity/","num_comments":0,"retrieved_on":1413468769,"selftext":"","link_flair_css_class":null,"score":0,"author_flair_text":null,"created_utc":1351007774,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","domain":"investuotojas.eu","secure_media":null,"author_flair_css_class":null,"ups":0,"secure_media_embed":{},"stickied":false,"thumbnail":"http://f.thumbs.redditmedia.com/wB7ZV9J2RNY9kFL_.jpg","selftext_html":null,"downs":0,"distinguished":null,"is_self":false,"title":"Exploring parliamentarians similarity","edited":false,"link_flair_text":null,"mod_reports":[],"media_embed":{},"user_reports":[],"id":"11y963","url":"http://www.investuotojas.eu/2012/10/23/machine-learning-for-hackers/","over_18":false}
{"ups":8,"secure_media_embed":{},"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"downs":0,"distinguished":null,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all,&lt;/p&gt;\n\n&lt;p&gt;I need your comments on the &lt;a href=\"http://www.mash-project.eu/\"&gt;MASH\nproject&lt;/a&gt; we have been working on over the\nlast few years.&lt;/p&gt;\n\n&lt;p&gt;The core idea behind it is to allow contributors to write image\nfeature extractors (edges, color, etc.), that will be automatically\ncombined with machine learning methods we have developed, to get high\nperformance image-based prediction system. By combining algorithms\ndeveloped by people with very different backgrounds, we hope to\nachieve performance higher than the state-of-the-art.&lt;/p&gt;\n\n&lt;p&gt;The &lt;a href=\"http://www.mash-project.eu/factory/\"&gt;Factory&lt;/a&gt; is the most recent\nincarnation of this idea. It allows you to write image features in C++\nand test them on-line. Performance is assessed on mimicking tasks: We\ntrain a virtual robot to mimic the choice of actions of a teacher, to\nreach a red flag in a 3d environment. Hence, your image features will\nbe combined by our machine learning methods to predict what do to\n(&amp;quot;turn left&amp;quot;, &amp;quot;turn right&amp;quot;, or &amp;quot;go forward&amp;quot;), given what the\nrobot sees, and has seen since the beginning of the current test.&lt;/p&gt;\n\n&lt;p&gt;The web site is at&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.mash-project.eu/factory/\"&gt;http://www.mash-project.eu/factory/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;and you can get documentation and a screen-cast at&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.mash-project.eu/wiki/index.php/MASH_Factory\"&gt;http://www.mash-project.eu/wiki/index.php/MASH_Factory&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.mash-project.eu/files/screencast-factory.mpg\"&gt;http://www.mash-project.eu/files/screencast-factory.mpg&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any comment is welcome. Please feel free to mail me if you have any\nquestion (francois.fleuret@idiap.ch).&lt;/p&gt;\n\n&lt;p&gt;Cheers,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","num_comments":9,"retrieved_on":1413469547,"permalink":"/r/MachineLearning/comments/11xpgg/the_mash_factory_you_can_write_and_test_image/","gilded":0,"author":"FrancoisFleuret","created_utc":1350978017,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","selftext":"Dear all,\n\nI need your comments on the [MASH\nproject](http://www.mash-project.eu/) we have been working on over the\nlast few years.\n\nThe core idea behind it is to allow contributors to write image\nfeature extractors (edges, color, etc.), that will be automatically\ncombined with machine learning methods we have developed, to get high\nperformance image-based prediction system. By combining algorithms\ndeveloped by people with very different backgrounds, we hope to\nachieve performance higher than the state-of-the-art.\n\nThe [Factory](http://www.mash-project.eu/factory/) is the most recent\nincarnation of this idea. It allows you to write image features in C++\nand test them on-line. Performance is assessed on mimicking tasks: We\ntrain a virtual robot to mimic the choice of actions of a teacher, to\nreach a red flag in a 3d environment. Hence, your image features will\nbe combined by our machine learning methods to predict what do to\n(\"turn left\", \"turn right\", or \"go forward\"), given what the\nrobot sees, and has seen since the beginning of the current test.\n\nThe web site is at\n\n  http://www.mash-project.eu/factory/\n\nand you can get documentation and a screen-cast at\n\n  http://www.mash-project.eu/wiki/index.php/MASH_Factory\n\n  http://www.mash-project.eu/files/screencast-factory.mpg\n\nAny comment is welcome. Please feel free to mail me if you have any\nquestion (francois.fleuret@idiap.ch).\n\nCheers,\n","link_flair_css_class":null,"score":8,"author_flair_text":null,"user_reports":[],"id":"11xpgg","url":"http://www.reddit.com/r/MachineLearning/comments/11xpgg/the_mash_factory_you_can_write_and_test_image/","mod_reports":[],"media_embed":{},"over_18":false,"title":"The MASH Factory: You can write and test image heuristics on-line, without installing anything on your computer.\n","is_self":true,"link_flair_text":null,"edited":1350978280}
{"title":"What should be a generic enough convergence criteria of Stochastic Gradient Descent.","is_self":true,"link_flair_text":null,"edited":1351135132,"id":"121ahq","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/121ahq/what_should_be_a_generic_enough_convergence/","mod_reports":[],"media_embed":{},"over_18":false,"num_comments":11,"retrieved_on":1413464576,"author":"akshayxyz","gilded":0,"permalink":"/r/MachineLearning/comments/121ahq/what_should_be_a_generic_enough_convergence/","banned_by":null,"created_utc":1351122063,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning","selftext":"I am implementing a generic module for Stochastic Gradient Descent. That takes arguments: training dataset, loss(x,y), dw(x,y) - per sample loss and per sample gradient change.\n\nNow, for the convergence criteria, I have thought of :-\n\na) Checking loss function after every 10% of the dataset.size, averaged over some window\n\nb) Checking the norm of the differences between weight vector, after every 10-20% of dataset size..\n\nc) Stabilization of error on the training set.\n\nd) Change in the sign of the gradient (again, checked after every fixed intervals) - \n\n\nI have noticed that these checks (precision of check etc.) depends on other stuff also, like step size, learning rate.. and the effect can vary from one training problem to another.\n\nI can't seem to make up mind on, what should be the generic stopping criterion, regardless of the training set, fx,df/dw thrown at the SGD module. What do you guys do?\n\nAlso, for (d), what would be the meaning of \"change in sign\" for a n-dimensional vector?\n\nEdit:formatting","link_flair_css_class":null,"score":7,"author_flair_text":null,"ups":7,"secure_media_embed":{},"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"downs":0,"distinguished":null,"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am implementing a generic module for Stochastic Gradient Descent. That takes arguments: training dataset, loss(x,y), dw(x,y) - per sample loss and per sample gradient change.&lt;/p&gt;\n\n&lt;p&gt;Now, for the convergence criteria, I have thought of :-&lt;/p&gt;\n\n&lt;p&gt;a) Checking loss function after every 10% of the dataset.size, averaged over some window&lt;/p&gt;\n\n&lt;p&gt;b) Checking the norm of the differences between weight vector, after every 10-20% of dataset size..&lt;/p&gt;\n\n&lt;p&gt;c) Stabilization of error on the training set.&lt;/p&gt;\n\n&lt;p&gt;d) Change in the sign of the gradient (again, checked after every fixed intervals) - &lt;/p&gt;\n\n&lt;p&gt;I have noticed that these checks (precision of check etc.) depends on other stuff also, like step size, learning rate.. and the effect can vary from one training problem to another.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t seem to make up mind on, what should be the generic stopping criterion, regardless of the training set, fx,df/dw thrown at the SGD module. What do you guys do?&lt;/p&gt;\n\n&lt;p&gt;Also, for (d), what would be the meaning of &amp;quot;change in sign&amp;quot; for a n-dimensional vector?&lt;/p&gt;\n\n&lt;p&gt;Edit:formatting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"}
{"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/120upp/learning_in_high_dimensions_question/","user_reports":[],"id":"120upp","media_embed":{},"mod_reports":[],"link_flair_text":null,"edited":false,"title":"Learning in high dimensions (question)","is_self":true,"distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I am wondering about learning in very high dimensions:  n/p &amp;gt; 1000.&lt;/p&gt;\n\n&lt;p&gt;Any kind of learning is good (supervised/unsupervised/reinforcement).&lt;/p&gt;\n\n&lt;p&gt;I have heard many negative talks about such tasks. Does anyone know any good &amp;quot;positive&amp;quot; research results about cases like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","stickied":false,"ups":3,"secure_media_embed":{},"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"subreddit":"MachineLearning","banned_by":null,"created_utc":1351108215,"subreddit_id":"t5_2r3gv","report_reasons":null,"media":null,"score":3,"author_flair_text":null,"link_flair_css_class":null,"selftext":"Hello Everyone,\n\nI am wondering about learning in very high dimensions:  n/p &gt; 1000.\n\nAny kind of learning is good (supervised/unsupervised/reinforcement).\n\nI have heard many negative talks about such tasks. Does anyone know any good \"positive\" research results about cases like that?","retrieved_on":1413465186,"num_comments":4,"gilded":0,"author":"PlayMeWhile","permalink":"/r/MachineLearning/comments/120upp/learning_in_high_dimensions_question/"}
{"secure_media_embed":{},"ups":1,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t have the time or energy to devote to learning another language.  My question is:  Can I read this book without having to know too much about R?  Or, will I have to dig through reference manuals in order to figure the details of the algorithms?  I suppose an equivalent, more general question is:  Is R readable by an experienced programmer (C, C++, Python, Common Lisp, Clojure)?&lt;/p&gt;\n\n&lt;p&gt;For example, if someone knows C++ and they read a book that uses Python as the demonstration language, they&amp;#39;ll be able to follow along as long as the writer doesn&amp;#39;t make use of too many of the concepts that aren&amp;#39;t shared between the two languages (list comprehensions, lambdas (pre 0x11), etc).&lt;/p&gt;\n\n&lt;p&gt;Thanks ML!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"default","retrieved_on":1413465801,"num_comments":0,"permalink":"/r/MachineLearning/comments/120eig/opinions_on_machine_learning_for_hackers_for/","gilded":0,"author":"[deleted]","subreddit":"MachineLearning","media":null,"created_utc":1351094393,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","author_flair_text":null,"score":1,"link_flair_css_class":null,"selftext":"I don't have the time or energy to devote to learning another language.  My question is:  Can I read this book without having to know too much about R?  Or, will I have to dig through reference manuals in order to figure the details of the algorithms?  I suppose an equivalent, more general question is:  Is R readable by an experienced programmer (C, C++, Python, Common Lisp, Clojure)?\n\nFor example, if someone knows C++ and they read a book that uses Python as the demonstration language, they'll be able to follow along as long as the writer doesn't make use of too many of the concepts that aren't shared between the two languages (list comprehensions, lambdas (pre 0x11), etc).\n\nThanks ML!","url":"http://www.reddit.com/r/MachineLearning/comments/120eig/opinions_on_machine_learning_for_hackers_for/","user_reports":[],"id":"120eig","media_embed":{},"mod_reports":[],"over_18":false,"title":"Opinions on \"Machine Learning for Hackers\" for someone not interested in learning R","is_self":true,"edited":false,"link_flair_text":null}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building two multi-class text classifiers on health care data for an experiment. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;11 classes&lt;/li&gt;\n&lt;li&gt;4 classes&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We are in the design phase and I&amp;#39;ve been asked to estimate the required sample size for the experiment. i.e. how many text reports do we need to extract, label, train and test the classifiers to meet a desired target performance (e.g. AUC 0.80).&lt;/p&gt;\n\n&lt;p&gt;Sample size estimation is commonly performed in designing health and medical experiments. Researchers want to know how many participants they need to recruit before conducting the experiment to determine its feasibility. i.e. it might be too expensive or difficult. &lt;/p&gt;\n\n&lt;p&gt;From my understanding, sample size estimation are used for hypothesis testing. i.e. to ensure there is enough data to look for differences between control and experiment groups based on a specified statistical power, effect size and other factors. See &lt;a href=\"http://en.wikipedia.org/wiki/Sample_size_determination#Required_sample_sizes_for_hypothesis_tests\"&gt;http://en.wikipedia.org/wiki/Sample_size_determination#Required_sample_sizes_for_hypothesis_tests&lt;/a&gt; for some examples.&lt;/p&gt;\n\n&lt;p&gt;There are two main reasons why I have been asked to provide a sample size estimate:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Minimise costs: we need to pay domain experts to label reports so we don&amp;#39;t want to label more data than is needed.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Classifier confidence: The rarest class in the 4-class experiment comprises of 0.5% of the reports. If a small sample size is used and the classifier is only tested against  lets say 2 instances of the rare class then can we really be confident of the classifier&amp;#39;s performance on this class?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I came across a 2012 paper in Medical Informatics: Figueroa et al. &amp;quot;Predicting sample size required for classification performance&amp;quot; - &lt;a href=\"http://www.biomedcentral.com/1472-6947/12/8\"&gt;http://www.biomedcentral.com/1472-6947/12/8&lt;/a&gt; which proposed to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Build the learning curve on a small amount of labelled data&lt;/li&gt;\n&lt;li&gt;Build a regression model (non linear, inverse power law) of the learning curve&lt;/li&gt;\n&lt;li&gt;Use the model to predict how many samples are needed to achieve target performance&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if this is the way to go so I wanted some feedback. I come from a computing background (not Health / Medicine) and have NOT performed sample size estimation in my machine learning work so far. &lt;/p&gt;\n\n&lt;p&gt;Many thanks!&lt;/p&gt;\n\n&lt;p&gt;P.S. I will update this post based on answers / discussions from the comments. Hopefully the answers will also be helpful to others with similar concerns.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been asked to provide sample size estimates for my text classification experiments. I&amp;#39;ve looked at some literature and online sources but not sure what are the most suitable models / methods.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","distinguished":null,"downs":0,"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"ups":3,"secure_media_embed":{},"score":3,"author_flair_text":null,"selftext":"I am building two multi-class text classifiers on health care data for an experiment. \n\n1. 11 classes\n2. 4 classes\n\nWe are in the design phase and I've been asked to estimate the required sample size for the experiment. i.e. how many text reports do we need to extract, label, train and test the classifiers to meet a desired target performance (e.g. AUC 0.80).\n\nSample size estimation is commonly performed in designing health and medical experiments. Researchers want to know how many participants they need to recruit before conducting the experiment to determine its feasibility. i.e. it might be too expensive or difficult. \n\nFrom my understanding, sample size estimation are used for hypothesis testing. i.e. to ensure there is enough data to look for differences between control and experiment groups based on a specified statistical power, effect size and other factors. See http://en.wikipedia.org/wiki/Sample_size_determination#Required_sample_sizes_for_hypothesis_tests for some examples.\n\nThere are two main reasons why I have been asked to provide a sample size estimate:\n\n1. Minimise costs: we need to pay domain experts to label reports so we don't want to label more data than is needed.\n\n2. Classifier confidence: The rarest class in the 4-class experiment comprises of 0.5% of the reports. If a small sample size is used and the classifier is only tested against  lets say 2 instances of the rare class then can we really be confident of the classifier's performance on this class?\n\nI came across a 2012 paper in Medical Informatics: Figueroa et al. \"Predicting sample size required for classification performance\" - http://www.biomedcentral.com/1472-6947/12/8 which proposed to:\n\n1. Build the learning curve on a small amount of labelled data\n2. Build a regression model (non linear, inverse power law) of the learning curve\n3. Use the model to predict how many samples are needed to achieve target performance\n\nI'm not sure if this is the way to go so I wanted some feedback. I come from a computing background (not Health / Medicine) and have NOT performed sample size estimation in my machine learning work so far. \n\nMany thanks!\n\nP.S. I will update this post based on answers / discussions from the comments. Hopefully the answers will also be helpful to others with similar concerns.\n\n**TL;DR**\n\nI've been asked to provide sample size estimates for my text classification experiments. I've looked at some literature and online sources but not sure what are the most suitable models / methods.","link_flair_css_class":null,"subreddit":"MachineLearning","created_utc":1351048418,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"gilded":0,"permalink":"/r/MachineLearning/comments/11zjd4/sample_size_estimation_for_classification/","author":"somealiass","retrieved_on":1413467017,"num_comments":0,"over_18":false,"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/11zjd4/sample_size_estimation_for_classification/","id":"11zjd4","user_reports":[],"link_flair_text":null,"edited":1351055617,"is_self":true,"title":"Sample size estimation for classification experiments"}
{"downs":0,"distinguished":null,"thumbnail":"http://d.thumbs.redditmedia.com/nZXbOHAeysWMx2_K.jpg","stickied":false,"selftext_html":null,"secure_media_embed":{},"ups":9,"secure_media":null,"domain":"oreillynet.com","author_flair_css_class":null,"media":null,"created_utc":1351205253,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"","author_flair_text":null,"score":9,"num_comments":4,"retrieved_on":1413461795,"gilded":0,"author":"AllenDowney","permalink":"/r/MachineLearning/comments/123c4f/webcast_on_basic_bayesian_statistics_in_python/","over_18":false,"id":"123c4f","user_reports":[],"url":"http://oreillynet.com/pub/e/2392","mod_reports":[],"media_embed":{},"link_flair_text":null,"edited":false,"title":"Webcast on basic Bayesian statistics in Python: Friday at 1pm EDT, O'Reilly Media.","is_self":false}
{"ups":3,"secure_media_embed":{},"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Mods: Please forgive me and delete this post if it falls outside of acceptable discussion for this subreddit.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I am a PhD student who has found discussions on this subreddit to be very rewarding, but so far I have been hesitant to ask any questions or start any discussions dealing with actual research work I am doing either for a paper or my dissertation.&lt;/p&gt;\n\n&lt;p&gt;This has been for a few reasons:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;A fear of having my ideas stolen.  Some of my ideas are quite novel (others not so much), and I worry about making comments about my dissertation work and find out 6 months from now that I have to start over because similar work has just been published.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A fear of having my work called into question as not being my own.  Certainly, I get input from my committee and other graduate students, but if there is a public discussion here which leads to a good idea, can I really claim it as my own contribution to the field?  What might happen if my committee or a potential employer sees that the idea was generated through a public thread on reddit and not a purely individual effort.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A fear of being accused of plagiarism/stealing work for using ideas that someone else suggested here.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I the only person who worries about these issues?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;tl;dr: Is posting my current research methods/topics a bad idea or not?&lt;/strong&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","stickied":false,"retrieved_on":1413461948,"num_comments":29,"gilded":0,"permalink":"/r/MachineLearning/comments/1237yr/meta_question_what_are_the_rulesguidlines_on_this/","author":"Omega037","subreddit":"MachineLearning","created_utc":1351201561,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"score":3,"author_flair_text":null,"selftext":"*Mods: Please forgive me and delete this post if it falls outside of acceptable discussion for this subreddit.*\n\nI am a PhD student who has found discussions on this subreddit to be very rewarding, but so far I have been hesitant to ask any questions or start any discussions dealing with actual research work I am doing either for a paper or my dissertation.\n\nThis has been for a few reasons:\n\n1. A fear of having my ideas stolen.  Some of my ideas are quite novel (others not so much), and I worry about making comments about my dissertation work and find out 6 months from now that I have to start over because similar work has just been published.\n\n2. A fear of having my work called into question as not being my own.  Certainly, I get input from my committee and other graduate students, but if there is a public discussion here which leads to a good idea, can I really claim it as my own contribution to the field?  What might happen if my committee or a potential employer sees that the idea was generated through a public thread on reddit and not a purely individual effort.\n\n3. A fear of being accused of plagiarism/stealing work for using ideas that someone else suggested here.\n\nAm I the only person who worries about these issues?\n\n**tl;dr: Is posting my current research methods/topics a bad idea or not?** ","link_flair_css_class":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1237yr/meta_question_what_are_the_rulesguidlines_on_this/","user_reports":[],"id":"1237yr","media_embed":{},"mod_reports":[],"over_18":false,"title":"[Meta Question] What are the rules/guidlines on this subreddit regarding discussing your current academic research?","is_self":true,"edited":false,"link_flair_text":null}
{"over_18":false,"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/122vev/anyone_have_any_experience_with_the_data_from/","id":"122vev","user_reports":[],"edited":false,"link_flair_text":null,"is_self":true,"title":"Anyone have any experience with the data from intrade.com?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw on their website you could get data about open contracts, but you have to buy historical data (with a discount for academia). Has anyone used this data or know how much they charge? &lt;/p&gt;\n\n&lt;p&gt;Obviously stock market mining is a difficult problem, but this type of market may have some interesting properties.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","distinguished":null,"downs":0,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","secure_media_embed":{},"ups":2,"author_flair_text":null,"score":2,"selftext":"I saw on their website you could get data about open contracts, but you have to buy historical data (with a discount for academia). Has anyone used this data or know how much they charge? \n\nObviously stock market mining is a difficult problem, but this type of market may have some interesting properties.","link_flair_css_class":null,"subreddit":"MachineLearning","media":null,"created_utc":1351190881,"banned_by":null,"subreddit_id":"t5_2r3gv","report_reasons":null,"author":"WhereIsShellBeach","gilded":0,"permalink":"/r/MachineLearning/comments/122vev/anyone_have_any_experience_with_the_data_from/","retrieved_on":1413462418,"num_comments":5}
{"score":32,"author_flair_text":null,"link_flair_css_class":null,"selftext":"","subreddit":"MachineLearning","created_utc":1351182873,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","media":null,"gilded":0,"author":"themandotcom","permalink":"/r/MachineLearning/comments/122m4r/massive_ml_project_that_will_land_you_a_job_at/","retrieved_on":1413462769,"num_comments":32,"selftext_html":null,"stickied":false,"thumbnail":"http://d.thumbs.redditmedia.com/dwpbJQhIaetNbyWo.jpg","distinguished":null,"downs":0,"author_flair_css_class":null,"domain":"kaggle.com","secure_media":null,"ups":32,"secure_media_embed":{},"edited":false,"link_flair_text":null,"is_self":false,"title":"Massive ML Project that will land you a job at facebook","over_18":false,"media_embed":{},"mod_reports":[],"url":"https://www.kaggle.com/c/facebook-ii/","id":"122m4r","user_reports":[]}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll try to make this brief.&lt;/p&gt;\n\n&lt;p&gt;I graduated with a bachelors in electrical engineering in December of 2011.  I took an intro to neural networks course while in school.  Since then, I&amp;#39;ve been very interested in the topic and have done a lot of what I would call brainstorming.&lt;/p&gt;\n\n&lt;p&gt;I have been clinging to the idea that I can apply neural networks to predicting financial markets and make a fortune.  I am sure that many others have had the same idea, and many have probably been disappointed.  However, I cannot shake the idea.&lt;/p&gt;\n\n&lt;p&gt;My basic idea is to train a neural net with as much data as I can gather.  Even potentially unrelated data like average temperature in the US, number of international airline flights, moon phases...  I&amp;#39;ll use historical data for training, and a small subset of it will be reserved for testing.&lt;/p&gt;\n\n&lt;p&gt;If the net seems to be accurate, I would consider throwing some money into the market.  Really, though, my dream is to make millions by either managing other people&amp;#39;s money or selling my services to some kind of hedge fund or other financial institution.  Trust me, I know that the odds are stacked heavily against me.  Just being honest about the hopes that are driving this.&lt;/p&gt;\n\n&lt;p&gt;I have spent maybe 30 hours actually writing code for my project, all in my spare time, outside of my full time working hours.  So far, I have succeeded in doing the following.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Programming a basic multilayer neural network class&lt;/li&gt;\n&lt;li&gt;Writing a script which downloaded all available historical data for every security listed on the NYSE, from yahoo finance&lt;/li&gt;\n&lt;li&gt;Writing a java class for generating some basic technical indicators&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have a basic understanding of neural networks and I have actually programmed a few which did something useful, including one which classified handwritten numerical digits.  However, I know there is so much more that I could learn in the field of machine learning.&lt;/p&gt;\n\n&lt;p&gt;I guess my questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Is this even worth my time?  It&amp;#39;s an interesting hobby but I would be disappointed if it never proved useful.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Would I be better off getting a stronger background in machine learning before even attempting this?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I am starved for good resources.  Everything is either way over my head, or way too basic.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Has anyone ever been independently successful at this type of thing?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any other advice is also welcome.  Thanks for reading.  I really appreciate any help.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;tl;dr: Interested in machine learning for finance.  See questions above.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","stickied":false,"distinguished":null,"downs":0,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","secure_media_embed":{},"ups":1,"author_flair_text":null,"score":1,"link_flair_css_class":null,"selftext":"I'll try to make this brief.\n\nI graduated with a bachelors in electrical engineering in December of 2011.  I took an intro to neural networks course while in school.  Since then, I've been very interested in the topic and have done a lot of what I would call brainstorming.\n\nI have been clinging to the idea that I can apply neural networks to predicting financial markets and make a fortune.  I am sure that many others have had the same idea, and many have probably been disappointed.  However, I cannot shake the idea.\n\nMy basic idea is to train a neural net with as much data as I can gather.  Even potentially unrelated data like average temperature in the US, number of international airline flights, moon phases...  I'll use historical data for training, and a small subset of it will be reserved for testing.\n\nIf the net seems to be accurate, I would consider throwing some money into the market.  Really, though, my dream is to make millions by either managing other people's money or selling my services to some kind of hedge fund or other financial institution.  Trust me, I know that the odds are stacked heavily against me.  Just being honest about the hopes that are driving this.\n\nI have spent maybe 30 hours actually writing code for my project, all in my spare time, outside of my full time working hours.  So far, I have succeeded in doing the following.\n\n - Programming a basic multilayer neural network class\n - Writing a script which downloaded all available historical data for every security listed on the NYSE, from yahoo finance\n - Writing a java class for generating some basic technical indicators\n\nI have a basic understanding of neural networks and I have actually programmed a few which did something useful, including one which classified handwritten numerical digits.  However, I know there is so much more that I could learn in the field of machine learning.\n\nI guess my questions are:\n\n1.  Is this even worth my time?  It's an interesting hobby but I would be disappointed if it never proved useful.\n\n2.  Would I be better off getting a stronger background in machine learning before even attempting this?\n\n3.  I am starved for good resources.  Everything is either way over my head, or way too basic.\n\n4.  Has anyone ever been independently successful at this type of thing?\n\nAny other advice is also welcome.  Thanks for reading.  I really appreciate any help.\n\n**tl;dr: Interested in machine learning for finance.  See questions above.**","subreddit":"MachineLearning","media":null,"report_reasons":null,"created_utc":1351136279,"subreddit_id":"t5_2r3gv","banned_by":null,"author":"emblem22","permalink":"/r/MachineLearning/comments/121q31/been_working_on_a_neural_network_software_pack/","gilded":0,"retrieved_on":1413463978,"num_comments":0,"over_18":false,"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/121q31/been_working_on_a_neural_network_software_pack/","user_reports":[],"id":"121q31","edited":false,"link_flair_text":null,"is_self":true,"title":"Been working on a neural network software pack for financial market analysis.  Unsure.  Looking for advice."}
{"mod_reports":[],"media_embed":{},"id":"124aou","user_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/124aou/detecting_repeating_patterns_in_a_sequence_of/","over_18":false,"is_self":true,"title":"Detecting repeating patterns in a sequence of states","edited":1351252082,"link_flair_text":null,"domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"ups":12,"secure_media_embed":{},"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey. I&amp;#39;ve got a project that I&amp;#39;m working on and trying to figure out.&lt;/p&gt;\n\n&lt;p&gt;Say I&amp;#39;m trying to model something that has N states (in my case, N=27). The system is typically at a different state in each time step but it&amp;#39;s not clear what the relationships are.&lt;/p&gt;\n\n&lt;p&gt;How would I be able to detect common patterns in this sequence? I&amp;#39;d like to be able to do this in a &amp;#39;fuzzy&amp;#39; way, so that very similar sequences count toward  the same pattern. &lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n\n&lt;p&gt;PS. I&amp;#39;m not a machine-learning guy&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null,"gilded":0,"author":"woggy","permalink":"/r/MachineLearning/comments/124aou/detecting_repeating_patterns_in_a_sequence_of/","num_comments":19,"retrieved_on":1413460435,"selftext":"Hey. I've got a project that I'm working on and trying to figure out.\n\nSay I'm trying to model something that has N states (in my case, N=27). The system is typically at a different state in each time step but it's not clear what the relationships are.\n\nHow would I be able to detect common patterns in this sequence? I'd like to be able to do this in a 'fuzzy' way, so that very similar sequences count toward  the same pattern. \n\nAny ideas?\n\nPS. I'm not a machine-learning guy","link_flair_css_class":null,"score":12,"author_flair_text":null,"created_utc":1351251696,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","media":null,"subreddit":"MachineLearning"}
{"secure_media":null,"domain":"r-bloggers.com","author_flair_css_class":null,"secure_media_embed":{},"ups":1,"stickied":false,"thumbnail":"http://a.thumbs.redditmedia.com/4gzcFpWHg-eBcR10.jpg","selftext_html":null,"downs":0,"distinguished":null,"author":"talgalili","permalink":"/r/MachineLearning/comments/1249ew/comparing_sas_hadoop_and_r_for_bigdata_insurance/","gilded":0,"num_comments":0,"retrieved_on":1413460489,"link_flair_css_class":null,"selftext":"","author_flair_text":null,"score":1,"media":null,"created_utc":1351248976,"banned_by":null,"subreddit_id":"t5_2r3gv","report_reasons":null,"subreddit":"MachineLearning","mod_reports":[],"media_embed":{},"user_reports":[],"id":"1249ew","url":"http://www.r-bloggers.com/allstate-compares-sas-hadoop-and-r-for-big-data-insurance-models/","over_18":false,"is_self":false,"title":"Comparing SAS, Hadoop and R for Big-Data Insurance Models","edited":false,"link_flair_text":null}
{"subreddit":"MachineLearning","media":null,"created_utc":1351551551,"banned_by":null,"subreddit_id":"t5_2r3gv","report_reasons":null,"author_flair_text":null,"score":1,"selftext":"","link_flair_css_class":null,"retrieved_on":1413451392,"num_comments":0,"permalink":"/r/MachineLearning/comments/12ayxe/analytics_made_skeezy_logistic_regression_for/","gilded":0,"author":"john4man","distinguished":null,"downs":0,"selftext_html":null,"stickied":false,"thumbnail":"default","secure_media_embed":{},"ups":1,"author_flair_css_class":null,"secure_media":null,"domain":"analyticsmadeskeezy.com","edited":false,"link_flair_text":null,"title":"Analytics Made Skeezy - Logistic Regression for Tripping Acid","is_self":false,"over_18":false,"url":"http://analyticsmadeskeezy.com/2012/10/29/introduction-to-machine-learning-logistic-regression-for-predicting-bad-trips/","id":"12ayxe","user_reports":[],"media_embed":{},"mod_reports":[]}
{"author_flair_text":null,"score":0,"selftext":"I'm a fairly good programmer, with a background of normal, procedural and object-oriented programming, using C/C++ on Unix, Java ( even on Android ) etc.\n\nI have this little college project for my AI class, and i don't have the time to study AI deep and intense, and i want, like a shortcut.\n\nMy homework is like: Create a neural network which learns something and then recognize it.\n\nPlease, guide me to some steps ( tutorials, chapters from various books etc ) so i can do this homework.\n\nAs i said, time is precious. Thanks","link_flair_css_class":null,"subreddit":"MachineLearning","media":null,"created_utc":1351548976,"banned_by":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/12avkr/do_a_simple_neural_network_with_minimum_of_ai/","gilded":0,"author":"iGalati","retrieved_on":1413451515,"num_comments":15,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a fairly good programmer, with a background of normal, procedural and object-oriented programming, using C/C++ on Unix, Java ( even on Android ) etc.&lt;/p&gt;\n\n&lt;p&gt;I have this little college project for my AI class, and i don&amp;#39;t have the time to study AI deep and intense, and i want, like a shortcut.&lt;/p&gt;\n\n&lt;p&gt;My homework is like: Create a neural network which learns something and then recognize it.&lt;/p&gt;\n\n&lt;p&gt;Please, guide me to some steps ( tutorials, chapters from various books etc ) so i can do this homework.&lt;/p&gt;\n\n&lt;p&gt;As i said, time is precious. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","stickied":false,"distinguished":null,"downs":0,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","secure_media_embed":{},"ups":0,"edited":false,"link_flair_text":null,"is_self":true,"title":"Do a simple neural network with minimum of AI study","over_18":false,"media_embed":{},"mod_reports":[],"url":"http://www.reddit.com/r/MachineLearning/comments/12avkr/do_a_simple_neural_network_with_minimum_of_ai/","user_reports":[],"id":"12avkr"}
{"retrieved_on":1413452225,"num_comments":0,"author":"[deleted]","gilded":0,"permalink":"/r/MachineLearning/comments/12ac4q/dataset_for_emotion_classification_in_social_media/","subreddit":"MachineLearning","report_reasons":null,"created_utc":1351533771,"subreddit_id":"t5_2r3gv","banned_by":null,"media":null,"score":1,"author_flair_text":null,"selftext":"Hi I would like to do emotion classification on text (posts from social media e.g. tweets, facebook wall posts). Though I can't find a good dataset with annotated data. I'm looking for more than just data annotated with positive and negative. I'm looking for a dataset with several emotions. This could be or discrete values (ekman 6 basic emotions) or continues values (arousal-valence model). Does anyone know where I can get such a dataset ?","link_flair_css_class":null,"ups":1,"secure_media_embed":{},"author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I would like to do emotion classification on text (posts from social media e.g. tweets, facebook wall posts). Though I can&amp;#39;t find a good dataset with annotated data. I&amp;#39;m looking for more than just data annotated with positive and negative. I&amp;#39;m looking for a dataset with several emotions. This could be or discrete values (ekman 6 basic emotions) or continues values (arousal-valence model). Does anyone know where I can get such a dataset ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"default","stickied":false,"title":"Dataset for emotion classification in social media","is_self":true,"edited":false,"link_flair_text":null,"url":"http://www.reddit.com/r/MachineLearning/comments/12ac4q/dataset_for_emotion_classification_in_social_media/","user_reports":[],"id":"12ac4q","media_embed":{},"mod_reports":[],"over_18":false}
{"edited":false,"link_flair_text":null,"title":"Peter Norvig reveals new developments by Google in hierarchical learning. Singularity Summit 2012","is_self":false,"over_18":false,"id":"129gsx","user_reports":[],"url":"http://fora.tv/2012/10/14/Peter_Norvig_Channeling_the_Flood_of_Data","mod_reports":[],"media_embed":{"scrolling":false,"height":264,"width":400,"content":"&lt;object type=\"application/x-shockwave-flash\" data=\"http://fora.tv/embedded_player\" width=\"400\" height=\"264\"&gt;    &lt;param name=\"movie\" value=\"http://fora.tv/embedded_player\"&gt;&lt;/param&gt;&lt;param name=\"quality\" value=\"high\"&gt;&lt;/param&gt;&lt;param name=\"allowFullScreen\" value=\"true\"&gt;&lt;/param&gt;&lt;param name=\"allowScriptAccess\" value=\"always\"&gt;&lt;/param&gt;&lt;param name=\"pluginspage\" value=\"http://www.macromedia.com/go/getflashplayer\"&gt;&lt;/param&gt;&lt;param name=\"autoplay\" value=\"false\"&gt;&lt;/param&gt;&lt;param name=\"autostart\" value=\"false\"&gt;&lt;/param&gt;&lt;param name=\"flashvars\" value=\"webhost=fora.tv&amp;clipid=16840&amp;cliptype=clip&amp;ie=f\"&gt;&lt;/param&gt;&lt;embed src=\"http://fora.tv/embedded_player\" flashvars=\"webhost=fora.tv&amp;clipid=16840&amp;cliptype=clip&amp;ie=f\" width=\"400\" height=\"264\" type=\"application/x-shockwave-flash\"&gt;&lt;/embed&gt;&lt;/object&gt;"},"created_utc":1351490136,"subreddit_id":"t5_2r3gv","banned_by":null,"report_reasons":null,"media":{"type":"fora.tv","oembed":{"thumbnail_url":"http://cdn.fora.tv/thumbnails/16840_320_240.jpg","description":"Peter Norvig, Engineering Director at Google, shares how we channel the flood of data in society.","version":"1.0","height":264,"type":"video","provider_url":"http://fora.tv","html":"&lt;object type=\"application/x-shockwave-flash\" data=\"http://fora.tv/embedded_player\" width=\"400\" height=\"264\"&gt;    &lt;param name=\"movie\" value=\"http://fora.tv/embedded_player\"&gt;&lt;/param&gt;&lt;param name=\"quality\" value=\"high\"&gt;&lt;/param&gt;&lt;param name=\"allowFullScreen\" value=\"true\"&gt;&lt;/param&gt;&lt;param name=\"allowScriptAccess\" value=\"always\"&gt;&lt;/param&gt;&lt;param name=\"pluginspage\" value=\"http://www.macromedia.com/go/getflashplayer\"&gt;&lt;/param&gt;&lt;param name=\"autoplay\" value=\"false\"&gt;&lt;/param&gt;&lt;param name=\"autostart\" value=\"false\"&gt;&lt;/param&gt;&lt;param name=\"flashvars\" value=\"webhost=fora.tv&amp;clipid=16840&amp;cliptype=clip&amp;ie=f\"&gt;&lt;/param&gt;&lt;embed src=\"http://fora.tv/embedded_player\" flashvars=\"webhost=fora.tv&amp;clipid=16840&amp;cliptype=clip&amp;ie=f\" width=\"400\" height=\"264\" type=\"application/x-shockwave-flash\"&gt;&lt;/embed&gt;&lt;/object&gt;","title":"Peter Norvig: Channeling the Flood of Data","thumbnail_height":240,"width":400,"thumbnail_width":320,"provider_name":"FORA.tv"}},"subreddit":"MachineLearning","selftext":"","link_flair_css_class":null,"score":111,"author_flair_text":null,"num_comments":8,"retrieved_on":1413453368,"gilded":0,"author":"[deleted]","permalink":"/r/MachineLearning/comments/129gsx/peter_norvig_reveals_new_developments_by_google/","downs":0,"distinguished":null,"thumbnail":"http://c.thumbs.redditmedia.com/VP4MXqVgFCHZcsRD.jpg","stickied":false,"selftext_html":null,"ups":111,"secure_media_embed":{},"domain":"fora.tv","secure_media":null,"author_flair_css_class":null}
{"subreddit":"MachineLearning","report_reasons":null,"created_utc":1351488345,"banned_by":null,"subreddit_id":"t5_2r3gv","media":{"type":"fora.tv","oembed":{"thumbnail_height":240,"thumbnail_width":320,"provider_name":"FORA.tv","width":400,"version":"1.0","thumbnail_url":"http://cdn.fora.tv/thumbnails/16840_320_240.jpg","description":"Peter Norvig, Engineering Director at Google, shares how we channel the flood of data in society.","height":264,"provider_url":"http://fora.tv","html":"&lt;object type=\"application/x-shockwave-flash\" data=\"http://fora.tv/embedded_player\" width=\"400\" height=\"264\"&gt;    &lt;param name=\"movie\" value=\"http://fora.tv/embedded_player\"&gt;&lt;/param&gt;&lt;param name=\"quality\" value=\"high\"&gt;&lt;/param&gt;&lt;param name=\"allowFullScreen\" value=\"true\"&gt;&lt;/param&gt;&lt;param name=\"allowScriptAccess\" value=\"always\"&gt;&lt;/param&gt;&lt;param name=\"pluginspage\" value=\"http://www.macromedia.com/go/getflashplayer\"&gt;&lt;/param&gt;&lt;param name=\"autoplay\" value=\"false\"&gt;&lt;/param&gt;&lt;param name=\"autostart\" value=\"false\"&gt;&lt;/param&gt;&lt;param name=\"flashvars\" value=\"webhost=fora.tv&amp;clipid=16840&amp;cliptype=clip&amp;ie=f\"&gt;&lt;/param&gt;&lt;embed src=\"http://fora.tv/embedded_player\" flashvars=\"webhost=fora.tv&amp;clipid=16840&amp;cliptype=clip&amp;ie=f\" width=\"400\" height=\"264\" type=\"application/x-shockwave-flash\"&gt;&lt;/embed&gt;&lt;/object&gt;","title":"Peter Norvig: Channeling the Flood of Data","type":"video"}},"score":1,"author_flair_text":null,"link_flair_css_class":null,"selftext":"","retrieved_on":1413453420,"num_comments":0,"gilded":0,"author":"[deleted]","permalink":"/r/MachineLearning/comments/129ff4/peter_norvig_at_the_singularity_summit_2012/","distinguished":null,"downs":0,"selftext_html":null,"stickied":false,"thumbnail":"default","ups":1,"secure_media_embed":{},"author_flair_css_class":null,"domain":"fora.tv","secure_media":null,"link_flair_text":null,"edited":false,"title":"Peter Norvig at the Singularity Summit 2012","is_self":false,"over_18":false,"url":"http://fora.tv/2012/10/14/Peter_Norvig_Channeling_the_Flood_of_Data","id":"129ff4","user_reports":[],"media_embed":{"content":"&lt;object type=\"application/x-shockwave-flash\" data=\"http://fora.tv/embedded_player\" width=\"400\" height=\"264\"&gt;    &lt;param name=\"movie\" value=\"http://fora.tv/embedded_player\"&gt;&lt;/param&gt;&lt;param name=\"quality\" value=\"high\"&gt;&lt;/param&gt;&lt;param name=\"allowFullScreen\" value=\"true\"&gt;&lt;/param&gt;&lt;param name=\"allowScriptAccess\" value=\"always\"&gt;&lt;/param&gt;&lt;param name=\"pluginspage\" value=\"http://www.macromedia.com/go/getflashplayer\"&gt;&lt;/param&gt;&lt;param name=\"autoplay\" value=\"false\"&gt;&lt;/param&gt;&lt;param name=\"autostart\" value=\"false\"&gt;&lt;/param&gt;&lt;param name=\"flashvars\" value=\"webhost=fora.tv&amp;clipid=16840&amp;cliptype=clip&amp;ie=f\"&gt;&lt;/param&gt;&lt;embed src=\"http://fora.tv/embedded_player\" flashvars=\"webhost=fora.tv&amp;clipid=16840&amp;cliptype=clip&amp;ie=f\" width=\"400\" height=\"264\" type=\"application/x-shockwave-flash\"&gt;&lt;/embed&gt;&lt;/object&gt;","width":400,"height":264,"scrolling":false},"mod_reports":[]}
{"gilded":0,"author":"dinkachik","permalink":"/r/MachineLearning/comments/12bqxc/should_i_take_intro_to_ai_before_machine_learning/","num_comments":13,"retrieved_on":1413450371,"link_flair_css_class":null,"selftext":"I am a second year computer science major really interested in AI. I've read a bit about ML and want to take a class in it. I am planning to take Intro to AI and ML together next semester. My friend said thats a bad idea to take ML before finishing Intro to AI. I really want to take both. What do you think I should do? I have a sound knowledge of all the basic data structures and algorithms including the popular graph algorithms. I have also already taken Linear Algebra and Applied Combinatorics. I haven't taken a Stats class yet.","score":4,"author_flair_text":null,"subreddit_id":"t5_2r3gv","created_utc":1351576897,"banned_by":null,"report_reasons":null,"media":null,"subreddit":"MachineLearning","domain":"self.MachineLearning","secure_media":null,"author_flair_css_class":null,"ups":4,"secure_media_embed":{},"thumbnail":"self","stickied":false,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a second year computer science major really interested in AI. I&amp;#39;ve read a bit about ML and want to take a class in it. I am planning to take Intro to AI and ML together next semester. My friend said thats a bad idea to take ML before finishing Intro to AI. I really want to take both. What do you think I should do? I have a sound knowledge of all the basic data structures and algorithms including the popular graph algorithms. I have also already taken Linear Algebra and Applied Combinatorics. I haven&amp;#39;t taken a Stats class yet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"distinguished":null,"is_self":true,"title":"Should I take Intro to AI before Machine Learning","edited":false,"link_flair_text":null,"mod_reports":[],"media_embed":{},"user_reports":[],"id":"12bqxc","url":"http://www.reddit.com/r/MachineLearning/comments/12bqxc/should_i_take_intro_to_ai_before_machine_learning/","over_18":false}
{"url":"http://www.reddit.com/r/MachineLearning/comments/12evgi/classification_when_80_of_my_training_set_is_of/","id":"12evgi","user_reports":[],"media_embed":{},"mod_reports":[],"over_18":false,"title":"Classification when 80% of my training set is of one class.","is_self":true,"edited":false,"link_flair_text":null,"secure_media_embed":{},"ups":24,"author_flair_css_class":null,"secure_media":null,"domain":"self.MachineLearning","distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to ML but I&amp;#39;ve been doing the ML course on coursera and have started messing about with Weka. I&amp;#39;m doing classification on 50,000 records where 79% of my predictor variable, y = 0. Any classification simulations I run also have a 79% success rate. Is my data set too noisy? Is there anything I can do improve this or not?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","stickied":false,"thumbnail":"self","retrieved_on":1413446190,"num_comments":15,"gilded":0,"permalink":"/r/MachineLearning/comments/12evgi/classification_when_80_of_my_training_set_is_of/","author":"adamashton","subreddit":"MachineLearning","media":null,"created_utc":1351709820,"report_reasons":null,"banned_by":null,"subreddit_id":"t5_2r3gv","author_flair_text":null,"score":24,"selftext":"I'm new to ML but I've been doing the ML course on coursera and have started messing about with Weka. I'm doing classification on 50,000 records where 79% of my predictor variable, y = 0. Any classification simulations I run also have a 79% success rate. Is my data set too noisy? Is there anything I can do improve this or not?","link_flair_css_class":null}
