{"mod_reports":[],"author_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"link_flair_css_class":null,"retrieved_on":1412102438,"banned_by":null,"media":null,"title":"Opinions on NLTK","stickied":false,"num_comments":15,"secure_media":null,"gilded":0,"domain":"self.MachineLearning","created_utc":1372708342,"report_reasons":null,"is_self":true,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1hg3f1/opinions_on_nltk/","downs":0,"author_flair_text":null,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been studying NLP for a little bit now and would like to do a project where I create a one sentence summary of a paragraph. I want to start off by analyzing sentence structure and creating a parse tree for each sentence. From the more experienced people, I&amp;#39;m wondering what are your thoughts on NLTK? Are there reason&amp;#39;s why I would write my own parser? I don&amp;#39;t have a lot of experience with NLP, so I&amp;#39;m wondering if NLTK is something I should always look at using when possible or if I would be better off learning the material myself and implementing my own tools.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"[deleted]","user_reports":[],"edited":false,"link_flair_text":null,"selftext":"Hi, I've been studying NLP for a little bit now and would like to do a project where I create a one sentence summary of a paragraph. I want to start off by analyzing sentence structure and creating a parse tree for each sentence. From the more experienced people, I'm wondering what are your thoughts on NLTK? Are there reason's why I would write my own parser? I don't have a lot of experience with NLP, so I'm wondering if NLTK is something I should always look at using when possible or if I would be better off learning the material myself and implementing my own tools.\n\nThanks in advance.","id":"1hg3f1","subreddit_id":"t5_2r3gv","thumbnail":"self","over_18":false,"ups":13,"score":13,"url":"http://www.reddit.com/r/MachineLearning/comments/1hg3f1/opinions_on_nltk/"}
{"subreddit_id":"t5_2r3gv","id":"1hfo0k","selftext":"","edited":false,"link_flair_text":null,"ups":3,"score":3,"url":"http://numenta.org/news/2013/07/01/patent-position.html","over_18":false,"thumbnail":"http://a.thumbs.redditmedia.com/vH5V8smbwg_qhoer.jpg","distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"author":"numenta","selftext_html":null,"gilded":0,"secure_media":null,"num_comments":2,"stickied":false,"title":"NuPIC Patent Position","permalink":"/r/MachineLearning/comments/1hfo0k/nupic_patent_position/","subreddit":"MachineLearning","report_reasons":null,"created_utc":1372697258,"is_self":false,"domain":"numenta.org","banned_by":null,"retrieved_on":1412103128,"link_flair_css_class":null,"author_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"mod_reports":[],"media":null}
{"over_18":false,"thumbnail":"self","ups":4,"url":"http://www.reddit.com/r/MachineLearning/comments/1hfkwg/question_about_regression_splines_or_poor_mans/","score":4,"link_flair_text":null,"edited":false,"selftext":"Hi all,\n\nI am wondering about estimating predictive variances for regression splines. In particular, I know that I could fit a cubic spline to predict the mean given some input, but what if I am interested in the output likelihood. I know that gaussian processes do this, but for reasonable size datasets with ~5000 points, gaussian processes take a long time.\n\nWhy not simply fit a local variance using another cubic spline, such that the predictive gaussian distribution is then parameterized by two local estimates.\n\nThis seems wrong, but I'm not sure why. Does anyone have any suggestions for how to think about this?\n","subreddit_id":"t5_2r3gv","id":"1hfkwg","author":"giror","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am wondering about estimating predictive variances for regression splines. In particular, I know that I could fit a cubic spline to predict the mean given some input, but what if I am interested in the output likelihood. I know that gaussian processes do this, but for reasonable size datasets with ~5000 points, gaussian processes take a long time.&lt;/p&gt;\n\n&lt;p&gt;Why not simply fit a local variance using another cubic spline, such that the predictive gaussian distribution is then parameterized by two local estimates.&lt;/p&gt;\n\n&lt;p&gt;This seems wrong, but I&amp;#39;m not sure why. Does anyone have any suggestions for how to think about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"domain":"self.MachineLearning","subreddit":"MachineLearning","is_self":true,"created_utc":1372694819,"report_reasons":null,"permalink":"/r/MachineLearning/comments/1hfkwg/question_about_regression_splines_or_poor_mans/","stickied":false,"title":"Question about regression splines OR poor man's gaussian processes?","gilded":0,"num_comments":8,"secure_media":null,"media":null,"mod_reports":[],"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"retrieved_on":1412103274,"banned_by":null}
{"gilded":0,"num_comments":1,"secure_media":null,"stickied":false,"title":"PeerRush: Mining for Unwanted P2P Traffic","permalink":"/r/MachineLearning/comments/1hfbtt/peerrush_mining_for_unwanted_p2p_traffic/","subreddit":"MachineLearning","is_self":false,"created_utc":1372686807,"report_reasons":null,"domain":"cs.uga.edu","banned_by":null,"retrieved_on":1412103721,"link_flair_css_class":null,"author_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"mod_reports":[],"media":null,"subreddit_id":"t5_2r3gv","id":"1hfbtt","selftext":"","link_flair_text":null,"edited":false,"url":"http://www.cs.uga.edu/~kangli/src/dimva2013.pdf","ups":4,"score":4,"over_18":false,"thumbnail":"default","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"author":"goonmaster","selftext_html":null}
{"id":"1hf4me","subreddit_id":"t5_2r3gv","selftext":"","edited":false,"link_flair_text":null,"score":0,"ups":0,"url":"http://www.proboatparts.com/boat-parts/","thumbnail":"default","over_18":false,"distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"selftext_html":null,"author":"lyrictroy","num_comments":0,"secure_media":null,"gilded":0,"title":"boat parts","stickied":false,"permalink":"/r/MachineLearning/comments/1hf4me/boat_parts/","created_utc":1372676892,"report_reasons":null,"is_self":false,"subreddit":"MachineLearning","domain":"proboatparts.com","retrieved_on":1412104271,"banned_by":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"link_flair_css_class":null,"mod_reports":[],"media":null}
{"score":21,"ups":21,"url":"https://www.youtube.com/watch?feature=player_embedded&amp;v=8hupHmBVvb0","thumbnail":"http://c.thumbs.redditmedia.com/VIJyyn-Y0qwxQr62.jpg","over_18":false,"id":"1hetj7","subreddit_id":"t5_2r3gv","selftext":"","edited":false,"link_flair_text":null,"user_reports":[],"selftext_html":null,"author":"rrenaud","distinguished":null,"downs":0,"author_flair_text":null,"permalink":"/r/MachineLearning/comments/1hetj7/jerome_friedman_on_the_genesis_of_decision_trees/","created_utc":1372658430,"report_reasons":null,"is_self":false,"subreddit":"MachineLearning","domain":"youtube.com","secure_media":null,"num_comments":0,"gilded":0,"title":"Jerome Friedman on the genesis of decision trees","stickied":false,"media":{"oembed":{"provider_url":"http://www.youtube.com/","title":"Jerome Friedman, Data Mining Software Founding Father","thumbnail_width":480,"html":"&lt;iframe width=\"600\" height=\"450\" src=\"http://www.youtube.com/embed/8hupHmBVvb0?feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","author_url":"http://www.youtube.com/user/salforddatamining","thumbnail_height":360,"version":"1.0","provider_name":"YouTube","type":"video","height":450,"author_name":"salforddatamining","description":"http://www.salford-systems.com Jerome Friedman, a founding father of CART, traces the events that led him to working with decision trees.","width":600,"url":"http://www.youtube.com/watch?v=8hupHmBVvb0","thumbnail_url":"http://i1.ytimg.com/vi/8hupHmBVvb0/hqdefault.jpg"},"type":"youtube.com"},"retrieved_on":1412104781,"banned_by":null,"author_flair_css_class":null,"media_embed":{"content":"&lt;iframe width=\"600\" height=\"450\" src=\"http://www.youtube.com/embed/8hupHmBVvb0?feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","scrolling":false,"width":600,"height":450},"secure_media_embed":{},"link_flair_css_class":null,"mod_reports":[]}
{"id":"1heipd","subreddit_id":"t5_2r3gv","selftext":"","link_flair_text":null,"edited":false,"ups":7,"score":7,"url":"http://jonfwilkins.com/2013/06/swarm-based-legal-action/","thumbnail":"default","over_18":false,"distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"selftext_html":null,"author":"DevFRus","secure_media":null,"num_comments":0,"gilded":0,"title":"Swarm optimization to refine legal strategies when agents can't form a class-action lawsuit.","stickied":false,"permalink":"/r/MachineLearning/comments/1heipd/swarm_optimization_to_refine_legal_strategies/","created_utc":1372647643,"is_self":false,"report_reasons":null,"subreddit":"MachineLearning","domain":"jonfwilkins.com","retrieved_on":1412105291,"banned_by":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"media":null}
{"retrieved_on":1412105291,"banned_by":null,"mod_reports":[],"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"num_comments":7,"secure_media":null,"gilded":0,"title":"Geoff Hinton on his new approach to deep neural networks: DREDNETs","stickied":false,"permalink":"/r/MachineLearning/comments/1heiol/geoff_hinton_on_his_new_approach_to_deep_neural/","domain":"techtalks.tv","report_reasons":null,"created_utc":1372647623,"is_self":false,"subreddit":"MachineLearning","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"selftext_html":null,"author":"rudyl313","selftext":"","id":"1heiol","subreddit_id":"t5_2r3gv","link_flair_text":null,"edited":false,"ups":50,"url":"http://techtalks.tv/talks/drednets/58115/","score":50,"thumbnail":"default","over_18":false}
{"stickied":false,"title":"Hierarchical clustering of phrases in audio?","gilded":0,"num_comments":3,"secure_media":null,"subreddit":"MachineLearning","is_self":true,"created_utc":1372794620,"report_reasons":null,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1hinoo/hierarchical_clustering_of_phrases_in_audio/","link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"mod_reports":[],"banned_by":null,"retrieved_on":1412098434,"media":null,"edited":false,"link_flair_text":null,"subreddit_id":"t5_2r3gv","id":"1hinoo","selftext":"I'm analyzing audio segments in songs. I want to find phrases: groups of segments which may repeat several times in the song. I want to hierarchically group phrases of phrases.\n\nA segment is a slice of audio usually 100-1000ms long. Python's echonest analyzer gives me a bunch of features to work with per segment (pitch vector, timbre vector, envelope vector).\n\nNo two segments are identical, but the euclidean distance of their feature vectors will be close. \n\nWhat kind of hierarchical phrase clustering algorithm works well for that? \n\nThe first thing I thought of was k-means on every segment, to reduce the dimensionality of all the data to a string of k different kinds of segment. Then using some kind of string compression algorithm that recursively looks for the most common n-grams. Thoughts?","over_18":false,"thumbnail":"self","score":8,"ups":8,"url":"http://www.reddit.com/r/MachineLearning/comments/1hinoo/hierarchical_clustering_of_phrases_in_audio/","downs":0,"author_flair_text":null,"distinguished":null,"author":"Cortexelus","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m analyzing audio segments in songs. I want to find phrases: groups of segments which may repeat several times in the song. I want to hierarchically group phrases of phrases.&lt;/p&gt;\n\n&lt;p&gt;A segment is a slice of audio usually 100-1000ms long. Python&amp;#39;s echonest analyzer gives me a bunch of features to work with per segment (pitch vector, timbre vector, envelope vector).&lt;/p&gt;\n\n&lt;p&gt;No two segments are identical, but the euclidean distance of their feature vectors will be close. &lt;/p&gt;\n\n&lt;p&gt;What kind of hierarchical phrase clustering algorithm works well for that? &lt;/p&gt;\n\n&lt;p&gt;The first thing I thought of was k-means on every segment, to reduce the dimensionality of all the data to a string of k different kinds of segment. Then using some kind of string compression algorithm that recursively looks for the most common n-grams. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[]}
{"media":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412099172,"banned_by":null,"report_reasons":null,"created_utc":1372782827,"is_self":false,"subreddit":"MachineLearning","domain":"guardian.co.uk","permalink":"/r/MachineLearning/comments/1hi7da/how_algorithms_rule_the_world_the_ubiquity_of/","title":"How algorithms rule the world: the ubiquity of machine-learning","stickied":false,"num_comments":4,"secure_media":null,"gilded":0,"selftext_html":null,"author":"DevFRus","user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null,"thumbnail":"http://c.thumbs.redditmedia.com/XeEnkExENBYXGUtn.jpg","over_18":false,"ups":36,"url":"http://www.guardian.co.uk/science/2013/jul/01/how-algorithms-rule-world-nsa","score":36,"link_flair_text":null,"edited":false,"id":"1hi7da","subreddit_id":"t5_2r3gv","selftext":""}
{"media":null,"mod_reports":[],"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"retrieved_on":1412099744,"banned_by":null,"domain":"technologyreview.com","subreddit":"MachineLearning","report_reasons":null,"created_utc":1372772515,"is_self":false,"permalink":"/r/MachineLearning/comments/1hhuwo/facial_analysis_software_now_detects_struggling/","stickied":false,"title":"Facial Analysis software now detects struggling students and professors get a better feedback (MIT Research)","gilded":0,"num_comments":1,"secure_media":null,"author":"obsoletelearner","selftext_html":null,"user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null,"over_18":false,"thumbnail":"default","score":1,"ups":1,"url":"http://www.technologyreview.com/news/516606/facial-analysis-software-spots-struggling-students/?utm_campaign=socialsync&amp;utm_medium=social-post&amp;utm_source=facebook","link_flair_text":null,"edited":false,"selftext":"","subreddit_id":"t5_2r3gv","id":"1hhuwo"}
{"distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"author":"hammerheadquark","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I am researching clustering algorithms for data that is not numeric. I am not at liberty to discuss exactly on what data I&amp;#39;m clustering (it&amp;#39;s proprietary information), but I can give you an idea of the kind of data I have. Also, I am somewhat new to this area of study. Please let me know if my understanding is off and I should be trying different things.&lt;/p&gt;\n\n&lt;p&gt;So, pretty much all of the clustering algorithms I&amp;#39;ve come across so far use some notion of distance to find clusters. This is fine if your data is numeric and it has some intrinsic &lt;em&gt;value&lt;/em&gt; that we find meaningful. For example, we would consider the value of a housing price meaningful because we could compare two instances of it in a helpful way: $200k - $150k = $50k lets us know that the value of the first price is more than the second. A distance measure would thus be helpful in this case. This is not so for categorical data. Categorical data is where the instances of the feature all fall into a set with no natural ordering. Car makes, for example, would be considered categorical data. We would find no meaning in comparing the names of two manufacturers in the same way we did the housing prices: Ford - Toyota = ??? is not very helpful. Even if we assigned numbers to the categories, the distances we would find would be arbitrary and hence meaningless.&lt;/p&gt;\n\n&lt;p&gt;My data is a mix of these two things. I have numeric, categorical, and boolean features in my data sets (I consider boolean data a subset of categorical data, although we &lt;em&gt;might&lt;/em&gt; find boolean distances meaningful with proper scaling). My research so far has turned up these two promising-ish papers:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"http://arxiv.org/ftp/cs/papers/0509/0509011.pdf\"&gt;Clustering Mixed Numeric and Categorical Data: A Cluster Ensemble Approach&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"http://www.cis.upenn.edu/%7Esudipto/mypapers/categorical.pdf\"&gt;Rock: A Robust Categorical Algorithm for Clustering Attributes&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I don&amp;#39;t know if these are quite what I&amp;#39;m looking for. They seem a bit hand-wavey about certain things (especially the first), but the other papers I found were much worse. Is there anyone on here who has experience with trying to cluster this type of data? If so, could you point me in the direction of some decent papers to read up on?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; - I need to cluster mixed categorical and numeric data. Know of any good papers?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;edit:&lt;/strong&gt; I was told you guys would be more suited to answer this question. Please let me know if somewhere else would be better. Thanks in advance.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;edit2:&lt;/strong&gt; Also, if you know of a good paper but there is a pay wall, don&amp;#39;t worry. Just link it as I can get access to almost any publication through our library.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;edit3:&lt;/strong&gt; Thanks all! This was extremely helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","subreddit_id":"t5_2r3gv","id":"1hhspf","selftext":"Hi all!\n\nI am researching clustering algorithms for data that is not numeric. I am not at liberty to discuss exactly on what data I'm clustering (it's proprietary information), but I can give you an idea of the kind of data I have. Also, I am somewhat new to this area of study. Please let me know if my understanding is off and I should be trying different things.\n\nSo, pretty much all of the clustering algorithms I've come across so far use some notion of distance to find clusters. This is fine if your data is numeric and it has some intrinsic *value* that we find meaningful. For example, we would consider the value of a housing price meaningful because we could compare two instances of it in a helpful way: $200k - $150k = $50k lets us know that the value of the first price is more than the second. A distance measure would thus be helpful in this case. This is not so for categorical data. Categorical data is where the instances of the feature all fall into a set with no natural ordering. Car makes, for example, would be considered categorical data. We would find no meaning in comparing the names of two manufacturers in the same way we did the housing prices: Ford - Toyota = ??? is not very helpful. Even if we assigned numbers to the categories, the distances we would find would be arbitrary and hence meaningless.\n\nMy data is a mix of these two things. I have numeric, categorical, and boolean features in my data sets (I consider boolean data a subset of categorical data, although we *might* find boolean distances meaningful with proper scaling). My research so far has turned up these two promising-ish papers:\n\n* [Clustering Mixed Numeric and Categorical Data: A Cluster Ensemble Approach](http://arxiv.org/ftp/cs/papers/0509/0509011.pdf)\n\n* [Rock: A Robust Categorical Algorithm for Clustering Attributes](http://www.cis.upenn.edu/~sudipto/mypapers/categorical.pdf)\n\nI don't know if these are quite what I'm looking for. They seem a bit hand-wavey about certain things (especially the first), but the other papers I found were much worse. Is there anyone on here who has experience with trying to cluster this type of data? If so, could you point me in the direction of some decent papers to read up on?\n\nThanks in advance!\n\n**tl;dr** - I need to cluster mixed categorical and numeric data. Know of any good papers?\n\n**edit:** I was told you guys would be more suited to answer this question. Please let me know if somewhere else would be better. Thanks in advance.\n\n**edit2:** Also, if you know of a good paper but there is a pay wall, don't worry. Just link it as I can get access to almost any publication through our library.\n\n**edit3:** Thanks all! This was extremely helpful.","edited":1372800301,"link_flair_text":null,"score":11,"ups":11,"url":"http://www.reddit.com/r/MachineLearning/comments/1hhspf/xpost_from_ralgorithms_clustering_on_nonnumeric/","over_18":false,"thumbnail":"self","retrieved_on":1412099845,"banned_by":null,"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"mod_reports":[],"media":null,"gilded":0,"num_comments":45,"secure_media":null,"stickied":false,"title":"[xpost from /r/algorithms] Clustering on non-numeric (categorical) data","permalink":"/r/MachineLearning/comments/1hhspf/xpost_from_ralgorithms_clustering_on_nonnumeric/","subreddit":"MachineLearning","is_self":true,"created_utc":1372770237,"report_reasons":null,"domain":"self.MachineLearning"}
{"stickied":false,"title":"Large Scale Document Clustering: Clustering and Searching 50 Million Web Pages","gilded":0,"num_comments":0,"secure_media":null,"subreddit":"MachineLearning","is_self":false,"created_utc":1372757039,"report_reasons":null,"domain":"chris.de-vries.id.au","permalink":"/r/MachineLearning/comments/1hhk39/large_scale_document_clustering_clustering_and/","link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"mod_reports":[],"retrieved_on":1412100213,"banned_by":null,"media":null,"edited":false,"link_flair_text":null,"subreddit_id":"t5_2r3gv","id":"1hhk39","selftext":"","over_18":false,"thumbnail":"default","ups":1,"url":"http://chris.de-vries.id.au/2013/07/large-scale-document-clustering.html","score":1,"downs":0,"author_flair_text":null,"distinguished":null,"author":"cmmdevries","selftext_html":null,"user_reports":[]}
{"title":"How can I quickly find data that causes some output of a neural net?","stickied":false,"num_comments":22,"secure_media":null,"gilded":0,"domain":"self.MachineLearning","is_self":true,"created_utc":1372748923,"report_reasons":null,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1hhf6y/how_can_i_quickly_find_data_that_causes_some/","mod_reports":[],"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"retrieved_on":1412100415,"banned_by":null,"media":null,"edited":1373012390,"link_flair_text":null,"selftext":"I could do backprop and learn the input values that maximize the probability of the output, but this would take a while, and since I have to do it many times it is undesirable.\n\nIt may help if there is a fast algorithm to do this for a single layer net, because I could settle for finding activations in the second to last layer that maximize the likelihood of the output, and then repeat on previous layers until I have input values.\n\nAnother approach would be to train some reconstruction weights to reconstruct the layer below after each feedforward pass during learning, as in the wake sleep algorithm for deep belief nets, but this would suffer from 'explaining away', because the net isn't a deep belief net. (In a deep belief net, the forward weights learn features that are able to be easily reconstructed via the reconstruction weights, thus explaining away explaining away.) My nets are trained to predict a target function, so I don't see any way around explaining away.\n\nI'd love to hear your thoughts, and hopefully see any links to relevant papers that you might have.\n\n**Edit:** I've posted this question here to help me brainstorm before I actually implement anything.\n\n**Edit:** The reason I wanted to find data with this property is that I am training a net to discriminate between genuine data and potentially fabricated data. I need to constantly make fake data that the net will think is real and use those fabricated data as negative examples in the training set. We discussed an algorithm for this in the comments, in which one initializes some fabricated particles, and for each minibatch, we adjust the fabricated particles to make them more believable, and then train the net to accept the current minibatch, and reject the fabricated particles. The learning always makes the fabricated particles less believable, so they are expected to mix quite quickly, exploring a huge space of fake data for the net to learn to reject.\n\nI implemented this persistent CD like algorithm that we discussed, and tested it using the MNIST data set. I used examples from the cross validation set to initialize the fabricated particles, as is common practice for persistent CD. For some reason the fabricated particles don't mix at all. The pixels of the fabricated particles quickly hardened to either completely on or completely off right as learning started, and then changed little for the rest of learning. Even a smudge that wasn't part of a digit hardened and stayed until the end of learning.\n\nThe features that the model learned for discriminating this static fabricated data from the training data were just blobs of mixed color pixels, surrounded by nothing in the areas that almost no digit occupies. Something is amiss.","id":"1hhf6y","subreddit_id":"t5_2r3gv","thumbnail":"self","over_18":false,"score":9,"ups":9,"url":"http://www.reddit.com/r/MachineLearning/comments/1hhf6y/how_can_i_quickly_find_data_that_causes_some/","downs":0,"author_flair_text":null,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I could do backprop and learn the input values that maximize the probability of the output, but this would take a while, and since I have to do it many times it is undesirable.&lt;/p&gt;\n\n&lt;p&gt;It may help if there is a fast algorithm to do this for a single layer net, because I could settle for finding activations in the second to last layer that maximize the likelihood of the output, and then repeat on previous layers until I have input values.&lt;/p&gt;\n\n&lt;p&gt;Another approach would be to train some reconstruction weights to reconstruct the layer below after each feedforward pass during learning, as in the wake sleep algorithm for deep belief nets, but this would suffer from &amp;#39;explaining away&amp;#39;, because the net isn&amp;#39;t a deep belief net. (In a deep belief net, the forward weights learn features that are able to be easily reconstructed via the reconstruction weights, thus explaining away explaining away.) My nets are trained to predict a target function, so I don&amp;#39;t see any way around explaining away.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your thoughts, and hopefully see any links to relevant papers that you might have.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; I&amp;#39;ve posted this question here to help me brainstorm before I actually implement anything.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; The reason I wanted to find data with this property is that I am training a net to discriminate between genuine data and potentially fabricated data. I need to constantly make fake data that the net will think is real and use those fabricated data as negative examples in the training set. We discussed an algorithm for this in the comments, in which one initializes some fabricated particles, and for each minibatch, we adjust the fabricated particles to make them more believable, and then train the net to accept the current minibatch, and reject the fabricated particles. The learning always makes the fabricated particles less believable, so they are expected to mix quite quickly, exploring a huge space of fake data for the net to learn to reject.&lt;/p&gt;\n\n&lt;p&gt;I implemented this persistent CD like algorithm that we discussed, and tested it using the MNIST data set. I used examples from the cross validation set to initialize the fabricated particles, as is common practice for persistent CD. For some reason the fabricated particles don&amp;#39;t mix at all. The pixels of the fabricated particles quickly hardened to either completely on or completely off right as learning started, and then changed little for the rest of learning. Even a smudge that wasn&amp;#39;t part of a digit hardened and stayed until the end of learning.&lt;/p&gt;\n\n&lt;p&gt;The features that the model learned for discriminating this static fabricated data from the training data were just blobs of mixed color pixels, surrounded by nothing in the areas that almost no digit occupies. Something is amiss.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"justonium","user_reports":[]}
{"retrieved_on":1412101109,"banned_by":null,"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"mod_reports":[],"media":null,"gilded":0,"num_comments":23,"secure_media":null,"stickied":false,"title":"Best Python IDE for Predictive Analytics and machine learning","permalink":"/r/MachineLearning/comments/1hgxwx/best_python_ide_for_predictive_analytics_and/","subreddit":"MachineLearning","created_utc":1372732072,"is_self":true,"report_reasons":null,"domain":"self.MachineLearning","distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"author":"mrlovell","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you think it the best Python IDE for debugging support, refactoring, etc when dealing in predictive analytics and machine learning?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","subreddit_id":"t5_2r3gv","id":"1hgxwx","selftext":"What do you think it the best Python IDE for debugging support, refactoring, etc when dealing in predictive analytics and machine learning?","link_flair_text":null,"edited":false,"score":15,"ups":15,"url":"http://www.reddit.com/r/MachineLearning/comments/1hgxwx/best_python_ide_for_predictive_analytics_and/","over_18":false,"thumbnail":"self"}
{"id":"1hkzgp","subreddit_id":"t5_2r3gv","selftext":"","link_flair_text":null,"edited":false,"ups":1,"score":1,"url":"http://www.r-bloggers.com/the-r-journal-volume-51-june-2013/","thumbnail":"default","over_18":false,"distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"selftext_html":null,"author":"talgalili","num_comments":0,"secure_media":null,"gilded":0,"title":"The R journal – Volume 5/1, June 2013 - has been released!","stickied":false,"permalink":"/r/MachineLearning/comments/1hkzgp/the_r_journal_volume_51_june_2013_has_been/","created_utc":1372876242,"is_self":false,"report_reasons":null,"subreddit":"MachineLearning","domain":"r-bloggers.com","banned_by":null,"retrieved_on":1412094595,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"media":null}
{"author_flair_text":null,"downs":0,"distinguished":null,"selftext_html":null,"author":"[deleted]","user_reports":[],"link_flair_text":null,"edited":false,"selftext":"","id":"1hk07j","subreddit_id":"t5_2r3gv","thumbnail":"http://d.thumbs.redditmedia.com/9DKBqM_URcfUzUdQ.jpg","over_18":false,"ups":21,"score":21,"url":"http://www.kickstarter.com/projects/jeffheaton/artificial-intelligence-for-humans-vol-1-fund-algo","mod_reports":[],"secure_media_embed":{},"media_embed":{"content":"&lt;iframe frameborder=\"0\" height=\"360\" src=\"http://www.kickstarter.com/projects/jeffheaton/artificial-intelligence-for-humans-vol-1-fund-algo/widget/video.html\" width=\"480\" border=\"0\" scrolling=\"no\"&gt;&lt;/iframe&gt;","scrolling":false,"width":480,"height":360},"author_flair_css_class":null,"link_flair_css_class":null,"banned_by":null,"retrieved_on":1412096234,"media":{"type":"kickstarter.com","oembed":{"version":"1.0","thumbnail_height":480,"provider_name":"Kickstarter","description":"Jeff Heaton is raising funds for Artificial Intelligence for Humans, Vol 1: Fund. Algorithms on Kickstarter! The first in a series of books to teach Artificial Intelligence with a gentle approach to mathematics.","author_name":"Jeff Heaton","width":480,"height":360,"type":"rich","thumbnail_url":"https://s3.amazonaws.com/ksr/projects/571584/photo-main.jpg?1370365684","title":"Artificial Intelligence for Humans, Vol 1: Fund. Algorithms","provider_url":"http://www.kickstarter.com/","html":"&lt;iframe frameborder=\"0\" height=\"360\" src=\"http://www.kickstarter.com/projects/jeffheaton/artificial-intelligence-for-humans-vol-1-fund-algo/widget/video.html\" width=\"480\" border=\"0\" scrolling=\"no\"&gt;&lt;/iframe&gt;","thumbnail_width":640,"author_url":"http://www.kickstarter.com/profile/jeffheaton"}},"title":"Artificial Intelligence for Humans - Fundamental Algorithms [KickStarter]","stickied":false,"num_comments":4,"secure_media":null,"gilded":0,"domain":"kickstarter.com","created_utc":1372837883,"is_self":false,"report_reasons":null,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1hk07j/artificial_intelligence_for_humans_fundamental/"}
{"media":null,"retrieved_on":1412090891,"banned_by":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1hn9gf/a_series_of_blog_posts_about_biclustering/","report_reasons":null,"created_utc":1372961111,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","num_comments":8,"secure_media":null,"gilded":0,"title":"A series of blog posts about biclustering","stickied":false,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This summer I am implementing biclustering algorithms for the &lt;a href=\"http://scikit-learn.org/stable/\"&gt;scikit-learn&lt;/a&gt; machine learning library and blogging about my progress. I thought some people on &lt;a href=\"/r/MachineLearning\"&gt;/r/MachineLearning&lt;/a&gt; might find them useful.&lt;/p&gt;\n\n&lt;p&gt;So far I have written two articles:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"http://www.kemaleren.com/an-introduction-to-biclustering.html\"&gt;An introduction to biclustering&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"http://www.kemaleren.com/spectral-biclustering-part-1.html\"&gt;Spectral biclustering, part 1&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"kemal_eren","distinguished":null,"author_flair_text":null,"downs":0,"url":"http://www.reddit.com/r/MachineLearning/comments/1hn9gf/a_series_of_blog_posts_about_biclustering/","ups":33,"score":33,"thumbnail":"self","over_18":false,"id":"1hn9gf","subreddit_id":"t5_2r3gv","selftext":"\nThis summer I am implementing biclustering algorithms for the [scikit-learn](http://scikit-learn.org/stable/) machine learning library and blogging about my progress. I thought some people on /r/MachineLearning might find them useful.\n\nSo far I have written two articles:\n\n1. [An introduction to biclustering](http://www.kemaleren.com/an-introduction-to-biclustering.html)\n\n2. [Spectral biclustering, part 1](http://www.kemaleren.com/spectral-biclustering-part-1.html)\n","link_flair_text":null,"edited":false}
{"retrieved_on":1412091149,"banned_by":null,"link_flair_css_class":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"mod_reports":[],"media":null,"gilded":0,"num_comments":0,"secure_media":null,"stickied":false,"title":"Fast Dropout Training [pdf warning]","permalink":"/r/MachineLearning/comments/1hn3ka/fast_dropout_training_pdf_warning/","subreddit":"MachineLearning","report_reasons":null,"created_utc":1372956030,"is_self":false,"domain":"jmlr.org","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"author":"Derpscientist","selftext_html":null,"subreddit_id":"t5_2r3gv","id":"1hn3ka","selftext":"","edited":false,"link_flair_text":null,"ups":1,"score":1,"url":"http://jmlr.org/proceedings/papers/v28/wang13a.pdf","over_18":false,"thumbnail":"default"}
{"retrieved_on":1412093403,"banned_by":null,"author_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"link_flair_css_class":null,"mod_reports":[],"media":null,"num_comments":25,"secure_media":null,"gilded":0,"title":"Came across something intriguing called Grey System Theory - anyone here heard of it? Apparently even with tiny data sets (as few as 4-6 data points), it's capable of outperforming many bread-and-butter time series algorithms with 10-100x larger data sets.","stickied":false,"permalink":"/r/MachineLearning/comments/1hlpz9/came_across_something_intriguing_called_grey/","report_reasons":null,"created_utc":1372897351,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You can read a few papers about it at &lt;a href=\"http://scholar.google.com/scholar?as_vis=1&amp;amp;q=%22grey+system+theory%22+OR+%22gray+system+theory%22&amp;amp;hl=en&amp;amp;as_sdt=1,21\"&gt;Scholar Google&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the &lt;a href=\"https://docs.google.com/viewer?url=http%3A%2F%2Fwww.researchinformation.co.uk%2Fgrey%2FIntroGreySysTheory.pdf\"&gt;paper&lt;/a&gt; introducing the theory.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m baffled that something so promising could be so obscure (there&amp;#39;s no article about it @ Wikipedia). Did the articles oversell Grey System? &lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t had a chance to read the introductory article yet, and only skimmed through the other articles to get a gist. I&amp;#39;m not really qualified to judge the merit of a predictive algorithm even if I were to read through everything anyway. Hopefully somebody is capable of enlightening me as well as the future interested parties.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"randombozo","id":"1hlpz9","subreddit_id":"t5_2r3gv","selftext":"You can read a few papers about it at [Scholar Google](http://scholar.google.com/scholar?as_vis=1&amp;q=%22grey+system+theory%22+OR+%22gray+system+theory%22&amp;hl=en&amp;as_sdt=1,21)\n\nHere's the [paper](https://docs.google.com/viewer?url=http%3A%2F%2Fwww.researchinformation.co.uk%2Fgrey%2FIntroGreySysTheory.pdf) introducing the theory.\n\nI'm baffled that something so promising could be so obscure (there's no article about it @ Wikipedia). Did the articles oversell Grey System? \n\nI haven't had a chance to read the introductory article yet, and only skimmed through the other articles to get a gist. I'm not really qualified to judge the merit of a predictive algorithm even if I were to read through everything anyway. Hopefully somebody is capable of enlightening me as well as the future interested parties.","edited":false,"link_flair_text":null,"score":20,"ups":20,"url":"http://www.reddit.com/r/MachineLearning/comments/1hlpz9/came_across_something_intriguing_called_grey/","thumbnail":"self","over_18":false}
{"author":"[deleted]","selftext_html":null,"user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null,"over_18":false,"thumbnail":"http://d.thumbs.redditmedia.com/Ha5qHUzcdABSltb9.jpg","score":35,"ups":35,"url":"https://www.youtube.com/watch?v=aObBHXsc_iw","link_flair_text":null,"edited":false,"selftext":"","subreddit_id":"t5_2r3gv","id":"1hpvl1","media":{"type":"youtube.com","oembed":{"author_url":"http://www.youtube.com/user/drdanhaupt","thumbnail_width":480,"html":"&lt;iframe width=\"600\" height=\"450\" src=\"http://www.youtube.com/embed/aObBHXsc_iw?feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","title":"Flying Heavy Metal Episode Four: Safer Skies-Part 1 HQ","provider_url":"http://www.youtube.com/","thumbnail_url":"http://i1.ytimg.com/vi/aObBHXsc_iw/hqdefault.jpg","url":"http://www.youtube.com/watch?v=aObBHXsc_iw","author_name":"drdanhaupt","description":"Bruce Dickinson of Iron Maiden presents the history of jet travel from his perspective as a Boeing 757 pilot for the UK airline Astraeus. A total of five episodes include historical footage from manufacturer's archives, including a test pilot completing an unauthorized barrel roll in the Boeing 707.","width":600,"type":"video","height":450,"provider_name":"YouTube","version":"1.0","thumbnail_height":360}},"mod_reports":[],"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{"content":"&lt;iframe width=\"600\" height=\"450\" src=\"http://www.youtube.com/embed/aObBHXsc_iw?feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","scrolling":false,"height":450,"width":600},"author_flair_css_class":null,"banned_by":null,"retrieved_on":1412086610,"domain":"youtube.com","subreddit":"MachineLearning","created_utc":1373065624,"report_reasons":null,"is_self":false,"permalink":"/r/MachineLearning/comments/1hpvl1/nasa_neural_networks_regain_control_in_the_case/","stickied":false,"title":"NASA neural networks regain control in the case of aviation control failure. Interesting application.","gilded":0,"secure_media":null,"num_comments":6}
{"mod_reports":[],"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"retrieved_on":1412087664,"banned_by":null,"media":null,"title":"Machine learning: Macroeconomics needs you!","stickied":false,"secure_media":null,"num_comments":0,"gilded":0,"domain":"voxeu.org","report_reasons":null,"created_utc":1373044886,"is_self":false,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1hp85f/machine_learning_macroeconomics_needs_you/","author_flair_text":null,"downs":0,"distinguished":null,"selftext_html":null,"author":"[deleted]","user_reports":[],"edited":false,"link_flair_text":null,"selftext":"","id":"1hp85f","subreddit_id":"t5_2r3gv","thumbnail":"default","over_18":false,"url":"http://www.voxeu.org/article/failed-forecasts-and-financial-crisis-how-resurrect-economic-modelling","ups":0,"score":0}
{"mod_reports":[],"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"link_flair_css_class":null,"banned_by":null,"retrieved_on":1412088160,"media":null,"title":"Basic [1 hidden layer] neural network in Python","stickied":false,"secure_media":null,"num_comments":8,"gilded":0,"domain":"danielfrg.github.io","created_utc":1373034808,"is_self":false,"report_reasons":null,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1hoxaf/basic_1_hidden_layer_neural_network_in_python/","author_flair_text":null,"downs":0,"distinguished":null,"selftext_html":null,"author":"turnersr","user_reports":[],"edited":false,"link_flair_text":null,"selftext":"","id":"1hoxaf","subreddit_id":"t5_2r3gv","thumbnail":"default","over_18":false,"ups":15,"url":"http://danielfrg.github.io/blog/2013/07/03/basic-neural-network-python/","score":15}
{"num_comments":8,"secure_media":null,"gilded":0,"title":"I'm looking for sequential binary data for which the mutual information between bits decays smoothely with distance.","stickied":false,"permalink":"/r/MachineLearning/comments/1htiy0/im_looking_for_sequential_binary_data_for_which/","created_utc":1373229134,"report_reasons":null,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","retrieved_on":1412080721,"banned_by":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"link_flair_css_class":null,"mod_reports":[],"media":null,"id":"1htiy0","subreddit_id":"t5_2r3gv","selftext":"The data that I'm currently using is 1 bit sound, but it doesn't work because there are long stretches of either all 1's or all 0's, due to the frequencies being orders of magnitude lower than the sample rate. I'm reluctant to use higher bit rate sound because to make it binary I would have to splice together the bit vectors that represent each sample, causing the mutual information versus bit distance in the sequence to be choppy for small bit distances.\n\nThe reason that I need the property of smoothly decaying mutual information versus bit distance within the sequence is that I am training a generative model using a greedy DP algorithm.","edited":1373229673,"link_flair_text":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1htiy0/im_looking_for_sequential_binary_data_for_which/","ups":4,"score":4,"thumbnail":"self","over_18":false,"distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The data that I&amp;#39;m currently using is 1 bit sound, but it doesn&amp;#39;t work because there are long stretches of either all 1&amp;#39;s or all 0&amp;#39;s, due to the frequencies being orders of magnitude lower than the sample rate. I&amp;#39;m reluctant to use higher bit rate sound because to make it binary I would have to splice together the bit vectors that represent each sample, causing the mutual information versus bit distance in the sequence to be choppy for small bit distances.&lt;/p&gt;\n\n&lt;p&gt;The reason that I need the property of smoothly decaying mutual information versus bit distance within the sequence is that I am training a generative model using a greedy DP algorithm.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"justonium"}
{"gilded":0,"num_comments":5,"secure_media":null,"stickied":false,"title":"Processing large files, line by line","permalink":"/r/MachineLearning/comments/1hsqa5/processing_large_files_line_by_line/","subreddit":"MachineLearning","report_reasons":null,"created_utc":1373195392,"is_self":false,"domain":"fastml.com","banned_by":null,"retrieved_on":1412081973,"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"mod_reports":[],"media":null,"subreddit_id":"t5_2r3gv","id":"1hsqa5","selftext":"","edited":false,"link_flair_text":null,"score":0,"ups":0,"url":"http://fastml.com/processing-large-files-line-by-line/","over_18":false,"thumbnail":"default","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"author":"Foxtr0t","selftext_html":null}
{"permalink":"/r/MachineLearning/comments/1hw6bk/opinion_a_correlation_for_the_21st_century/","subreddit":"MachineLearning","created_utc":1373321378,"is_self":true,"report_reasons":null,"domain":"self.MachineLearning","gilded":0,"secure_media":null,"num_comments":27,"stickied":false,"title":"Opinion?: \"A correlation for the 21st century\"","media":null,"banned_by":null,"retrieved_on":1412076565,"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"mod_reports":[],"ups":16,"score":16,"url":"http://www.reddit.com/r/MachineLearning/comments/1hw6bk/opinion_a_correlation_for_the_21st_century/","over_18":false,"thumbnail":"self","subreddit_id":"t5_2r3gv","id":"1hw6bk","selftext":"Ref: http://www.sciencemag.org/content/334/6062/1502\n\nWhat does r/ML think about the MIC correlation-measure proposed in the article above? Digging deeper into what people are saying about the paper referred to by the article reveals some criticisms (eg. http://en.wikipedia.org/wiki/Maximal_information_coefficient). ","edited":false,"link_flair_text":null,"user_reports":[],"author":"satsatsat","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ref: &lt;a href=\"http://www.sciencemag.org/content/334/6062/1502\"&gt;http://www.sciencemag.org/content/334/6062/1502&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What does r/ML think about the MIC correlation-measure proposed in the article above? Digging deeper into what people are saying about the paper referred to by the article reveals some criticisms (eg. &lt;a href=\"http://en.wikipedia.org/wiki/Maximal_information_coefficient\"&gt;http://en.wikipedia.org/wiki/Maximal_information_coefficient&lt;/a&gt;). &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"author_flair_text":null,"downs":0}
{"retrieved_on":1412077969,"banned_by":null,"mod_reports":[],"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"media":null,"secure_media":null,"num_comments":3,"gilded":0,"title":"Clustering of distributions","stickied":false,"permalink":"/r/MachineLearning/comments/1hva2h/clustering_of_distributions/","domain":"self.MachineLearning","report_reasons":null,"created_utc":1373297647,"is_self":true,"subreddit":"MachineLearning","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anybody know of any methods or modifications of methods which could define clusters of multinomial distributions? For example, imagine developing a group of N race/ethnicity distributions based on a dataset of all census tracts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"saosebastiao","selftext":"Does anybody know of any methods or modifications of methods which could define clusters of multinomial distributions? For example, imagine developing a group of N race/ethnicity distributions based on a dataset of all census tracts.","id":"1hva2h","subreddit_id":"t5_2r3gv","edited":false,"link_flair_text":null,"ups":4,"score":4,"url":"http://www.reddit.com/r/MachineLearning/comments/1hva2h/clustering_of_distributions/","thumbnail":"self","over_18":false}
{"author_flair_text":null,"downs":0,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been playing around with pretraining with K-means. Usually if you go for autoencoders or RBM&amp;#39;s you get a filter bank and a bias vector. But with K-means you just get the filter bank, right? I was thinking of doing mean normalization and using the mean as the bias, but that didn&amp;#39;t seem very smart of me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"alexsuse","user_reports":[],"edited":false,"link_flair_text":null,"selftext":"So I've been playing around with pretraining with K-means. Usually if you go for autoencoders or RBM's you get a filter bank and a bias vector. But with K-means you just get the filter bank, right? I was thinking of doing mean normalization and using the mean as the bias, but that didn't seem very smart of me.","id":"1hupql","subreddit_id":"t5_2r3gv","thumbnail":"self","over_18":false,"ups":3,"score":3,"url":"http://www.reddit.com/r/MachineLearning/comments/1hupql/obtaining_a_bias_in_kmeans_pretraining/","mod_reports":[],"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"link_flair_css_class":null,"retrieved_on":1412078860,"banned_by":null,"media":null,"title":"Obtaining a bias in K-Means pretraining","stickied":false,"num_comments":7,"secure_media":null,"gilded":0,"domain":"self.MachineLearning","is_self":true,"created_utc":1373270850,"report_reasons":null,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1hupql/obtaining_a_bias_in_kmeans_pretraining/"}
{"title":"Predicting Movement with IR Sensors, My Experience at the First NuPIC Hackathon","stickied":false,"num_comments":0,"secure_media":null,"gilded":0,"domain":"numenta.org","report_reasons":null,"created_utc":1373408806,"is_self":false,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1hysgs/predicting_movement_with_ir_sensors_my_experience/","mod_reports":[],"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"retrieved_on":1412072627,"banned_by":null,"media":null,"link_flair_text":null,"edited":false,"selftext":"","id":"1hysgs","subreddit_id":"t5_2r3gv","thumbnail":"http://a.thumbs.redditmedia.com/vH5V8smbwg_qhoer.jpg","over_18":false,"url":"http://numenta.org/news/2013/07/09/predicting-movement-with-ir-sensors.html","ups":14,"score":14,"author_flair_text":null,"downs":0,"distinguished":null,"selftext_html":null,"author":"numenta","user_reports":[]}
{"edited":false,"link_flair_text":null,"selftext":"","subreddit_id":"t5_2r3gv","id":"1hydth","over_18":false,"thumbnail":"http://a.thumbs.redditmedia.com/SjaQpAmcYJ9BwcNN.jpg","ups":0,"url":"http://siliconangle.com/blog/2013/06/28/eharmony-refines-the-science-of-love-hadoop-machine-learning-hadoopsummit/","score":0,"downs":0,"author_flair_text":null,"distinguished":null,"author":"saulsherry","selftext_html":null,"user_reports":[],"stickied":false,"title":"Big Dater: eHarmony Refines the Science of Love : Hadoop + Machine Learning","gilded":0,"secure_media":null,"num_comments":0,"domain":"siliconangle.com","subreddit":"MachineLearning","is_self":false,"created_utc":1373398398,"report_reasons":null,"permalink":"/r/MachineLearning/comments/1hydth/big_dater_eharmony_refines_the_science_of_love/","mod_reports":[],"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"retrieved_on":1412073244,"banned_by":null,"media":null}
{"user_reports":[],"author":"saulsherry","selftext_html":null,"distinguished":null,"downs":0,"author_flair_text":null,"score":0,"ups":0,"url":"http://www.bigdatarepublic.com/author.asp?section_id=2642&amp;doc_id=265345&amp;","over_18":false,"thumbnail":"default","subreddit_id":"t5_2r3gv","id":"1hxx4p","selftext":"","edited":false,"link_flair_text":null,"media":null,"retrieved_on":1412073946,"banned_by":null,"link_flair_css_class":null,"author_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"mod_reports":[],"permalink":"/r/MachineLearning/comments/1hxx4p/a_very_gentle_introduction_to_the_concepts_behind/","subreddit":"MachineLearning","created_utc":1373386331,"is_self":false,"report_reasons":null,"domain":"bigdatarepublic.com","gilded":0,"secure_media":null,"num_comments":6,"stickied":false,"title":"A very gentle introduction to the concepts behind machine learning"}
{"media":null,"banned_by":null,"retrieved_on":1412075703,"mod_reports":[],"link_flair_css_class":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"permalink":"/r/MachineLearning/comments/1hwqep/would_you_use_a_lda_based_topic_modeling_library/","domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1373337515,"report_reasons":null,"is_self":true,"gilded":0,"secure_media":null,"num_comments":19,"stickied":false,"title":"Would you use a LDA based Topic Modeling library in Java which handled a few million documents on a single 16 GB Machine","user_reports":[],"author":"textml2730","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running a prototype which I developed in Java to perform LDA on a few million documents in Java. I have personally found it very useful as most LDA implementations in Java or R or Python either run out of memory for a few thousand documents or run down to a crawl. &lt;/p&gt;\n\n&lt;p&gt;I am planning on open sourcing it but I still have to add the licensing text in my source files and create some documentations. I was curious if there would be any interest in such as library. Or are people using LDA content with what is out there in the Open Source space.&lt;/p&gt;\n\n&lt;p&gt;Edit : Forgot to add that for 500 topics on 2 million documents I am getting a performance of approximately 5 hours for 1000 iterations on EC2 High Memory Instance with Java Max Heap Memory set as 10GB.&lt;/p&gt;\n\n&lt;p&gt;Edit2: On my regular home machine with 8GB RAM and Quad Core I-7 processor I ran the process for 500,000 US Patent Abstract for 1000 topics and 1000 iterations in 1hr 30 minutes. The iterations take about 15 seconds initially but eventually started running in 3 seconds or less.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"author_flair_text":null,"downs":0,"url":"http://www.reddit.com/r/MachineLearning/comments/1hwqep/would_you_use_a_lda_based_topic_modeling_library/","ups":13,"score":13,"over_18":false,"thumbnail":"self","selftext":"I am running a prototype which I developed in Java to perform LDA on a few million documents in Java. I have personally found it very useful as most LDA implementations in Java or R or Python either run out of memory for a few thousand documents or run down to a crawl. \n\nI am planning on open sourcing it but I still have to add the licensing text in my source files and create some documentations. I was curious if there would be any interest in such as library. Or are people using LDA content with what is out there in the Open Source space.\n\nEdit : Forgot to add that for 500 topics on 2 million documents I am getting a performance of approximately 5 hours for 1000 iterations on EC2 High Memory Instance with Java Max Heap Memory set as 10GB.\n\nEdit2: On my regular home machine with 8GB RAM and Quad Core I-7 processor I ran the process for 500,000 US Patent Abstract for 1000 topics and 1000 iterations in 1hr 30 minutes. The iterations take about 15 seconds initially but eventually started running in 3 seconds or less.","subreddit_id":"t5_2r3gv","id":"1hwqep","edited":1373374075,"link_flair_text":null}
{"media":null,"retrieved_on":1412069681,"banned_by":null,"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"mod_reports":[],"permalink":"/r/MachineLearning/comments/1i0pgx/next_nupic_hackathon_location_poll/","subreddit":"MachineLearning","report_reasons":null,"created_utc":1373476892,"is_self":false,"domain":"surveymonkey.com","gilded":0,"secure_media":null,"num_comments":4,"stickied":false,"title":"Next NuPIC Hackathon Location Poll","user_reports":[],"author":"numenta","selftext_html":null,"distinguished":null,"author_flair_text":null,"downs":0,"score":4,"ups":4,"url":"https://www.surveymonkey.com/s/K3QNPT2","over_18":false,"thumbnail":"http://a.thumbs.redditmedia.com/uugZJc5egwDHxdfZ.jpg","subreddit_id":"t5_2r3gv","id":"1i0pgx","selftext":"","edited":false,"link_flair_text":null}
{"edited":false,"link_flair_text":null,"selftext":"","subreddit_id":"t5_2r3gv","id":"1i0ld2","over_18":false,"thumbnail":"http://d.thumbs.redditmedia.com/qwVXHPgc_EN5keju.jpg","url":"http://moderntoolmaking.blogspot.com/2013/07/for-faster-r-on-mac-use-veclib.html","ups":13,"score":13,"author_flair_text":null,"downs":0,"distinguished":null,"author":"pandemik","selftext_html":null,"user_reports":[],"stickied":false,"title":"For faster R on a mac, use Apple's BLAS (vecLib)","gilded":0,"num_comments":19,"secure_media":null,"domain":"moderntoolmaking.blogspot.com","subreddit":"MachineLearning","created_utc":1373473884,"is_self":false,"report_reasons":null,"permalink":"/r/MachineLearning/comments/1i0ld2/for_faster_r_on_a_mac_use_apples_blas_veclib/","mod_reports":[],"link_flair_css_class":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"retrieved_on":1412069862,"banned_by":null,"media":null}
{"score":3,"ups":3,"url":"http://www.reddit.com/r/MachineLearning/comments/1hzum0/how_to_do_reinforcement_learning_with_noisy/","thumbnail":"self","over_18":false,"selftext":"I'm having trouble finding a good resource for this type of problem, so I thought I'd ask you guys. I'm already familiar with vanilla value function learning when the agent is told what state it is in all the time.\n\nHere is the setup I am interested in. At each time step, the agent receives a noisy and incomplete reading from its environment, and a real valued reward. It is up to the agent to construct an internal representation of the environment, so that it can select actions that maximize the rate that it receives reward. In order to build a useful model of the environment, the agent must be able to put together information it received from many time steps in the past.\n\nThis seems like a problem that would be encountered in most real life reinforcement learning problems (not all the information relevant to your decisions is a current percept; that's why you have explicit memories), so I'm sure there is plenty of research on it; I just don't know terminology.","id":"1hzum0","subreddit_id":"t5_2r3gv","edited":1373443383,"link_flair_text":null,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m having trouble finding a good resource for this type of problem, so I thought I&amp;#39;d ask you guys. I&amp;#39;m already familiar with vanilla value function learning when the agent is told what state it is in all the time.&lt;/p&gt;\n\n&lt;p&gt;Here is the setup I am interested in. At each time step, the agent receives a noisy and incomplete reading from its environment, and a real valued reward. It is up to the agent to construct an internal representation of the environment, so that it can select actions that maximize the rate that it receives reward. In order to build a useful model of the environment, the agent must be able to put together information it received from many time steps in the past.&lt;/p&gt;\n\n&lt;p&gt;This seems like a problem that would be encountered in most real life reinforcement learning problems (not all the information relevant to your decisions is a current percept; that&amp;#39;s why you have explicit memories), so I&amp;#39;m sure there is plenty of research on it; I just don&amp;#39;t know terminology.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"justonium","distinguished":null,"author_flair_text":null,"downs":0,"permalink":"/r/MachineLearning/comments/1hzum0/how_to_do_reinforcement_learning_with_noisy/","domain":"self.MachineLearning","is_self":true,"created_utc":1373443167,"report_reasons":null,"subreddit":"MachineLearning","num_comments":6,"secure_media":null,"gilded":0,"title":"How to do reinforcement learning with noisy information about the current state","stickied":false,"media":null,"banned_by":null,"retrieved_on":1412070990,"mod_reports":[],"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null}
{"permalink":"/r/MachineLearning/comments/1hzdwq/image_features_supervised_learning_removing/","domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1373425661,"report_reasons":null,"is_self":true,"gilded":0,"secure_media":null,"num_comments":2,"stickied":false,"title":"Image features &amp; supervised learning - removing meteoradar noise","media":null,"retrieved_on":1412071719,"banned_by":null,"mod_reports":[],"link_flair_css_class":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"ups":3,"score":3,"url":"http://www.reddit.com/r/MachineLearning/comments/1hzdwq/image_features_supervised_learning_removing/","over_18":false,"thumbnail":"self","selftext":"I found interesting article about meteodata processing with neural network :\n\nhttp://blog.forecast.io/cleaning-radar-images-using-neural-nets-computer-vision/\n\nHow those guys can filter noise ? I know many neural network samples where computer recognizes object e.g. OCR, shape recognition, face recognition...  but i don't know how to implement noise removal - neural network have to mark noisy area somehow and that's tricky - sometimes you do have cloud and noise mixed together. \n\nHow to implement such thing, do you know any helpful articles/link on this topic ?\n\nSample image (noisy / without noise) :\nhttp://blog.forecast.io/wp-content/uploads/2013/05/conus.gif\n","subreddit_id":"t5_2r3gv","id":"1hzdwq","link_flair_text":null,"edited":false,"user_reports":[],"author":"raaaaraaaa","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found interesting article about meteodata processing with neural network :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://blog.forecast.io/cleaning-radar-images-using-neural-nets-computer-vision/\"&gt;http://blog.forecast.io/cleaning-radar-images-using-neural-nets-computer-vision/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;How those guys can filter noise ? I know many neural network samples where computer recognizes object e.g. OCR, shape recognition, face recognition...  but i don&amp;#39;t know how to implement noise removal - neural network have to mark noisy area somehow and that&amp;#39;s tricky - sometimes you do have cloud and noise mixed together. &lt;/p&gt;\n\n&lt;p&gt;How to implement such thing, do you know any helpful articles/link on this topic ?&lt;/p&gt;\n\n&lt;p&gt;Sample image (noisy / without noise) :\n&lt;a href=\"http://blog.forecast.io/wp-content/uploads/2013/05/conus.gif\"&gt;http://blog.forecast.io/wp-content/uploads/2013/05/conus.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"downs":0,"author_flair_text":null}
{"distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"author":"uber_kerbonaut","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand how whitening is a very helpful step often used to pre-process data for deep learning or or convolutional neural networks, but does it rely on having all the data up front or can it be performed independently on each data vector? Are there any on-line versions which use running averages etc.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","subreddit_id":"t5_2r3gv","id":"1i3rd7","selftext":"I understand how whitening is a very helpful step often used to pre-process data for deep learning or or convolutional neural networks, but does it rely on having all the data up front or can it be performed independently on each data vector? Are there any on-line versions which use running averages etc.?","link_flair_text":null,"edited":false,"score":1,"ups":1,"url":"http://www.reddit.com/r/MachineLearning/comments/1i3rd7/is_whitening_possible_in_an_online_learning/","over_18":false,"thumbnail":"self","retrieved_on":1412064993,"banned_by":null,"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"mod_reports":[],"media":null,"gilded":0,"secure_media":null,"num_comments":0,"stickied":false,"title":"Is whitening possible in an on-line learning environment?","permalink":"/r/MachineLearning/comments/1i3rd7/is_whitening_possible_in_an_online_learning/","subreddit":"MachineLearning","is_self":true,"created_utc":1373573272,"report_reasons":null,"domain":"self.MachineLearning"}
{"author":"yokoon","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;More specifically, is it possible to use machine learning techniques to discover and diagnose software bugs or vulnerabilities, perform program verification and automated test generation? If so, how? Any pointers to the current research going on that seeks to use machine learning for static and dynamic analysis of programs, particularly for (modern) mixed concrete and symbolic execution of programs is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null,"over_18":false,"thumbnail":"self","ups":2,"url":"http://www.reddit.com/r/MachineLearning/comments/1i2md0/how_can_machine_learning_be_applied_to_software/","score":2,"link_flair_text":null,"edited":false,"subreddit_id":"t5_2r3gv","id":"1i2md0","selftext":"More specifically, is it possible to use machine learning techniques to discover and diagnose software bugs or vulnerabilities, perform program verification and automated test generation? If so, how? Any pointers to the current research going on that seeks to use machine learning for static and dynamic analysis of programs, particularly for (modern) mixed concrete and symbolic execution of programs is appreciated.","media":null,"link_flair_css_class":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"mod_reports":[],"retrieved_on":1412066763,"banned_by":null,"subreddit":"MachineLearning","is_self":true,"created_utc":1373538790,"report_reasons":null,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1i2md0/how_can_machine_learning_be_applied_to_software/","stickied":false,"title":"How can machine learning be applied to software security and software testing?","gilded":0,"secure_media":null,"num_comments":13}
{"over_18":false,"thumbnail":"default","ups":0,"url":"http://www.giochi-slotmachine.org/slot-machine-online/slot-machine-online-gratis","score":0,"edited":false,"link_flair_text":null,"subreddit_id":"t5_2r3gv","id":"1i2m7k","selftext":"","author":"nikybaba","selftext_html":null,"user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"subreddit":"MachineLearning","is_self":false,"created_utc":1373538564,"report_reasons":null,"domain":"giochi-slotmachine.org","permalink":"/r/MachineLearning/comments/1i2m7k/giochislotmachineorg/","stickied":false,"title":"giochi-slotmachine.org","gilded":0,"num_comments":0,"secure_media":null,"media":null,"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"mod_reports":[],"retrieved_on":1412066769,"banned_by":null}
{"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"mod_reports":[],"retrieved_on":1412066873,"banned_by":null,"media":null,"stickied":false,"title":"Hi everyone; I would like to share with you my second free online course titled \"Advanced Numerical Analysis\". Feel free to register this course and share it with your friends. The course material is now available and you can start the course at anytime.","gilded":0,"secure_media":null,"num_comments":0,"subreddit":"MachineLearning","created_utc":1373534068,"report_reasons":null,"is_self":false,"domain":"udemy.com","permalink":"/r/MachineLearning/comments/1i2jo4/hi_everyone_i_would_like_to_share_with_you_my/","downs":0,"author_flair_text":null,"distinguished":null,"author":"mkaabar","selftext_html":null,"user_reports":[],"edited":false,"link_flair_text":null,"subreddit_id":"t5_2r3gv","id":"1i2jo4","selftext":"","over_18":false,"thumbnail":"http://d.thumbs.redditmedia.com/X2YgFpPLpIyS8c3u.jpg","url":"https://www.udemy.com/advanced-numerical-analysis/","ups":0,"score":0}
{"num_comments":27,"secure_media":null,"gilded":0,"title":"Can you explain compressive sensing in a few words from a machine learning perspective?","stickied":false,"permalink":"/r/MachineLearning/comments/1i27jd/can_you_explain_compressive_sensing_in_a_few/","report_reasons":null,"created_utc":1373518106,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","retrieved_on":1412067385,"banned_by":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"media":null,"id":"1i27jd","subreddit_id":"t5_2r3gv","selftext":"I've been reading about compressive sensing, looking at some tutorials / slides / papers.\n\nAll of the tutorials start with nyquist frequencies and other signal processing talk, treating samples as discrete frequency values. Couldn't find any papers that explain it from a non-DSP perspective.\n\n**What I think I know:**\n\nMost real data is sparse and that compressive sensing randomly samples your input with some (learnt?) bases to compress them to give an error bound that is extremely small.\n\n\n**What I dont know but want to know:**\n\n* If the bases are learnt, how are they learnt? Matrix factorization? Any very simple explanation on how its learnt? And maybe a link/paper for just understanding the learning process?\n\n* How are the bases that are learnt in compressive sensing different from ones learnt from autoencoders (with sparsity enforced)? How are they different from kmeans centroids?\n\n* If you can, can you explain how it is different in terms of one commonly used machine learning model? (so that it is easy to understand with a comparison)\n\n* Are there any applications apart from reconstructing noisy data, saving bandwidth etc.? \n\nIf you can answer any of these questions at all, or link to appropriate slides/blog entries etc. I'd be greatful. I took a look at some blog entries on Nuit Blanche. Thanks.\n\n","edited":false,"link_flair_text":null,"ups":20,"score":20,"url":"http://www.reddit.com/r/MachineLearning/comments/1i27jd/can_you_explain_compressive_sensing_in_a_few/","thumbnail":"self","over_18":false,"distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been reading about compressive sensing, looking at some tutorials / slides / papers.&lt;/p&gt;\n\n&lt;p&gt;All of the tutorials start with nyquist frequencies and other signal processing talk, treating samples as discrete frequency values. Couldn&amp;#39;t find any papers that explain it from a non-DSP perspective.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I think I know:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Most real data is sparse and that compressive sensing randomly samples your input with some (learnt?) bases to compress them to give an error bound that is extremely small.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I dont know but want to know:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;If the bases are learnt, how are they learnt? Matrix factorization? Any very simple explanation on how its learnt? And maybe a link/paper for just understanding the learning process?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How are the bases that are learnt in compressive sensing different from ones learnt from autoencoders (with sparsity enforced)? How are they different from kmeans centroids?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If you can, can you explain how it is different in terms of one commonly used machine learning model? (so that it is easy to understand with a comparison)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Are there any applications apart from reconstructing noisy data, saving bandwidth etc.? &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you can answer any of these questions at all, or link to appropriate slides/blog entries etc. I&amp;#39;d be greatful. I took a look at some blog entries on Nuit Blanche. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"r-sync"}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week I &lt;a href=\"http://www.reddit.com/r/MachineLearning/comments/1hn9gf/a_series_of_blog_posts_about_biclustering/\"&gt;mentioned&lt;/a&gt; my series of posts about biclustering. Here is the newest entry, which covers the Spectral Biclustering algorithm (Kluger, et. al., 2003):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"http://www.kemaleren.com/spectral-biclustering-part-2.html\"&gt;Spectral biclustering, part 2&lt;/a&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"kemal_eren","user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"thumbnail":"self","over_18":false,"ups":8,"url":"http://www.reddit.com/r/MachineLearning/comments/1i6ntd/spectral_biclustering_part_2/","score":8,"link_flair_text":null,"edited":1373674457,"id":"1i6ntd","subreddit_id":"t5_2r3gv","selftext":"Last week I [mentioned](http://www.reddit.com/r/MachineLearning/comments/1hn9gf/a_series_of_blog_posts_about_biclustering/) my series of posts about biclustering. Here is the newest entry, which covers the Spectral Biclustering algorithm (Kluger, et. al., 2003):\n\n* [Spectral biclustering, part 2](http://www.kemaleren.com/spectral-biclustering-part-2.html).","media":null,"author_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412060767,"banned_by":null,"created_utc":1373668576,"report_reasons":null,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1i6ntd/spectral_biclustering_part_2/","title":"Spectral biclustering, part 2","stickied":false,"num_comments":7,"secure_media":null,"gilded":0}
{"permalink":"/r/MachineLearning/comments/1i6hu1/help_me_understand_the_nuances_between_pca_and_svd/","domain":"self.MachineLearning","subreddit":"MachineLearning","is_self":true,"created_utc":1373663838,"report_reasons":null,"gilded":0,"secure_media":null,"num_comments":1,"stickied":false,"title":"Help me understand the nuances between PCA and SVD","media":null,"retrieved_on":1412061013,"banned_by":null,"mod_reports":[],"link_flair_css_class":null,"author_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"url":"http://www.reddit.com/r/MachineLearning/comments/1i6hu1/help_me_understand_the_nuances_between_pca_and_svd/","ups":5,"score":5,"over_18":false,"thumbnail":"self","selftext":"So I'm just getting started with Machine Learning, having just finished Andrew Ng's Coursera course on the subject.  I've fallen in love with the field, and have immediately starting putting my new found knowledge to use for my work in the semiconductor industry.\n\nI understand that doing SVD on the covariance matrix turns this problem into Principle Components Analysis and that my U and V matrices end up being exactly the same, and the vectors in each one are orthonormal.  \n\nA question that has been consuming my mind for the last couple of weeks is as follows:\n\n**When would you ever choose to do an SVD on the data matrix itself vs doing an SVD on the covariance matrix of the data (PCA), and vice versa?  What are the different end goals that you are striving for with each?**\n\nI work in the semiconductor industry and have been using my new found knowledge to do spatial pattern recognition for wafers, and also dimension reduction.  SVD on the data matrix and SVD on the covariance matrix (PCA) are kinda/sorta giving me similar results, and I'd really love to understand the subtle differences.\n\n\n","subreddit_id":"t5_2r3gv","id":"1i6hu1","link_flair_text":null,"edited":false,"user_reports":[],"author":"voodoochile78","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m just getting started with Machine Learning, having just finished Andrew Ng&amp;#39;s Coursera course on the subject.  I&amp;#39;ve fallen in love with the field, and have immediately starting putting my new found knowledge to use for my work in the semiconductor industry.&lt;/p&gt;\n\n&lt;p&gt;I understand that doing SVD on the covariance matrix turns this problem into Principle Components Analysis and that my U and V matrices end up being exactly the same, and the vectors in each one are orthonormal.  &lt;/p&gt;\n\n&lt;p&gt;A question that has been consuming my mind for the last couple of weeks is as follows:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;When would you ever choose to do an SVD on the data matrix itself vs doing an SVD on the covariance matrix of the data (PCA), and vice versa?  What are the different end goals that you are striving for with each?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I work in the semiconductor industry and have been using my new found knowledge to do spatial pattern recognition for wafers, and also dimension reduction.  SVD on the data matrix and SVD on the covariance matrix (PCA) are kinda/sorta giving me similar results, and I&amp;#39;d really love to understand the subtle differences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"downs":0,"author_flair_text":null}
{"link_flair_text":null,"edited":false,"selftext":"","subreddit_id":"t5_2r3gv","id":"1i685q","over_18":false,"thumbnail":"http://c.thumbs.redditmedia.com/Fhu8kPBxFoR7aWX2.jpg","ups":3,"url":"http://rvlasveld.github.io/blog/2013/07/12/introduction-to-one-class-support-vector-machines/","score":3,"author_flair_text":null,"downs":0,"distinguished":null,"author":"flaxfield","selftext_html":null,"user_reports":[],"stickied":false,"title":"Introduction to one-class Support Vector Machines","gilded":0,"num_comments":0,"secure_media":null,"domain":"rvlasveld.github.io","subreddit":"MachineLearning","report_reasons":null,"created_utc":1373656898,"is_self":false,"permalink":"/r/MachineLearning/comments/1i685q/introduction_to_oneclass_support_vector_machines/","mod_reports":[],"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"retrieved_on":1412061385,"banned_by":null,"media":null}
{"media":null,"retrieved_on":1412061661,"banned_by":null,"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1i616j/data_mining_blog/","subreddit":"MachineLearning","is_self":false,"created_utc":1373651979,"report_reasons":null,"domain":"1.salford-systems.com","gilded":0,"num_comments":0,"secure_media":null,"stickied":false,"title":"Data Mining Blog","user_reports":[],"author":"heatherhinman","selftext_html":null,"distinguished":null,"downs":0,"author_flair_text":null,"ups":10,"url":"http://1.salford-systems.com/blog/?&amp;amp;t=93716","score":10,"over_18":false,"thumbnail":"http://a.thumbs.redditmedia.com/m2qgQrc1DoKMJksN.jpg","subreddit_id":"t5_2r3gv","id":"1i616j","selftext":"","edited":false,"link_flair_text":null}
{"author":"dnoel","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on clustering a set of news articles by topic. I&amp;#39;m applying both unsupervised and supervised algorithms. For the supervised component I&amp;#39;m either going to have to manually generate training data (build a list of clusters by hand), or find a pre-existing data set containing known good cluster information. I&amp;#39;d rather not have to do it all by hand (it&amp;#39;ll take weeks). Does anyone know of such a set? Thanks in advance. -dnoel&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"over_18":false,"thumbnail":"self","score":2,"ups":2,"url":"http://www.reddit.com/r/MachineLearning/comments/1i5o5l/document_clustering_training_data_do_preclustered/","edited":1373649810,"link_flair_text":null,"subreddit_id":"t5_2r3gv","id":"1i5o5l","selftext":"I'm working on clustering a set of news articles by topic. I'm applying both unsupervised and supervised algorithms. For the supervised component I'm either going to have to manually generate training data (build a list of clusters by hand), or find a pre-existing data set containing known good cluster information. I'd rather not have to do it all by hand (it'll take weeks). Does anyone know of such a set? Thanks in advance. -dnoel","media":null,"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"mod_reports":[],"retrieved_on":1412062166,"banned_by":null,"subreddit":"MachineLearning","report_reasons":null,"created_utc":1373642530,"is_self":true,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1i5o5l/document_clustering_training_data_do_preclustered/","stickied":false,"title":"Document clustering training data. Do pre-clustered sets exist?","gilded":0,"secure_media":null,"num_comments":5}
{"id":"1i4r43","subreddit_id":"t5_2r3gv","selftext":"I'd like to group similar text then create groups based on their similarities. For example say I ran a grocery store and I wanted to group my products. If I had Boneless Chicken, Chicken Thighs, Chicken Legs, I'd like those four items to be categorized chicken.\n\nPart of the problem though is I need an algorithm that can make groups based on the \"best match\" so that something like orange popsicles and orange juice don't get grouped with orange. \n\nWhat would be a good place to start for such an algorithm? I'm thinking something like a SVM but I have little experience with them.","link_flair_text":null,"edited":false,"score":13,"ups":13,"url":"http://www.reddit.com/r/MachineLearning/comments/1i4r43/choosing_an_algorithm_for_a_text_classification/","thumbnail":"self","over_18":false,"distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to group similar text then create groups based on their similarities. For example say I ran a grocery store and I wanted to group my products. If I had Boneless Chicken, Chicken Thighs, Chicken Legs, I&amp;#39;d like those four items to be categorized chicken.&lt;/p&gt;\n\n&lt;p&gt;Part of the problem though is I need an algorithm that can make groups based on the &amp;quot;best match&amp;quot; so that something like orange popsicles and orange juice don&amp;#39;t get grouped with orange. &lt;/p&gt;\n\n&lt;p&gt;What would be a good place to start for such an algorithm? I&amp;#39;m thinking something like a SVM but I have little experience with them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"edude03","num_comments":12,"secure_media":null,"gilded":0,"title":"Choosing an algorithm for a text classification type project.","stickied":false,"permalink":"/r/MachineLearning/comments/1i4r43/choosing_an_algorithm_for_a_text_classification/","report_reasons":null,"created_utc":1373601696,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","retrieved_on":1412063453,"banned_by":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"media":null}
{"media":null,"banned_by":null,"retrieved_on":1412058203,"mod_reports":[],"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"permalink":"/r/MachineLearning/comments/1i8f64/looking_for_advice_for_masters_thesis_focusing_on/","domain":"self.MachineLearning","report_reasons":null,"created_utc":1373744866,"is_self":true,"subreddit":"MachineLearning","secure_media":null,"num_comments":4,"gilded":0,"title":"Looking for advice for Masters Thesis focusing on Machine Learning.","stickied":false,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I&amp;#39;ve primarily been a reader of this subreddit until now and I was looking for some advice for my graudate research. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on on M.S. in Engineering, specifically in Machine Learning. I&amp;#39;m almost done wrapping up the exact direction I want to take my research in, which involves developing an algorithm with thorough evaluation on synthetic and real-world data. &lt;/p&gt;\n\n&lt;p&gt;My problem is to address and overcome the following hurdles:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Concept drift&lt;/strong&gt; (also known as covariate drift, domain adaptation, non-stationary data) - In a batch learning scenario, adjacent time-series &amp;#39;snapshots&amp;#39; of the data can be drawn from different data distributions if there is a hidden context in the data, causing the decision boundaries to change over time. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Inductive Learning&lt;/strong&gt; - Since the labeling of real-world data can be expensive, the algorithm should be able to deal with only receiving unlabeled data for a series of consecutive time steps until labeled data eventually arives.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Imbalanced data&lt;/strong&gt; - Prior probabilities for a given class may be heavily lopsided at a given series of time steps.&lt;/p&gt;\n\n&lt;p&gt;The restrictions of the algorithm are strictly on the data retention. Training and test data cannot be stored and used in future time steps. The idea here is to deal with the stability-plasticity dilemma in an environment that gradually (simply defined as not completely at random) over time. &lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone had any advice or information as to what direction I can explore or what the current methods are that can be used for motivation or a basis for improvement. Another great piece of information would be where I can find real-world data to experiment with. The UCI Machine Learning repository doesn&amp;#39;t seem to have anything that specifically relates to concept drift.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read a couple books which have summarized some of the following methods &lt;a href=\"http://sugiyama-www.cs.titech.ac.jp/%7Esugi/software/\"&gt;found here&lt;/a&gt; (we use MATLAB for implementation at my school), so I am familiar with these concepts as well as ensemble learning methods using a variety of different base learning models (SVM, MLP, Naive Bayes). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a lot of great knowledge shared on here and this seems like a  great place to get advice for an aspiring ML student. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"HowYaGuysDoin","distinguished":null,"author_flair_text":null,"downs":0,"score":8,"ups":8,"url":"http://www.reddit.com/r/MachineLearning/comments/1i8f64/looking_for_advice_for_masters_thesis_focusing_on/","thumbnail":"self","over_18":false,"selftext":"Hi. I've primarily been a reader of this subreddit until now and I was looking for some advice for my graudate research. \n\nI'm working on on M.S. in Engineering, specifically in Machine Learning. I'm almost done wrapping up the exact direction I want to take my research in, which involves developing an algorithm with thorough evaluation on synthetic and real-world data. \n\nMy problem is to address and overcome the following hurdles:\n\n**Concept drift** (also known as covariate drift, domain adaptation, non-stationary data) - In a batch learning scenario, adjacent time-series 'snapshots' of the data can be drawn from different data distributions if there is a hidden context in the data, causing the decision boundaries to change over time. \n \n**Inductive Learning** - Since the labeling of real-world data can be expensive, the algorithm should be able to deal with only receiving unlabeled data for a series of consecutive time steps until labeled data eventually arives.\n\n **Imbalanced data** - Prior probabilities for a given class may be heavily lopsided at a given series of time steps.\n\nThe restrictions of the algorithm are strictly on the data retention. Training and test data cannot be stored and used in future time steps. The idea here is to deal with the stability-plasticity dilemma in an environment that gradually (simply defined as not completely at random) over time. \n\nI was wondering if anyone had any advice or information as to what direction I can explore or what the current methods are that can be used for motivation or a basis for improvement. Another great piece of information would be where I can find real-world data to experiment with. The UCI Machine Learning repository doesn't seem to have anything that specifically relates to concept drift.\n\nI've read a couple books which have summarized some of the following methods [found here](http://sugiyama-www.cs.titech.ac.jp/~sugi/software/) (we use MATLAB for implementation at my school), so I am familiar with these concepts as well as ensemble learning methods using a variety of different base learning models (SVM, MLP, Naive Bayes). \n\nI've seen a lot of great knowledge shared on here and this seems like a  great place to get advice for an aspiring ML student. \n\nThank you in advance!","id":"1i8f64","subreddit_id":"t5_2r3gv","edited":false,"link_flair_text":null}
{"edited":false,"link_flair_text":null,"id":"1i7ocx","subreddit_id":"t5_2r3gv","selftext":"","thumbnail":"http://b.thumbs.redditmedia.com/DHXpP8p9FTMX3awa.jpg","over_18":false,"ups":33,"score":33,"url":"http://www.youtube.com/watch?feature=player_embedded&amp;v=3PdxQbOvAlI#at=60","downs":0,"author_flair_text":null,"distinguished":null,"selftext_html":null,"author":"linuxjava","user_reports":[],"title":"Marvin Minsky Calls the Turing Test a Joke and criticizes the use of the Turing Test as an identifier of artificial intelligence","stickied":false,"num_comments":21,"secure_media":null,"gilded":0,"created_utc":1373713606,"is_self":false,"report_reasons":null,"subreddit":"MachineLearning","domain":"youtube.com","permalink":"/r/MachineLearning/comments/1i7ocx/marvin_minsky_calls_the_turing_test_a_joke_and/","author_flair_css_class":null,"secure_media_embed":{},"media_embed":{"content":"&lt;iframe width=\"600\" height=\"338\" src=\"http://www.youtube.com/embed/3PdxQbOvAlI?feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","scrolling":false,"height":338,"width":600},"link_flair_css_class":null,"mod_reports":[],"banned_by":null,"retrieved_on":1412059316,"media":{"type":"youtube.com","oembed":{"author_url":"http://www.youtube.com/user/ndanaylov","thumbnail_width":480,"html":"&lt;iframe width=\"600\" height=\"338\" src=\"http://www.youtube.com/embed/3PdxQbOvAlI?feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","title":"Marvin Minsky on Singularity 1 on 1: The Turing Test is a Joke!","provider_url":"http://www.youtube.com/","thumbnail_url":"http://i1.ytimg.com/vi/3PdxQbOvAlI/hqdefault.jpg","url":"http://www.youtube.com/watch?v=3PdxQbOvAlI","description":"http://www.singularityweblog.com/marvin-minsky/ Marvin Minsky is often called the Father of Artificial Intelligence and I have been looking for an opportunity to interview him for years. I was hoping that I will finally get my chance at the GF2045 conference in NY City. Unfortunately, Prof. Minsky had bronchitis and consequently had to speak via video.","author_name":"Nikola Danaylov","width":600,"height":338,"type":"video","provider_name":"YouTube","version":"1.0","thumbnail_height":360}}}
{"user_reports":[],"selftext_html":null,"author":"locster","distinguished":null,"downs":0,"author_flair_text":null,"ups":0,"score":0,"url":"http://sifter.org/~simon/journal/20130713.h.html","thumbnail":"default","over_18":false,"selftext":"","id":"1iatz4","subreddit_id":"t5_2r3gv","link_flair_text":null,"edited":false,"media":null,"banned_by":null,"retrieved_on":1412054519,"mod_reports":[],"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"permalink":"/r/MachineLearning/comments/1iatz4/on_knowledge_representation_essay/","domain":"sifter.org","created_utc":1373840826,"report_reasons":null,"is_self":false,"subreddit":"MachineLearning","secure_media":null,"num_comments":0,"gilded":0,"title":"On Knowledge Representation [Essay]","stickied":false}
{"retrieved_on":1412055569,"banned_by":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"mod_reports":[],"media":null,"num_comments":3,"secure_media":null,"gilded":0,"title":"Group Theory and Machine Learning by Risi Kondor","stickied":false,"permalink":"/r/MachineLearning/comments/1ia6fi/group_theory_and_machine_learning_by_risi_kondor/","is_self":false,"created_utc":1373820181,"report_reasons":null,"subreddit":"MachineLearning","domain":"videolectures.net","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"selftext_html":null,"author":"turnersr","id":"1ia6fi","subreddit_id":"t5_2r3gv","selftext":"","edited":false,"link_flair_text":null,"url":"http://videolectures.net/mlcued08_kondor_gtm/","ups":35,"score":35,"thumbnail":"default","over_18":false}
{"author_flair_text":null,"downs":0,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys! I am an undergrad double majoring in Mathematics and Economics. I have become quite fascinated with Machine Learning over the summer! So I started recently pondering what branches of Mathematics would be a good compliment to Machine Learning. I mean aside from the statistical theory, such as Bayesian statistics, which forms a somewhat of a base for it, what bodies in Mathematics would set the stage for a more complete understanding. &lt;/p&gt;\n\n&lt;p&gt;So I thought that a good place to ask this question would be here. &lt;/p&gt;\n\n&lt;p&gt;More topology? More combinatorics? More analysis? None of em and something else entirely? &lt;/p&gt;\n\n&lt;p&gt;Any comments would be highly appreciated. Thanks! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"mmasood","user_reports":[],"edited":false,"link_flair_text":null,"id":"1i9z5i","subreddit_id":"t5_2r3gv","selftext":"Hey guys! I am an undergrad double majoring in Mathematics and Economics. I have become quite fascinated with Machine Learning over the summer! So I started recently pondering what branches of Mathematics would be a good compliment to Machine Learning. I mean aside from the statistical theory, such as Bayesian statistics, which forms a somewhat of a base for it, what bodies in Mathematics would set the stage for a more complete understanding. \n\nSo I thought that a good place to ask this question would be here. \n\nMore topology? More combinatorics? More analysis? None of em and something else entirely? \n\nAny comments would be highly appreciated. Thanks! ","thumbnail":"self","over_18":false,"ups":2,"url":"http://www.reddit.com/r/MachineLearning/comments/1i9z5i/machine_learning_for_an_undergrad/","score":2,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412055889,"banned_by":null,"media":null,"title":"Machine learning for an undergrad?","stickied":false,"secure_media":null,"num_comments":9,"gilded":0,"report_reasons":null,"created_utc":1373812443,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1i9z5i/machine_learning_for_an_undergrad/"}
{"media":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412056764,"banned_by":null,"created_utc":1373778210,"report_reasons":null,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1i9ebi/considering_a_career_in_finance_with_a_focus_in/","title":"Considering a career in finance with a focus in machine learning","stickied":false,"num_comments":25,"secure_media":null,"gilded":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking about going into finance with a focus in machine learning. What kinds of jobs would be available? Are those jobs are cutthroat and miserable as I hear they are? Would I only need a Bachelor&amp;#39;s in CS from a low rank CS school or would I need a graduate degree as well? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"saxman666","user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"thumbnail":"self","over_18":false,"ups":4,"url":"http://www.reddit.com/r/MachineLearning/comments/1i9ebi/considering_a_career_in_finance_with_a_focus_in/","score":4,"link_flair_text":null,"edited":false,"id":"1i9ebi","subreddit_id":"t5_2r3gv","selftext":"I was thinking about going into finance with a focus in machine learning. What kinds of jobs would be available? Are those jobs are cutthroat and miserable as I hear they are? Would I only need a Bachelor's in CS from a low rank CS school or would I need a graduate degree as well? Thank you."}
{"media":null,"retrieved_on":1412056826,"banned_by":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1i9d2m/im_looking_for_information_on_combining_recurrent/","report_reasons":null,"created_utc":1373776861,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","num_comments":11,"secure_media":null,"gilded":0,"title":"I'm looking for information on combining recurrent neural nets that run at different frequencies.","stickied":false,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So here&amp;#39;s the idea. You have a vanilla recurrent neural net (RNN) that does a recurrent feedforward pass at each time step in the sequence it is reading. Then you pass it&amp;#39;s hidden states as data to a recurrent neural net that does a feedforward pass on every other time step, and train this RNN to help fix the errors in the original one. If one continues to stack slower and slower RNN&amp;#39;s like this, it&amp;#39;s possible for information to flow through N time steps in only about log N feedforward passes, rather than N feedforward passes as in a vanilla RNN. I implemented this and found out that it works, but I can&amp;#39;t find any literature on it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"justonium","distinguished":null,"author_flair_text":null,"downs":0,"score":10,"ups":10,"url":"http://www.reddit.com/r/MachineLearning/comments/1i9d2m/im_looking_for_information_on_combining_recurrent/","thumbnail":"self","over_18":false,"id":"1i9d2m","subreddit_id":"t5_2r3gv","selftext":"So here's the idea. You have a vanilla recurrent neural net (RNN) that does a recurrent feedforward pass at each time step in the sequence it is reading. Then you pass it's hidden states as data to a recurrent neural net that does a feedforward pass on every other time step, and train this RNN to help fix the errors in the original one. If one continues to stack slower and slower RNN's like this, it's possible for information to flow through N time steps in only about log N feedforward passes, rather than N feedforward passes as in a vanilla RNN. I implemented this and found out that it works, but I can't find any literature on it.","edited":false,"link_flair_text":null}
{"media":null,"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"mod_reports":[],"retrieved_on":1412050159,"banned_by":null,"subreddit":"MachineLearning","created_utc":1373932100,"report_reasons":null,"is_self":false,"domain":"adaptroninc.com","permalink":"/r/MachineLearning/comments/1idjid/binons_and_perceptra_a_new_neural_net/","stickied":false,"title":"Binons and perceptra - a new neural net?","gilded":0,"secure_media":null,"num_comments":41,"author":"gordo_099","selftext_html":null,"user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null,"over_18":false,"thumbnail":"http://e.thumbs.redditmedia.com/NIB3zoeJPWPC7_84.jpg","ups":7,"url":"http://adaptroninc.com/html/adaptron_inc_-_perceptra.html","score":7,"link_flair_text":null,"edited":false,"subreddit_id":"t5_2r3gv","id":"1idjid","selftext":""}
{"banned_by":null,"retrieved_on":1412050753,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"link_flair_css_class":null,"mod_reports":[],"media":null,"num_comments":0,"secure_media":null,"gilded":0,"title":"A new ML competition is afoot - this time, to create the brain of DARPA/Boston Dynamics' new humanoid robot.","stickied":false,"permalink":"/r/MachineLearning/comments/1id5qp/a_new_ml_competition_is_afoot_this_time_to_create/","is_self":false,"created_utc":1373921762,"report_reasons":null,"subreddit":"MachineLearning","domain":"extremetech.com","distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"selftext_html":null,"author":"[deleted]","id":"1id5qp","subreddit_id":"t5_2r3gv","selftext":"","edited":false,"link_flair_text":null,"ups":0,"score":0,"url":"http://www.extremetech.com/extreme/161193-meet-darpas-real-world-terminator-atlas","thumbnail":"default","over_18":false}
{"mod_reports":[],"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"retrieved_on":1412051197,"banned_by":null,"media":null,"stickied":false,"title":"Are there any design principals for creating descriptor vectors?","gilded":0,"num_comments":2,"secure_media":null,"domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1373914481,"is_self":true,"report_reasons":null,"permalink":"/r/MachineLearning/comments/1icvdx/are_there_any_design_principals_for_creating/","downs":0,"author_flair_text":null,"distinguished":null,"author":"kamonohashisan","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking about creating a new descriptor vector using some rather irregular biological data for classification via SVM. For example one property I want to measure may occur from zero to may times. I have recently learned about normal forms in database design.  It would be nice if there were some kind of generalized rules or guidelines for handling data with different properties when designing a descriptor vector . &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"link_flair_text":null,"edited":false,"selftext":"I am thinking about creating a new descriptor vector using some rather irregular biological data for classification via SVM. For example one property I want to measure may occur from zero to may times. I have recently learned about normal forms in database design.  It would be nice if there were some kind of generalized rules or guidelines for handling data with different properties when designing a descriptor vector . ","subreddit_id":"t5_2r3gv","id":"1icvdx","over_18":false,"thumbnail":"self","score":7,"ups":7,"url":"http://www.reddit.com/r/MachineLearning/comments/1icvdx/are_there_any_design_principals_for_creating/"}
{"stickied":false,"title":"Self study machine learning?","gilded":0,"num_comments":35,"secure_media":null,"domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1373892293,"report_reasons":null,"is_self":true,"permalink":"/r/MachineLearning/comments/1ic408/self_study_machine_learning/","mod_reports":[],"link_flair_css_class":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"retrieved_on":1412052408,"banned_by":null,"media":null,"link_flair_text":null,"edited":false,"selftext":"I haven't done any serious math in quite a long time and I wanted to know what resources would you recommend to raise my rusty math skills to the appropriate level for machine learning and genetic programming?\n\nI hope to re-learn mathematics the proper way instead of memorizing steps to solve a problem.\n\nThanks for your time.","subreddit_id":"t5_2r3gv","id":"1ic408","over_18":false,"thumbnail":"default","score":37,"ups":37,"url":"http://www.reddit.com/r/MachineLearning/comments/1ic408/self_study_machine_learning/","author_flair_text":null,"downs":0,"distinguished":null,"author":"[deleted]","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t done any serious math in quite a long time and I wanted to know what resources would you recommend to raise my rusty math skills to the appropriate level for machine learning and genetic programming?&lt;/p&gt;\n\n&lt;p&gt;I hope to re-learn mathematics the proper way instead of memorizing steps to solve a problem.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[]}
{"over_18":false,"thumbnail":"http://d.thumbs.redditmedia.com/NH0W5xGgHPczmW3Q.jpg","ups":19,"url":"http://alandgraf.blogspot.com/2013/01/restricted-boltzmann-machines-in-r.html","score":19,"link_flair_text":null,"edited":false,"selftext":"","subreddit_id":"t5_2r3gv","id":"1ibq56","author":"atabeykaygun","selftext_html":null,"user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"domain":"alandgraf.blogspot.com","subreddit":"MachineLearning","created_utc":1373870724,"is_self":false,"report_reasons":null,"permalink":"/r/MachineLearning/comments/1ibq56/restricted_boltzmann_machines_in_r/","stickied":false,"title":"Restricted Boltzmann Machines in R","gilded":0,"secure_media":null,"num_comments":2,"media":null,"mod_reports":[],"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"banned_by":null,"retrieved_on":1412053048}
{"subreddit_id":"t5_2r3gv","id":"1if11s","selftext":"","link_flair_text":null,"edited":false,"score":16,"ups":16,"url":"http://mathbabe.org/2013/07/16/money-in-politics-the-bff-project/","over_18":false,"thumbnail":"http://e.thumbs.redditmedia.com/i4aQb_qCB_4GGsQd.jpg","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"author":"DevFRus","selftext_html":null,"gilded":0,"secure_media":null,"num_comments":1,"stickied":false,"title":"New data set for analysis and visualization: the BFF project on campaign contributions, votes, speeches, and bill (co-)sponsorship in congress. How much does money influence politics?","permalink":"/r/MachineLearning/comments/1if11s/new_data_set_for_analysis_and_visualization_the/","subreddit":"MachineLearning","created_utc":1373987609,"report_reasons":null,"is_self":false,"domain":"mathbabe.org","banned_by":null,"retrieved_on":1412047742,"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"mod_reports":[],"media":null}
{"subreddit":"MachineLearning","report_reasons":null,"created_utc":1373945873,"is_self":true,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1ie0x0/creating_data_compatible_with_mnist_digit_dataset/","stickied":false,"title":"Creating data compatible with MNIST digit dataset from raw images","gilded":0,"secure_media":null,"num_comments":1,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"mod_reports":[],"banned_by":null,"retrieved_on":1412049315,"over_18":false,"thumbnail":"self","url":"http://www.reddit.com/r/MachineLearning/comments/1ie0x0/creating_data_compatible_with_mnist_digit_dataset/","ups":1,"score":1,"edited":false,"link_flair_text":null,"subreddit_id":"t5_2r3gv","id":"1ie0x0","selftext":"I'm new to ML and have a small project, where I have a million or so images containing handwritten texts in some uncommon languages. I'd like to experiment using the code that been written to process the MNIST digit dataset. \n\nHow do I get from image containing digits to the MNIST digit format?\n\nI have written some opencv code to pull out the characters into separate images, and normalize the size etc., but I'm guessing there is some code that does this better than I can achieve. \n\nCan anyone point me in the right direction? ","author":"macarthy","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to ML and have a small project, where I have a million or so images containing handwritten texts in some uncommon languages. I&amp;#39;d like to experiment using the code that been written to process the MNIST digit dataset. &lt;/p&gt;\n\n&lt;p&gt;How do I get from image containing digits to the MNIST digit format?&lt;/p&gt;\n\n&lt;p&gt;I have written some opencv code to pull out the characters into separate images, and normalize the size etc., but I&amp;#39;m guessing there is some code that does this better than I can achieve. &lt;/p&gt;\n\n&lt;p&gt;Can anyone point me in the right direction? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null}
{"domain":"completebusinessanalytics.com","subreddit":"MachineLearning","report_reasons":null,"created_utc":1373934505,"is_self":false,"permalink":"/r/MachineLearning/comments/1idmi0/text_mining_how_to_mine_email_data_from_an_imap/","stickied":false,"title":"Text mining: How to mine e-mail data from an IMAP account using RapidMiner","gilded":0,"secure_media":null,"num_comments":0,"media":null,"mod_reports":[],"link_flair_css_class":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"retrieved_on":1412050022,"banned_by":null,"over_18":false,"thumbnail":"default","url":"http://www.completebusinessanalytics.com/post/2013/07/14/Text-mining-How-to-mine-e-mail-data-from-an-IMAP-account-using-RapidMiner.aspx","ups":0,"score":0,"link_flair_text":null,"edited":false,"selftext":"","subreddit_id":"t5_2r3gv","id":"1idmi0","author":"buddybjames","selftext_html":null,"user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null}
{"ups":3,"score":3,"url":"http://www.reddit.com/r/MachineLearning/comments/1ihkdq/is_this_a_reasonable_approach_to_handling_nominal/","over_18":false,"thumbnail":"self","subreddit_id":"t5_2r3gv","id":"1ihkdq","selftext":"A while back I needed a decision tree learning implementation in Java and wasn't satisfied with any of the options out there, so I decided to roll my own, you can find the result [here](https://github.com/sanity/quickdt).  My goals were to make it efficient enough to run on Google App Engine, and have a clean and fluent API consistent with modern Java API design approaches.\n\nI tried a variety of different split scoring algorithms and eventually settled on [this one](https://github.com/sanity/quickdt/blob/master/src/main/java/quickdt/scorers/Scorer1.java) which is of my own design, but seemed to yield better results on various datasets I tested with.  The code is of reasonable quality, but could use a lot more unit testing, and there are some complex methods in there that should be broken down.\n\nI came up with an approach to handling nominal attributes (eg. gender, city, zipcode) which seemed smart at the time, but now I'm having second thoughts and wanted some feedback.\n\nSo let's say I'm trying to find an optimal split for a \"city\" attribute in a dataset.  Nominal branches in the decision tree are of the form \"is the value in the following set of values?\".\n\nI start by picking the first city, placing it in this \"in\" set, and scoring this split.  I do this for each successive city, in each case creating a set of size 1 and testing the split.  Once I've tested all cities I pick the best one, and it becomes the first city in my \"in\" set.  I then repeat this process, adding each second city to the set, and testing the split.\n\nI keep adding cities to the \"in\" set until adding a new city results in a worse split score, at this point I'm done, I have my nominal decision node.\n\nYou can see an example of the type of decision tree this builds [here](http://cord-sa.appspot.com/dumpDT).\n\nMy concern is that the trees built using this approach rapidly approach 100% recall on the training set, even with a relatively limited depth.  My concern is that I'm giving too much flexibility to the decision tree builder to construct any set whatsoever at each nominal branch.\n\nI'd appreciate any thoughts on this.","edited":false,"link_flair_text":null,"user_reports":[],"author":"sanity","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A while back I needed a decision tree learning implementation in Java and wasn&amp;#39;t satisfied with any of the options out there, so I decided to roll my own, you can find the result &lt;a href=\"https://github.com/sanity/quickdt\"&gt;here&lt;/a&gt;.  My goals were to make it efficient enough to run on Google App Engine, and have a clean and fluent API consistent with modern Java API design approaches.&lt;/p&gt;\n\n&lt;p&gt;I tried a variety of different split scoring algorithms and eventually settled on &lt;a href=\"https://github.com/sanity/quickdt/blob/master/src/main/java/quickdt/scorers/Scorer1.java\"&gt;this one&lt;/a&gt; which is of my own design, but seemed to yield better results on various datasets I tested with.  The code is of reasonable quality, but could use a lot more unit testing, and there are some complex methods in there that should be broken down.&lt;/p&gt;\n\n&lt;p&gt;I came up with an approach to handling nominal attributes (eg. gender, city, zipcode) which seemed smart at the time, but now I&amp;#39;m having second thoughts and wanted some feedback.&lt;/p&gt;\n\n&lt;p&gt;So let&amp;#39;s say I&amp;#39;m trying to find an optimal split for a &amp;quot;city&amp;quot; attribute in a dataset.  Nominal branches in the decision tree are of the form &amp;quot;is the value in the following set of values?&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I start by picking the first city, placing it in this &amp;quot;in&amp;quot; set, and scoring this split.  I do this for each successive city, in each case creating a set of size 1 and testing the split.  Once I&amp;#39;ve tested all cities I pick the best one, and it becomes the first city in my &amp;quot;in&amp;quot; set.  I then repeat this process, adding each second city to the set, and testing the split.&lt;/p&gt;\n\n&lt;p&gt;I keep adding cities to the &amp;quot;in&amp;quot; set until adding a new city results in a worse split score, at this point I&amp;#39;m done, I have my nominal decision node.&lt;/p&gt;\n\n&lt;p&gt;You can see an example of the type of decision tree this builds &lt;a href=\"http://cord-sa.appspot.com/dumpDT\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;My concern is that the trees built using this approach rapidly approach 100% recall on the training set, even with a relatively limited depth.  My concern is that I&amp;#39;m giving too much flexibility to the decision tree builder to construct any set whatsoever at each nominal branch.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any thoughts on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"downs":0,"author_flair_text":null,"permalink":"/r/MachineLearning/comments/1ihkdq/is_this_a_reasonable_approach_to_handling_nominal/","subreddit":"MachineLearning","report_reasons":null,"created_utc":1374071901,"is_self":true,"domain":"self.MachineLearning","gilded":0,"num_comments":12,"secure_media":null,"stickied":false,"title":"Is this a reasonable approach to handling nominal attributes in a decision tree learner?","media":null,"banned_by":null,"retrieved_on":1412043539,"link_flair_css_class":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"mod_reports":[]}
{"distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"selftext_html":null,"author":"jamesjoyceroseroyce","selftext":"","id":"1ihj29","subreddit_id":"t5_2r3gv","edited":false,"link_flair_text":null,"ups":30,"url":"http://georgemdallas.wordpress.com/2013/06/11/big-data-data-mining-and-machine-learning-under-the-hood/","score":30,"thumbnail":"http://e.thumbs.redditmedia.com/gJ0RRMTlqx6sLmaL.jpg","over_18":false,"retrieved_on":1412043597,"banned_by":null,"mod_reports":[],"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"secure_media":null,"num_comments":13,"gilded":0,"title":"Machine Learning: Under the hood. Blog post explains the principles of machine learning in layman terms. Simple and clear","stickied":false,"permalink":"/r/MachineLearning/comments/1ihj29/machine_learning_under_the_hood_blog_post/","domain":"georgemdallas.wordpress.com","created_utc":1374070754,"is_self":false,"report_reasons":null,"subreddit":"MachineLearning"}
{"selftext":"I am facing a classification problem. There might be 50K observations and 1M factor (only in 0 or 1)features, while those features are all sparse, with little 1 and many 0 (the proportion of 1 is almost under 5% for any feature). I am wondering what can I do besides SVD and PCA(if possible)? Is feature selection possible? Do I have to consider association rules? Thanks a lot.","subreddit_id":"t5_2r3gv","id":"1ih1l0","link_flair_text":null,"edited":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1ih1l0/what_to_do_with_many_super_sparse_features_in_a/","ups":3,"score":3,"over_18":false,"thumbnail":"self","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"author":"hetong_007","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am facing a classification problem. There might be 50K observations and 1M factor (only in 0 or 1)features, while those features are all sparse, with little 1 and many 0 (the proportion of 1 is almost under 5% for any feature). I am wondering what can I do besides SVD and PCA(if possible)? Is feature selection possible? Do I have to consider association rules? Thanks a lot.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","gilded":0,"secure_media":null,"num_comments":11,"stickied":false,"title":"What to do with many super sparse features, in a classification problem?","permalink":"/r/MachineLearning/comments/1ih1l0/what_to_do_with_many_super_sparse_features_in_a/","domain":"self.MachineLearning","subreddit":"MachineLearning","is_self":true,"created_utc":1374046829,"report_reasons":null,"retrieved_on":1412044452,"banned_by":null,"mod_reports":[],"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"media":null}
{"downs":0,"author_flair_text":null,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently finished Andrew Ng&amp;#39;s course on machine learning offered at cousera. Im blown away with the applications of ML and I want to learn more. What should my next step be in continuing to learn about this area? Im able to find tons of information but honestly do not know where to start. My end goal is education, I would LOVE to be able to build something neat out of this (planning on doing linear regression and a classification ML application)&lt;/p&gt;\n\n&lt;p&gt;Secondary Question (if anyone has the time to answer!):\nIve also started doing work in cleaning some data I collected (I&amp;#39;m feeling that cleaning and gathering data is about 90% of the fight so far) and I&amp;#39;m running into issues with my computer not being fast/strong enough to handle the volume of data Im trying to make use of. Its slow to do operations such as shuffling a matrix (15mill x 14). Would anyone have a solution to this? Should I perhaps leverage AWS? &lt;/p&gt;\n\n&lt;p&gt;I have a strong calculus and linear algebra background. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"feedtheaimbot","user_reports":[],"link_flair_text":null,"edited":false,"id":"1igpxs","subreddit_id":"t5_2r3gv","selftext":"I recently finished Andrew Ng's course on machine learning offered at cousera. Im blown away with the applications of ML and I want to learn more. What should my next step be in continuing to learn about this area? Im able to find tons of information but honestly do not know where to start. My end goal is education, I would LOVE to be able to build something neat out of this (planning on doing linear regression and a classification ML application)\n\nSecondary Question (if anyone has the time to answer!):\nIve also started doing work in cleaning some data I collected (I'm feeling that cleaning and gathering data is about 90% of the fight so far) and I'm running into issues with my computer not being fast/strong enough to handle the volume of data Im trying to make use of. Its slow to do operations such as shuffling a matrix (15mill x 14). Would anyone have a solution to this? Should I perhaps leverage AWS? \n\nI have a strong calculus and linear algebra background. ","thumbnail":"self","over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1igpxs/ask_ml_next_step_after_andrews_ngs_course/","ups":16,"score":16,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412045019,"banned_by":null,"media":null,"title":"Ask ML: Next step after Andrews Ng's course","stickied":false,"secure_media":null,"num_comments":17,"gilded":0,"created_utc":1374033822,"is_self":true,"report_reasons":null,"subreddit":"MachineLearning","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1igpxs/ask_ml_next_step_after_andrews_ngs_course/"}
{"mod_reports":[],"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"retrieved_on":1412045855,"banned_by":null,"media":null,"stickied":false,"title":"What is the simplest to implement (from scratch) yet reasonably effective supervised learning algorithm?","gilded":0,"num_comments":54,"secure_media":null,"domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1374019418,"is_self":true,"report_reasons":null,"permalink":"/r/MachineLearning/comments/1ig8jm/what_is_the_simplest_to_implement_from_scratch/","author_flair_text":null,"downs":0,"distinguished":null,"author":"sanity","selftext_html":null,"user_reports":[],"link_flair_text":null,"edited":false,"selftext":"","subreddit_id":"t5_2r3gv","id":"1ig8jm","over_18":false,"thumbnail":"self","ups":31,"score":31,"url":"http://www.reddit.com/r/MachineLearning/comments/1ig8jm/what_is_the_simplest_to_implement_from_scratch/"}
{"gilded":0,"num_comments":9,"secure_media":null,"stickied":false,"title":"How to factor in tf-idf with Naive Bayes?","permalink":"/r/MachineLearning/comments/1inxnq/how_to_factor_in_tfidf_with_naive_bayes/","domain":"self.MachineLearning","subreddit":"MachineLearning","is_self":true,"created_utc":1374276241,"report_reasons":null,"retrieved_on":1412033646,"banned_by":null,"mod_reports":[],"link_flair_css_class":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"media":null,"selftext":"From my understanding of naive bayes (multinomial edition), it has to deal with the count of the word for each class and the total count of all words in the class for the following part of the formula, so I am a tad confused:\n\n\n    P(word|class)=(word_count_in_class + 1)/(total_words_in_class+total_unique_words_in_class) \n\n\n\n","subreddit_id":"t5_2r3gv","id":"1inxnq","edited":1374277222,"link_flair_text":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1inxnq/how_to_factor_in_tfidf_with_naive_bayes/","ups":14,"score":14,"over_18":false,"thumbnail":"self","distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"author":"mangaprincess","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From my understanding of naive bayes (multinomial edition), it has to deal with the count of the word for each class and the total count of all words in the class for the following part of the formula, so I am a tad confused:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;P(word|class)=(word_count_in_class + 1)/(total_words_in_class+total_unique_words_in_class) \n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"}
{"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was looking for a Data Visualization tool, preferably in Java, that can capture Dynamically growing clusters for streaming data. In addition, can i superimpose that visualization over some kind of Geographical/Map background with that tool ?&lt;/p&gt;\n\n&lt;p&gt;Do let me know all possible options to do the same.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"nemlhitchride","distinguished":null,"author_flair_text":null,"downs":0,"score":7,"ups":7,"url":"http://www.reddit.com/r/MachineLearning/comments/1injia/data_visualization_tools_in_java_preferably_for/","thumbnail":"self","over_18":false,"id":"1injia","subreddit_id":"t5_2r3gv","selftext":"I was looking for a Data Visualization tool, preferably in Java, that can capture Dynamically growing clusters for streaming data. In addition, can i superimpose that visualization over some kind of Geographical/Map background with that tool ?\n\nDo let me know all possible options to do the same.","link_flair_text":null,"edited":false,"media":null,"retrieved_on":1412034299,"banned_by":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1injia/data_visualization_tools_in_java_preferably_for/","created_utc":1374264724,"is_self":true,"report_reasons":null,"subreddit":"MachineLearning","domain":"self.MachineLearning","num_comments":1,"secure_media":null,"gilded":0,"title":"Data Visualization tools (in Java preferably) for capturing Dynamic Clustering.","stickied":false}
{"permalink":"/r/MachineLearning/comments/1ipri3/researcher_proposes_using_machine_learning_to/","report_reasons":null,"created_utc":1374355364,"is_self":false,"subreddit":"MachineLearning","domain":"eweek.com","secure_media":null,"num_comments":0,"gilded":0,"title":"Researcher Proposes Using Machine Learning to Improve Network Defense","stickied":false,"media":null,"retrieved_on":1412030625,"banned_by":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"link_flair_css_class":null,"mod_reports":[],"ups":3,"score":3,"url":"http://www.eweek.com/security/researcher-proposes-using-machine-learning-to-improve-network-defense/","thumbnail":"http://d.thumbs.redditmedia.com/kVyk9mi8FjjYsKKu.jpg","over_18":false,"id":"1ipri3","subreddit_id":"t5_2r3gv","selftext":"","link_flair_text":null,"edited":false,"user_reports":[],"selftext_html":null,"author":"alexcpsec","distinguished":null,"author_flair_text":null,"downs":0}
{"url":"http://www.reddit.com/r/MachineLearning/comments/1ipqb2/image_processing_toolkit_and_training_data/","ups":4,"score":4,"thumbnail":"self","over_18":false,"selftext":"Hey all, \n\nI am interested in writing my own skeleton tracker for kinnect data, but I don't want to reinvent too many wheels. I want to do this because in my experience openni is only good when directly facing the camera.\n\n\nI was wondering:\n\n1. what would you recommend as a python toolkit for fragmenting and resizing image patches in python? opencv? mahotas?\n\n2. where might I find good labeled training data for this type of project?  \n\n3. do you know of pakages already out there that do skeleton tracking with rotational invariance?  do you know of any packages for studying body language using kinnect?\n\n\nbtw, I am not doing this for the kaggle competition that's currently happening. ","id":"1ipqb2","subreddit_id":"t5_2r3gv","link_flair_text":null,"edited":false,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;I am interested in writing my own skeleton tracker for kinnect data, but I don&amp;#39;t want to reinvent too many wheels. I want to do this because in my experience openni is only good when directly facing the camera.&lt;/p&gt;\n\n&lt;p&gt;I was wondering:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;what would you recommend as a python toolkit for fragmenting and resizing image patches in python? opencv? mahotas?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;where might I find good labeled training data for this type of project?  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;do you know of pakages already out there that do skeleton tracking with rotational invariance?  do you know of any packages for studying body language using kinnect?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;btw, I am not doing this for the kaggle competition that&amp;#39;s currently happening. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"giror","distinguished":null,"downs":0,"author_flair_text":null,"permalink":"/r/MachineLearning/comments/1ipqb2/image_processing_toolkit_and_training_data/","domain":"self.MachineLearning","is_self":true,"created_utc":1374354214,"report_reasons":null,"subreddit":"MachineLearning","num_comments":2,"secure_media":null,"gilded":0,"title":"image processing toolkit and training data suggestions","stickied":false,"media":null,"retrieved_on":1412030676,"banned_by":null,"mod_reports":[],"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"link_flair_css_class":null}
{"permalink":"/r/MachineLearning/comments/1ippv3/using_less_data_loss_proportional_subsampling/","domain":"machinedlearnings.com","report_reasons":null,"created_utc":1374353808,"is_self":false,"subreddit":"MachineLearning","secure_media":null,"num_comments":2,"gilded":0,"title":"Using Less Data -- Loss Proportional Subsampling","stickied":false,"media":null,"retrieved_on":1412030705,"banned_by":null,"mod_reports":[],"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"link_flair_css_class":null,"ups":9,"score":9,"url":"http://www.machinedlearnings.com/2013/07/using-less-data.html","thumbnail":"default","over_18":false,"selftext":"","id":"1ippv3","subreddit_id":"t5_2r3gv","edited":false,"link_flair_text":null,"user_reports":[],"selftext_html":null,"author":"rrenaud","distinguished":null,"downs":0,"author_flair_text":null}
{"author":"[deleted]","selftext_html":null,"user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"over_18":false,"thumbnail":"default","url":"http://www.eweek.com/security/researcher-proposes-using-machine-learning-to-improve-network-defense/?utm_source=twitterfeed&amp;utm_medium=twitter","ups":1,"score":1,"edited":false,"link_flair_text":null,"selftext":"","subreddit_id":"t5_2r3gv","id":"1ipn1j","media":null,"mod_reports":[],"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"retrieved_on":1412030832,"banned_by":null,"domain":"eweek.com","subreddit":"MachineLearning","is_self":false,"created_utc":1374351088,"report_reasons":null,"permalink":"/r/MachineLearning/comments/1ipn1j/researcher_proposes_using_machine_learning_to/","stickied":false,"title":"Researcher Proposes Using Machine Learning to Improve Network Defense - See more at: http://www.eweek.com/security/researcher-proposes-using-machine-learning-to-improve-network-defense","gilded":0,"num_comments":0,"secure_media":null}
{"over_18":false,"thumbnail":"self","score":2,"ups":2,"url":"http://www.reddit.com/r/MachineLearning/comments/1ipajf/is_there_a_ml_environment_like_rapidminer_that/","edited":false,"link_flair_text":null,"selftext":"Bi-normal seperation (http://jmlr.org/papers/volume3/forman03a/forman03a.pdf) seems to be a nice feature selection method and I would like to try it on my data set to see if it actually works. \n\nDoes anybody know a ml environment to try this feature selection method?","subreddit_id":"t5_2r3gv","id":"1ipajf","author":"ComplexIt","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bi-normal seperation (&lt;a href=\"http://jmlr.org/papers/volume3/forman03a/forman03a.pdf\"&gt;http://jmlr.org/papers/volume3/forman03a/forman03a.pdf&lt;/a&gt;) seems to be a nice feature selection method and I would like to try it on my data set to see if it actually works. &lt;/p&gt;\n\n&lt;p&gt;Does anybody know a ml environment to try this feature selection method?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1374339738,"report_reasons":null,"is_self":true,"permalink":"/r/MachineLearning/comments/1ipajf/is_there_a_ml_environment_like_rapidminer_that/","stickied":false,"title":"Is there a ml environment (like RapidMiner) that supports bi-normal separation?","gilded":0,"num_comments":11,"secure_media":null,"media":null,"mod_reports":[],"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"retrieved_on":1412031407,"banned_by":null}
{"selftext":"In the last two weeks I studied Matrix Calculus, i.e. the set of rules and methods for differentiating functions involving vectors and matrices. It wasn't easy to make sense of the various methods. Not so many books cover this important topic and the book by Magnus and Neudecker is too long for someone who wants to get up to speed in a short time.\nI wrote an article about what I learned about this topic. It should provide a brief but self-contained and practical introduction to Matrix Calculus useful for Machine Learning.\nPlease let me know if something is unclear or if you have any questions about the article and the topic.\n\nedit: I'm going to add some examples of how to compute Hessian matrices as well.\n\n[link!](http://easymachinelearning.tumblr.com/post/55967954817/matrix-calculus)","subreddit_id":"t5_2r3gv","id":"1ip9y4","edited":1374405654,"link_flair_text":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1ip9y4/matrix_calculus_for_machine_learning/","ups":42,"score":42,"over_18":false,"thumbnail":"self","distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"author":"Kiuhnm","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the last two weeks I studied Matrix Calculus, i.e. the set of rules and methods for differentiating functions involving vectors and matrices. It wasn&amp;#39;t easy to make sense of the various methods. Not so many books cover this important topic and the book by Magnus and Neudecker is too long for someone who wants to get up to speed in a short time.\nI wrote an article about what I learned about this topic. It should provide a brief but self-contained and practical introduction to Matrix Calculus useful for Machine Learning.\nPlease let me know if something is unclear or if you have any questions about the article and the topic.&lt;/p&gt;\n\n&lt;p&gt;edit: I&amp;#39;m going to add some examples of how to compute Hessian matrices as well.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://easymachinelearning.tumblr.com/post/55967954817/matrix-calculus\"&gt;link!&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","gilded":0,"num_comments":8,"secure_media":null,"stickied":false,"title":"Matrix Calculus for Machine Learning","permalink":"/r/MachineLearning/comments/1ip9y4/matrix_calculus_for_machine_learning/","domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1374339213,"is_self":true,"report_reasons":null,"retrieved_on":1412031434,"banned_by":null,"mod_reports":[],"link_flair_css_class":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"media":null}
{"user_reports":[],"selftext_html":null,"author":"[deleted]","distinguished":null,"downs":0,"author_flair_text":null,"score":1,"ups":1,"url":"http://blog.hackingevolution.net/2013/07/21/what-is-evolutionary-computation-good-for/","thumbnail":"default","over_18":false,"selftext":"","id":"1irwky","subreddit_id":"t5_2r3gv","link_flair_text":null,"edited":false,"media":null,"retrieved_on":1412026924,"banned_by":null,"mod_reports":[],"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"permalink":"/r/MachineLearning/comments/1irwky/what_is_evolutionary_computation_good_for_a_lot/","domain":"blog.hackingevolution.net","created_utc":1374446345,"report_reasons":null,"is_self":false,"subreddit":"MachineLearning","secure_media":null,"num_comments":0,"gilded":0,"title":"What is Evolutionary Computation good for? A lot apparently!","stickied":false}
{"media":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412027375,"banned_by":null,"created_utc":1374438032,"report_reasons":null,"is_self":false,"subreddit":"MachineLearning","domain":"jstatsoft.org","permalink":"/r/MachineLearning/comments/1irmun/fastcluster_fast_hierarchical_agglomerative/","title":"fastcluster: Fast Hierarchical, Agglomerative Clustering Routines for R and Python","stickied":false,"secure_media":null,"num_comments":0,"gilded":0,"selftext_html":null,"author":"turnersr","user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null,"thumbnail":"default","over_18":false,"ups":17,"url":"http://www.jstatsoft.org/v53/i09/","score":17,"edited":false,"link_flair_text":null,"id":"1irmun","subreddit_id":"t5_2r3gv","selftext":""}
{"title":"Videos of all the talks of ICML 2013 are now available","stickied":false,"secure_media":null,"num_comments":10,"gilded":0,"domain":"techtalks.tv","is_self":false,"created_utc":1374408821,"report_reasons":null,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1iqwnt/videos_of_all_the_talks_of_icml_2013_are_now/","mod_reports":[],"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"link_flair_css_class":null,"banned_by":null,"retrieved_on":1412028660,"media":null,"edited":false,"link_flair_text":null,"selftext":"","id":"1iqwnt","subreddit_id":"t5_2r3gv","thumbnail":"http://e.thumbs.redditmedia.com/sgkHVkvzAFfl65vj.jpg","over_18":false,"ups":65,"url":"http://techtalks.tv/icml/2013/","score":65,"downs":0,"author_flair_text":null,"distinguished":null,"selftext_html":null,"author":"urish","user_reports":[]}
{"media":null,"link_flair_css_class":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"mod_reports":[],"retrieved_on":1412029604,"banned_by":null,"subreddit":"MachineLearning","is_self":true,"created_utc":1374376997,"report_reasons":null,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1iqda0/merging_clusterings_of_data/","stickied":false,"title":"Merging clusterings of data","gilded":0,"secure_media":null,"num_comments":0,"author":"[deleted]","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got some data that I&amp;#39;ve clustered in two different ways.  Each method has it&amp;#39;s strengths and I firmly believe that both are necessary.  Each of my measurements ends up with a unique ID indicating the group it belonged to in each method.  What I&amp;#39;d like to do is merge the results of both clusterings in order to build larger clusters, with the hope that the two methods will cover for the other when one fails.  &lt;/p&gt;\n\n&lt;p&gt;Is there a (hopefully low complexity) algorithm to do this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null,"over_18":false,"thumbnail":"default","score":1,"ups":1,"url":"http://www.reddit.com/r/MachineLearning/comments/1iqda0/merging_clusterings_of_data/","link_flair_text":null,"edited":1374377194,"subreddit_id":"t5_2r3gv","id":"1iqda0","selftext":"I've got some data that I've clustered in two different ways.  Each method has it's strengths and I firmly believe that both are necessary.  Each of my measurements ends up with a unique ID indicating the group it belonged to in each method.  What I'd like to do is merge the results of both clusterings in order to build larger clusters, with the hope that the two methods will cover for the other when one fails.  \n\nIs there a (hopefully low complexity) algorithm to do this? "}
{"media":null,"banned_by":null,"retrieved_on":1412023516,"link_flair_css_class":null,"author_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"mod_reports":[],"permalink":"/r/MachineLearning/comments/1itvru/why_use_lda_over_perceptron/","subreddit":"MachineLearning","created_utc":1374519268,"report_reasons":null,"is_self":true,"domain":"self.MachineLearning","gilded":0,"secure_media":null,"num_comments":21,"stickied":false,"title":"Why use LDA over Perceptron?","user_reports":[],"author":"Ayakalam","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;So I am very familiar with the percpetron, and I just recently learned about LDA. I get that it is an algorithm that finds the best hyperplane unto which to project your data for classification... however, I also understand that the perceptron does the same thing. &lt;/p&gt;\n\n&lt;p&gt;So... why would someone elect to use LDA over the Perceptron? What advantages or disadvantages are there? I am trying to understand how all this fits together. Is it just another technique to so supervised learning?&lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"author_flair_text":null,"downs":0,"ups":21,"score":21,"url":"http://www.reddit.com/r/MachineLearning/comments/1itvru/why_use_lda_over_perceptron/","over_18":false,"thumbnail":"self","subreddit_id":"t5_2r3gv","id":"1itvru","selftext":"\nHey all, \n\nSo I am very familiar with the percpetron, and I just recently learned about LDA. I get that it is an algorithm that finds the best hyperplane unto which to project your data for classification... however, I also understand that the perceptron does the same thing. \n\nSo... why would someone elect to use LDA over the Perceptron? What advantages or disadvantages are there? I am trying to understand how all this fits together. Is it just another technique to so supervised learning?\n\nThanks. ","link_flair_text":null,"edited":false}
{"selftext":"Hey /r/machinelearning--\n\nI don't see too many [question] posts here, so I hope I'm not in the wrong sub.  If so, please point me to a better option.\n\nCurrently  I am using SciKit Learn to classify text documents.  I badly need to lower the dimensionality of my data, and I have began doing so by attempting to implement some feature selection classes.  The only problem is that they're not working very well.\n\nI found this [streamhacker post](http://streamhacker.com/2010/06/16/text-classification-sentiment-analysis-eliminate-low-information-features/), but I am less familiar with the NLTK, so I was hoping to learn of other feature selection options (i.e., low information feature elimination) before I started.\n\nCan anyone here suggest anything??  Has anyone here ever reduced dimensionality using SciKit before??  Thank you in advance for any leads!\n\nPS: Is there a sub-group or sub-reddit dedicated to scikit question and, if not, is there any interest in starting one??","subreddit_id":"t5_2r3gv","id":"1itjyb","edited":false,"link_flair_text":null,"ups":15,"url":"http://www.reddit.com/r/MachineLearning/comments/1itjyb/question_best_resources_for_feature_selection/","score":15,"over_18":false,"thumbnail":"self","distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"author":"dickishbent","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/machinelearning\"&gt;/r/machinelearning&lt;/a&gt;--&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t see too many [question] posts here, so I hope I&amp;#39;m not in the wrong sub.  If so, please point me to a better option.&lt;/p&gt;\n\n&lt;p&gt;Currently  I am using SciKit Learn to classify text documents.  I badly need to lower the dimensionality of my data, and I have began doing so by attempting to implement some feature selection classes.  The only problem is that they&amp;#39;re not working very well.&lt;/p&gt;\n\n&lt;p&gt;I found this &lt;a href=\"http://streamhacker.com/2010/06/16/text-classification-sentiment-analysis-eliminate-low-information-features/\"&gt;streamhacker post&lt;/a&gt;, but I am less familiar with the NLTK, so I was hoping to learn of other feature selection options (i.e., low information feature elimination) before I started.&lt;/p&gt;\n\n&lt;p&gt;Can anyone here suggest anything??  Has anyone here ever reduced dimensionality using SciKit before??  Thank you in advance for any leads!&lt;/p&gt;\n\n&lt;p&gt;PS: Is there a sub-group or sub-reddit dedicated to scikit question and, if not, is there any interest in starting one??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","gilded":0,"num_comments":8,"secure_media":null,"stickied":false,"title":"[Question] Best resources for feature selection when classifying text using python??","permalink":"/r/MachineLearning/comments/1itjyb/question_best_resources_for_feature_selection/","domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1374510888,"report_reasons":null,"is_self":true,"retrieved_on":1412024071,"banned_by":null,"mod_reports":[],"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"media":null}
{"author_flair_text":null,"downs":0,"distinguished":null,"selftext_html":null,"author":"talgalili","user_reports":[],"edited":false,"link_flair_text":null,"selftext":"","id":"1itesj","subreddit_id":"t5_2r3gv","thumbnail":"http://f.thumbs.redditmedia.com/wfmJLJAIWPnkdLM_.jpg","over_18":false,"url":"http://www.r-bloggers.com/analyzing-your-data-on-the-aws-cloud-with-r/","ups":1,"score":1,"mod_reports":[],"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"retrieved_on":1412024313,"banned_by":null,"media":null,"title":"Analyzing Your Data on the AWS Amazon Cloud (with R!)","stickied":false,"num_comments":0,"secure_media":null,"gilded":0,"domain":"r-bloggers.com","created_utc":1374506932,"is_self":false,"report_reasons":null,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1itesj/analyzing_your_data_on_the_aws_amazon_cloud_with_r/"}
{"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412026391,"banned_by":null,"media":null,"title":"Q: What is Evolutionary Computation Good For? A: A versatile form of computational learning","stickied":false,"secure_media":null,"num_comments":3,"gilded":0,"created_utc":1374455885,"report_reasons":null,"is_self":false,"subreddit":"MachineLearning","domain":"blog.hackingevolution.net","permalink":"/r/MachineLearning/comments/1is796/q_what_is_evolutionary_computation_good_for_a_a/","author_flair_text":null,"downs":0,"distinguished":null,"selftext_html":null,"author":"kburjorj","user_reports":[],"edited":false,"link_flair_text":null,"id":"1is796","subreddit_id":"t5_2r3gv","selftext":"","thumbnail":"http://c.thumbs.redditmedia.com/dpoiBfei_IGW_pl8.jpg","over_18":false,"score":18,"ups":18,"url":"http://blog.hackingevolution.net/2013/07/21/what-is-evolutionary-computation-good-for/"}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t taken a course in Machine Learning yet, set to take a course in the fall. I have a non-linear function simulating kinematic motion (so it doesn&amp;#39;t have a finite equation). I want to perform a sensitivity analysis to study the effects of tolerances and mechanical wear on the system output, and determine the most significant contributors to error. I think variance-based sensitivity analysis is what I&amp;#39;m looking for, but I haven&amp;#39;t been able to find an algorithm that tells me how to do it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"criksus","user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"thumbnail":"self","over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1iwxuj/algorithm_request_variancebased_sensitivity/","ups":0,"score":0,"link_flair_text":null,"edited":false,"id":"1iwxuj","subreddit_id":"t5_2r3gv","selftext":"I haven't taken a course in Machine Learning yet, set to take a course in the fall. I have a non-linear function simulating kinematic motion (so it doesn't have a finite equation). I want to perform a sensitivity analysis to study the effects of tolerances and mechanical wear on the system output, and determine the most significant contributors to error. I think variance-based sensitivity analysis is what I'm looking for, but I haven't been able to find an algorithm that tells me how to do it.","media":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"link_flair_css_class":null,"mod_reports":[],"banned_by":null,"retrieved_on":1412018466,"is_self":true,"created_utc":1374617598,"report_reasons":null,"subreddit":"MachineLearning","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1iwxuj/algorithm_request_variancebased_sensitivity/","title":"Algorithm Request: Variance-Based Sensitivity Analysis","stickied":false,"num_comments":1,"secure_media":null,"gilded":0}
{"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I want to determine the usefulness of each input attribute to my supervised machine learner, which is producing a probability of an event occurring as output.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s assume that the machine learning algorithm is doing a good job (we&amp;#39;ve experimented and found the one that yields the best RMSE, and we have confidence in this).&lt;/p&gt;\n\n&lt;p&gt;My approach, which I think is common, is to go through each attribute, build a predictive model which excludes that attribute, cross-validate it, and measure the result (using RMSE in this case).  The attribute which yields the highest/worst RMSE when it is excluded is then assumed to be the most valuable to the predictive model.&lt;/p&gt;\n\n&lt;p&gt;A colleague suggested an alternative approach which I couldn&amp;#39;t think of a good counter-argument to.  His argument was basically that the better the predictive model, the more divergent the predictions would be, meaning that the standard deviation of the predictions would be higher for a better model.&lt;/p&gt;\n\n&lt;p&gt;The idea seems to work at the extremes.  A model that always gave the same prediction would obviously be useless, and the predictions would have a standard deviation of 0.&lt;/p&gt;\n\n&lt;p&gt;Similarly, a model that predicted perfectly would have predictions only of 1 and 0, and thus would have a very high standard deviation.  You might say that the standard deviation could be higher in this case by making the predictions 50% 1 and 50% 0 irrespective of what actually happened, but we&amp;#39;re assuming that our predictive model is doing a good job given the input data, and so that should be an option.&lt;/p&gt;\n\n&lt;p&gt;Is the standard deviation of the predictions a reasonable way to measure the usefulness of each input attribute?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"sanity","distinguished":null,"downs":0,"author_flair_text":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1iwvfg/does_a_higher_standard_deviation_in_your/","ups":2,"score":2,"thumbnail":"self","over_18":false,"id":"1iwvfg","subreddit_id":"t5_2r3gv","selftext":"So I want to determine the usefulness of each input attribute to my supervised machine learner, which is producing a probability of an event occurring as output.\n\nLet's assume that the machine learning algorithm is doing a good job (we've experimented and found the one that yields the best RMSE, and we have confidence in this).\n\nMy approach, which I think is common, is to go through each attribute, build a predictive model which excludes that attribute, cross-validate it, and measure the result (using RMSE in this case).  The attribute which yields the highest/worst RMSE when it is excluded is then assumed to be the most valuable to the predictive model.\n\nA colleague suggested an alternative approach which I couldn't think of a good counter-argument to.  His argument was basically that the better the predictive model, the more divergent the predictions would be, meaning that the standard deviation of the predictions would be higher for a better model.\n\nThe idea seems to work at the extremes.  A model that always gave the same prediction would obviously be useless, and the predictions would have a standard deviation of 0.\n\nSimilarly, a model that predicted perfectly would have predictions only of 1 and 0, and thus would have a very high standard deviation.  You might say that the standard deviation could be higher in this case by making the predictions 50% 1 and 50% 0 irrespective of what actually happened, but we're assuming that our predictive model is doing a good job given the input data, and so that should be an option.\n\nIs the standard deviation of the predictions a reasonable way to measure the usefulness of each input attribute?","link_flair_text":null,"edited":false,"media":null,"banned_by":null,"retrieved_on":1412018561,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1iwvfg/does_a_higher_standard_deviation_in_your/","created_utc":1374615733,"report_reasons":null,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","num_comments":8,"secure_media":null,"gilded":0,"title":"Does a higher standard deviation in your predictions indicate that your predictive model is doing a better job?","stickied":false}
{"user_reports":[],"author":"israellopez","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any papers out there that work to identify/characterize mechanical sounds? For example, I want to be able to identify a healthy engine by sound, versus an unhealthy one.  Then a deeper classification of what that sound could indicate.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the middle of gathering data on the subject and I&amp;#39;m trying to see if its a viable avenue of research.  I&amp;#39;m just a hobbyist in Machine Learning, so I do not have access to journals at the moment.  I appreciate any pointers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"author_flair_text":null,"downs":0,"url":"http://www.reddit.com/r/MachineLearning/comments/1iwuo0/papers_on_identifying_mechanical_sound_patterns/","ups":6,"score":6,"over_18":false,"thumbnail":"self","selftext":"Are there any papers out there that work to identify/characterize mechanical sounds? For example, I want to be able to identify a healthy engine by sound, versus an unhealthy one.  Then a deeper classification of what that sound could indicate.\n\nI'm in the middle of gathering data on the subject and I'm trying to see if its a viable avenue of research.  I'm just a hobbyist in Machine Learning, so I do not have access to journals at the moment.  I appreciate any pointers.","subreddit_id":"t5_2r3gv","id":"1iwuo0","link_flair_text":null,"edited":1374640965,"media":null,"retrieved_on":1412018592,"banned_by":null,"mod_reports":[],"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"permalink":"/r/MachineLearning/comments/1iwuo0/papers_on_identifying_mechanical_sound_patterns/","domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1374615161,"report_reasons":null,"is_self":true,"gilded":0,"num_comments":4,"secure_media":null,"stickied":false,"title":"Papers on Identifying Mechanical Sound Patterns"}
{"downs":0,"author_flair_text":null,"distinguished":null,"author":"mangaprincess","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Besides knowing what, when, and where to apply technique X to your task&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;edit:&lt;/strong&gt; thanks everyone. soopa helpful&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"edited":1374617971,"link_flair_text":null,"subreddit_id":"t5_2r3gv","id":"1iw7ab","selftext":"Besides knowing what, when, and where to apply technique X to your task\n\n**edit:** thanks everyone. soopa helpful\n","over_18":false,"thumbnail":"self","ups":26,"url":"http://www.reddit.com/r/MachineLearning/comments/1iw7ab/with_so_many_offtheshelf_libraries_and_packages/","score":26,"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"mod_reports":[],"retrieved_on":1412019590,"banned_by":null,"media":null,"stickied":false,"title":"With so many off-the-shelf libraries and packages already implemented of ML algos, where does expertise come in?","gilded":0,"secure_media":null,"num_comments":17,"subreddit":"MachineLearning","is_self":true,"created_utc":1374598764,"report_reasons":null,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1iw7ab/with_so_many_offtheshelf_libraries_and_packages/"}
{"id":"1izahf","subreddit_id":"t5_2r3gv","selftext":"Hey hi!!! I have taken the coursera class on ML by Prof Andrew Ng. Now a days i am exploring the ideas of Deep learning and aslo its application. Can anyone suggest  me some application on it (My be some seminal paper on that can be improvised.) ","edited":false,"link_flair_text":null,"ups":1,"score":1,"url":"http://www.reddit.com/r/MachineLearning/comments/1izahf/deep_learning_applcation/","thumbnail":"self","over_18":false,"distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey hi!!! I have taken the coursera class on ML by Prof Andrew Ng. Now a days i am exploring the ideas of Deep learning and aslo its application. Can anyone suggest  me some application on it (My be some seminal paper on that can be improvised.) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"koushiksaha89","secure_media":null,"num_comments":2,"gilded":0,"title":"Deep Learning Applcation","stickied":false,"permalink":"/r/MachineLearning/comments/1izahf/deep_learning_applcation/","report_reasons":null,"created_utc":1374697794,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","retrieved_on":1412014853,"banned_by":null,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"mod_reports":[],"media":null}
{"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\ndoes anyone know of research that applies machine learning concepts to psychometrics? I&amp;#39;m particularly interested in how machine learning theory (such as statistical learning theory and Hilbert-Schmidt norms) can be used to design better psychometric tests.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Hydreigon92","distinguished":null,"author_flair_text":null,"downs":0,"url":"http://www.reddit.com/r/MachineLearning/comments/1iz89u/machine_learning_and_psychometrics/","ups":6,"score":6,"thumbnail":"self","over_18":false,"id":"1iz89u","subreddit_id":"t5_2r3gv","selftext":"Hi,\ndoes anyone know of research that applies machine learning concepts to psychometrics? I'm particularly interested in how machine learning theory (such as statistical learning theory and Hilbert-Schmidt norms) can be used to design better psychometric tests.","link_flair_text":null,"edited":false,"media":null,"retrieved_on":1412014945,"banned_by":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1iz89u/machine_learning_and_psychometrics/","created_utc":1374696173,"is_self":true,"report_reasons":null,"subreddit":"MachineLearning","domain":"self.MachineLearning","secure_media":null,"num_comments":8,"gilded":0,"title":"Machine Learning and Psychometrics","stickied":false}
{"edited":false,"link_flair_text":null,"subreddit_id":"t5_2r3gv","id":"1iytz4","selftext":"Hi, I'm a rising freshman who'll be majoring in Math/Computer Science at UMass-Amherst. I'm interested in learning about machine learning. Fortunately, UMass has a good CS department, and is doing a lot of cool research in machine learning. I've been programming for the last 1-2 years. Mostly basic web development stuff, and some Matlab. Recently, I've been learning Python this summer. I'd like to learn about ML and its applications in computer vision, NLP (linguistics minor?), and bioinformatics. I'm not sure where to proceed from here. I AP'd out of a ton of classes, most of my gen eds are done (I'm basically a sophomore). I'm taking Linear Algebra, and Multi for math my freshman year. For CS, I just have a data structures course. I'm taking a class in linguistics as well. I'd like to get involved in kaggle competitions as well. If I want to work in ML, do I need to go graduate school? Any advice and/or suggestions related to doing an undergrad in CS, learning ML, etc. would be greatly appreciated.\n\nThanks!","over_18":false,"thumbnail":"self","ups":13,"url":"http://www.reddit.com/r/MachineLearning/comments/1iytz4/college_undergrad_interested_in_ml_need_some/","score":13,"downs":0,"author_flair_text":null,"distinguished":null,"author":"schwarz-brudda","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a rising freshman who&amp;#39;ll be majoring in Math/Computer Science at UMass-Amherst. I&amp;#39;m interested in learning about machine learning. Fortunately, UMass has a good CS department, and is doing a lot of cool research in machine learning. I&amp;#39;ve been programming for the last 1-2 years. Mostly basic web development stuff, and some Matlab. Recently, I&amp;#39;ve been learning Python this summer. I&amp;#39;d like to learn about ML and its applications in computer vision, NLP (linguistics minor?), and bioinformatics. I&amp;#39;m not sure where to proceed from here. I AP&amp;#39;d out of a ton of classes, most of my gen eds are done (I&amp;#39;m basically a sophomore). I&amp;#39;m taking Linear Algebra, and Multi for math my freshman year. For CS, I just have a data structures course. I&amp;#39;m taking a class in linguistics as well. I&amp;#39;d like to get involved in kaggle competitions as well. If I want to work in ML, do I need to go graduate school? Any advice and/or suggestions related to doing an undergrad in CS, learning ML, etc. would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"stickied":false,"title":"College undergrad interested in ML. Need some guidance.","gilded":0,"secure_media":null,"num_comments":17,"subreddit":"MachineLearning","is_self":true,"created_utc":1374686183,"report_reasons":null,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1iytz4/college_undergrad_interested_in_ml_need_some/","link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"mod_reports":[],"retrieved_on":1412015537,"banned_by":null,"media":null}
{"media":null,"retrieved_on":1412016104,"banned_by":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"link_flair_css_class":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1iygj9/12_predictive_analytics_screwups/","report_reasons":null,"created_utc":1374675703,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","secure_media":null,"num_comments":4,"gilded":0,"title":"12 Predictive Analytics Screw-ups","stickied":false,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sometimes getting the technical parts right is only half the battle. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"johnny_a","distinguished":null,"author_flair_text":null,"downs":0,"url":"http://www.reddit.com/r/MachineLearning/comments/1iygj9/12_predictive_analytics_screwups/","ups":0,"score":0,"thumbnail":"self","over_18":false,"id":"1iygj9","subreddit_id":"t5_2r3gv","selftext":"Sometimes getting the technical parts right is only half the battle. ","link_flair_text":null,"edited":false}
{"ups":6,"url":"http://www.reddit.com/r/MachineLearning/comments/1ixoh1/matrix_factorization_techniques_for_recommender/","score":6,"over_18":false,"thumbnail":"self","selftext":"Given a movie-user rating dataset and a task to predict the user rating for a movie. I would like to know how matrix factorization techniques (collaborative filtering) would perform for when the movies present in the test set is not present in training set. I presume the features uncovered by matrix factorization in these scenarios would be bad because the movie was unseen during the training phase. Are there any other set of algorithms that deal with these kinds of scenarios?","subreddit_id":"t5_2r3gv","id":"1ixoh1","link_flair_text":null,"edited":false,"user_reports":[],"author":"srinathsmn","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given a movie-user rating dataset and a task to predict the user rating for a movie. I would like to know how matrix factorization techniques (collaborative filtering) would perform for when the movies present in the test set is not present in training set. I presume the features uncovered by matrix factorization in these scenarios would be bad because the movie was unseen during the training phase. Are there any other set of algorithms that deal with these kinds of scenarios?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"author_flair_text":null,"downs":0,"permalink":"/r/MachineLearning/comments/1ixoh1/matrix_factorization_techniques_for_recommender/","domain":"self.MachineLearning","subreddit":"MachineLearning","report_reasons":null,"created_utc":1374639241,"is_self":true,"gilded":0,"secure_media":null,"num_comments":3,"stickied":false,"title":"Matrix factorization techniques for recommender systems given test set contains items not in train set","media":null,"retrieved_on":1412017316,"banned_by":null,"mod_reports":[],"link_flair_css_class":null,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{}}
{"subreddit_id":"t5_2r3gv","id":"1j1v39","selftext":"I am trying to scrape labeled data from various websites. The data I need is \"description: ..., title: ... , contact: ... , etc\" (most times these appear in html tables). The problem is that each website's page structure is different. Since I know what data I need, and it is almost always labeled. is there any ML technique I can use that could infer the information that I need?","link_flair_text":null,"edited":false,"ups":2,"url":"http://www.reddit.com/r/MachineLearning/comments/1j1v39/extracting_semistructured_data/","score":2,"over_18":false,"thumbnail":"self","distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"author":"M1Reeder","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to scrape labeled data from various websites. The data I need is &amp;quot;description: ..., title: ... , contact: ... , etc&amp;quot; (most times these appear in html tables). The problem is that each website&amp;#39;s page structure is different. Since I know what data I need, and it is almost always labeled. is there any ML technique I can use that could infer the information that I need?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","gilded":0,"secure_media":null,"num_comments":2,"stickied":false,"title":"Extracting Semi-Structured Data","permalink":"/r/MachineLearning/comments/1j1v39/extracting_semistructured_data/","subreddit":"MachineLearning","created_utc":1374784374,"report_reasons":null,"is_self":true,"domain":"self.MachineLearning","banned_by":null,"retrieved_on":1412010845,"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"mod_reports":[],"media":null}
{"distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Should you add corruption on every layer? It seems like you should to me but someone has told me otherwise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"slickric","id":"1j1qja","subreddit_id":"t5_2r3gv","selftext":"Should you add corruption on every layer? It seems like you should to me but someone has told me otherwise.","link_flair_text":null,"edited":false,"ups":5,"score":5,"url":"http://www.reddit.com/r/MachineLearning/comments/1j1qja/question_about_stacked_denoising_autoencoders/","thumbnail":"self","over_18":false,"banned_by":null,"retrieved_on":1412011049,"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"mod_reports":[],"media":null,"num_comments":7,"secure_media":null,"gilded":0,"title":"Question about Stacked Denoising Autoencoders","stickied":false,"permalink":"/r/MachineLearning/comments/1j1qja/question_about_stacked_denoising_autoencoders/","created_utc":1374781090,"is_self":true,"report_reasons":null,"subreddit":"MachineLearning","domain":"self.MachineLearning"}
{"created_utc":1374776315,"report_reasons":null,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1j1jrs/request_for_help_making_sense_of_an_unstructured/","title":"Request for Help: Making Sense of an Unstructured Variable as Well as Categorizing Transactions.","stickied":false,"secure_media":null,"num_comments":10,"gilded":0,"media":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412011355,"banned_by":null,"thumbnail":"self","over_18":false,"ups":5,"url":"http://www.reddit.com/r/MachineLearning/comments/1j1jrs/request_for_help_making_sense_of_an_unstructured/","score":5,"edited":false,"link_flair_text":null,"id":"1j1jrs","subreddit_id":"t5_2r3gv","selftext":"So here is the issue:\n\nI have a dataset of mildly organized transaction data with limited to no demographic information on the purchasers.  This is a *massive* dataset, totaling in the millions. Transactions can be anything purchased online, from shoes to groceries and sex toys.  My ultimate goal is to have a program that will classify these transactions into their respective industries, so a TV would be placed into \"consumer electronics\" and a T Shirt would be placed into Apparel.  There will be about 10-15 different possible industries as well as a catch all \"Not Applicable\" for industries that won't be looked at.  After this, I'd like to break down the information to categories within that industry, so the TV that went into Consumer Electronics would also be in the \"TV\" category.\n\nIn regards to item information itself, I have the merchant and the price, but most information on the item is located within a \"description\" variable.  However, the layout of this variable is not structured.  So a pair of Nike shoes could show up as \"Nike: Size - 9.5: Dunks\" Sliver/Grey/Green\" or could just read \"NIKE\". Pretty much, it's a grab bag as to what's there and how it's arranged.   However, I have expanded information including brand, features, category and all relevant details for about 1% of the total database for each industry.\n\n\nI was wondering if anyone had a good idea on where to start for this process?\n\nMy current line of thinking would be a Naive Bayes method using the 1% of more detailed data as the training set and classifying the data by industry first, then doing it by category. \nAnother idea was to use an Inverse Document Frequency procedure to help pick apart that description field and hopefully help classify the transaction.\n\nI'm currently looking into R's text miner program as well as a program named DataFlux but was curious if anyone had another idea of a program which may prove useful, a different approach i hadn't thought of or some words of advice in general.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So here is the issue:&lt;/p&gt;\n\n&lt;p&gt;I have a dataset of mildly organized transaction data with limited to no demographic information on the purchasers.  This is a &lt;em&gt;massive&lt;/em&gt; dataset, totaling in the millions. Transactions can be anything purchased online, from shoes to groceries and sex toys.  My ultimate goal is to have a program that will classify these transactions into their respective industries, so a TV would be placed into &amp;quot;consumer electronics&amp;quot; and a T Shirt would be placed into Apparel.  There will be about 10-15 different possible industries as well as a catch all &amp;quot;Not Applicable&amp;quot; for industries that won&amp;#39;t be looked at.  After this, I&amp;#39;d like to break down the information to categories within that industry, so the TV that went into Consumer Electronics would also be in the &amp;quot;TV&amp;quot; category.&lt;/p&gt;\n\n&lt;p&gt;In regards to item information itself, I have the merchant and the price, but most information on the item is located within a &amp;quot;description&amp;quot; variable.  However, the layout of this variable is not structured.  So a pair of Nike shoes could show up as &amp;quot;Nike: Size - 9.5: Dunks&amp;quot; Sliver/Grey/Green&amp;quot; or could just read &amp;quot;NIKE&amp;quot;. Pretty much, it&amp;#39;s a grab bag as to what&amp;#39;s there and how it&amp;#39;s arranged.   However, I have expanded information including brand, features, category and all relevant details for about 1% of the total database for each industry.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone had a good idea on where to start for this process?&lt;/p&gt;\n\n&lt;p&gt;My current line of thinking would be a Naive Bayes method using the 1% of more detailed data as the training set and classifying the data by industry first, then doing it by category. \nAnother idea was to use an Inverse Document Frequency procedure to help pick apart that description field and hopefully help classify the transaction.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking into R&amp;#39;s text miner program as well as a program named DataFlux but was curious if anyone had another idea of a program which may prove useful, a different approach i hadn&amp;#39;t thought of or some words of advice in general.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"murdahmamurdah","user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for training data for classifying customers feedback into categories like General Opinion, Grievances, Success Stories, Popularity, Strong Opinion etc.&lt;/p&gt;\n\n&lt;p&gt;Please guide to references&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"anshulwall","user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"thumbnail":"self","over_18":false,"score":1,"ups":1,"url":"http://www.reddit.com/r/MachineLearning/comments/1j0vqj/looking_for_training_data_having_customer/","link_flair_text":null,"edited":false,"id":"1j0vqj","subreddit_id":"t5_2r3gv","selftext":"\n\nI am looking for training data for classifying customers feedback into categories like General Opinion, Grievances, Success Stories, Popularity, Strong Opinion etc.\n\nPlease guide to references\n","media":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412012428,"banned_by":null,"created_utc":1374756781,"report_reasons":null,"is_self":true,"subreddit":"MachineLearning","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1j0vqj/looking_for_training_data_having_customer/","title":"looking for training data ( having customer feedback) for text classification","stickied":false,"num_comments":0,"secure_media":null,"gilded":0}
{"thumbnail":"default","over_18":false,"ups":0,"score":0,"url":"http://www.ken-flow.net/","edited":false,"link_flair_text":null,"id":"1j0lte","subreddit_id":"t5_2r3gv","selftext":"","selftext_html":null,"author":"kenflowro","user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null,"created_utc":1374740791,"report_reasons":null,"is_self":false,"subreddit":"MachineLearning","domain":"ken-flow.net","permalink":"/r/MachineLearning/comments/1j0lte/ro_water_purifier/","title":"RO water purifier","stickied":false,"secure_media":null,"num_comments":0,"gilded":0,"media":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412012864,"banned_by":null}
{"author":"iu42","selftext_html":null,"user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null,"over_18":false,"thumbnail":"http://c.thumbs.redditmedia.com/7YDWbUfkLUWwFImP.jpg","ups":2,"score":2,"url":"http://channel9.msdn.com/Events/Build/2013/3-704","link_flair_text":null,"edited":false,"subreddit_id":"t5_2r3gv","id":"1j0hl1","selftext":"","media":null,"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"mod_reports":[],"retrieved_on":1412013042,"banned_by":null,"subreddit":"MachineLearning","report_reasons":null,"created_utc":1374734630,"is_self":false,"domain":"channel9.msdn.com","permalink":"/r/MachineLearning/comments/1j0hl1/realworld_machine_learning_how_kinect_gesture/","stickied":false,"title":"Real-World Machine Learning: How Kinect Gesture Recognition Works","gilded":0,"num_comments":0,"secure_media":null}
{"subreddit":"MachineLearning","report_reasons":null,"created_utc":1374725548,"is_self":false,"domain":"simonsfoundation.org","permalink":"/r/MachineLearning/comments/1j09bm/as_machines_get_smart_evidence_they_learn_like_us/","stickied":false,"title":"As Machines Get Smart, Evidence They Learn Like Us","gilded":0,"secure_media":null,"num_comments":0,"media":null,"link_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"mod_reports":[],"retrieved_on":1412013390,"banned_by":null,"over_18":false,"thumbnail":"http://b.thumbs.redditmedia.com/wzLrUx-j8cs1dt7a.jpg","ups":12,"score":12,"url":"https://www.simonsfoundation.org/quanta/20130723-as-machines-get-smarter-evidence-they-learn-like-us/","link_flair_text":null,"edited":false,"subreddit_id":"t5_2r3gv","id":"1j09bm","selftext":"","author":"wisintel","selftext_html":null,"user_reports":[],"author_flair_text":null,"downs":0,"distinguished":null}
{"author_flair_text":null,"downs":0,"distinguished":null,"author":"zigzagp","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll take a typical example of a retail company. Lets say a retail company opened up in 2011 and has been running since. It captures the total sales for every day and wants to forecast the total sales for 2013 for each day given the data for 2011 and 2012. Now, since, there are simply 365 rows each for 2011 and 2012 with some additional attributes with each of them, would existing Machine Learning algorithms be able to forecast it with a decent accuracy? If yes, could you give a few pointers on how that is done. From whatever i&amp;#39;ve seen till now, most of the sales forecasting problems seems to have data for quite some time. If ML is not helpful here because of less data, how does one propose to approach such a problem?\nAny help is appreciated!\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"link_flair_text":null,"edited":false,"subreddit_id":"t5_2r3gv","id":"1j0904","selftext":"I'll take a typical example of a retail company. Lets say a retail company opened up in 2011 and has been running since. It captures the total sales for every day and wants to forecast the total sales for 2013 for each day given the data for 2011 and 2012. Now, since, there are simply 365 rows each for 2011 and 2012 with some additional attributes with each of them, would existing Machine Learning algorithms be able to forecast it with a decent accuracy? If yes, could you give a few pointers on how that is done. From whatever i've seen till now, most of the sales forecasting problems seems to have data for quite some time. If ML is not helpful here because of less data, how does one propose to approach such a problem?\nAny help is appreciated!\nThanks","over_18":false,"thumbnail":"self","score":6,"ups":6,"url":"http://www.reddit.com/r/MachineLearning/comments/1j0904/can_we_learn_with_less_data/","link_flair_css_class":null,"author_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"mod_reports":[],"retrieved_on":1412013404,"banned_by":null,"media":null,"stickied":false,"title":"Can we learn with less data?","gilded":0,"num_comments":20,"secure_media":null,"subreddit":"MachineLearning","report_reasons":null,"created_utc":1374725274,"is_self":true,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1j0904/can_we_learn_with_less_data/"}
{"title":"Reasons Franking Machines are Beneficial","stickied":false,"num_comments":0,"secure_media":null,"gilded":0,"domain":"tanishadevries.weebly.com","report_reasons":null,"created_utc":1374718339,"is_self":false,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1j00sp/reasons_franking_machines_are_beneficial/","mod_reports":[],"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"banned_by":null,"retrieved_on":1412013745,"media":null,"edited":false,"link_flair_text":null,"selftext":"","id":"1j00sp","subreddit_id":"t5_2r3gv","thumbnail":"default","over_18":false,"url":"http://tanishadevries.weebly.com/1/post/2013/07/reasons-franking-machines-are-beneficial.html","ups":0,"score":0,"downs":0,"author_flair_text":null,"distinguished":null,"selftext_html":null,"author":"duttonantoni0","user_reports":[]}
{"gilded":0,"secure_media":null,"num_comments":4,"stickied":false,"title":"A Quick Guide to SVMs for Scientists &amp; Engineers","permalink":"/r/MachineLearning/comments/1izuqf/a_quick_guide_to_svms_for_scientists_engineers/","subreddit":"MachineLearning","report_reasons":null,"created_utc":1374713356,"is_self":false,"domain":"newfolder.github.io","retrieved_on":1412013998,"banned_by":null,"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"mod_reports":[],"media":null,"subreddit_id":"t5_2r3gv","id":"1izuqf","selftext":"","edited":false,"link_flair_text":null,"url":"http://newfolder.github.io/blog/2013/07/24/using-svms/","ups":54,"score":54,"over_18":false,"thumbnail":"http://e.thumbs.redditmedia.com/2UUk1st1-eWQkVmL.jpg","distinguished":null,"downs":0,"author_flair_text":null,"user_reports":[],"author":"peterTorrione","selftext_html":null}
{"over_18":false,"thumbnail":"self","ups":34,"url":"http://www.reddit.com/r/MachineLearning/comments/1j4prp/lets_learn_r_together_kaggles_titanic_competition/","score":34,"link_flair_text":null,"edited":false,"selftext":"Kaggle currently has a \"knowledge\" competition going where you are given some basic demographic information about passengers and are asked to use this information to predict whether or not they survived the disaster.\n\nHere's a link to the competition: http://www.kaggle.com/c/titanic-gettingStarted\n\nThis is a great learning problem because the data set is relatively simple, with some missing values thrown in, and just enough noise to make things interesting.\n\nI'm just learning R and here's what I propose: If you're interested in honing your R skills (or are just learning predictive modeling) we try to tackle this problem together. In this thread we will post our R models--with plenty of comments explaining what each line of code does and why we chose to do it. In addition, we'll post our scores so everyone can see how successful our models are. To start things off, I'll post a comment with my best scoring randomForest model.\n\nSince this is a learning thread, if you don't understand something about any code that's posted, just ask! R has a slight learning curve and everyone has to start somewhere.","subreddit_id":"t5_2r3gv","id":"1j4prp","author":"[deleted]","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kaggle currently has a &amp;quot;knowledge&amp;quot; competition going where you are given some basic demographic information about passengers and are asked to use this information to predict whether or not they survived the disaster.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a link to the competition: &lt;a href=\"http://www.kaggle.com/c/titanic-gettingStarted\"&gt;http://www.kaggle.com/c/titanic-gettingStarted&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a great learning problem because the data set is relatively simple, with some missing values thrown in, and just enough noise to make things interesting.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just learning R and here&amp;#39;s what I propose: If you&amp;#39;re interested in honing your R skills (or are just learning predictive modeling) we try to tackle this problem together. In this thread we will post our R models--with plenty of comments explaining what each line of code does and why we chose to do it. In addition, we&amp;#39;ll post our scores so everyone can see how successful our models are. To start things off, I&amp;#39;ll post a comment with my best scoring randomForest model.&lt;/p&gt;\n\n&lt;p&gt;Since this is a learning thread, if you don&amp;#39;t understand something about any code that&amp;#39;s posted, just ask! R has a slight learning curve and everyone has to start somewhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"domain":"self.MachineLearning","subreddit":"MachineLearning","created_utc":1374882313,"report_reasons":null,"is_self":true,"permalink":"/r/MachineLearning/comments/1j4prp/lets_learn_r_together_kaggles_titanic_competition/","stickied":false,"title":"Let's learn R together! Kaggle's \"Titanic\" competition.","gilded":0,"secure_media":null,"num_comments":19,"media":null,"mod_reports":[],"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"retrieved_on":1412006468,"banned_by":null}
{"permalink":"/r/MachineLearning/comments/1j4omd/pattern_generation_reverse_pattern_recognition/","domain":"self.MachineLearning","created_utc":1374881309,"is_self":true,"report_reasons":null,"subreddit":"MachineLearning","secure_media":null,"num_comments":7,"gilded":0,"title":"Pattern generation: Reverse pattern recognition?","stickied":false,"media":null,"retrieved_on":1412006525,"banned_by":null,"mod_reports":[],"secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"ups":5,"score":5,"url":"http://www.reddit.com/r/MachineLearning/comments/1j4omd/pattern_generation_reverse_pattern_recognition/","thumbnail":"self","over_18":false,"selftext":"Sup guys. ML noob here.\n\nIs there such a thing as the opposite of pattern recognition? is there a proper name for it?\n\nE.g., in hand-written digit recognition (supervised or unsupervised) there is the pattern '1', and there is the idea '1' behind the pattern. And the purpose of ML code is to recognize the idea from the pattern.\n\nBut I want a code, that has learnt the pattern, to generate patterns for that idea, such that no two generated patterns are alike.\n\nAny ideas?","id":"1j4omd","subreddit_id":"t5_2r3gv","link_flair_text":null,"edited":false,"user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sup guys. ML noob here.&lt;/p&gt;\n\n&lt;p&gt;Is there such a thing as the opposite of pattern recognition? is there a proper name for it?&lt;/p&gt;\n\n&lt;p&gt;E.g., in hand-written digit recognition (supervised or unsupervised) there is the pattern &amp;#39;1&amp;#39;, and there is the idea &amp;#39;1&amp;#39; behind the pattern. And the purpose of ML code is to recognize the idea from the pattern.&lt;/p&gt;\n\n&lt;p&gt;But I want a code, that has learnt the pattern, to generate patterns for that idea, such that no two generated patterns are alike.&lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"yudlejoza","distinguished":null,"author_flair_text":null,"downs":0}
{"title":"What is the distinction between r/datamining, r/bigdata, r/machinelearning, r/datascience, r/datasets?","stickied":false,"num_comments":8,"secure_media":null,"gilded":0,"is_self":true,"created_utc":1374879449,"report_reasons":null,"subreddit":"MachineLearning","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1j4ml5/what_is_the_distinction_between_rdatamining/","secure_media_embed":{},"author_flair_css_class":null,"media_embed":{},"link_flair_css_class":null,"mod_reports":[],"banned_by":null,"retrieved_on":1412006610,"media":null,"edited":false,"link_flair_text":null,"id":"1j4ml5","subreddit_id":"t5_2r3gv","selftext":"For a newcomer in the Data Science community, it's great that there are so many subreddits on the topic. But there are a lot of subreddits that seem to have a significant amount of overlap, and I don't know where to begin reading.\n\nFor a person who wants to analyze/display datasets as a hobby, and perhaps an eventual career, which subreddit is the best place to start? What sets each subreddit apart from each other, and what combo of subreddits have you found to be the most useful to follow? \n\nP.S. Posted this here since it has the largest # of subscribers. Thanks!","thumbnail":"self","over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1j4ml5/what_is_the_distinction_between_rdatamining/","ups":13,"score":13,"downs":0,"author_flair_text":null,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a newcomer in the Data Science community, it&amp;#39;s great that there are so many subreddits on the topic. But there are a lot of subreddits that seem to have a significant amount of overlap, and I don&amp;#39;t know where to begin reading.&lt;/p&gt;\n\n&lt;p&gt;For a person who wants to analyze/display datasets as a hobby, and perhaps an eventual career, which subreddit is the best place to start? What sets each subreddit apart from each other, and what combo of subreddits have you found to be the most useful to follow? &lt;/p&gt;\n\n&lt;p&gt;P.S. Posted this here since it has the largest # of subscribers. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"bluefoot3","user_reports":[]}
{"author_flair_text":null,"downs":0,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any optimized libraries that are currently being utilized for Autoencoders and DNN generation? &lt;/p&gt;\n\n&lt;p&gt;-I am currently working with OpenCV and integration would be nice (but not really necessary). &lt;/p&gt;\n\n&lt;p&gt;-GPU implementations would be helpful so that the system is scalable [CUDA or OpenCL works]&lt;/p&gt;\n\n&lt;p&gt;-Linux library is a requirement&lt;/p&gt;\n\n&lt;p&gt;-Free to implement in a commercial product is preferable. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"bge0","user_reports":[],"link_flair_text":null,"edited":false,"selftext":"Are there any optimized libraries that are currently being utilized for Autoencoders and DNN generation? \n\n\n-I am currently working with OpenCV and integration would be nice (but not really necessary). \n\n\n-GPU implementations would be helpful so that the system is scalable [CUDA or OpenCL works]\n\n\n-Linux library is a requirement\n\n\n-Free to implement in a commercial product is preferable. \n","id":"1j3xq1","subreddit_id":"t5_2r3gv","thumbnail":"self","over_18":false,"ups":2,"score":2,"url":"http://www.reddit.com/r/MachineLearning/comments/1j3xq1/c_library_for_deep_neural_netsautoencoders/","mod_reports":[],"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"retrieved_on":1412007680,"banned_by":null,"media":null,"title":"C++ Library for Deep Neural Nets/AutoEncoders","stickied":false,"secure_media":null,"num_comments":4,"gilded":0,"domain":"self.MachineLearning","report_reasons":null,"created_utc":1374860183,"is_self":true,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1j3xq1/c_library_for_deep_neural_netsautoencoders/"}
{"selftext_html":null,"author":"_dexter","user_reports":[],"downs":0,"author_flair_text":null,"distinguished":null,"thumbnail":"default","over_18":false,"ups":17,"score":17,"url":"http://hunch.net/?p=2664","link_flair_text":null,"edited":false,"selftext":"","id":"1j3vqy","subreddit_id":"t5_2r3gv","media":null,"mod_reports":[],"secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"retrieved_on":1412007762,"banned_by":null,"domain":"hunch.net","created_utc":1374858726,"report_reasons":null,"is_self":false,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/1j3vqy/icml_2012_videos_lost_machine_learning_theory/","title":"ICML 2012 videos lost « Machine Learning (Theory)","stickied":false,"num_comments":1,"secure_media":null,"gilded":0}
{"subreddit_id":"t5_2r3gv","id":"1j3ohq","selftext":"Choosing the right technology stack can mean the difference between SUCCESS and FAILURE in data science. It can also mean the difference between ‘I Feel Productive’ and ‘Everything I try takes so much time’.\nWhen deciding which toolkit / stack be sure to learn from others, consider implementation partners, and always remain cautious.\n\nI am surveying people to determine which data science technology stacks are being used right now.\n\nThe survey responses will remain confidential and can be accessed via this link: http://bit.ly/ToolkitSurvey (takes less than 200 seconds!).\nThose that complete the survey will get a copy of a report (which will detail the pros/cons of popular data science technology stacks).\n\nFull post here: http://becomingadatascientist.wordpress.com/2013/07/26/choosing-a-data-science-technology-stack-w-survey/\n\nInterested to see what technology stacks others here are using.","link_flair_text":null,"edited":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1j3ohq/machine_learning_redditors_what_technology/","ups":1,"score":1,"over_18":false,"thumbnail":"default","distinguished":null,"author_flair_text":null,"downs":0,"user_reports":[],"author":"[deleted]","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Choosing the right technology stack can mean the difference between SUCCESS and FAILURE in data science. It can also mean the difference between ‘I Feel Productive’ and ‘Everything I try takes so much time’.\nWhen deciding which toolkit / stack be sure to learn from others, consider implementation partners, and always remain cautious.&lt;/p&gt;\n\n&lt;p&gt;I am surveying people to determine which data science technology stacks are being used right now.&lt;/p&gt;\n\n&lt;p&gt;The survey responses will remain confidential and can be accessed via this link: &lt;a href=\"http://bit.ly/ToolkitSurvey\"&gt;http://bit.ly/ToolkitSurvey&lt;/a&gt; (takes less than 200 seconds!).\nThose that complete the survey will get a copy of a report (which will detail the pros/cons of popular data science technology stacks).&lt;/p&gt;\n\n&lt;p&gt;Full post here: &lt;a href=\"http://becomingadatascientist.wordpress.com/2013/07/26/choosing-a-data-science-technology-stack-w-survey/\"&gt;http://becomingadatascientist.wordpress.com/2013/07/26/choosing-a-data-science-technology-stack-w-survey/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Interested to see what technology stacks others here are using.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","gilded":0,"num_comments":0,"secure_media":null,"stickied":false,"title":"Machine Learning Redditors: What technology / toolkit stack do you use? [X-post from /r/datascience]","permalink":"/r/MachineLearning/comments/1j3ohq/machine_learning_redditors_what_technology/","subreddit":"MachineLearning","created_utc":1374852947,"is_self":true,"report_reasons":null,"domain":"self.MachineLearning","retrieved_on":1412008061,"banned_by":null,"link_flair_css_class":null,"author_flair_css_class":null,"secure_media_embed":{},"media_embed":{},"mod_reports":[],"media":null}
{"score":2,"ups":2,"url":"http://www.reddit.com/r/MachineLearning/comments/1j3jg4/merging_classes_without_contradictions/","over_18":false,"thumbnail":"default","selftext":"I've got an association problem I'm working on, and I've currently got two ways of classifying my data.  Let's say I basically have measurements that are red, blue or green over time, and I want to associate things together in time as well as across colors. I have a way to classify across colors that I like and I think I trust.  Similarly, I have a way to group within a color temporally.   \n\nI'd like to merge these two classes when I'm done so that I have larger clusters that associate the data over time and between colors.  The problem is I have a constraint that you can't have two or more of the same color at the same time, at most you can have one red, one blue, one green.\n\nIs there a smart way to do this merging to avoid conflicts?","subreddit_id":"t5_2r3gv","id":"1j3jg4","link_flair_text":null,"edited":1374853180,"user_reports":[],"author":"[deleted]","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got an association problem I&amp;#39;m working on, and I&amp;#39;ve currently got two ways of classifying my data.  Let&amp;#39;s say I basically have measurements that are red, blue or green over time, and I want to associate things together in time as well as across colors. I have a way to classify across colors that I like and I think I trust.  Similarly, I have a way to group within a color temporally.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to merge these two classes when I&amp;#39;m done so that I have larger clusters that associate the data over time and between colors.  The problem is I have a constraint that you can&amp;#39;t have two or more of the same color at the same time, at most you can have one red, one blue, one green.&lt;/p&gt;\n\n&lt;p&gt;Is there a smart way to do this merging to avoid conflicts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"downs":0,"author_flair_text":null,"permalink":"/r/MachineLearning/comments/1j3jg4/merging_classes_without_contradictions/","domain":"self.MachineLearning","subreddit":"MachineLearning","is_self":true,"created_utc":1374848740,"report_reasons":null,"gilded":0,"secure_media":null,"num_comments":0,"stickied":false,"title":"Merging classes without contradictions?","media":null,"retrieved_on":1412008270,"banned_by":null,"mod_reports":[],"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null}
{"downs":0,"author_flair_text":null,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My goal is to use machine learning to train a system to play a certain game. I can generate an arbitrarily large amount of data. There would be 30-50 inputs and one output (this is not classification).&lt;/p&gt;\n\n&lt;p&gt;Generating 10 million training examples should not be too hard, but I realize that training something like a neural network with such a large training set would take a long time... Prediction time must not be much more than 1 second.&lt;/p&gt;\n\n&lt;p&gt;Given that I want good accuracy and reasonable training time given a large amount of data, which machine learning algorithms should I consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"TheCatelier","user_reports":[],"link_flair_text":null,"edited":false,"id":"1j2ffk","subreddit_id":"t5_2r3gv","selftext":"My goal is to use machine learning to train a system to play a certain game. I can generate an arbitrarily large amount of data. There would be 30-50 inputs and one output (this is not classification).\n\nGenerating 10 million training examples should not be too hard, but I realize that training something like a neural network with such a large training set would take a long time... Prediction time must not be much more than 1 second.\n\nGiven that I want good accuracy and reasonable training time given a large amount of data, which machine learning algorithms should I consider?","thumbnail":"self","over_18":false,"ups":10,"score":10,"url":"http://www.reddit.com/r/MachineLearning/comments/1j2ffk/given_an_arbitrarily_large_amount_of_data_which/","secure_media_embed":{},"media_embed":{},"author_flair_css_class":null,"link_flair_css_class":null,"mod_reports":[],"retrieved_on":1412009963,"banned_by":null,"media":null,"title":"Given an arbitrarily large amount of data, which regression algorithm should I use?","stickied":false,"secure_media":null,"num_comments":43,"gilded":0,"created_utc":1374800647,"is_self":true,"report_reasons":null,"subreddit":"MachineLearning","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1j2ffk/given_an_arbitrarily_large_amount_of_data_which/"}
{"secure_media":null,"link_flair_css_class":null,"distinguished":null,"mod_reports":[],"retrieved_on":1411996782,"permalink":"/r/MachineLearning/comments/1j6s7w/q_dirichlet_and_topic_modeling/","over_18":false,"created_utc":1374968670,"author_flair_css_class":null,"gilded":0,"banned_by":null,"title":"[Q] Dirichlet and topic modeling","user_reports":[],"stickied":false,"num_comments":2,"domain":"self.MachineLearning","link_flair_text":null,"selftext":"Explain like I'm 11, why the Dirichlet distribution for topic modeling?\rThanks.","downs":0,"author":"drki56","url":"http://www.reddit.com/r/MachineLearning/comments/1j6s7w/q_dirichlet_and_topic_modeling/","report_reasons":null,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Explain like I&amp;#39;m 11, why the Dirichlet distribution for topic modeling?\nThanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"media_embed":{},"id":"1j6s7w","author_flair_text":null,"edited":false,"media":null,"secure_media_embed":{},"score":0,"ups":0,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv"}
{"secure_media":null,"link_flair_css_class":null,"mod_reports":[],"distinguished":null,"retrieved_on":1411996890,"created_utc":1374965712,"over_18":false,"author_flair_css_class":null,"permalink":"/r/MachineLearning/comments/1j6pbn/what_should_be_in_a_machine_learning_course/","gilded":0,"title":"What should be in a machine learning course?","banned_by":null,"num_comments":1,"user_reports":[],"stickied":false,"domain":"andrewgelman.com","author":"mttd","downs":0,"selftext":"","link_flair_text":null,"url":"http://andrewgelman.com/2013/07/25/what-should-be-in-a-machine-learning-course/","report_reasons":null,"media_embed":{},"id":"1j6pbn","thumbnail":"http://c.thumbs.redditmedia.com/TSW_5BIjOzH7wjt2.jpg","is_self":false,"selftext_html":null,"media":null,"secure_media_embed":{},"author_flair_text":null,"edited":false,"score":11,"subreddit":"MachineLearning","ups":11,"subreddit_id":"t5_2r3gv"}
{"score":19,"ups":19,"url":"http://algorithmicthoughts.wordpress.com/2013/07/26/machine-learning-mini-batch-k-means/","over_18":false,"thumbnail":"http://f.thumbs.redditmedia.com/2YcYOzZb3fh76UE_.jpg","subreddit_id":"t5_2r3gv","id":"1j5o63","selftext":"","link_flair_text":null,"edited":false,"user_reports":[],"author":"rrenaud","selftext_html":null,"distinguished":null,"downs":0,"author_flair_text":null,"permalink":"/r/MachineLearning/comments/1j5o63/a_short_article_on_mini_batch_kmeans/","subreddit":"MachineLearning","is_self":false,"created_utc":1374927948,"report_reasons":null,"domain":"algorithmicthoughts.wordpress.com","gilded":0,"secure_media":null,"num_comments":0,"stickied":false,"title":"A short article on mini batch K-Means","media":null,"banned_by":null,"retrieved_on":1412005075,"link_flair_css_class":null,"media_embed":{},"secure_media_embed":{},"author_flair_css_class":null,"mod_reports":[]}
{"score":12,"media":null,"secure_media_embed":{},"author_flair_text":null,"edited":false,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","ups":12,"author":"bugra","downs":0,"selftext":"","link_flair_text":null,"domain":"bugra.github.io","media_embed":{},"id":"1j8hz2","is_self":false,"thumbnail":"http://a.thumbs.redditmedia.com/LW6vSl9qjum3Qxdx.jpg","selftext_html":null,"url":"http://bugra.github.io/work/notes/2013-07-27/PCA-EigenFace-And-All-That/","report_reasons":null,"gilded":0,"created_utc":1375046606,"over_18":false,"author_flair_css_class":null,"permalink":"/r/MachineLearning/comments/1j8hz2/pca_eigenface_and_all_that/","num_comments":2,"user_reports":[],"stickied":false,"title":"PCA, EigenFace and All That","banned_by":null,"mod_reports":[],"distinguished":null,"secure_media":null,"link_flair_css_class":null,"retrieved_on":1411994455}
{"secure_media":null,"link_flair_css_class":null,"mod_reports":[],"distinguished":null,"retrieved_on":1411995669,"over_18":false,"created_utc":1375009630,"author_flair_css_class":null,"permalink":"/r/MachineLearning/comments/1j7ll3/what_is_the_intrinsic_information_in_decision/","gilded":0,"banned_by":null,"title":"What is the intrinsic information in decision trees algorithms? (xpost from ELI5)","num_comments":5,"user_reports":[],"stickied":false,"domain":"self.MachineLearning","author":"throwaway890353","downs":0,"link_flair_text":null,"selftext":"I searched quite a lot in google, but I cannot make my mind up on what the split information concept is, in decision tree algorithms. Is it a synonym of \"split information\"? I cannot find a good example and for me the while concept is still obscure. Any help?\n","url":"http://www.reddit.com/r/MachineLearning/comments/1j7ll3/what_is_the_intrinsic_information_in_decision/","report_reasons":null,"media_embed":{},"id":"1j7ll3","thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I searched quite a lot in google, but I cannot make my mind up on what the split information concept is, in decision tree algorithms. Is it a synonym of &amp;quot;split information&amp;quot;? I cannot find a good example and for me the while concept is still obscure. Any help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"media":null,"secure_media_embed":{},"author_flair_text":null,"edited":false,"score":6,"subreddit":"MachineLearning","ups":6,"subreddit_id":"t5_2r3gv"}
{"retrieved_on":1411995836,"link_flair_css_class":null,"secure_media":null,"distinguished":null,"mod_reports":[],"banned_by":null,"title":"Machine Learning Redditors: What technology / toolkit stack do you use?","stickied":false,"user_reports":[],"num_comments":0,"permalink":"/r/MachineLearning/comments/1j7hc4/machine_learning_redditors_what_technology/","author_flair_css_class":null,"created_utc":1374999839,"over_18":false,"gilded":0,"report_reasons":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1j7hc4/machine_learning_redditors_what_technology/","is_self":true,"thumbnail":"default","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Choosing the right technology stack can mean the difference between SUCCESS and FAILURE in data science. It can also mean the difference between ‘I Feel Productive’ and ‘Everything I try takes so much time’. When deciding which toolkit / stack be sure to learn from others, consider implementation partners, and always remain cautious.\nI am surveying people to determine which data science technology stacks are being used right now.&lt;/p&gt;\n\n&lt;p&gt;The survey responses will remain confidential and can be accessed via this link: &lt;a href=\"https://docs.google.com/forms/d/1OxjiHx3S7AEsfVu5rYy0E9pjfuPeg7SSAt0CXqRJX2k/viewformy\"&gt;https://docs.google.com/forms/d/1OxjiHx3S7AEsfVu5rYy0E9pjfuPeg7SSAt0CXqRJX2k/viewformy&lt;/a&gt; (takes less than 200 seconds!). I&amp;#39;ll post a copy of the report here when complete (which will detail the pros/cons of popular data science technology stacks).&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://becomingadatascientist.wordpress.com/2013/07/26/choosing-a-data-science-technology-stack-w-survey/\"&gt;http://becomingadatascientist.wordpress.com/2013/07/26/choosing-a-data-science-technology-stack-w-survey/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Interested to see what technology stacks others here are using.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","id":"1j7hc4","media_embed":{},"domain":"self.MachineLearning","selftext":"Choosing the right technology stack can mean the difference between SUCCESS and FAILURE in data science. It can also mean the difference between ‘I Feel Productive’ and ‘Everything I try takes so much time’. When deciding which toolkit / stack be sure to learn from others, consider implementation partners, and always remain cautious.\nI am surveying people to determine which data science technology stacks are being used right now.\n\nThe survey responses will remain confidential and can be accessed via this link: https://docs.google.com/forms/d/1OxjiHx3S7AEsfVu5rYy0E9pjfuPeg7SSAt0CXqRJX2k/viewformy (takes less than 200 seconds!). I'll post a copy of the report here when complete (which will detail the pros/cons of popular data science technology stacks).\n\nhttp://becomingadatascientist.wordpress.com/2013/07/26/choosing-a-data-science-technology-stack-w-survey/\n\nInterested to see what technology stacks others here are using.","link_flair_text":null,"author":"[deleted]","downs":0,"ups":1,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","edited":false,"author_flair_text":null,"secure_media_embed":{},"media":null,"score":1}
{"domain":"self.MachineLearning","selftext":"Hello, \n\nI'm a high school student working on a project at my local university. Our project has some computer vision aspects. Unfortunately, the professor I'm working with is not an expert in computer vision which has kind of left me in the dark on those parts of the project. I'm just looking to get a small start and some suggestions.\n\nI'll start by explaining the problem.\n\nWe're working on improving the landform classification accuracy of terrestrial surfaces. Essentially, our sites will consist of many different landforms such as crater walls, ridges, plateaus, etc. Here's a ground truth for what one of our sites looks like: http://d.pr/i/Z4sI . We're trying to do this on a segmented map of that site. The segmented map was done by a k-means algorithm and consists of about 7000 segments. Each landform that you see is made up of many many segments.\n\nWhat we want to do is exploit the fact that different landforms have different shapes. A crater wall is circular, ridges are diagonal and linear, etc etc. The best way to do this, we thought, was capture visual patterns around each segment. We need to extract a feature on the segment level. We hope that the visual patterns around, for example, all crater wall segments would be similar when compared to the visual patterns around all ridge segments.\n\n\nThe whole point is to relate the segment back to the shape of the landform.\n\n\nDo you have any idea, suggestions, or papers I could look at for this.\n\nThanks\n\nEDIT: Just wanted to include this to ward off any confusion. The kind of data we're working with is called a DEM, digital elevation model. The data stores the elevation of every pixel at that specific point. If I computer the magnitude of the gradient vectors of each pixel, this is what it looks like: http://d.pr/i/TfXF . Also, here's an RGB image where the 3 channels are 3 different pixel based features calculated off of the DEM: http://d.pr/i/6n8K . The k-means algorithm was done on the RGB image to produce the segments. You can contrast that with what the ground truth is supposed to look like. \n\nEDIT: This is what the segmented map looks like: http://d.pr/i/FR1O","link_flair_text":null,"author":"logrech","downs":0,"url":"http://www.reddit.com/r/MachineLearning/comments/1jamk6/capturing_visual_patterns_for_each_segment_on_a/","report_reasons":null,"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a high school student working on a project at my local university. Our project has some computer vision aspects. Unfortunately, the professor I&amp;#39;m working with is not an expert in computer vision which has kind of left me in the dark on those parts of the project. I&amp;#39;m just looking to get a small start and some suggestions.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll start by explaining the problem.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re working on improving the landform classification accuracy of terrestrial surfaces. Essentially, our sites will consist of many different landforms such as crater walls, ridges, plateaus, etc. Here&amp;#39;s a ground truth for what one of our sites looks like: &lt;a href=\"http://d.pr/i/Z4sI\"&gt;http://d.pr/i/Z4sI&lt;/a&gt; . We&amp;#39;re trying to do this on a segmented map of that site. The segmented map was done by a k-means algorithm and consists of about 7000 segments. Each landform that you see is made up of many many segments.&lt;/p&gt;\n\n&lt;p&gt;What we want to do is exploit the fact that different landforms have different shapes. A crater wall is circular, ridges are diagonal and linear, etc etc. The best way to do this, we thought, was capture visual patterns around each segment. We need to extract a feature on the segment level. We hope that the visual patterns around, for example, all crater wall segments would be similar when compared to the visual patterns around all ridge segments.&lt;/p&gt;\n\n&lt;p&gt;The whole point is to relate the segment back to the shape of the landform.&lt;/p&gt;\n\n&lt;p&gt;Do you have any idea, suggestions, or papers I could look at for this.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n\n&lt;p&gt;EDIT: Just wanted to include this to ward off any confusion. The kind of data we&amp;#39;re working with is called a DEM, digital elevation model. The data stores the elevation of every pixel at that specific point. If I computer the magnitude of the gradient vectors of each pixel, this is what it looks like: &lt;a href=\"http://d.pr/i/TfXF\"&gt;http://d.pr/i/TfXF&lt;/a&gt; . Also, here&amp;#39;s an RGB image where the 3 channels are 3 different pixel based features calculated off of the DEM: &lt;a href=\"http://d.pr/i/6n8K\"&gt;http://d.pr/i/6n8K&lt;/a&gt; . The k-means algorithm was done on the RGB image to produce the segments. You can contrast that with what the ground truth is supposed to look like. &lt;/p&gt;\n\n&lt;p&gt;EDIT: This is what the segmented map looks like: &lt;a href=\"http://d.pr/i/FR1O\"&gt;http://d.pr/i/FR1O&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","media_embed":{},"id":"1jamk6","author_flair_text":null,"edited":1375127327,"media":null,"secure_media_embed":{},"score":9,"ups":9,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","secure_media":null,"link_flair_css_class":null,"distinguished":null,"mod_reports":[],"retrieved_on":1411991558,"permalink":"/r/MachineLearning/comments/1jamk6/capturing_visual_patterns_for_each_segment_on_a/","over_18":false,"created_utc":1375124898,"author_flair_css_class":null,"gilded":0,"banned_by":null,"title":"Capturing visual patterns for each segment on a segmented site","user_reports":[],"stickied":false,"num_comments":7}
{"downs":0,"author":"PokerPirate","selftext":"","link_flair_text":null,"domain":"izbicki.me","media_embed":{},"id":"1ja3o8","is_self":false,"selftext_html":null,"thumbnail":"http://b.thumbs.redditmedia.com/5-PNg--Y0qygyBvU.jpg","url":"http://izbicki.me/blog/functors-and-monads-for-analyzing-data","report_reasons":null,"score":7,"media":null,"secure_media_embed":{},"author_flair_text":null,"edited":false,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","ups":7,"mod_reports":[],"distinguished":null,"secure_media":null,"link_flair_css_class":null,"retrieved_on":1411992285,"gilded":0,"over_18":false,"created_utc":1375111302,"author_flair_css_class":null,"permalink":"/r/MachineLearning/comments/1ja3o8/functors_and_monads_for_analyzing_data/","num_comments":0,"user_reports":[],"stickied":false,"banned_by":null,"title":"Functors and monads for analyzing data"}
{"subreddit_id":"t5_2r3gv","ups":19,"subreddit":"MachineLearning","score":19,"author_flair_text":null,"edited":false,"media":null,"secure_media_embed":{},"is_self":false,"thumbnail":"default","selftext_html":null,"media_embed":{},"id":"1ja1c3","url":"http://www.databozo.com/2013/07/28/Modeling_complex_cause_and_effect_with_Bayesian_Networks.html","report_reasons":null,"selftext":"","link_flair_text":null,"author":"DarkXanthos","downs":0,"domain":"databozo.com","user_reports":[],"stickied":false,"num_comments":0,"banned_by":null,"title":"Modeling complex cause &amp; effect with Bayesian Networks","gilded":0,"permalink":"/r/MachineLearning/comments/1ja1c3/modeling_complex_cause_effect_with_bayesian/","created_utc":1375109412,"over_18":false,"author_flair_css_class":null,"retrieved_on":1411992373,"distinguished":null,"mod_reports":[],"secure_media":null,"link_flair_css_class":null}
{"secure_media_embed":{},"media":null,"edited":false,"author_flair_text":null,"score":53,"subreddit":"MachineLearning","ups":53,"subreddit_id":"t5_2r3gv","domain":"peekaboo-vision.blogspot.de","downs":0,"author":"t3kcit","selftext":"","link_flair_text":null,"report_reasons":null,"url":"http://peekaboo-vision.blogspot.de/2013/07/scikit-learn-sprint-and-014-release.html","id":"1j9toa","media_embed":{},"selftext_html":null,"thumbnail":"http://d.thumbs.redditmedia.com/j449NrE6NvMk5B5i.jpg","is_self":false,"author_flair_css_class":null,"over_18":false,"created_utc":1375101532,"permalink":"/r/MachineLearning/comments/1j9toa/peekaboo_scikitlearn_014_release_candidate/","gilded":0,"banned_by":null,"title":"Peekaboo: Scikit-learn 0.14 release candidate","num_comments":18,"stickied":false,"user_reports":[],"link_flair_css_class":null,"secure_media":null,"mod_reports":[],"distinguished":null,"retrieved_on":1411992661}
{"user_reports":[],"stickied":false,"num_comments":10,"title":"Why isn't there much talk about neural networks with mixed depth connections?","banned_by":null,"gilded":0,"permalink":"/r/MachineLearning/comments/1j92au/why_isnt_there_much_talk_about_neural_networks/","created_utc":1375064958,"over_18":false,"author_flair_css_class":null,"retrieved_on":1411993699,"distinguished":null,"mod_reports":[],"secure_media":null,"link_flair_css_class":null,"subreddit_id":"t5_2r3gv","ups":17,"subreddit":"MachineLearning","score":17,"author_flair_text":null,"edited":1375121356,"media":null,"secure_media_embed":{},"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Practically all of the literature focuses on neural networks with separated hidden layers, in which a neuron in the n&amp;#39;th layer only has input connections from layer n - 1. I was playing with the idea of putting together sigmoid units by hand as a white box model, and realized that this model can be seen as a neural net with no distinct layers. My intuition tells me that it also has more representational power, if just by a constant factor. It definitely has the downside of being harder to implement quickly on a computer (matrix multiplication won&amp;#39;t work as nicely) but if it has greater representational power per neuron than a network with discrete layers, perhaps it is worth some research.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit&lt;/strong&gt;: I am mainly asking about feedforward nets in which there is no restriction on connectivity, aside from having no cycles (that is required for it to be considered a feedforward net). So far all the responses seem to be about nets with more structure than this (they all consider nets that are still organized into layers, whose activations are computed using possibly more than one previous layer). Still on topic, but my main concern is still unanswered here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media_embed":{},"id":"1j92au","url":"http://www.reddit.com/r/MachineLearning/comments/1j92au/why_isnt_there_much_talk_about_neural_networks/","report_reasons":null,"link_flair_text":null,"selftext":"Practically all of the literature focuses on neural networks with separated hidden layers, in which a neuron in the n'th layer only has input connections from layer n - 1. I was playing with the idea of putting together sigmoid units by hand as a white box model, and realized that this model can be seen as a neural net with no distinct layers. My intuition tells me that it also has more representational power, if just by a constant factor. It definitely has the downside of being harder to implement quickly on a computer (matrix multiplication won't work as nicely) but if it has greater representational power per neuron than a network with discrete layers, perhaps it is worth some research.\n\n**Edit**: I am mainly asking about feedforward nets in which there is no restriction on connectivity, aside from having no cycles (that is required for it to be considered a feedforward net). So far all the responses seem to be about nets with more structure than this (they all consider nets that are still organized into layers, whose activations are computed using possibly more than one previous layer). Still on topic, but my main concern is still unanswered here.","downs":0,"author":"justonium","domain":"self.MachineLearning"}
{"retrieved_on":1411993809,"link_flair_css_class":null,"secure_media":null,"mod_reports":[],"distinguished":null,"banned_by":null,"title":"What are some interesting facts we can pull out of transactional data with machine learning?","num_comments":6,"stickied":false,"user_reports":[],"author_flair_css_class":null,"over_18":false,"created_utc":1375062443,"permalink":"/r/MachineLearning/comments/1j8ze1/what_are_some_interesting_facts_we_can_pull_out/","gilded":0,"report_reasons":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1j8ze1/what_are_some_interesting_facts_we_can_pull_out/","id":"1j8ze1","media_embed":{},"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve done some machine learning in my day, but never on this type of data.  I have been given access to some transactional data and I&amp;#39;d like to use it to explore new ideas in machine learning, but it&amp;#39;s not clear to me what kind of techniques would exploit the fact that the data is transactional (each data point has a distinct time that it was &amp;quot;born&amp;quot; at and a user or location).  &lt;/p&gt;\n\n&lt;p&gt;My question is pretty simple: What kind of information can we use machine learning to reveal from this type of data?  And what types of machine learning techniques would we use to extract that interesting information?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"self","domain":"self.MachineLearning","downs":0,"author":"sockblock1","selftext":"I've done some machine learning in my day, but never on this type of data.  I have been given access to some transactional data and I'd like to use it to explore new ideas in machine learning, but it's not clear to me what kind of techniques would exploit the fact that the data is transactional (each data point has a distinct time that it was \"born\" at and a user or location).  \n\nMy question is pretty simple: What kind of information can we use machine learning to reveal from this type of data?  And what types of machine learning techniques would we use to extract that interesting information?","link_flair_text":null,"subreddit":"MachineLearning","ups":0,"subreddit_id":"t5_2r3gv","secure_media_embed":{},"media":null,"edited":false,"author_flair_text":null,"score":0}
{"secure_media_embed":{},"media":null,"edited":false,"author_flair_text":null,"score":0,"subreddit":"MachineLearning","ups":0,"subreddit_id":"t5_2r3gv","domain":"self.MachineLearning","author":"SeoNeoGeo","downs":0,"selftext":"","link_flair_text":null,"report_reasons":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1jdfl4/all_of_my_degree_work_was_in_matlab_and_fortran/","id":"1jdfl4","media_embed":{},"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"default","is_self":true,"author_flair_css_class":null,"over_18":false,"created_utc":1375216109,"permalink":"/r/MachineLearning/comments/1jdfl4/all_of_my_degree_work_was_in_matlab_and_fortran/","gilded":0,"title":"All of my degree work was in Matlab and Fortran. What language should I work on to get a programming position?","banned_by":null,"num_comments":10,"stickied":false,"user_reports":[],"link_flair_css_class":null,"secure_media":null,"mod_reports":[],"distinguished":null,"retrieved_on":1411987717}
{"gilded":0,"permalink":"/r/MachineLearning/comments/1jde55/what_other_machine_learning_communities_are_there/","created_utc":1375215077,"over_18":false,"author_flair_css_class":null,"user_reports":[],"stickied":false,"num_comments":18,"banned_by":null,"title":"What other machine learning communities are there? Is there a way to find companies that use machine learning techniques?","distinguished":null,"mod_reports":[],"secure_media":null,"link_flair_css_class":null,"retrieved_on":1411987771,"score":14,"author_flair_text":null,"edited":false,"media":null,"secure_media_embed":{},"subreddit_id":"t5_2r3gv","ups":14,"subreddit":"MachineLearning","selftext":"","link_flair_text":null,"author":"SeoNeoGeo","downs":0,"domain":"self.MachineLearning","thumbnail":"self","selftext_html":null,"is_self":true,"media_embed":{},"id":"1jde55","url":"http://www.reddit.com/r/MachineLearning/comments/1jde55/what_other_machine_learning_communities_are_there/","report_reasons":null}
{"score":5,"secure_media_embed":{},"media":null,"edited":false,"author_flair_text":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","ups":5,"downs":0,"author":"[deleted]","link_flair_text":null,"selftext":"Trying to explain the algorithm to non technical audiences, my going explanation is that we have horses and want to identifier the winners so we come up with rules of thumb that work and then create subrules and do it over and over again....\n","domain":"self.MachineLearning","id":"1jcx2a","media_embed":{},"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to explain the algorithm to non technical audiences, my going explanation is that we have horses and want to identifier the winners so we come up with rules of thumb that work and then create subrules and do it over and over again....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"self","report_reasons":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1jcx2a/an_eli5_explanation_of_adaboost/","gilded":0,"author_flair_css_class":null,"created_utc":1375203392,"over_18":false,"permalink":"/r/MachineLearning/comments/1jcx2a/an_eli5_explanation_of_adaboost/","num_comments":12,"stickied":false,"user_reports":[],"title":"an ELI5 explanation of adaboost","banned_by":null,"mod_reports":[],"distinguished":null,"link_flair_css_class":null,"secure_media":null,"retrieved_on":1411988402}
{"domain":"self.MachineLearning","downs":0,"author":"z4r4","selftext":"","link_flair_text":null,"report_reasons":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1jcjuc/machine_learning_roadmap/","id":"1jcjuc","media_embed":{},"thumbnail":"default","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","secure_media_embed":{},"media":null,"edited":false,"author_flair_text":null,"score":11,"subreddit":"MachineLearning","ups":11,"subreddit_id":"t5_2r3gv","link_flair_css_class":null,"secure_media":null,"mod_reports":[],"distinguished":null,"retrieved_on":1411988918,"author_flair_css_class":null,"over_18":false,"created_utc":1375192945,"permalink":"/r/MachineLearning/comments/1jcjuc/machine_learning_roadmap/","gilded":0,"title":"Machine Learning Roadmap","banned_by":null,"num_comments":10,"stickied":false,"user_reports":[]}
{"domain":"self.MachineLearning","downs":0,"author":"Gamvit","link_flair_text":null,"selftext":"I am currently a senior majoring in Statistics and Economics and am wondering if a Data Science type career is right for me. I was first interested in a career as a market researcher but as I learned from my current internship, it isn't that challenging (not really that challenging). What I really had a passion for in my early years of college(which attracted me to market research), was assisting in the product development phase. Using massive datasets to make better decisions about what future products to introduce and what these products should have included in them to make them profitable. I looked into specific fields in data science (data mining, machine learning, etc..) but for me it seems like all of these are in one way or another, connected. What I seek from this post, is a better sense of what I would be doing in a couple career fields involving data science. I looked online for several applications but due to past several events (NSA spying), everything seemed to directed about data mining and the government. If someone could describe the difference between the following, I would really appreciate it. 1.) market researcher 2.) data miner 3.) machine learning 4.) predictive analytics 5.) big data. I apologize for asking such basic questions but every resource online seems to be mentioning similar things to each of these fields. Also, if anyone has any advice for me, I would really appreciate that. Thanks","url":"http://www.reddit.com/r/MachineLearning/comments/1jboou/career_as_a_data_scientist/","report_reasons":null,"media_embed":{},"id":"1jboou","thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a senior majoring in Statistics and Economics and am wondering if a Data Science type career is right for me. I was first interested in a career as a market researcher but as I learned from my current internship, it isn&amp;#39;t that challenging (not really that challenging). What I really had a passion for in my early years of college(which attracted me to market research), was assisting in the product development phase. Using massive datasets to make better decisions about what future products to introduce and what these products should have included in them to make them profitable. I looked into specific fields in data science (data mining, machine learning, etc..) but for me it seems like all of these are in one way or another, connected. What I seek from this post, is a better sense of what I would be doing in a couple career fields involving data science. I looked online for several applications but due to past several events (NSA spying), everything seemed to directed about data mining and the government. If someone could describe the difference between the following, I would really appreciate it. 1.) market researcher 2.) data miner 3.) machine learning 4.) predictive analytics 5.) big data. I apologize for asking such basic questions but every resource online seems to be mentioning similar things to each of these fields. Also, if anyone has any advice for me, I would really appreciate that. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"media":null,"secure_media_embed":{},"author_flair_text":null,"edited":false,"score":1,"subreddit":"MachineLearning","ups":1,"subreddit_id":"t5_2r3gv","secure_media":null,"link_flair_css_class":null,"mod_reports":[],"distinguished":null,"retrieved_on":1411990099,"over_18":false,"created_utc":1375154021,"author_flair_css_class":null,"permalink":"/r/MachineLearning/comments/1jboou/career_as_a_data_scientist/","gilded":0,"banned_by":null,"title":"Career as a Data Scientist","num_comments":0,"user_reports":[],"stickied":false}
{"gilded":0,"permalink":"/r/MachineLearning/comments/1jfpgk/texture_descriptors_based_on_oriented_gradients/","author_flair_css_class":null,"created_utc":1375294189,"over_18":false,"stickied":false,"user_reports":[],"num_comments":2,"banned_by":null,"title":"Texture descriptors based on oriented gradients?","distinguished":null,"mod_reports":[],"link_flair_css_class":null,"secure_media":null,"retrieved_on":1411984615,"score":9,"edited":1375294377,"author_flair_text":null,"secure_media_embed":{},"media":null,"subreddit_id":"t5_2r3gv","ups":9,"subreddit":"MachineLearning","link_flair_text":null,"selftext":"I asked a previous question yesterday. [The post can be found here.](http://www.reddit.com/r/MachineLearning/comments/1jamk6/capturing_visual_patterns_for_each_segment_on_a/) The post has many details that I'm going to reference below. \n\nI have a k-means segmented image that represents a terrestrial site. The site consists of different landforms. The details of this can be found in the above post. \n\nI made an interesting discovery yesterday when playing around with some of the data we have. I took the RGB image (which I explain in detail in the above link), where the 3 channels are pixel based features, and calculated the magnitude of the oriented gradient at each pixel in each channel. I mapped the maximum magnitude in all three channels and here is what it looked like: http://d.pr/i/fS8f . As you can see, the gradients of the craters are much stronger and thicker as compared to the ridges. I mapped their corresponding angles and this is what I got: http://d.pr/i/4C1L . \n\nMy goal is to essentially calculate a feature vector for each segment in the image so I can put it through a classifier. It seems to me that texture analysis would be apt for this, but I can't seem to find any descriptors that use oriented gradients. \n\nI am familiar with HOG and some of its variants. Obviously, HOG wouldn't work for this problem, but I'm looking to do something similar. \n\nI am also familiar with the Haralick features and their implementations. I'm not sure if they would be ideal in this scenario however. The reason why I'm keen on using oriented gradients is because they allow for distinction between landform boundaries. \n\nI'd appreciate any thoughts or inputs on this. \n\nEDIT: I includes this in my previous post, but for easier access: here is the ground truth: http://d.pr/i/Z4sI . Here is the RGB image, where the three channels are pixel based features: http://d.pr/i/6n8K . Here is what the k-means segmented map looks like: http://d.pr/i/FR1O . ","author":"logrech","downs":0,"domain":"self.MachineLearning","thumbnail":"self","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I asked a previous question yesterday. &lt;a href=\"http://www.reddit.com/r/MachineLearning/comments/1jamk6/capturing_visual_patterns_for_each_segment_on_a/\"&gt;The post can be found here.&lt;/a&gt; The post has many details that I&amp;#39;m going to reference below. &lt;/p&gt;\n\n&lt;p&gt;I have a k-means segmented image that represents a terrestrial site. The site consists of different landforms. The details of this can be found in the above post. &lt;/p&gt;\n\n&lt;p&gt;I made an interesting discovery yesterday when playing around with some of the data we have. I took the RGB image (which I explain in detail in the above link), where the 3 channels are pixel based features, and calculated the magnitude of the oriented gradient at each pixel in each channel. I mapped the maximum magnitude in all three channels and here is what it looked like: &lt;a href=\"http://d.pr/i/fS8f\"&gt;http://d.pr/i/fS8f&lt;/a&gt; . As you can see, the gradients of the craters are much stronger and thicker as compared to the ridges. I mapped their corresponding angles and this is what I got: &lt;a href=\"http://d.pr/i/4C1L\"&gt;http://d.pr/i/4C1L&lt;/a&gt; . &lt;/p&gt;\n\n&lt;p&gt;My goal is to essentially calculate a feature vector for each segment in the image so I can put it through a classifier. It seems to me that texture analysis would be apt for this, but I can&amp;#39;t seem to find any descriptors that use oriented gradients. &lt;/p&gt;\n\n&lt;p&gt;I am familiar with HOG and some of its variants. Obviously, HOG wouldn&amp;#39;t work for this problem, but I&amp;#39;m looking to do something similar. &lt;/p&gt;\n\n&lt;p&gt;I am also familiar with the Haralick features and their implementations. I&amp;#39;m not sure if they would be ideal in this scenario however. The reason why I&amp;#39;m keen on using oriented gradients is because they allow for distinction between landform boundaries. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any thoughts or inputs on this. &lt;/p&gt;\n\n&lt;p&gt;EDIT: I includes this in my previous post, but for easier access: here is the ground truth: &lt;a href=\"http://d.pr/i/Z4sI\"&gt;http://d.pr/i/Z4sI&lt;/a&gt; . Here is the RGB image, where the three channels are pixel based features: &lt;a href=\"http://d.pr/i/6n8K\"&gt;http://d.pr/i/6n8K&lt;/a&gt; . Here is what the k-means segmented map looks like: &lt;a href=\"http://d.pr/i/FR1O\"&gt;http://d.pr/i/FR1O&lt;/a&gt; . &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","id":"1jfpgk","media_embed":{},"report_reasons":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1jfpgk/texture_descriptors_based_on_oriented_gradients/"}
{"gilded":0,"permalink":"/r/MachineLearning/comments/1jeysp/eli5_no_free_lunch_for_search/","author_flair_css_class":null,"created_utc":1375271311,"over_18":false,"stickied":false,"user_reports":[],"num_comments":10,"title":"ELI5: No free lunch (for search)","banned_by":null,"distinguished":null,"mod_reports":[],"link_flair_css_class":null,"secure_media":null,"retrieved_on":1411985676,"score":8,"edited":false,"author_flair_text":null,"secure_media_embed":{},"media":null,"subreddit_id":"t5_2r3gv","ups":8,"subreddit":"MachineLearning","selftext":"Hey,\nas far as I understood it the No free lunch theorem states that for all possible search problems all search algorithm will behave equally good on average.\n\nI have problems believing this: For example: can't we show that A*  is an optimal search algorithm while Greedy search is not?  Hence for all search problems A* will find an optimal solution while Greedy search doesnt. So on average A* will be better than Greedy Search for all possible Search problems.\n\nPls help :) ","link_flair_text":null,"downs":0,"author":"sssub","domain":"self.MachineLearning","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,\nas far as I understood it the No free lunch theorem states that for all possible search problems all search algorithm will behave equally good on average.&lt;/p&gt;\n\n&lt;p&gt;I have problems believing this: For example: can&amp;#39;t we show that A*  is an optimal search algorithm while Greedy search is not?  Hence for all search problems A* will find an optimal solution while Greedy search doesnt. So on average A* will be better than Greedy Search for all possible Search problems.&lt;/p&gt;\n\n&lt;p&gt;Pls help :) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"self","id":"1jeysp","media_embed":{},"report_reasons":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1jeysp/eli5_no_free_lunch_for_search/"}
{"mod_reports":[],"distinguished":null,"link_flair_css_class":null,"secure_media":null,"retrieved_on":1411986150,"gilded":0,"author_flair_css_class":null,"created_utc":1375251043,"over_18":false,"permalink":"/r/MachineLearning/comments/1jelx7/google_describes_details_of_their_ad_system_in/","num_comments":0,"stickied":false,"user_reports":[],"banned_by":null,"title":"Google describes details of their ad system in this paper, to appear at KDD next month.","author":"moultano","downs":0,"link_flair_text":null,"selftext":"","domain":"plus.google.com","id":"1jelx7","media_embed":{},"selftext_html":null,"thumbnail":"http://b.thumbs.redditmedia.com/MzLo-vS0vtYCeJDI.jpg","is_self":false,"report_reasons":null,"url":"https://plus.google.com/118227548810368513262/posts/Y2EuTQKYYVC","score":14,"secure_media_embed":{},"media":null,"edited":false,"author_flair_text":null,"subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","ups":14}
{"subreddit":"MachineLearning","ups":4,"subreddit_id":"t5_2r3gv","secure_media_embed":{},"media":null,"edited":false,"author_flair_text":null,"score":4,"report_reasons":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1jejsk/normalizing_a_feature_matrix/","id":"1jejsk","media_embed":{},"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was working on a side project and I started wondering about the normalization I was doing on a feature matrix. &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I have an X by F feature matrix, where X is the numbers_of_samples, and F is the numbers_of_features.  First, I am taking the principle components (however many is needed to reach 95% of the variance), then I am just running a GMM on it. It&amp;#39;s just a proof of concept to show that there is something learnable. &lt;/p&gt;\n\n&lt;p&gt;Currently, I am normalizing each feature vector.  Is this the right thing to be doing? Or should I be normalizing each sample? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"self","domain":"self.MachineLearning","author":"in_cog_nito","downs":0,"link_flair_text":null,"selftext":"I was working on a side project and I started wondering about the normalization I was doing on a feature matrix. \n\nLet's say I have an X by F feature matrix, where X is the numbers_of_samples, and F is the numbers_of_features.  First, I am taking the principle components (however many is needed to reach 95% of the variance), then I am just running a GMM on it. It's just a proof of concept to show that there is something learnable. \n\nCurrently, I am normalizing each feature vector.  Is this the right thing to be doing? Or should I be normalizing each sample? \n\nThanks in advance!","banned_by":null,"title":"Normalizing a feature matrix","num_comments":6,"stickied":false,"user_reports":[],"author_flair_css_class":null,"created_utc":1375248643,"over_18":false,"permalink":"/r/MachineLearning/comments/1jejsk/normalizing_a_feature_matrix/","gilded":0,"retrieved_on":1411986230,"link_flair_css_class":null,"secure_media":null,"mod_reports":[],"distinguished":null}
{"ups":175,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","edited":1375317761,"author_flair_text":null,"secure_media_embed":{},"media":null,"score":175,"report_reasons":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1jeawf/machine_learning_books/","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been collecting machine learning books over the past couple months.  It seems that machine learning professors are good about posting free legal pdfs of their work.  I hope they are useful to you.  I saw a couple of these books posted individually, but not many of them and not all in one place, so I decided to post. &lt;/p&gt;\n\n&lt;p&gt;Machine Learning&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www-stat.stanford.edu/%7Etibs/ElemStatLearn/printings/ESLII_print10.pdf\"&gt;Elements of Statistical Learning. Hastie, Tibshirani, Friedman &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.ucl.ac.uk/%7Ermjbale/Stat/wasserman2.pdf\"&gt;All of Statistics. Larry Wasserman&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf\"&gt;Machine Learning and Bayesian Reasoning. David Barber &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.gaussianprocess.org/gpml/chapters/RW.pdf\"&gt;Gaussian Processes for Machine Learning. Rasmussen and Williams&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.cs.toronto.edu/%7Emackay/itprnn/book.pdf\"&gt;Information Theory, Inference, and Learning Algorithms. David MacKay &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://alex.smola.org/drafts/thebook.pdf\"&gt;Introduction to Machine Learning. Smola and Vishwanathan&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.szit.bme.hu/%7Egyorfi/pbook.pdf\"&gt;A Probabilistic Theory of Pattern Recognition.  Devroye, Gyorfi, Lugosi.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://nlp.stanford.edu/IR-book/pdf/irbookprint.pdf\"&gt;Introduction to Information Retrieval. Manning, Rhagavan, Shutze&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://otexts.com/fpp/\"&gt;Forecasting: principles and practice. Hyndman, Athanasopoulos. (Online Book) &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Probability / Stats&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.math.umass.edu/%7Elavine/Book/book.pdf\"&gt;Introduction to statistical thought. Lavine &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.math.uiuc.edu/%7Er-ash/BPT/BPT.pdf\"&gt;Basic Probability Theory. Robert Ash&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://math.dartmouth.edu/%7Eprob/prob/prob.pdf\"&gt;Introduction to probability. Grinstead and Snell&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://uncertainty.stat.cmu.edu/wp-content/uploads/2011/05/principles-of-uncertainty.pdf\"&gt;Principle of Uncertainty. Kadane&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Linear Algebra / Optimization&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://math.byu.edu/%7Eklkuttle/Linearalgebra.pdf\"&gt;Linear Algebra, Theory, and Applications. Kuttler&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.math.brown.edu/%7Etreil/papers/LADW/LADW.pdf\"&gt;Linear Algebra Done Wrong. Treil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.seas.ucla.edu/%7Evandenbe/103/reader.pdf\"&gt;Applied Numerical Computing. Vandenberghe&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://uqu.edu.sa/files2/tiny_mce/plugins/filemanager/files/4281667/hamdy/hamdy1/cgfvnv/hamdy2/h1/h2/h3/h4/h5/h6/Applied%20Numerical%20Linear%20.pdf\"&gt;Applied Numerical Linear Algebra.  James Demmel&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.stanford.edu/%7Eboyd/cvxbook/bv_cvxbook.pdf\"&gt;Convex Optimization. Boyd and Vandenberghe&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Genetic Algorithms&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://dces.essex.ac.uk/staff/rpoli/gp-field-guide/A_Field_Guide_to_Genetic_Programming.pdf\"&gt; A Field Guide to Genetic Programming. Poli, Langdon, McPhee.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.lulu.com/ie/en/shop/moshe-sipper/evolved-to-win/ebook/product-18719826.html\"&gt;Evolved To Win. Sipper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://cs.gmu.edu/%7Esean/book/metaheuristics/Essentials.pdf\"&gt;Essentials of Metaheuristics.  Luke&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Edit: added books listed in comments. added probability, LA, and GA sections&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","is_self":true,"id":"1jeawf","media_embed":{},"domain":"self.MachineLearning","link_flair_text":null,"selftext":"I have been collecting machine learning books over the past couple months.  It seems that machine learning professors are good about posting free legal pdfs of their work.  I hope they are useful to you.  I saw a couple of these books posted individually, but not many of them and not all in one place, so I decided to post. \n\nMachine Learning\n\n[Elements of Statistical Learning. Hastie, Tibshirani, Friedman ] (http://www-stat.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf)\n\n[All of Statistics. Larry Wasserman](http://www.ucl.ac.uk/~rmjbale/Stat/wasserman2.pdf)\n\n\n[Machine Learning and Bayesian Reasoning. David Barber ](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf)\n\n[Gaussian Processes for Machine Learning. Rasmussen and Williams](http://www.gaussianprocess.org/gpml/chapters/RW.pdf)\n\n[Information Theory, Inference, and Learning Algorithms. David MacKay ] (http://www.cs.toronto.edu/~mackay/itprnn/book.pdf)\n\n[Introduction to Machine Learning. Smola and Vishwanathan](http://alex.smola.org/drafts/thebook.pdf)\n\n[A Probabilistic Theory of Pattern Recognition.  Devroye, Gyorfi, Lugosi.](http://www.szit.bme.hu/%7Egyorfi/pbook.pdf)\n\n[Introduction to Information Retrieval. Manning, Rhagavan, Shutze](http://nlp.stanford.edu/IR-book/pdf/irbookprint.pdf)\n\n[Forecasting: principles and practice. Hyndman, Athanasopoulos. (Online Book) ] (http://otexts.com/fpp/)\n\nProbability / Stats\n\n[Introduction to statistical thought. Lavine ](https://www.math.umass.edu/%7Elavine/Book/book.pdf)\n\n[Basic Probability Theory. Robert Ash](http://www.math.uiuc.edu/~r-ash/BPT/BPT.pdf)\n\n[Introduction to probability. Grinstead and Snell](http://math.dartmouth.edu/~prob/prob/prob.pdf)\n\n[Principle of Uncertainty. Kadane](http://uncertainty.stat.cmu.edu/wp-content/uploads/2011/05/principles-of-uncertainty.pdf)\n\nLinear Algebra / Optimization\n\n[Linear Algebra, Theory, and Applications. Kuttler](https://math.byu.edu/~klkuttle/Linearalgebra.pdf)\n\n[Linear Algebra Done Wrong. Treil](http://www.math.brown.edu/~treil/papers/LADW/LADW.pdf)\n\n[Applied Numerical Computing. Vandenberghe](http://www.seas.ucla.edu/~vandenbe/103/reader.pdf)\n\n[Applied Numerical Linear Algebra.  James Demmel](http://uqu.edu.sa/files2/tiny_mce/plugins/filemanager/files/4281667/hamdy/hamdy1/cgfvnv/hamdy2/h1/h2/h3/h4/h5/h6/Applied%20Numerical%20Linear%20.pdf)\n\n[Convex Optimization. Boyd and Vandenberghe](http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)\n\nGenetic Algorithms\n\n[ A Field Guide to Genetic Programming. Poli, Langdon, McPhee.](http://dces.essex.ac.uk/staff/rpoli/gp-field-guide/A_Field_Guide_to_Genetic_Programming.pdf)\n\n[Evolved To Win. Sipper](http://www.lulu.com/ie/en/shop/moshe-sipper/evolved-to-win/ebook/product-18719826.html)\n\n[Essentials of Metaheuristics.  Luke](http://cs.gmu.edu/%7Esean/book/metaheuristics/Essentials.pdf) \n\n\nEdit: added books listed in comments. added probability, LA, and GA sections","author":"ilsunil","downs":0,"title":"Machine Learning Books","banned_by":null,"stickied":false,"user_reports":[],"num_comments":38,"permalink":"/r/MachineLearning/comments/1jeawf/machine_learning_books/","author_flair_css_class":null,"created_utc":1375240426,"over_18":false,"gilded":0,"retrieved_on":1411986558,"link_flair_css_class":null,"secure_media":null,"distinguished":null,"mod_reports":[]}
