{"downs":11,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.r-statistics.com/2012/01/top-20-r-posts-of-2011-and-some-r-bloggers-statistics/","link_flair_css_class":null,"id":"nyp0h","edited":false,"num_reports":null,"created_utc":1325438923,"banned_by":null,"name":"t3_nyp0h","subreddit":"MachineLearning","title":"Top 20 R posts of 2011 (as measured by R-bloggers.com)","author_flair_text":null,"is_self":false,"author":"talgalili","media_embed":{},"permalink":"/r/MachineLearning/comments/nyp0h/top_20_r_posts_of_2011_as_measured_by_rbloggerscom/","author_flair_css_class":null,"selftext":"","domain":"r-statistics.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":19,"approved_by":null,"score":8,"selftext_html":null,"created":1325438923,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/nzvtw/ask_rml_kmeans_clustering_is_putting_everything/","link_flair_css_class":null,"id":"nzvtw","edited":true,"num_reports":null,"created_utc":1325522123,"banned_by":null,"name":"t3_nzvtw","subreddit":"MachineLearning","title":"Ask r/ML: k-means clustering is putting everything in one cluster, how come?","author_flair_text":null,"is_self":true,"author":"projector","media_embed":{},"permalink":"/r/MachineLearning/comments/nzvtw/ask_rml_kmeans_clustering_is_putting_everything/","author_flair_css_class":null,"selftext":"Hi r/ML,\n\nFirst, I'm not sure if this subreddit accepts questions like this. Please redirect me if it's better posted elsewhere.\n\nThe presenting problem I have is that running k-means clustering on my data set results in almost everything being put in one cluster. I've tried varying the number of clusters but it keeps happening. I'd like to understand why this is happening and what my options are for getting a more even, or more informative, distribution between clusters.\n\nSome background: I've gathered a list of friends and their likes from Facebook, making a sparse matrix like this:\n\n    data = {\n        'friend1': ['like1', 'like2', 'like3'],\n        'friend2': ['like4'],\n        'friend3': ['like1', 'like4'],\n    }\n\nThere's about 100 friends with about 1 to 300 likes each. I make k centroids, giving each a random set of likes, and count the shared likes for my distance function (dist = 1 - total_shared_likes / 1000).\n\nEach iteration I calculate the distance between a friend and each centroid and assign them to the nearest. Almost all end up in the same centroid. To move the centroids to the average position of their members, I total all the user and centroid likes, then divide by the number of users + 1 (for the centroid's likes). Each users' likes count for 1, but the centroid likes are floats. \n\nAny thoughts on why this is happening? Am I missing something or doing something wrong? Or is this data set not amenable to k-means, should I try a different algorithm?\n\nThanks!\n\n**edit** Still getting all friends in the same cluster despite\n\n*(i)* creating a euclidian distance function\n\n    def distance(self, other):\n        dist = 0.0\n        for i, l in enumerate(self.likes):\n            if l != other.likes[i]:\n                dist += 1\n        \n        return math.sqrt(diet)\n\nThe likes variables hold tuples where each item is 1 or 0 (like or dislike), and all users' tuples are the same length (equal to the number of all possible items to like). I'm adding 1 if they're different as this is the only possible distance (and it's 1 squared, of course).\n\n*(ii)*\n\nOn initialisation, assigning a random friends' likes to the first centroid, then for each other centroid (up to *k*) assigning the likes of the friend furthest from all previous centroids.\n\n*(iii)*\n\nOn each iteration, if a centroid has no members, it's assigned the likes of the friend furthest from all centroids.\n\n*(iv)*\n\nNo longer including the centroid's likes when calculating the average position between its members.\n\nI've put my code on paste bin as I might have overlooked something - http://pastebin.com/ZFvFfFe3\n\nHere's some example output:\n\n    --- iteration 4\n    {'cluster 0': {'dist': 1256.4364795929926, 'members': 174},\n     'cluster 1': {'dist': 0.0, 'members': 0},\n     'cluster 2': {'dist': 0.0, 'members': 0},\n     'cluster 3': {'dist': 0.0, 'members': 0},\n     'cluster 4': {'dist': 0.0, 'members': 0}}\n    --- iteration 5\n    {'cluster 0': {'dist': 0.0, 'members': 0},\n     'cluster 1': {'dist': 1256.4364795929926, 'members': 174},\n     'cluster 2': {'dist': 0.0, 'members': 0},\n     'cluster 3': {'dist': 0.0, 'members': 0},\n     'cluster 4': {'dist': 0.0, 'members': 0}}\n\nThanks for all of your input, I'm very grateful. Please keep posting feedback, I'm set on solving this! \n\n**edit 2**\n\nFixed the distance function\n\n    def distance(self, other):\n        total_dist = 0.0\n        for i, l in enumerate(self.likes):\n            if l != other.likes[i]:\n                total_dist += (l - other.likes[i])**2\n\n        return math.sqrt(total_dist / len(self.likes))\n\nAnd the error in the centroid update calculation (line 126)\n\n    new_likes[i] += user_vote\n\nThe paste bin code is updated, it's still behaving as before.","domain":"self.MachineLearning","num_comments":30,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":20,"approved_by":null,"score":16,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi r/ML,&lt;/p&gt;\n\n&lt;p&gt;First, I&amp;#39;m not sure if this subreddit accepts questions like this. Please redirect me if it&amp;#39;s better posted elsewhere.&lt;/p&gt;\n\n&lt;p&gt;The presenting problem I have is that running k-means clustering on my data set results in almost everything being put in one cluster. I&amp;#39;ve tried varying the number of clusters but it keeps happening. I&amp;#39;d like to understand why this is happening and what my options are for getting a more even, or more informative, distribution between clusters.&lt;/p&gt;\n\n&lt;p&gt;Some background: I&amp;#39;ve gathered a list of friends and their likes from Facebook, making a sparse matrix like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;data = {\n    &amp;#39;friend1&amp;#39;: [&amp;#39;like1&amp;#39;, &amp;#39;like2&amp;#39;, &amp;#39;like3&amp;#39;],\n    &amp;#39;friend2&amp;#39;: [&amp;#39;like4&amp;#39;],\n    &amp;#39;friend3&amp;#39;: [&amp;#39;like1&amp;#39;, &amp;#39;like4&amp;#39;],\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;There&amp;#39;s about 100 friends with about 1 to 300 likes each. I make k centroids, giving each a random set of likes, and count the shared likes for my distance function (dist = 1 - total_shared_likes / 1000).&lt;/p&gt;\n\n&lt;p&gt;Each iteration I calculate the distance between a friend and each centroid and assign them to the nearest. Almost all end up in the same centroid. To move the centroids to the average position of their members, I total all the user and centroid likes, then divide by the number of users + 1 (for the centroid&amp;#39;s likes). Each users&amp;#39; likes count for 1, but the centroid likes are floats. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts on why this is happening? Am I missing something or doing something wrong? Or is this data set not amenable to k-means, should I try a different algorithm?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;edit&lt;/strong&gt; Still getting all friends in the same cluster despite&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(i)&lt;/em&gt; creating a euclidian distance function&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def distance(self, other):\n    dist = 0.0\n    for i, l in enumerate(self.likes):\n        if l != other.likes[i]:\n            dist += 1\n\n    return math.sqrt(diet)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The likes variables hold tuples where each item is 1 or 0 (like or dislike), and all users&amp;#39; tuples are the same length (equal to the number of all possible items to like). I&amp;#39;m adding 1 if they&amp;#39;re different as this is the only possible distance (and it&amp;#39;s 1 squared, of course).&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(ii)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;On initialisation, assigning a random friends&amp;#39; likes to the first centroid, then for each other centroid (up to &lt;em&gt;k&lt;/em&gt;) assigning the likes of the friend furthest from all previous centroids.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(iii)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;On each iteration, if a centroid has no members, it&amp;#39;s assigned the likes of the friend furthest from all centroids.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(iv)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;No longer including the centroid&amp;#39;s likes when calculating the average position between its members.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve put my code on paste bin as I might have overlooked something - &lt;a href=\"http://pastebin.com/ZFvFfFe3\"&gt;http://pastebin.com/ZFvFfFe3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s some example output:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;--- iteration 4\n{&amp;#39;cluster 0&amp;#39;: {&amp;#39;dist&amp;#39;: 1256.4364795929926, &amp;#39;members&amp;#39;: 174},\n &amp;#39;cluster 1&amp;#39;: {&amp;#39;dist&amp;#39;: 0.0, &amp;#39;members&amp;#39;: 0},\n &amp;#39;cluster 2&amp;#39;: {&amp;#39;dist&amp;#39;: 0.0, &amp;#39;members&amp;#39;: 0},\n &amp;#39;cluster 3&amp;#39;: {&amp;#39;dist&amp;#39;: 0.0, &amp;#39;members&amp;#39;: 0},\n &amp;#39;cluster 4&amp;#39;: {&amp;#39;dist&amp;#39;: 0.0, &amp;#39;members&amp;#39;: 0}}\n--- iteration 5\n{&amp;#39;cluster 0&amp;#39;: {&amp;#39;dist&amp;#39;: 0.0, &amp;#39;members&amp;#39;: 0},\n &amp;#39;cluster 1&amp;#39;: {&amp;#39;dist&amp;#39;: 1256.4364795929926, &amp;#39;members&amp;#39;: 174},\n &amp;#39;cluster 2&amp;#39;: {&amp;#39;dist&amp;#39;: 0.0, &amp;#39;members&amp;#39;: 0},\n &amp;#39;cluster 3&amp;#39;: {&amp;#39;dist&amp;#39;: 0.0, &amp;#39;members&amp;#39;: 0},\n &amp;#39;cluster 4&amp;#39;: {&amp;#39;dist&amp;#39;: 0.0, &amp;#39;members&amp;#39;: 0}}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Thanks for all of your input, I&amp;#39;m very grateful. Please keep posting feedback, I&amp;#39;m set on solving this! &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;edit 2&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Fixed the distance function&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def distance(self, other):\n    total_dist = 0.0\n    for i, l in enumerate(self.likes):\n        if l != other.likes[i]:\n            total_dist += (l - other.likes[i])**2\n\n    return math.sqrt(total_dist / len(self.likes))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And the error in the centroid update calculation (line 126)&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;new_likes[i] += user_vote\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The paste bin code is updated, it&amp;#39;s still behaving as before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1325522123,"hidden":false,"over_18":false}
{"downs":5,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://hunch.net/?p=22","link_flair_css_class":null,"id":"o1h2a","edited":false,"num_reports":null,"created_utc":1325621446,"banned_by":null,"name":"t3_o1h2a","subreddit":"MachineLearning","title":"Clever and unintentional ways to overfit a data set","author_flair_text":null,"is_self":false,"author":"rrenaud","media_embed":{},"permalink":"/r/MachineLearning/comments/o1h2a/clever_and_unintentional_ways_to_overfit_a_data/","author_flair_css_class":null,"selftext":"","domain":"hunch.net","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":51,"approved_by":null,"score":46,"selftext_html":null,"created":1325621446,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/o2ti2/decision_tree_implementation/","link_flair_css_class":null,"id":"o2ti2","edited":true,"num_reports":null,"created_utc":1325703955,"banned_by":null,"name":"t3_o2ti2","subreddit":"MachineLearning","title":"Decision Tree implementation","author_flair_text":null,"is_self":true,"author":"rylko","media_embed":{},"permalink":"/r/MachineLearning/comments/o2ti2/decision_tree_implementation/","author_flair_css_class":null,"selftext":"Hi,\nI'm looking for implementation of Decision Tree algorithm which is\n\n* very scalable, \n* supports classification / regression, \n* customizable (for example selection of masure - entropy based / Chi-square Statistic / ...),\n* in C++ / Java\n* open source &amp; free\n\nIt will be used on supercomputer with very large data.\n\nNow I'm observing\n\n* [OpenDT](http://opendt.sourceforge.net/)\n* [OpenCV](http://opencv.willowgarage.com/documentation/cpp/decision_trees.html)\n\nCan You suggest any other implementation of DT algorithm? (No Mahout/Hadoop and idally with some references / real-word use cases.)\n\n\nEDIT:\n\nSupervisor about size of data: \"For massive datasets, we remark that our basic requirement is to efficiently handle datasets of at least hundreds of thousands patterns in a higher than 10-dimension feature space. In other words we must be able to ingest data files higher than hundreds of MB (TB is the final goal when survey projects will prompt observed data).\"","domain":"self.MachineLearning","num_comments":20,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":17,"approved_by":null,"score":16,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI&amp;#39;m looking for implementation of Decision Tree algorithm which is&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;very scalable, &lt;/li&gt;\n&lt;li&gt;supports classification / regression, &lt;/li&gt;\n&lt;li&gt;customizable (for example selection of masure - entropy based / Chi-square Statistic / ...),&lt;/li&gt;\n&lt;li&gt;in C++ / Java&lt;/li&gt;\n&lt;li&gt;open source &amp;amp; free&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It will be used on supercomputer with very large data.&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m observing&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"http://opendt.sourceforge.net/\"&gt;OpenDT&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"http://opencv.willowgarage.com/documentation/cpp/decision_trees.html\"&gt;OpenCV&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Can You suggest any other implementation of DT algorithm? (No Mahout/Hadoop and idally with some references / real-word use cases.)&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;Supervisor about size of data: &amp;quot;For massive datasets, we remark that our basic requirement is to efficiently handle datasets of at least hundreds of thousands patterns in a higher than 10-dimension feature space. In other words we must be able to ingest data files higher than hundreds of MB (TB is the final goal when survey projects will prompt observed data).&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1325703955,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://doingbayesiandataanalysis.blogspot.com/2012/01/now-in-jags-now-in-jags.html","link_flair_css_class":null,"id":"o2e0v","edited":false,"num_reports":null,"created_utc":1325675027,"banned_by":null,"name":"t3_o2e0v","subreddit":"MachineLearning","title":"Doing Bayesian Data Analysis Now in Jags","author_flair_text":null,"is_self":false,"author":"cavedave","media_embed":{},"permalink":"/r/MachineLearning/comments/o2e0v/doing_bayesian_data_analysis_now_in_jags/","author_flair_css_class":null,"selftext":"","domain":"doingbayesiandataanalysis.blogspot.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"http://a.thumbs.redditmedia.com/zGhZel9Oy9xfsj8f.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":5,"approved_by":null,"score":4,"selftext_html":null,"created":1325675027,"hidden":false,"over_18":false}
{"downs":10,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://web.archive.org/web/20051228215255/www.jmlg.org/papers/wankendon05.pdf","link_flair_css_class":null,"id":"o4dev","edited":false,"num_reports":null,"created_utc":1325794529,"banned_by":null,"name":"t3_o4dev","subreddit":"MachineLearning","title":"A case study of web pornography search [PDF][SFW]","author_flair_text":null,"is_self":false,"author":"psyyduck","media_embed":{},"permalink":"/r/MachineLearning/comments/o4dev/a_case_study_of_web_pornography_search_pdfsfw/","author_flair_css_class":null,"selftext":"","domain":"web.archive.org","num_comments":8,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":17,"approved_by":null,"score":7,"selftext_html":null,"created":1325794529,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.hydraulicnews.hidraulicapractica.com/news/caterpillar-to-expand-chinese-rd-centre-khl-group","link_flair_css_class":null,"id":"o62uu","edited":false,"num_reports":null,"created_utc":1325893260,"banned_by":null,"name":"t3_o62uu","subreddit":"MachineLearning","title":"Caterpillar to expand Chinese R&amp;D centre - KHL Group | HYDRAULICS - News","author_flair_text":null,"is_self":false,"author":"kamilrhu","media_embed":{},"permalink":"/r/MachineLearning/comments/o62uu/caterpillar_to_expand_chinese_rd_centre_khl_group/","author_flair_css_class":null,"selftext":"","domain":"hydraulicnews.hidraulicapractica.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1325893260,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/","link_flair_css_class":null,"id":"o5mjy","edited":false,"num_reports":null,"created_utc":1325871146,"banned_by":null,"name":"t3_o5mjy","subreddit":"MachineLearning","title":"Introduction to Conditional Random Fields","author_flair_text":null,"is_self":false,"author":"kapichu","media_embed":{},"permalink":"/r/MachineLearning/comments/o5mjy/introduction_to_conditional_random_fields/","author_flair_css_class":null,"selftext":"","domain":"blog.echen.me","num_comments":0,"likes":null,"clicked":false,"thumbnail":"http://d.thumbs.redditmedia.com/to55zxG51HghfXYo.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":32,"approved_by":null,"score":28,"selftext_html":null,"created":1325871146,"hidden":false,"over_18":false}
{"downs":3,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/o5ayp/diagnosing_the_way_a_ml_algorithm_behaves_on_a/","link_flair_css_class":null,"id":"o5ayp","edited":false,"num_reports":null,"created_utc":1325847752,"banned_by":null,"name":"t3_o5ayp","subreddit":"MachineLearning","title":"Diagnosing the way a ML algorithm behaves on a problem is non trivial. Has anyone tried to apply machine learning on itself to automatically solve this?","author_flair_text":null,"is_self":true,"author":"visarga","media_embed":{},"permalink":"/r/MachineLearning/comments/o5ayp/diagnosing_the_way_a_ml_algorithm_behaves_on_a/","author_flair_css_class":null,"selftext":"I got the idea from seeing the title of this paper: [Knows what it knows: a framework for self-aware\nlearning](http://paul.rutgers.edu/~thomaswa/pub/Li11Knows.pdf).\n\nSo, it would be nice to have an extra layer on top of a ML algorithm that would look at its performance and fine tune it: suggest features, number of examples needed, complexity of the model and so on?\n\nAt a higher level, this \"ML expert\" could suggest algorithms (and kernels) that work best on the dataset at hand - why rely on human intuition alone?\n","domain":"self.MachineLearning","num_comments":11,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":20,"approved_by":null,"score":17,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got the idea from seeing the title of this paper: &lt;a href=\"http://paul.rutgers.edu/%7Ethomaswa/pub/Li11Knows.pdf\"&gt;Knows what it knows: a framework for self-aware\nlearning&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;So, it would be nice to have an extra layer on top of a ML algorithm that would look at its performance and fine tune it: suggest features, number of examples needed, complexity of the model and so on?&lt;/p&gt;\n\n&lt;p&gt;At a higher level, this &amp;quot;ML expert&amp;quot; could suggest algorithms (and kernels) that work best on the dataset at hand - why rely on human intuition alone?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1325847752,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/o59jk/how_similar_is_machine_learning_to_business/","link_flair_css_class":null,"id":"o59jk","edited":true,"num_reports":null,"created_utc":1325843484,"banned_by":null,"name":"t3_o59jk","subreddit":"MachineLearning","title":"How similar is machine learning to business application development?","author_flair_text":null,"is_self":true,"author":"tonio4321","media_embed":{},"permalink":"/r/MachineLearning/comments/o59jk/how_similar_is_machine_learning_to_business/","author_flair_css_class":null,"selftext":"Do machine learning scientist use agile development and unit testing? How about object oriented programming? What's the career prospects? Can machine learning scientists do startups?","domain":"self.MachineLearning","num_comments":6,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":9,"approved_by":null,"score":8,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do machine learning scientist use agile development and unit testing? How about object oriented programming? What&amp;#39;s the career prospects? Can machine learning scientists do startups?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1325843484,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.wired.co.uk/news/archive/2012-01/06/big-data-evolution-and-missiles","link_flair_css_class":null,"id":"o9xxg","edited":false,"num_reports":null,"created_utc":1326149916,"banned_by":null,"name":"t3_o9xxg","subreddit":"MachineLearning","title":"How Big Data analysts reappropriate algorithms from evolution and warfare","author_flair_text":null,"is_self":false,"author":"protein_bricks_4_all","media_embed":{},"permalink":"/r/MachineLearning/comments/o9xxg/how_big_data_analysts_reappropriate_algorithms/","author_flair_css_class":null,"selftext":"","domain":"wired.co.uk","num_comments":0,"likes":null,"clicked":false,"thumbnail":"http://f.thumbs.redditmedia.com/qZsgnwGgsZOnEm4w.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":11,"approved_by":null,"score":10,"selftext_html":null,"created":1326149916,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/oayzk/knn_distance_measure/","link_flair_css_class":null,"id":"oayzk","edited":false,"num_reports":null,"created_utc":1326213501,"banned_by":null,"name":"t3_oayzk","subreddit":"MachineLearning","title":"kNN distance measure","author_flair_text":null,"is_self":true,"author":"kumquatz","media_embed":{},"permalink":"/r/MachineLearning/comments/oayzk/knn_distance_measure/","author_flair_css_class":null,"selftext":"I am traing a kNN with binary feature vectors. Why does it practically make no difference if I am using Euclidian distance or Hamming/Manhatten distance? Are they theoretically the same for binary data?","domain":"self.MachineLearning","num_comments":2,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":3,"approved_by":null,"score":2,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am traing a kNN with binary feature vectors. Why does it practically make no difference if I am using Euclidian distance or Hamming/Manhatten distance? Are they theoretically the same for binary data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326213501,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/oaybv/how_to_learn_programming_jargon_please_help/","link_flair_css_class":null,"id":"oaybv","edited":false,"num_reports":null,"created_utc":1326212550,"banned_by":null,"name":"t3_oaybv","subreddit":"MachineLearning","title":"How to learn programming jargon.  Please help.","author_flair_text":null,"is_self":true,"author":"mathsuu","media_embed":{},"permalink":"/r/MachineLearning/comments/oaybv/how_to_learn_programming_jargon_please_help/","author_flair_css_class":null,"selftext":"I have a stats background, and everything I know from programming (SAS, R, Python) is self-taught.  Most websites that have what I'm interested in are filled with jargon that I don't understand. Is there a glossary of programming words like \"overhead\", \"fork (v)\", etc.?  Especially one designed for people who come from a different background?","domain":"self.MachineLearning","num_comments":10,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":4,"approved_by":null,"score":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a stats background, and everything I know from programming (SAS, R, Python) is self-taught.  Most websites that have what I&amp;#39;m interested in are filled with jargon that I don&amp;#39;t understand. Is there a glossary of programming words like &amp;quot;overhead&amp;quot;, &amp;quot;fork (v)&amp;quot;, etc.?  Especially one designed for people who come from a different background?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326212550,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://tunedit.org/challenge/JRS12Contest","link_flair_css_class":null,"id":"oay0a","edited":false,"num_reports":null,"created_utc":1326212093,"banned_by":null,"name":"t3_oay0a","subreddit":"MachineLearning","title":"JRS'12 Competition: design best algorithm for multi-label classification of biomedical papers","author_flair_text":null,"is_self":false,"author":"datt","media_embed":{},"permalink":"/r/MachineLearning/comments/oay0a/jrs12_competition_design_best_algorithm_for/","author_flair_css_class":null,"selftext":"","domain":"tunedit.org","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":0,"selftext_html":null,"created":1326212093,"hidden":false,"over_18":false}
{"downs":5,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://bickson.blogspot.com/2012/01/worlds-coolest-machine-learning.html","link_flair_css_class":null,"id":"oaw4d","edited":false,"num_reports":null,"created_utc":1326209049,"banned_by":null,"name":"t3_oaw4d","subreddit":"MachineLearning","title":"The world's coolest machine learning internships","author_flair_text":null,"is_self":false,"author":"dataranch","media_embed":{},"permalink":"/r/MachineLearning/comments/oaw4d/the_worlds_coolest_machine_learning_internships/","author_flair_css_class":null,"selftext":"","domain":"bickson.blogspot.com","num_comments":3,"likes":null,"clicked":false,"thumbnail":"http://b.thumbs.redditmedia.com/3YlzHCwCZj7d9wmO.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":26,"approved_by":null,"score":21,"selftext_html":null,"created":1326209049,"hidden":false,"over_18":false}
{"downs":2,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://cran.r-project.org/web/packages/sentiment/index.html","link_flair_css_class":null,"id":"oakg5","edited":false,"num_reports":null,"created_utc":1326179430,"banned_by":null,"name":"t3_oakg5","subreddit":"MachineLearning","title":"Package \"sentiment\" now available on CRAN: naïve Bayes classifier for polarity classification (e.g. positivity/negativity)","author_flair_text":null,"is_self":false,"author":"tymekpavel","media_embed":{},"permalink":"/r/MachineLearning/comments/oakg5/package_sentiment_now_available_on_cran_naïve/","author_flair_css_class":null,"selftext":"","domain":"cran.r-project.org","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":8,"approved_by":null,"score":6,"selftext_html":null,"created":1326179430,"hidden":false,"over_18":false}
{"downs":2,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/oajwo/data_analystdata_scientistdata_mineretc_job/","link_flair_css_class":null,"id":"oajwo","edited":true,"num_reports":null,"created_utc":1326178394,"banned_by":null,"name":"t3_oajwo","subreddit":"MachineLearning","title":"Data Analyst/Data Scientist/Data Miner/etc job salaries","author_flair_text":null,"is_self":true,"author":"nd_irish","media_embed":{},"permalink":"/r/MachineLearning/comments/oajwo/data_analystdata_scientistdata_mineretc_job/","author_flair_css_class":null,"selftext":"Hi /r/ML. I am graduating soon with my Ph.D. in ml/data mining, and I've been looking around for jobs. A lot of companies advertise \"competitive salaries\", and I was wondering if people here wouldn't mind giving me an idea of what that means.\n\nFor instance if someone is advertising a \"competitive salary\" in San Franciso, does that mean $50k / year? 80k? 100k? What about NYC? San Diego? Seattle? etc?\n\nNon US-redditors what are the salaries in Europe/Asia/Australia/etc like?\n\nHopefully this question doesn't offend anyone, I'm just trying to gauge when a company is actually offering me what they claim, i.e., a competitive salary, and I think such knowledge is a great tool for new grads. Thanks!\n\n**EDIT** If you don't feel comfortable saying your salary/giving knowledge under your main, throw aways are a great resource.","domain":"self.MachineLearning","num_comments":20,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":22,"approved_by":null,"score":20,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/ML\"&gt;/r/ML&lt;/a&gt;. I am graduating soon with my Ph.D. in ml/data mining, and I&amp;#39;ve been looking around for jobs. A lot of companies advertise &amp;quot;competitive salaries&amp;quot;, and I was wondering if people here wouldn&amp;#39;t mind giving me an idea of what that means.&lt;/p&gt;\n\n&lt;p&gt;For instance if someone is advertising a &amp;quot;competitive salary&amp;quot; in San Franciso, does that mean $50k / year? 80k? 100k? What about NYC? San Diego? Seattle? etc?&lt;/p&gt;\n\n&lt;p&gt;Non US-redditors what are the salaries in Europe/Asia/Australia/etc like?&lt;/p&gt;\n\n&lt;p&gt;Hopefully this question doesn&amp;#39;t offend anyone, I&amp;#39;m just trying to gauge when a company is actually offering me what they claim, i.e., a competitive salary, and I think such knowledge is a great tool for new grads. Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt; If you don&amp;#39;t feel comfortable saying your salary/giving knowledge under your main, throw aways are a great resource.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326178394,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.r-statistics.com/2012/01/aggregation-and-restructuring-data-from-r-in-action/#more-891","link_flair_css_class":null,"id":"oahd6","edited":false,"num_reports":null,"created_utc":1326174279,"banned_by":null,"name":"t3_oahd6","subreddit":"MachineLearning","title":"Aggregation and Restructuring data (in R)","author_flair_text":null,"is_self":false,"author":"talgalili","media_embed":{},"permalink":"/r/MachineLearning/comments/oahd6/aggregation_and_restructuring_data_in_r/","author_flair_css_class":null,"selftext":"","domain":"r-statistics.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1326174279,"hidden":false,"over_18":false}
{"downs":5,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://holehouse.org/mlclass/","link_flair_css_class":null,"id":"oa633","edited":false,"num_reports":null,"created_utc":1326160131,"banned_by":null,"name":"t3_oa633","subreddit":"MachineLearning","title":"Complete notes of Stanford machine learning course","author_flair_text":null,"is_self":false,"author":"sunng","media_embed":{},"permalink":"/r/MachineLearning/comments/oa633/complete_notes_of_stanford_machine_learning_course/","author_flair_css_class":null,"selftext":"","domain":"holehouse.org","num_comments":3,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":61,"approved_by":null,"score":56,"selftext_html":null,"created":1326160131,"hidden":false,"over_18":false}
{"downs":12,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://take-a-bite.org/","link_flair_css_class":null,"id":"ocgwx","edited":false,"num_reports":null,"created_utc":1326298405,"banned_by":null,"name":"t3_ocgwx","subreddit":"MachineLearning","title":"Help a friend of mine with his master's thesis, trying to uniquely identify online users without cookies using ML","author_flair_text":null,"is_self":false,"author":"Emore","media_embed":{},"permalink":"/r/MachineLearning/comments/ocgwx/help_a_friend_of_mine_with_his_masters_thesis/","author_flair_css_class":null,"selftext":"","domain":"take-a-bite.org","num_comments":3,"likes":null,"clicked":false,"thumbnail":"http://d.thumbs.redditmedia.com/pkqhkwSKQdZQRvhc.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":6,"approved_by":null,"score":0,"selftext_html":null,"created":1326298405,"hidden":false,"over_18":false}
{"downs":2,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/occsk/can_someone_explain_to_me_what_a_bayes_point/","link_flair_css_class":null,"id":"occsk","edited":false,"num_reports":null,"created_utc":1326292055,"banned_by":null,"name":"t3_occsk","subreddit":"MachineLearning","title":"Can someone explain to me what a \nBayes Point Machine is?","author_flair_text":null,"is_self":true,"author":"Jigsus","media_embed":{},"permalink":"/r/MachineLearning/comments/occsk/can_someone_explain_to_me_what_a_bayes_point/","author_flair_css_class":null,"selftext":"I'm having quite a bit of trouble understanding the original Herbrich paper. Can someone explain it to me in simple terms?","domain":"self.MachineLearning","num_comments":2,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":18,"approved_by":null,"score":16,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m having quite a bit of trouble understanding the original Herbrich paper. Can someone explain it to me in simple terms?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326292055,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://queue.acm.org/icpc/","link_flair_css_class":null,"id":"obyq1","edited":false,"num_reports":null,"created_utc":1326259256,"banned_by":null,"name":"t3_obyq1","subreddit":"MachineLearning","title":"Queue ICPC Challenge","author_flair_text":null,"is_self":false,"author":"[deleted]","media_embed":{},"permalink":"/r/MachineLearning/comments/obyq1/queue_icpc_challenge/","author_flair_css_class":null,"selftext":"","domain":"queue.acm.org","num_comments":0,"likes":null,"clicked":false,"thumbnail":"http://c.thumbs.redditmedia.com/J8mckODtfNPCxDyh.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":11,"approved_by":null,"score":10,"selftext_html":null,"created":1326259256,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/oejsh/reinforcement_learning_resources/","link_flair_css_class":null,"id":"oejsh","edited":false,"num_reports":null,"created_utc":1326407559,"banned_by":null,"name":"t3_oejsh","subreddit":"MachineLearning","title":"Reinforcement learning resources?","author_flair_text":null,"is_self":true,"author":"[deleted]","media_embed":{},"permalink":"/r/MachineLearning/comments/oejsh/reinforcement_learning_resources/","author_flair_css_class":null,"selftext":"Any pointers to a good tutorial, or practical introduction into reinforcement learning? Thanks!","domain":"self.MachineLearning","num_comments":6,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":9,"approved_by":null,"score":8,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any pointers to a good tutorial, or practical introduction into reinforcement learning? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326407559,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/oe0s5/fishers_information_matrix/","link_flair_css_class":null,"id":"oe0s5","edited":false,"num_reports":null,"created_utc":1326384551,"banned_by":null,"name":"t3_oe0s5","subreddit":"MachineLearning","title":"Fisher's Information Matrix","author_flair_text":null,"is_self":true,"author":"tncardoso","media_embed":{},"permalink":"/r/MachineLearning/comments/oe0s5/fishers_information_matrix/","author_flair_css_class":null,"selftext":"Hi guys,\n\nI am trying to implement an Active Learning algorithm using the Fisher's Information Matrix as the selection strategy. I tried different papers but I couldn't understand how the matrix is obtained. Some of these papers are:\n\nA Probability Analysis on the Value of Unlabeled Data for Classification Problems\nTong Zhang, Frank J. Oles\n\nActive Learning for Logistic Regression: an evaluation\nAndrew I. Schein, Lyle H. Ungar\n\nI will be grateful if someone can explain this matrix or provide me with good references. A reference implementation would be really nice too.\n\nThanks!","domain":"self.MachineLearning","num_comments":2,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":2,"approved_by":null,"score":1,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I am trying to implement an Active Learning algorithm using the Fisher&amp;#39;s Information Matrix as the selection strategy. I tried different papers but I couldn&amp;#39;t understand how the matrix is obtained. Some of these papers are:&lt;/p&gt;\n\n&lt;p&gt;A Probability Analysis on the Value of Unlabeled Data for Classification Problems\nTong Zhang, Frank J. Oles&lt;/p&gt;\n\n&lt;p&gt;Active Learning for Logistic Regression: an evaluation\nAndrew I. Schein, Lyle H. Ungar&lt;/p&gt;\n\n&lt;p&gt;I will be grateful if someone can explain this matrix or provide me with good references. A reference implementation would be really nice too.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326384551,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.kg-machinery.com/product/index.html","link_flair_css_class":null,"id":"odnb4","edited":false,"num_reports":null,"created_utc":1326352144,"banned_by":null,"name":"t3_odnb4","subreddit":"MachineLearning","title":"Camlock Coupling","author_flair_text":null,"is_self":false,"author":"stephanieme","media_embed":{},"permalink":"/r/MachineLearning/comments/odnb4/camlock_coupling/","author_flair_css_class":null,"selftext":"","domain":"kg-machinery.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":2,"approved_by":null,"score":1,"selftext_html":null,"created":1326352144,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/og42n/what_is_the_best_java_neural_network_library_for/","link_flair_css_class":null,"id":"og42n","edited":false,"num_reports":null,"created_utc":1326497373,"banned_by":null,"name":"t3_og42n","subreddit":"MachineLearning","title":"What is the best Java neural network library for research?","author_flair_text":null,"is_self":true,"author":"coopster","media_embed":{},"permalink":"/r/MachineLearning/comments/og42n/what_is_the_best_java_neural_network_library_for/","author_flair_css_class":null,"selftext":"I am a PhD student in machine learning, and am now starting my 'serious' dissertation effort.  I will be doing research involving neural networks and I am likely going to use Java for development.  What would you say is the best Java library to use?  Knowing that I am going to be implementing my own training functions, architectures, etc., is there one that is more flexible than the others?\n\nCurrently, I'm leaning towards [Encog](http://www.heatonresearch.com/encog) or [Neuroph](http://neuroph.sourceforge.net/).  Any thoughts?","domain":"self.MachineLearning","num_comments":20,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":12,"approved_by":null,"score":8,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a PhD student in machine learning, and am now starting my &amp;#39;serious&amp;#39; dissertation effort.  I will be doing research involving neural networks and I am likely going to use Java for development.  What would you say is the best Java library to use?  Knowing that I am going to be implementing my own training functions, architectures, etc., is there one that is more flexible than the others?&lt;/p&gt;\n\n&lt;p&gt;Currently, I&amp;#39;m leaning towards &lt;a href=\"http://www.heatonresearch.com/encog\"&gt;Encog&lt;/a&gt; or &lt;a href=\"http://neuroph.sourceforge.net/\"&gt;Neuroph&lt;/a&gt;.  Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326497373,"hidden":false,"over_18":false}
{"downs":9,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/ofz6y/is_there_any_way_to_embed_a_widget_in_a_facebook/","link_flair_css_class":null,"id":"ofz6y","edited":false,"num_reports":null,"created_utc":1326490837,"banned_by":null,"name":"t3_ofz6y","subreddit":"MachineLearning","title":"Is there any way to embed a widget in a Facebook post?","author_flair_text":null,"is_self":true,"author":"[deleted]","media_embed":{},"permalink":"/r/MachineLearning/comments/ofz6y/is_there_any_way_to_embed_a_widget_in_a_facebook/","author_flair_css_class":null,"selftext":"","domain":"self.MachineLearning","num_comments":1,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":3,"approved_by":null,"score":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326490837,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/ofpc8/tell_me_about_lucenesolr/","link_flair_css_class":null,"id":"ofpc8","edited":false,"num_reports":null,"created_utc":1326478149,"banned_by":null,"name":"t3_ofpc8","subreddit":"MachineLearning","title":"Tell me about Lucene/SOLR","author_flair_text":null,"is_self":true,"author":"shaggorama","media_embed":{},"permalink":"/r/MachineLearning/comments/ofpc8/tell_me_about_lucenesolr/","author_flair_css_class":null,"selftext":"I tend to find myself in forums talking about predictive statistics more than NLP, so I basically never see anyone talking about Lucene. All of a sudden at work everyone's talking about it like applying it to our problem will be a magic pill (which it may well be). Anyone here have any experience? What do you guys think of this tool","domain":"self.MachineLearning","num_comments":7,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":11,"approved_by":null,"score":7,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tend to find myself in forums talking about predictive statistics more than NLP, so I basically never see anyone talking about Lucene. All of a sudden at work everyone&amp;#39;s talking about it like applying it to our problem will be a magic pill (which it may well be). Anyone here have any experience? What do you guys think of this tool&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326478149,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/ofac9/is_using_pca_a_good_way_to_reduce_dimensionality/","link_flair_css_class":null,"id":"ofac9","edited":true,"num_reports":null,"created_utc":1326448129,"banned_by":null,"name":"t3_ofac9","subreddit":"MachineLearning","title":"Is using PCA a good way to reduce dimensionality of text features?","author_flair_text":null,"is_self":true,"author":"joelthelion","media_embed":{},"permalink":"/r/MachineLearning/comments/ofac9/is_using_pca_a_good_way_to_reduce_dimensionality/","author_flair_css_class":null,"selftext":"I'm working on a classifier for reddit posts, and I have the impression that non-text features such as subreddit, author, domain or votes are being drown by the sheer number of features from the text (link title, and optionnally comments and linked page).\n\nSo I'm thinking of using some sort of dimensionality reduction on the text features before handing them to the classifier. Am I on the right path?\n\nEDIT: thanks everyone for the answers!","domain":"self.MachineLearning","num_comments":21,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":19,"approved_by":null,"score":15,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a classifier for reddit posts, and I have the impression that non-text features such as subreddit, author, domain or votes are being drown by the sheer number of features from the text (link title, and optionnally comments and linked page).&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m thinking of using some sort of dimensionality reduction on the text features before handing them to the classifier. Am I on the right path?&lt;/p&gt;\n\n&lt;p&gt;EDIT: thanks everyone for the answers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326448129,"hidden":false,"over_18":false}
{"downs":3,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/ogg3e/a_good_place_to_start/","link_flair_css_class":null,"id":"ogg3e","edited":true,"num_reports":null,"created_utc":1326516157,"banned_by":null,"name":"t3_ogg3e","subreddit":"MachineLearning","title":"A good place to start?","author_flair_text":null,"is_self":true,"author":"cheraphy","media_embed":{},"permalink":"/r/MachineLearning/comments/ogg3e/a_good_place_to_start/","author_flair_css_class":null,"selftext":"What would be an ideal place to start self study in regards to Machine Learning? I have sparse bits of knowledge of the topic but no concrete base to begin teaching my self anything. So I'm wondering what subjects I should look into first and/or what books would be good to begin reading.\n\nI am currently an undergrad Computer Science student in my second year, but I've been studying Computer Science in general for almost six years. This particular field of research has always been the most intriguing to me and what initially got me into programming as child.\n\nI am a proficient imperative programmer and am trying to learn functional programming. \n\nThank you in advanced.\n\n**EDIT**: Someone pointed out to me how open ended this question could be and suggested I give specific areas in this field I'm interested. As I still have a very shallow understanding of the field I would have to guess that Machine Perception and Pattern Recognition are what interest me most.\n","domain":"self.MachineLearning","num_comments":15,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":12,"approved_by":null,"score":9,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What would be an ideal place to start self study in regards to Machine Learning? I have sparse bits of knowledge of the topic but no concrete base to begin teaching my self anything. So I&amp;#39;m wondering what subjects I should look into first and/or what books would be good to begin reading.&lt;/p&gt;\n\n&lt;p&gt;I am currently an undergrad Computer Science student in my second year, but I&amp;#39;ve been studying Computer Science in general for almost six years. This particular field of research has always been the most intriguing to me and what initially got me into programming as child.&lt;/p&gt;\n\n&lt;p&gt;I am a proficient imperative programmer and am trying to learn functional programming. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advanced.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt;: Someone pointed out to me how open ended this question could be and suggested I give specific areas in this field I&amp;#39;m interested. As I still have a very shallow understanding of the field I would have to guess that Machine Perception and Pattern Recognition are what interest me most.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326516157,"hidden":false,"over_18":false}
{"downs":7,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.datasciencetoolkit.org/about","link_flair_css_class":null,"id":"oi7ra","edited":false,"num_reports":null,"created_utc":1326654169,"banned_by":null,"name":"t3_oi7ra","subreddit":"MachineLearning","title":"Data Science Toolkit - A Linux distro for data science","author_flair_text":null,"is_self":false,"author":"kimmel_","media_embed":{},"permalink":"/r/MachineLearning/comments/oi7ra/data_science_toolkit_a_linux_distro_for_data/","author_flair_css_class":null,"selftext":"","domain":"datasciencetoolkit.org","num_comments":4,"likes":null,"clicked":false,"thumbnail":"http://b.thumbs.redditmedia.com/izkFy1Zo-rcQV4wI.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":22,"approved_by":null,"score":15,"selftext_html":null,"created":1326654169,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.r-bloggers.com/big-media-waking-up-to-big-data/","link_flair_css_class":null,"id":"ohx41","edited":false,"num_reports":null,"created_utc":1326630005,"banned_by":null,"name":"t3_ohx41","subreddit":"MachineLearning","title":"Big media waking up to big data","author_flair_text":null,"is_self":false,"author":"talgalili","media_embed":{},"permalink":"/r/MachineLearning/comments/ohx41/big_media_waking_up_to_big_data/","author_flair_css_class":null,"selftext":"","domain":"r-bloggers.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1326630005,"hidden":false,"over_18":false}
{"downs":2,"link_flair_text":null,"distinguished":null,"media":{"oembed":{"width":600,"author_name":"Drew Conway","author_url":"http://vimeo.com/user2150538","version":"1.0","provider_url":"http://vimeo.com/","provider_name":"Vimeo","thumbnail_width":640,"thumbnail_url":"http://b.vimeocdn.com/ts/229/144/229144975_640.jpg","height":338,"description":"This presentation was given to the NYC Open Statistical Computing Meetup by Hadley Wickham, Assistant Professor of Statistics at Rice University, and creator of many of the most popular R packages in CRAN. It's often said that 80% of the effort of analysis is spent just getting the data ready to analyse, the process of data cleaning.","thumbnail_height":360,"html":"&lt;iframe src=\"http://player.vimeo.com/video/33727555\" width=\"600\" height=\"338\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;","title":"Tidy Data","type":"video"},"type":"vimeo.com"},"url":"http://vimeo.com/33727555","link_flair_css_class":null,"id":"ojxe1","edited":false,"num_reports":null,"created_utc":1326754062,"banned_by":null,"name":"t3_ojxe1","subreddit":"MachineLearning","title":"Tidy Data, talk by Hadley Wickham [vid]","author_flair_text":null,"is_self":false,"author":"agconway","media_embed":{"width":600,"scrolling":false,"content":"&lt;iframe src=\"http://player.vimeo.com/video/33727555\" width=\"600\" height=\"338\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;","height":338},"permalink":"/r/MachineLearning/comments/ojxe1/tidy_data_talk_by_hadley_wickham_vid/","author_flair_css_class":null,"selftext":"","domain":"vimeo.com","num_comments":1,"likes":null,"clicked":false,"thumbnail":"http://a.thumbs.redditmedia.com/BBKAzIjTQXtqGGoZ.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":23,"approved_by":null,"score":21,"selftext_html":null,"created":1326754062,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.r-bloggers.com/crdata-org-to-shut-down/","link_flair_css_class":null,"id":"ojmdq","edited":false,"num_reports":null,"created_utc":1326741033,"banned_by":null,"name":"t3_ojmdq","subreddit":"MachineLearning","title":"Will CRdata.org (R related cloud computing service)  shut down?","author_flair_text":null,"is_self":false,"author":"talgalili","media_embed":{},"permalink":"/r/MachineLearning/comments/ojmdq/will_crdataorg_r_related_cloud_computing_service/","author_flair_css_class":null,"selftext":"","domain":"r-bloggers.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1326741033,"hidden":false,"over_18":false}
{"downs":3,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/ojjay/anyone_got_10_minutes_to_help_me_with_a/","link_flair_css_class":null,"id":"ojjay","edited":false,"num_reports":null,"created_utc":1326737217,"banned_by":null,"name":"t3_ojjay","subreddit":"MachineLearning","title":"Anyone got 10 minutes to help me with a rapidminer user issue please?  [Beginner human error]","author_flair_text":null,"is_self":true,"author":"johnyma22","media_embed":{},"permalink":"/r/MachineLearning/comments/ojjay/anyone_got_10_minutes_to_help_me_with_a/","author_flair_css_class":null,"selftext":"I just need a little human help via whatever comms method you prefer..  I have watched loads of tutorial videos and tried to get started but I got stuck on a \"label\" issue.\n\nThanks in advance","domain":"self.MachineLearning","num_comments":2,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":5,"approved_by":null,"score":2,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just need a little human help via whatever comms method you prefer..  I have watched loads of tutorial videos and tried to get started but I got stuck on a &amp;quot;label&amp;quot; issue.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326737217,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/ojdry/what_data_stores_do_you_use_for_data_analysis/","link_flair_css_class":null,"id":"ojdry","edited":false,"num_reports":null,"created_utc":1326729475,"banned_by":null,"name":"t3_ojdry","subreddit":"MachineLearning","title":"What data stores do you use for data analysis?","author_flair_text":null,"is_self":true,"author":"descentintomael","media_embed":{},"permalink":"/r/MachineLearning/comments/ojdry/what_data_stores_do_you_use_for_data_analysis/","author_flair_css_class":null,"selftext":"I'm trying to do a side project where I need to store 30M+ rows of data.  Tried MySQL at first just to see what would happen (tl;dr; it didn't).  I'm looking at Cassandra next but it doesn't have a very robust query system.  I don't need anything complex, just something to throw data at and then say I need all rows (one at a time) which have or don't have column X as null.\n\nRegardless of that, I'm curious what you all use on various projects?","domain":"self.MachineLearning","num_comments":14,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":5,"approved_by":null,"score":1,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to do a side project where I need to store 30M+ rows of data.  Tried MySQL at first just to see what would happen (tl;dr; it didn&amp;#39;t).  I&amp;#39;m looking at Cassandra next but it doesn&amp;#39;t have a very robust query system.  I don&amp;#39;t need anything complex, just something to throw data at and then say I need all rows (one at a time) which have or don&amp;#39;t have column X as null.&lt;/p&gt;\n\n&lt;p&gt;Regardless of that, I&amp;#39;m curious what you all use on various projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326729475,"hidden":false,"over_18":false}
{"downs":6,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.epjdatascience.com/","link_flair_css_class":null,"id":"oj9x5","edited":false,"num_reports":null,"created_utc":1326721548,"banned_by":null,"name":"t3_oj9x5","subreddit":"MachineLearning","title":"New open-access journal on data science, now accepting submissions","author_flair_text":null,"is_self":false,"author":"fbahr","media_embed":{},"permalink":"/r/MachineLearning/comments/oj9x5/new_openaccess_journal_on_data_science_now/","author_flair_css_class":null,"selftext":"","domain":"epjdatascience.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"http://f.thumbs.redditmedia.com/aKwRhPYuQNk0_bJe.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":25,"approved_by":null,"score":19,"selftext_html":null,"created":1326721548,"hidden":false,"over_18":false}
{"downs":6,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://meclia.tumblr.com/post/15940629300/first-i-need-to-learn-then-a-machine-can-learn","link_flair_css_class":null,"id":"oj554","edited":false,"num_reports":null,"created_utc":1326706928,"banned_by":null,"name":"t3_oj554","subreddit":"MachineLearning","title":"First I need to learn then a machine can learn! ","author_flair_text":null,"is_self":false,"author":"ijhyez","media_embed":{},"permalink":"/r/MachineLearning/comments/oj554/first_i_need_to_learn_then_a_machine_can_learn/","author_flair_css_class":null,"selftext":"","domain":"meclia.tumblr.com","num_comments":2,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":2,"approved_by":null,"score":0,"selftext_html":null,"created":1326706928,"hidden":false,"over_18":false}
{"downs":5,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://semantic-link.com","link_flair_css_class":null,"id":"oiubt","edited":false,"num_reports":null,"created_utc":1326686940,"banned_by":null,"name":"t3_oiubt","subreddit":"MachineLearning","title":"Semantic Link: automatically find related words","author_flair_text":null,"is_self":false,"author":"mpacula","media_embed":{},"permalink":"/r/MachineLearning/comments/oiubt/semantic_link_automatically_find_related_words/","author_flair_css_class":null,"selftext":"","domain":"semantic-link.com","num_comments":9,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":13,"approved_by":null,"score":8,"selftext_html":null,"created":1326686940,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/okm5c/can_anyone_suggest_a_semester_project_related_to/","link_flair_css_class":null,"id":"okm5c","edited":false,"num_reports":null,"created_utc":1326787438,"banned_by":null,"name":"t3_okm5c","subreddit":"MachineLearning","title":"Can anyone suggest a semester project related to machine learning/AI?","author_flair_text":null,"is_self":true,"author":"GotGoose","media_embed":{},"permalink":"/r/MachineLearning/comments/okm5c/can_anyone_suggest_a_semester_project_related_to/","author_flair_css_class":null,"selftext":"I'm in a undergraduate research/project type class this semester and need to write a project proposal soon. I've already taken an intro to AI class, so I know the basics of the field. My teacher recommended a Twitter crawler/analyzer which sounds interesting to me, but I was wondering what else is out there.","domain":"self.MachineLearning","num_comments":21,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":12,"approved_by":null,"score":8,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in a undergraduate research/project type class this semester and need to write a project proposal soon. I&amp;#39;ve already taken an intro to AI class, so I know the basics of the field. My teacher recommended a Twitter crawler/analyzer which sounds interesting to me, but I was wondering what else is out there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326787438,"hidden":false,"over_18":false}
{"downs":7,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/onuiu/what_is_the_most_useless_application_of_machine/","link_flair_css_class":null,"id":"onuiu","edited":false,"num_reports":null,"created_utc":1327008857,"banned_by":null,"name":"t3_onuiu","subreddit":"MachineLearning","title":"What is the most useless application of machine learning you've come across?","author_flair_text":null,"is_self":true,"author":"shaggorama","media_embed":{},"permalink":"/r/MachineLearning/comments/onuiu/what_is_the_most_useless_application_of_machine/","author_flair_css_class":null,"selftext":"Maybe your coworker modeled the parking lot to try and predict where he could most likely find an empty space, or you wanted to validate your intuition that the best place to start a minesweeper game is on the corners, but you're too lazy to do the math so you wrote a monte carlo simulation instead (OK...that last one was me).","domain":"self.MachineLearning","num_comments":16,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":22,"approved_by":null,"score":15,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe your coworker modeled the parking lot to try and predict where he could most likely find an empty space, or you wanted to validate your intuition that the best place to start a minesweeper game is on the corners, but you&amp;#39;re too lazy to do the math so you wrote a monte carlo simulation instead (OK...that last one was me).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327008857,"hidden":false,"over_18":false}
{"downs":2,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.wired.com/dangerroom/2012/01/social-radar-sees-minds/","link_flair_css_class":null,"id":"onhax","edited":false,"num_reports":null,"created_utc":1326992979,"banned_by":null,"name":"t3_onhax","subreddit":"MachineLearning","title":"Air Force's Top Brain Wants a 'Social Radar' to 'See Into Hearts and Minds'","author_flair_text":null,"is_self":false,"author":"jdw25","media_embed":{},"permalink":"/r/MachineLearning/comments/onhax/air_forces_top_brain_wants_a_social_radar_to_see/","author_flair_css_class":null,"selftext":"","domain":"wired.com","num_comments":2,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":21,"approved_by":null,"score":19,"selftext_html":null,"created":1326992979,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/on4wu/classifying_meanstdev_data/","link_flair_css_class":null,"id":"on4wu","edited":false,"num_reports":null,"created_utc":1326972326,"banned_by":null,"name":"t3_on4wu","subreddit":"MachineLearning","title":"Classifying [mean,stdev] data","author_flair_text":null,"is_self":true,"author":"RagingDoug","media_embed":{},"permalink":"/r/MachineLearning/comments/on4wu/classifying_meanstdev_data/","author_flair_css_class":null,"selftext":"I have a large dataset and each item is either of type A or type B. My data is a [mean,stdev] pair. What would be a good approach to classifying this data?\n\nI know that one approach if I had a bunch of points I wanted to classify would be to take the mean and stdev and use it to model the pdf with a guassian classifier.\n\nHowever, since each \"point\" in my dataset is a [mean,stdev] pair (which itself implicitly defines some distribution) I'm curious as to a way to build a classifier for this type of data.\n\nHopefully that made sense.\n\nCheers","domain":"self.MachineLearning","num_comments":4,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":5,"approved_by":null,"score":5,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large dataset and each item is either of type A or type B. My data is a [mean,stdev] pair. What would be a good approach to classifying this data?&lt;/p&gt;\n\n&lt;p&gt;I know that one approach if I had a bunch of points I wanted to classify would be to take the mean and stdev and use it to model the pdf with a guassian classifier.&lt;/p&gt;\n\n&lt;p&gt;However, since each &amp;quot;point&amp;quot; in my dataset is a [mean,stdev] pair (which itself implicitly defines some distribution) I&amp;#39;m curious as to a way to build a classifier for this type of data.&lt;/p&gt;\n\n&lt;p&gt;Hopefully that made sense.&lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1326972326,"hidden":false,"over_18":false}
{"downs":6,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.newscientist.com/mobile/article/mg21328484.200-neural-network-gets-an-idea-of-number-without-counting.html","link_flair_css_class":null,"id":"oor1a","edited":false,"num_reports":null,"created_utc":1327061597,"banned_by":null,"name":"t3_oor1a","subreddit":"MachineLearning","title":"Neural network gets an idea of number without counting","author_flair_text":null,"is_self":false,"author":"bubbles212","media_embed":{},"permalink":"/r/MachineLearning/comments/oor1a/neural_network_gets_an_idea_of_number_without/","author_flair_css_class":null,"selftext":"","domain":"newscientist.com","num_comments":16,"likes":null,"clicked":false,"thumbnail":"http://e.thumbs.redditmedia.com/uSPClo3cPY0DGKAp.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":36,"approved_by":null,"score":30,"selftext_html":null,"created":1327061597,"hidden":false,"over_18":false}
{"downs":3,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://mpacula.com/autocorpus","link_flair_css_class":null,"id":"oqlyh","edited":false,"num_reports":null,"created_utc":1327179641,"banned_by":null,"name":"t3_oqlyh","subreddit":"MachineLearning","title":"AutoCorpus - natural language corpora from large public datasets","author_flair_text":null,"is_self":false,"author":"autoencoder","media_embed":{},"permalink":"/r/MachineLearning/comments/oqlyh/autocorpus_natural_language_corpora_from_large/","author_flair_css_class":null,"selftext":"","domain":"mpacula.com","num_comments":2,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":30,"approved_by":null,"score":27,"selftext_html":null,"created":1327179641,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/oprfn/has_this_been_tried_does_it_have_a_name_random/","link_flair_css_class":null,"id":"oprfn","edited":false,"num_reports":null,"created_utc":1327115369,"banned_by":null,"name":"t3_oprfn","subreddit":"MachineLearning","title":"Has this been tried, does it have a name? (random projections and database hash)","author_flair_text":null,"is_self":true,"author":"marshallp","media_embed":{},"permalink":"/r/MachineLearning/comments/oprfn/has_this_been_tried_does_it_have_a_name_random/","author_flair_css_class":null,"selftext":"I'm trying to find if this has been done or has a name. You take data vectors, multiply them by a set of n random vectors (you use thesame random vectors on every data vector), and sum the result along each multiplication, yielding a new vector of size n. (this i believe might be random matrices or a random two layer net).\n\nThe next step, you digitize the resulting vectors m times for various bin sizes (e.g. 2 bins, 10 bins, 20 bins etc.). Then you hash the resulting vectors and save to a key value store with hashes as key and data labels as value (the hashing step is simply to reduce database size).\n\nThen on the prediction task, you do the random projection and binnings, and then instead of saving to disk, query the hashes. You should get a number of labels back, you take the most common label as your prediction.\n","domain":"self.MachineLearning","num_comments":8,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":9,"approved_by":null,"score":8,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to find if this has been done or has a name. You take data vectors, multiply them by a set of n random vectors (you use thesame random vectors on every data vector), and sum the result along each multiplication, yielding a new vector of size n. (this i believe might be random matrices or a random two layer net).&lt;/p&gt;\n\n&lt;p&gt;The next step, you digitize the resulting vectors m times for various bin sizes (e.g. 2 bins, 10 bins, 20 bins etc.). Then you hash the resulting vectors and save to a key value store with hashes as key and data labels as value (the hashing step is simply to reduce database size).&lt;/p&gt;\n\n&lt;p&gt;Then on the prediction task, you do the random projection and binnings, and then instead of saving to disk, query the hashes. You should get a number of labels back, you take the most common label as your prediction.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327115369,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/or433/restricted_boltzmann_machine_troubles_not_sure_if/","link_flair_css_class":null,"id":"or433","edited":false,"num_reports":null,"created_utc":1327208223,"banned_by":null,"name":"t3_or433","subreddit":"MachineLearning","title":"Restricted Boltzmann Machine Troubles: Not sure if broken, or working and I'm just stupid.","author_flair_text":null,"is_self":true,"author":"omgitsjo","media_embed":{},"permalink":"/r/MachineLearning/comments/or433/restricted_boltzmann_machine_troubles_not_sure_if/","author_flair_css_class":null,"selftext":"I've been trying to get an RBM up because I want to be sure I'm understanding it well enough before using a library.  I have one now which seems to be learning, but isn't recreating linear values on the visible side.  I think my learning function is incorrect, but the error is decreasing across epochs.  I've tried averaging the runs rather than applying the weights immediately, but it only seems to smooth out the learning.\n\nThe reason I suspect it's not learning right is as follows.  If I train it on a linear value, say (x, 2*x) for all x in the (0, 1000) or (0,1) with step 0.01, and push some value like (1.0, 1.0), I don't get back (1.0, 2.0).  I get either 1,1 if I'm activating on the real like, or I get something like 2.0e-10, 1.4e-10 if I use real valued numbers.\n\nI'd appreciate any hints about what I'm doing wrong, or advice on how to test the validity of the RBM.\n\nSource: http://pastebin.com/KytDMwUz","domain":"self.MachineLearning","num_comments":7,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":9,"approved_by":null,"score":8,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been trying to get an RBM up because I want to be sure I&amp;#39;m understanding it well enough before using a library.  I have one now which seems to be learning, but isn&amp;#39;t recreating linear values on the visible side.  I think my learning function is incorrect, but the error is decreasing across epochs.  I&amp;#39;ve tried averaging the runs rather than applying the weights immediately, but it only seems to smooth out the learning.&lt;/p&gt;\n\n&lt;p&gt;The reason I suspect it&amp;#39;s not learning right is as follows.  If I train it on a linear value, say (x, 2*x) for all x in the (0, 1000) or (0,1) with step 0.01, and push some value like (1.0, 1.0), I don&amp;#39;t get back (1.0, 2.0).  I get either 1,1 if I&amp;#39;m activating on the real like, or I get something like 2.0e-10, 1.4e-10 if I use real valued numbers.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any hints about what I&amp;#39;m doing wrong, or advice on how to test the validity of the RBM.&lt;/p&gt;\n\n&lt;p&gt;Source: &lt;a href=\"http://pastebin.com/KytDMwUz\"&gt;http://pastebin.com/KytDMwUz&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327208223,"hidden":false,"over_18":false}
{"downs":2,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/otcxr/want_to_test_my_recommendation_engine_need_help/","link_flair_css_class":null,"id":"otcxr","edited":false,"num_reports":null,"created_utc":1327351940,"banned_by":null,"name":"t3_otcxr","subreddit":"MachineLearning","title":"Want to test my recommendation engine, need help finding new datasets!","author_flair_text":null,"is_self":true,"author":"arh_the_drones_come","media_embed":{},"permalink":"/r/MachineLearning/comments/otcxr/want_to_test_my_recommendation_engine_need_help/","author_flair_css_class":null,"selftext":"Hey everyone, I've written a recommendation engine that does some neat stuff (ILP relational OTF subgraph building) and some boring traditional stuff (w00t matts correlation, bayesian statistics). Without getting too technical, I was wondering if anyone knows a generic source for these. I already found the movieslens one, which worked, but I'd like something that people disagree about a lot more.\n\nThe problem with the movielens dataset was that a very small number of movies had a very large percentage of likes and almost everyone agreed that the good movies were really, really good. So in order to optimize for a peak matts correlation (after intelligently breaking apart the graph into a training and testing set) the types of recommendations that came out (while correct) made little sense to humans. For example, when I ignored metadata like genre, Shrek was very high up for people that liked The Matrix. That recommendation would surprise people because those movies are impossibly dissimilar, but the overlap between people that liked The Matrix was very high into liking Shrek (though not the other way around, obviously).\n\nAnyways, I'm pretty amped about what I've built and I'm looking for more validation. Ideally the dataset would have both positive and negative signals, but it's not strictly required. I've got a couple NLP modules in here too, so don't shy away from text heavy content either.\n\nThanks in advance :D","domain":"self.MachineLearning","num_comments":4,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":4,"approved_by":null,"score":2,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;ve written a recommendation engine that does some neat stuff (ILP relational OTF subgraph building) and some boring traditional stuff (w00t matts correlation, bayesian statistics). Without getting too technical, I was wondering if anyone knows a generic source for these. I already found the movieslens one, which worked, but I&amp;#39;d like something that people disagree about a lot more.&lt;/p&gt;\n\n&lt;p&gt;The problem with the movielens dataset was that a very small number of movies had a very large percentage of likes and almost everyone agreed that the good movies were really, really good. So in order to optimize for a peak matts correlation (after intelligently breaking apart the graph into a training and testing set) the types of recommendations that came out (while correct) made little sense to humans. For example, when I ignored metadata like genre, Shrek was very high up for people that liked The Matrix. That recommendation would surprise people because those movies are impossibly dissimilar, but the overlap between people that liked The Matrix was very high into liking Shrek (though not the other way around, obviously).&lt;/p&gt;\n\n&lt;p&gt;Anyways, I&amp;#39;m pretty amped about what I&amp;#39;ve built and I&amp;#39;m looking for more validation. Ideally the dataset would have both positive and negative signals, but it&amp;#39;s not strictly required. I&amp;#39;ve got a couple NLP modules in here too, so don&amp;#39;t shy away from text heavy content either.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327351940,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/ot92r/how_to_find_the_split_in_regression_trees/","link_flair_css_class":null,"id":"ot92r","edited":false,"num_reports":null,"created_utc":1327347413,"banned_by":null,"name":"t3_ot92r","subreddit":"MachineLearning","title":"How to find the split in regression trees","author_flair_text":null,"is_self":true,"author":"erUserName","media_embed":{},"permalink":"/r/MachineLearning/comments/ot92r/how_to_find_the_split_in_regression_trees/","author_flair_css_class":null,"selftext":"See: http://math.uprm.edu/~wrolke/esma6665/regtree.htm (How to Grow a tree). I'm having a bit of confusion. \n\nSo we have some predicting variable X, and target Y. We want to find a value that splits X into 2 sets, that minimizes the sum of squared error. So let us say there are n data points. Then there are O(n^2) combinations we would need to test, but the page seems to indicate that this split can be found quickly O(n) maybe? I tried looking in \"The Elements of Statistical Learning\" but it says the same thing, without explaining how and only saying that it can be done very quickly. \n\nCan anyone provide a bit of enlightenment on this matter? Is O(n^2) somehow considered \"quick\" in this case, or am I just an idiot and missing something? ","domain":"self.MachineLearning","num_comments":14,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":7,"approved_by":null,"score":6,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;See: &lt;a href=\"http://math.uprm.edu/%7Ewrolke/esma6665/regtree.htm\"&gt;http://math.uprm.edu/~wrolke/esma6665/regtree.htm&lt;/a&gt; (How to Grow a tree). I&amp;#39;m having a bit of confusion. &lt;/p&gt;\n\n&lt;p&gt;So we have some predicting variable X, and target Y. We want to find a value that splits X into 2 sets, that minimizes the sum of squared error. So let us say there are n data points. Then there are O(n&lt;sup&gt;2)&lt;/sup&gt; combinations we would need to test, but the page seems to indicate that this split can be found quickly O(n) maybe? I tried looking in &amp;quot;The Elements of Statistical Learning&amp;quot; but it says the same thing, without explaining how and only saying that it can be done very quickly. &lt;/p&gt;\n\n&lt;p&gt;Can anyone provide a bit of enlightenment on this matter? Is O(n&lt;sup&gt;2)&lt;/sup&gt; somehow considered &amp;quot;quick&amp;quot; in this case, or am I just an idiot and missing something? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327347413,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://stats.stackexchange.com/questions/21530/do-random-forests-exhibit-prediction-bias","link_flair_css_class":null,"id":"os2vz","edited":false,"num_reports":null,"created_utc":1327276832,"banned_by":null,"name":"t3_os2vz","subreddit":"MachineLearning","title":"Do Random Forests Exhibit Prediction Bias?","author_flair_text":null,"is_self":false,"author":"locster","media_embed":{},"permalink":"/r/MachineLearning/comments/os2vz/do_random_forests_exhibit_prediction_bias/","author_flair_css_class":null,"selftext":"","domain":"stats.stackexchange.com","num_comments":20,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":10,"approved_by":null,"score":6,"selftext_html":null,"created":1327276832,"hidden":false,"over_18":false}
{"downs":5,"link_flair_text":null,"distinguished":null,"media":{"oembed":{"width":600,"author_name":"shriphanip","author_url":"http://www.youtube.com/user/shriphanip","version":"1.0","provider_url":"http://www.youtube.com/","provider_name":"YouTube","thumbnail_width":480,"thumbnail_url":"http://i3.ytimg.com/vi/N38Ry7xvD8I/hqdefault.jpg","height":338,"description":"Using a Nearest-Neighbor classifier to detect hiragana symbols. The test used the symbols in the order shown in the VS window: あいうえおかきくけこさしすせそらりるれろまみめも Currently, I have very little data to work with. I'll upload results with more data.","thumbnail_height":360,"html":"&lt;iframe width=\"600\" height=\"338\" src=\"http://www.youtube.com/embed/N38Ry7xvD8I?fs=1&amp;feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","url":"http://www.youtube.com/watch?v=N38Ry7xvD8I","type":"video","title":"Hiragana-Prediction"},"type":"youtube.com"},"url":"http://www.youtube.com/watch?v=N38Ry7xvD8I&amp;feature=g-upl&amp;context=G27a9118AUAAAAAAAAAA","link_flair_css_class":null,"id":"ov1q7","edited":false,"num_reports":null,"created_utc":1327442016,"banned_by":null,"name":"t3_ov1q7","subreddit":"MachineLearning","title":"hiragana stroke prediction.","author_flair_text":null,"is_self":false,"author":"shriphani","media_embed":{"width":600,"scrolling":false,"content":"&lt;iframe width=\"600\" height=\"338\" src=\"http://www.youtube.com/embed/N38Ry7xvD8I?fs=1&amp;feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","height":338},"permalink":"/r/MachineLearning/comments/ov1q7/hiragana_stroke_prediction/","author_flair_css_class":null,"selftext":"","domain":"youtube.com","num_comments":5,"likes":null,"clicked":false,"thumbnail":"http://b.thumbs.redditmedia.com/SsMPJsUr2hUX8t0g.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":19,"approved_by":null,"score":14,"selftext_html":null,"created":1327442016,"hidden":false,"over_18":false}
{"downs":5,"link_flair_text":null,"distinguished":null,"media":null,"url":"https://www.innocentive.com/ar/challenge/9932863","link_flair_css_class":null,"id":"oun0j","edited":false,"num_reports":null,"created_utc":1327424310,"banned_by":null,"name":"t3_oun0j","subreddit":"MachineLearning","title":"$50,000 The Challenge is looking for a portable device capable of a no-contact (“from a distance”) weight measuring of live pigs in the farm setting. (x-post from r/engineering)","author_flair_text":null,"is_self":false,"author":"[deleted]","media_embed":{},"permalink":"/r/MachineLearning/comments/oun0j/50000_the_challenge_is_looking_for_a_portable/","author_flair_css_class":null,"selftext":"","domain":"innocentive.com","num_comments":19,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":13,"approved_by":null,"score":8,"selftext_html":null,"created":1327424310,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.r-statistics.com/2012/01/interactive-graphics-with-the-iplots-package-from-r-in-action/","link_flair_css_class":null,"id":"oudyc","edited":false,"num_reports":null,"created_utc":1327408395,"banned_by":null,"name":"t3_oudyc","subreddit":"MachineLearning","title":"Interactive Graphics with the iplots Package","author_flair_text":null,"is_self":false,"author":"talgalili","media_embed":{},"permalink":"/r/MachineLearning/comments/oudyc/interactive_graphics_with_the_iplots_package/","author_flair_css_class":null,"selftext":"","domain":"r-statistics.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1327408395,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/ou0p2/help_a_library_address_digital_content/","link_flair_css_class":null,"id":"ou0p2","edited":false,"num_reports":null,"created_utc":1327379918,"banned_by":null,"name":"t3_ou0p2","subreddit":"MachineLearning","title":"Help a Library address digital content...","author_flair_text":null,"is_self":true,"author":"yacob_uk","media_embed":{},"permalink":"/r/MachineLearning/comments/ou0p2/help_a_library_address_digital_content/","author_flair_css_class":null,"selftext":"I work for a large National library, in the digital arena. Almost every day I come across digital text objects that belong to sets, that we are describing (in a library kind of way). \n\nIt strikes me that we could be doing things with ML, especially where we have a large set of related files, and the single description we use in library land is 'collection of 'things' from producer 'A' from Jan 1993.'\n\nThis collection set might be a hundred text files. I would love to demonstrate to my library colleagues the benefit we could get by automatically extracting key terms (dates, names, places etc) and producing some basic keyword based summary of the collection to augment the chronological record we produce at the moment. An added advantage of running an ML tool over the set would be a I guess to create a full text index that could also be searched - allowing users to search for their own keys amongst the collection. \n\nDoes this sound (1) plausible and (2) achievable - especially if I do it myself, as one with only rudimentary python and even less MYSQL at the end of their finger tips. \n\nSuggestions, corrections, mild abuse (where appropriate) and offers of assistance all gratefully received.  ","domain":"self.MachineLearning","num_comments":14,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":5,"approved_by":null,"score":5,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a large National library, in the digital arena. Almost every day I come across digital text objects that belong to sets, that we are describing (in a library kind of way). &lt;/p&gt;\n\n&lt;p&gt;It strikes me that we could be doing things with ML, especially where we have a large set of related files, and the single description we use in library land is &amp;#39;collection of &amp;#39;things&amp;#39; from producer &amp;#39;A&amp;#39; from Jan 1993.&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;This collection set might be a hundred text files. I would love to demonstrate to my library colleagues the benefit we could get by automatically extracting key terms (dates, names, places etc) and producing some basic keyword based summary of the collection to augment the chronological record we produce at the moment. An added advantage of running an ML tool over the set would be a I guess to create a full text index that could also be searched - allowing users to search for their own keys amongst the collection. &lt;/p&gt;\n\n&lt;p&gt;Does this sound (1) plausible and (2) achievable - especially if I do it myself, as one with only rudimentary python and even less MYSQL at the end of their finger tips. &lt;/p&gt;\n\n&lt;p&gt;Suggestions, corrections, mild abuse (where appropriate) and offers of assistance all gratefully received.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327379918,"hidden":false,"over_18":false}
{"downs":5,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://blog.bigml.com/2012/01/23/beautiful-decisions-inside-bigmls-decision-trees/","link_flair_css_class":null,"id":"otpj3","edited":false,"num_reports":null,"created_utc":1327366632,"banned_by":null,"name":"t3_otpj3","subreddit":"MachineLearning","title":"Beautiful Decisions: Inside BigML’s Decision Trees","author_flair_text":null,"is_self":false,"author":"jjdonald","media_embed":{},"permalink":"/r/MachineLearning/comments/otpj3/beautiful_decisions_inside_bigmls_decision_trees/","author_flair_css_class":null,"selftext":"","domain":"blog.bigml.com","num_comments":2,"likes":null,"clicked":false,"thumbnail":"http://e.thumbs.redditmedia.com/HbgqlaiQ4nNzubXX.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":10,"approved_by":null,"score":5,"selftext_html":null,"created":1327366632,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://rdf.ookaboo.com/","link_flair_css_class":null,"id":"owkxz","edited":false,"num_reports":null,"created_utc":1327526396,"banned_by":null,"name":"t3_owkxz","subreddit":"MachineLearning","title":"RDF based image and topic dump","author_flair_text":null,"is_self":false,"author":"Curry_Boy","media_embed":{},"permalink":"/r/MachineLearning/comments/owkxz/rdf_based_image_and_topic_dump/","author_flair_css_class":null,"selftext":"","domain":"rdf.ookaboo.com","num_comments":1,"likes":null,"clicked":false,"thumbnail":"http://f.thumbs.redditmedia.com/1Jw7SOQdg__qbw65.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":6,"approved_by":null,"score":5,"selftext_html":null,"created":1327526396,"hidden":false,"over_18":false}
{"downs":5,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://allendowney.blogspot.com/2012/01/think-complexity.html","link_flair_css_class":null,"id":"ow3vk","edited":false,"num_reports":null,"created_utc":1327504598,"banned_by":null,"name":"t3_ow3vk","subreddit":"MachineLearning","title":"Excerpts from Redditor AllenDowney's new book 'Think Complexity' ","author_flair_text":null,"is_self":false,"author":"cavedave","media_embed":{},"permalink":"/r/MachineLearning/comments/ow3vk/excerpts_from_redditor_allendowneys_new_book/","author_flair_css_class":null,"selftext":"","domain":"allendowney.blogspot.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"http://f.thumbs.redditmedia.com/bAAJsyNkAQQ_mNde.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":20,"approved_by":null,"score":15,"selftext_html":null,"created":1327504598,"hidden":false,"over_18":false}
{"downs":13,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://blog.bigml.com/2012/01/26/data-is-the-new-gold/","link_flair_css_class":null,"id":"oxqsi","edited":false,"num_reports":null,"created_utc":1327596401,"banned_by":null,"name":"t3_oxqsi","subreddit":"MachineLearning","title":"Data is the New Gold, But You’ll Have to Dig For It","author_flair_text":null,"is_self":false,"author":"jjdonald","media_embed":{},"permalink":"/r/MachineLearning/comments/oxqsi/data_is_the_new_gold_but_youll_have_to_dig_for_it/","author_flair_css_class":null,"selftext":"","domain":"blog.bigml.com","num_comments":6,"likes":null,"clicked":false,"thumbnail":"http://d.thumbs.redditmedia.com/t2AU_MQSZ5pveT2u.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":7,"approved_by":null,"score":0,"selftext_html":null,"created":1327596401,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.r-bloggers.com/announcing-the-winners-of-the-applications-of-r-in-business-contest/","link_flair_css_class":null,"id":"oxcza","edited":false,"num_reports":null,"created_utc":1327564598,"banned_by":null,"name":"t3_oxcza","subreddit":"MachineLearning","title":"The winners of the Applications of R in Business contest","author_flair_text":null,"is_self":false,"author":"talgalili","media_embed":{},"permalink":"/r/MachineLearning/comments/oxcza/the_winners_of_the_applications_of_r_in_business/","author_flair_css_class":null,"selftext":"","domain":"r-bloggers.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1327564598,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.hydraulicnews.hidraulicapractica.com/news/caterpillar-inc-caterpillar-announces-new-cat%C2%AE-e-series-mini-hydraulic-e-4traders-press-release","link_flair_css_class":null,"id":"owv30","edited":false,"num_reports":null,"created_utc":1327538615,"banned_by":null,"name":"t3_owv30","subreddit":"MachineLearning","title":"CATERPILLAR INC.: Caterpillar Announces New Cat® E Series Mini Hydraulic E.. - 4-traders (press release) | HYDRAULICS - News","author_flair_text":null,"is_self":false,"author":"kamilrhu","media_embed":{},"permalink":"/r/MachineLearning/comments/owv30/caterpillar_inc_caterpillar_announces_new_cat_e/","author_flair_css_class":null,"selftext":"","domain":"hydraulicnews.hidraulicapractica.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1327538615,"hidden":false,"over_18":false}
{"downs":11,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.fastcompany.com/1811441/why-big-data-won-t-make-you-smart-rich-or-pretty","link_flair_css_class":null,"id":"ozrep","edited":false,"num_reports":null,"created_utc":1327704403,"banned_by":null,"name":"t3_ozrep","subreddit":"MachineLearning","title":"Why Big Data Won’t Make You Smart, Rich, Or Pretty","author_flair_text":null,"is_self":false,"author":"cavedave","media_embed":{},"permalink":"/r/MachineLearning/comments/ozrep/why_big_data_wont_make_you_smart_rich_or_pretty/","author_flair_css_class":null,"selftext":"","domain":"fastcompany.com","num_comments":2,"likes":null,"clicked":false,"thumbnail":"http://a.thumbs.redditmedia.com/qbDs4cMaayJDixjB.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":21,"approved_by":null,"score":10,"selftext_html":null,"created":1327704403,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":{"oembed":{"width":600,"author_name":"TheJakeDTH","author_url":"http://www.youtube.com/user/TheJakeDTH","version":"1.0","provider_url":"http://www.youtube.com/","provider_name":"YouTube","thumbnail_width":480,"thumbnail_url":"http://i3.ytimg.com/vi/r2gonFtc1yc/hqdefault.jpg","height":338,"description":"From http://www.inatux.com/article?r=development-gimp-version-2.7-review Lately, people have been speaking highly of Adobe Photoshop over this video showing what Bryan O'Neil Hughes calls \"Content-Aware Fill\" which is a technique for synthesizing texture. http://www.youtube.com/watch?v=NH0aEp1oDOI Here's a little old favorite GIMP plugin called Resynthesizer. Resynthesizer works just as well as Photoshop's \"Content-Aware Fill\", only Resynthesizer appears to have more options.","thumbnail_height":360,"html":"&lt;iframe width=\"600\" height=\"338\" src=\"http://www.youtube.com/embed/r2gonFtc1yc?fs=1&amp;feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","url":"http://www.youtube.com/watch?v=r2gonFtc1yc","type":"video","title":"GIMP plugin \"Resynthesizer\" and \"Single Window\" mode"},"type":"youtube.com"},"url":"http://www.youtube.com/watch?v=r2gonFtc1yc","link_flair_css_class":null,"id":"ozctg","edited":false,"num_reports":null,"created_utc":1327686110,"banned_by":null,"name":"t3_ozctg","subreddit":"MachineLearning","title":"Ask r/ML: How does the Resynthesizer (GIMP)/Content Aware Fill (Photoshop) algorithm work?","author_flair_text":null,"is_self":false,"author":"shaggorama","media_embed":{"width":600,"scrolling":false,"content":"&lt;iframe width=\"600\" height=\"338\" src=\"http://www.youtube.com/embed/r2gonFtc1yc?fs=1&amp;feature=oembed\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","height":338},"permalink":"/r/MachineLearning/comments/ozctg/ask_rml_how_does_the_resynthesizer_gimpcontent/","author_flair_css_class":null,"selftext":"","domain":"youtube.com","num_comments":5,"likes":null,"clicked":false,"thumbnail":"http://b.thumbs.redditmedia.com/fVdLTzt3SY35ILEO.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":4,"approved_by":null,"score":3,"selftext_html":null,"created":1327686110,"hidden":false,"over_18":false}
{"downs":2,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/oz1r4/how_to_use_spotty_labeled_training_data_knowing/","link_flair_css_class":null,"id":"oz1r4","edited":false,"num_reports":null,"created_utc":1327667158,"banned_by":null,"name":"t3_oz1r4","subreddit":"MachineLearning","title":"How to use spotty labeled training data, knowing there is correlation between features and whether an example is labeled or not?","author_flair_text":null,"is_self":true,"author":"solen-skiner","media_embed":{},"permalink":"/r/MachineLearning/comments/oz1r4/how_to_use_spotty_labeled_training_data_knowing/","author_flair_css_class":null,"selftext":"I have a data-set with both labeled and unlabeled examples. Due to my knowledge of the domain I know that some of the examples features greatly affect whether an example is labeled or unlabeled, causing very biased label data and grave errors in prediction. How can I use this knowledge of the correlation between the features and the probability of an example having a label to reduce bias and prediction errors?","domain":"self.MachineLearning","num_comments":11,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":11,"approved_by":null,"score":9,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data-set with both labeled and unlabeled examples. Due to my knowledge of the domain I know that some of the examples features greatly affect whether an example is labeled or unlabeled, causing very biased label data and grave errors in prediction. How can I use this knowledge of the correlation between the features and the probability of an example having a label to reduce bias and prediction errors?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327667158,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/oz1go/probabilistic_classification_algorithm/","link_flair_css_class":null,"id":"oz1go","edited":true,"num_reports":null,"created_utc":1327666358,"banned_by":null,"name":"t3_oz1go","subreddit":"MachineLearning","title":"Probabilistic classification algorithm?","author_flair_text":null,"is_self":true,"author":"solen-skiner","media_embed":{},"permalink":"/r/MachineLearning/comments/oz1go/probabilistic_classification_algorithm/","author_flair_css_class":null,"selftext":"Say I have a dataset and their respective labels, which are discreet. However, examples with the same features often have different labels, while examples with different features can share label. What are some good algorithms to find the probability for every label given the input features?","domain":"self.MachineLearning","num_comments":12,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":3,"approved_by":null,"score":2,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I have a dataset and their respective labels, which are discreet. However, examples with the same features often have different labels, while examples with different features can share label. What are some good algorithms to find the probability for every label given the input features?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327666358,"hidden":false,"over_18":false}
{"downs":5,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/oykce/a_machine_learning_project_idea_for_mlreddit/","link_flair_css_class":null,"id":"oykce","edited":false,"num_reports":null,"created_utc":1327632350,"banned_by":null,"name":"t3_oykce","subreddit":"MachineLearning","title":"A Machine Learning project idea for ML-reddit,  RTFA-bot.","author_flair_text":null,"is_self":true,"author":"[deleted]","media_embed":{},"permalink":"/r/MachineLearning/comments/oykce/a_machine_learning_project_idea_for_mlreddit/","author_flair_css_class":null,"selftext":"All too often you click on a link, read the article, go to the comments and see questions that could be easily answered by just copying and pasting from the article.  Of course every once in a while some smart-ass (sometimes me) will do just that, but I'm thinking it might be possible to write a RTFA-bot (read-the-effing-article-bot) that can detect posts that can be answered from the article.  I personally don't have the time to work on this, but I feel like once or twice a month someone posts asking for project ideas... I thought this might be a good (albeit challenging) problem that some of you might want to work on. ","domain":"self.MachineLearning","num_comments":10,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":9,"approved_by":null,"score":4,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;All too often you click on a link, read the article, go to the comments and see questions that could be easily answered by just copying and pasting from the article.  Of course every once in a while some smart-ass (sometimes me) will do just that, but I&amp;#39;m thinking it might be possible to write a RTFA-bot (read-the-effing-article-bot) that can detect posts that can be answered from the article.  I personally don&amp;#39;t have the time to work on this, but I feel like once or twice a month someone posts asking for project ideas... I thought this might be a good (albeit challenging) problem that some of you might want to work on. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327632350,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.hydraulicnews.hidraulicapractica.com/news/case-updates-nseries-loaders-and-backhoes-site-prep","link_flair_css_class":null,"id":"oyfgb","edited":false,"num_reports":null,"created_utc":1327626207,"banned_by":null,"name":"t3_oyfgb","subreddit":"MachineLearning","title":"Case Updates N-Series Loaders and Backhoes - Site Prep | HYDRAULICS - News","author_flair_text":null,"is_self":false,"author":"kamilrhu","media_embed":{},"permalink":"/r/MachineLearning/comments/oyfgb/case_updates_nseries_loaders_and_backhoes_site/","author_flair_css_class":null,"selftext":"","domain":"hydraulicnews.hidraulicapractica.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1327626207,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://allendowney.blogspot.com/2012/01/think-complexity-part-two.html","link_flair_css_class":null,"id":"p0fr0","edited":false,"num_reports":null,"created_utc":1327754572,"banned_by":null,"name":"t3_p0fr0","subreddit":"MachineLearning","title":"The philosophy of complexity: part two of my book, Think Complexity [xpost from statistics]","author_flair_text":null,"is_self":false,"author":"AllenDowney","media_embed":{},"permalink":"/r/MachineLearning/comments/p0fr0/the_philosophy_of_complexity_part_two_of_my_book/","author_flair_css_class":null,"selftext":"","domain":"allendowney.blogspot.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"http://f.thumbs.redditmedia.com/UQc2NQVdDFvsoBiq.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":14,"approved_by":null,"score":10,"selftext_html":null,"created":1327754572,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/p237z/gist_at_high_level_and_precision_evaluations/","link_flair_css_class":null,"id":"p237z","edited":false,"num_reports":null,"created_utc":1327873990,"banned_by":null,"name":"t3_p237z","subreddit":"MachineLearning","title":"GIST at high level, and Precision evaluations","author_flair_text":null,"is_self":true,"author":"keije","media_embed":{},"permalink":"/r/MachineLearning/comments/p237z/gist_at_high_level_and_precision_evaluations/","author_flair_css_class":null,"selftext":"After finding out about GIST and reading an [excellent paper on its performance](http://lear.inrialpes.fr/pubs/2009/DJSAS09/gist_evaluation.pdf) I have a couple of questions:  \n\n1. Is there a higher level (as in, mathematical or pseudo-code) definition of GIST anywhere? While some papers' authors provide the code they've used, trying to decipher particular implementation is rather slow process (especially when it's not in a language I know). I've tried googling, but that's a slow going too, **G**astro-**I**nte**s**tinal **T**umors get in the way.\n\n2. That paper I've linked to, does a good job evaluating GIST performance for Recall (number of correct matches), but doesn't evaluate for Precision (number of false matches). To me Precision is of much higher importance. Since due to #1 I can't run my own experiments atm, I'm hoping there are papers that evaluate GIST for precision on similarly varied dataset as the paper above.","domain":"self.MachineLearning","num_comments":1,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":7,"approved_by":null,"score":6,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After finding out about GIST and reading an &lt;a href=\"http://lear.inrialpes.fr/pubs/2009/DJSAS09/gist_evaluation.pdf\"&gt;excellent paper on its performance&lt;/a&gt; I have a couple of questions:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Is there a higher level (as in, mathematical or pseudo-code) definition of GIST anywhere? While some papers&amp;#39; authors provide the code they&amp;#39;ve used, trying to decipher particular implementation is rather slow process (especially when it&amp;#39;s not in a language I know). I&amp;#39;ve tried googling, but that&amp;#39;s a slow going too, &lt;strong&gt;G&lt;/strong&gt;astro-&lt;strong&gt;I&lt;/strong&gt;nte&lt;strong&gt;s&lt;/strong&gt;tinal &lt;strong&gt;T&lt;/strong&gt;umors get in the way.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;That paper I&amp;#39;ve linked to, does a good job evaluating GIST performance for Recall (number of correct matches), but doesn&amp;#39;t evaluate for Precision (number of false matches). To me Precision is of much higher importance. Since due to #1 I can&amp;#39;t run my own experiments atm, I&amp;#39;m hoping there are papers that evaluate GIST for precision on similarly varied dataset as the paper above.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327873990,"hidden":false,"over_18":false}
{"downs":2,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://intelligent-artifacts.com/press-release/","link_flair_css_class":null,"id":"p1z6t","edited":false,"num_reports":null,"created_utc":1327866025,"banned_by":null,"name":"t3_p1z6t","subreddit":"MachineLearning","title":"National Science Foundation said it was coming in the '90s, here it is: machine reads echo cardiogram project 30 minutes start to finish...","author_flair_text":null,"is_self":false,"author":"SeanHallahan","media_embed":{},"permalink":"/r/MachineLearning/comments/p1z6t/national_science_foundation_said_it_was_coming_in/","author_flair_css_class":null,"selftext":"","domain":"intelligent-artifacts.com","num_comments":1,"likes":null,"clicked":false,"thumbnail":"http://c.thumbs.redditmedia.com/6_BMwHN4hXTVvoq2.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":14,"approved_by":null,"score":12,"selftext_html":null,"created":1327866025,"hidden":false,"over_18":false}
{"downs":7,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.quantisan.com/ask-not-what-accuracy-your-algorithm-achieves-but-what-value-it-can-add/","link_flair_css_class":null,"id":"p1n14","edited":false,"num_reports":null,"created_utc":1327841153,"banned_by":null,"name":"t3_p1n14","subreddit":"MachineLearning","title":"Ask not what accuracy your algorithm achieves but what value it can add","author_flair_text":null,"is_self":false,"author":"piikac","media_embed":{},"permalink":"/r/MachineLearning/comments/p1n14/ask_not_what_accuracy_your_algorithm_achieves_but/","author_flair_css_class":null,"selftext":"","domain":"quantisan.com","num_comments":1,"likes":null,"clicked":false,"thumbnail":"http://a.thumbs.redditmedia.com/uHPxupclWPp4fN60.jpg","saved":false,"subreddit_id":"t5_2r3gv","ups":16,"approved_by":null,"score":9,"selftext_html":null,"created":1327841153,"hidden":false,"over_18":false}
{"downs":1,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/p1bl6/what_is_the_state_of_the_art_in_finding_features/","link_flair_css_class":null,"id":"p1bl6","edited":false,"num_reports":null,"created_utc":1327809565,"banned_by":null,"name":"t3_p1bl6","subreddit":"MachineLearning","title":"what is the State of the art in finding 'features' in images","author_flair_text":null,"is_self":true,"author":"qwsazxerfdcv","media_embed":{},"permalink":"/r/MachineLearning/comments/p1bl6/what_is_the_state_of_the_art_in_finding_features/","author_flair_css_class":null,"selftext":"i was going through the Computer vision and pattern recognition, conference  papers  over the last few years , and was wondering what is the state of the art in finding 'dense' features in an image which may then be used to do image based content retrieval. ","domain":"self.MachineLearning","num_comments":17,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":15,"approved_by":null,"score":14,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i was going through the Computer vision and pattern recognition, conference  papers  over the last few years , and was wondering what is the state of the art in finding &amp;#39;dense&amp;#39; features in an image which may then be used to do image based content retrieval. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327809565,"hidden":false,"over_18":false}
{"downs":4,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/p14yx/what_methods_are_there_for_selecting_an/","link_flair_css_class":null,"id":"p14yx","edited":true,"num_reports":null,"created_utc":1327799036,"banned_by":null,"name":"t3_p14yx","subreddit":"MachineLearning","title":"What methods are there for selecting an \"appropriate\" cutoff height in a dendrogram when performing hierarchical clustering on sample data points to partition a hyperspace into subspaces?","author_flair_text":null,"is_self":true,"author":"hyppo","media_embed":{},"permalink":"/r/MachineLearning/comments/p14yx/what_methods_are_there_for_selecting_an/","author_flair_css_class":null,"selftext":"Little bit of background: \n\nI'm looking at using the [CHAMELEON](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.44.5847) hierarchical clustering algorithm to create a [dendrogram](http://en.wikipedia.org/wiki/Dendrogram) of sample data points generated by a procedure that imitates an arbitrary problem space.  I'm looking for a way to choose an \"appropriate\" height in the dendrogram in order to partition the problem space in an \"intuitive way.\"  Does anyone know of an algorithm for doing this?  I've searched, but either such an algorithm doesn't exist (which I highly doubt) or I'm choosing the wrong words in my searches.  If it makes any difference, the clusters will probably end up being hyper-ellipsoidal. \n\n**EDIT:** Also, I forgot to mention that these are unlabeled/uncategorized data points, so I cannot compare the clustering with any ground truth","domain":"self.MachineLearning","num_comments":15,"likes":null,"clicked":false,"thumbnail":"self","saved":false,"subreddit_id":"t5_2r3gv","ups":9,"approved_by":null,"score":5,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Little bit of background: &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at using the &lt;a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.44.5847\"&gt;CHAMELEON&lt;/a&gt; hierarchical clustering algorithm to create a &lt;a href=\"http://en.wikipedia.org/wiki/Dendrogram\"&gt;dendrogram&lt;/a&gt; of sample data points generated by a procedure that imitates an arbitrary problem space.  I&amp;#39;m looking for a way to choose an &amp;quot;appropriate&amp;quot; height in the dendrogram in order to partition the problem space in an &amp;quot;intuitive way.&amp;quot;  Does anyone know of an algorithm for doing this?  I&amp;#39;ve searched, but either such an algorithm doesn&amp;#39;t exist (which I highly doubt) or I&amp;#39;m choosing the wrong words in my searches.  If it makes any difference, the clusters will probably end up being hyper-ellipsoidal. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; Also, I forgot to mention that these are unlabeled/uncategorized data points, so I cannot compare the clustering with any ground truth&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","created":1327799036,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.hydraulicnews.hidraulicapractica.com/news/cat-introduces-three-k-series-small-wheel-loaders-site-prep","link_flair_css_class":null,"id":"p12uc","edited":false,"num_reports":null,"created_utc":1327795694,"banned_by":null,"name":"t3_p12uc","subreddit":"MachineLearning","title":"Cat Introduces Three K Series Small Wheel Loaders - Site Prep | HYDRAULICS - News","author_flair_text":null,"is_self":false,"author":"kamilrhu","media_embed":{},"permalink":"/r/MachineLearning/comments/p12uc/cat_introduces_three_k_series_small_wheel_loaders/","author_flair_css_class":null,"selftext":"","domain":"hydraulicnews.hidraulicapractica.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1327795694,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.r-bloggers.com/user-2012-earlybird-registration-for-international-r-users-conference-nashville-tn-12-15-2012/","link_flair_css_class":null,"id":"p36pf","edited":false,"num_reports":null,"created_utc":1327943579,"banned_by":null,"name":"t3_p36pf","subreddit":"MachineLearning","title":"useR! 2012: Earlybird Registration","author_flair_text":null,"is_self":false,"author":"talgalili","media_embed":{},"permalink":"/r/MachineLearning/comments/p36pf/user_2012_earlybird_registration/","author_flair_css_class":null,"selftext":"","domain":"r-bloggers.com","num_comments":0,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1327943579,"hidden":false,"over_18":false}
{"downs":0,"link_flair_text":null,"distinguished":null,"media":null,"url":"http://www.cashewpeelingmachinemanufacturer.com/","link_flair_css_class":null,"id":"p4jtt","edited":false,"num_reports":null,"created_utc":1328019777,"banned_by":null,"name":"t3_p4jtt","subreddit":"MachineLearning","title":"Shree Isaradevi Machinery","author_flair_text":null,"is_self":false,"author":"bhaveshgajjar1414","media_embed":{},"permalink":"/r/MachineLearning/comments/p4jtt/shree_isaradevi_machinery/","author_flair_css_class":null,"selftext":"","domain":"cashewpeelingmachinemanufacturer.com","num_comments":1,"likes":null,"clicked":false,"thumbnail":"default","saved":false,"subreddit_id":"t5_2r3gv","ups":1,"approved_by":null,"score":1,"selftext_html":null,"created":1328019777,"hidden":false,"over_18":false}
