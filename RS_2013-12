{"edited":false,"downs":0,"report_reasons":null,"distinguished":null,"thumbnail":"http://d.thumbs.redditmedia.com/Y9bThsIycCOu2fTu.jpg","selftext_html":null,"mod_reports":[],"retrieved_on":1411527450,"domain":"engineering.stanford.edu","score":5,"permalink":"/r/MachineLearning/comments/1rvbd7/stanford_algorithm_analyzes_sentence_sentiment/","over_18":false,"num_comments":5,"user_reports":[],"id":"1rvbd7","gilded":0,"media_embed":{},"secure_media_embed":{},"subreddit":"MachineLearning","stickied":false,"title":"Stanford algorithm analyzes sentence sentiment","author":"hrb1979","subreddit_id":"t5_2r3gv","url":"http://engineering.stanford.edu/news/stanford-algorithm-analyzes-sentence-sentiment-advances-machine-learning?utm_source=buffer&amp;utm_campaign=Buffer&amp;utm_content=buffer6276d&amp;utm_medium=twitter#!","secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"ups":5,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1385940187,"selftext":""}
{"permalink":"/r/MachineLearning/comments/1rv45o/what_is_a_reproducing_kernel_hilbert_space/","score":18,"domain":"self.MachineLearning","secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":4,"user_reports":[],"id":"1rv45o","over_18":false,"thumbnail":"self","distinguished":null,"report_reasons":null,"downs":0,"edited":false,"retrieved_on":1411527769,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could someone explain this and the underlying concepts simply, please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":18,"created_utc":1385935051,"selftext":"Could someone explain this and the underlying concepts simply, please?","is_self":true,"url":"http://www.reddit.com/r/MachineLearning/comments/1rv45o/what_is_a_reproducing_kernel_hilbert_space/","title":"What is a reproducing kernel Hilbert space?","subreddit_id":"t5_2r3gv","author":"jamesmcm","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null}
{"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"title":"Probabilistic Systems Analysis and Applied Probability (MIT 6.041) [Playlist]","author":"jry_AIHub","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1ruz05/probabilistic_systems_analysis_and_applied/","stickied":false,"subreddit":"MachineLearning","created_utc":1385931411,"selftext":"\"Welcome to the MIT Course 6.041/6.431 [Full Playlist], a subject on the modeling and analysis of random phenomena and processes, including the basics of statistical inference. Nowadays, there is broad consensus that the ability to think probabilistically is a fundamental component of scientific literacy.\"","is_self":true,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":12,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Welcome to the MIT Course 6.041/6.431 [Full Playlist], a subject on the modeling and analysis of random phenomena and processes, including the basics of statistical inference. Nowadays, there is broad consensus that the ability to think probabilistically is a fundamental component of scientific literacy.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411528015,"thumbnail":"self","edited":false,"distinguished":null,"report_reasons":null,"downs":0,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":3,"user_reports":[],"id":"1ruz05","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1ruz05/probabilistic_systems_analysis_and_applied/","score":12}
{"stickied":false,"subreddit":"MachineLearning","title":"Free Newsletter: Data Science Weekly Newsletter (Issue 1)","subreddit_id":"t5_2r3gv","author":"seabass","url":"http://www.datascienceweekly.org/newsletters/data-science-weekly-newsletter-issue-1","secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"author_flair_css_class":null,"ups":4,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1385929385,"selftext":"","edited":false,"distinguished":null,"report_reasons":null,"downs":0,"thumbnail":"http://b.thumbs.redditmedia.com/kWn-Pd1Dk5Hjp9Nm.jpg","selftext_html":null,"mod_reports":[],"retrieved_on":1411528128,"domain":"datascienceweekly.org","permalink":"/r/MachineLearning/comments/1ruw2f/free_newsletter_data_science_weekly_newsletter/","score":4,"over_18":false,"num_comments":1,"id":"1ruw2f","user_reports":[],"media_embed":{},"gilded":0,"secure_media_embed":{}}
{"retrieved_on":1411528234,"mod_reports":[],"selftext_html":null,"thumbnail":"self","distinguished":null,"report_reasons":null,"downs":0,"edited":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":11,"id":"1ruti0","user_reports":[],"over_18":false,"permalink":"/r/MachineLearning/comments/1ruti0/why_has_deep_learning_suddenly_become_so_popular/","score":19,"domain":"self.MachineLearning","banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1ruti0/why_has_deep_learning_suddenly_become_so_popular/","title":"Why has deep learning suddenly become so popular? Any recent breakthroughs?","author":"HerrKanin","subreddit_id":"t5_2r3gv","stickied":false,"subreddit":"MachineLearning","created_utc":1385927491,"selftext":"","is_self":true,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":19}
{"is_self":true,"selftext":"I came across this Stanford paper from NIPS 2013 proceddings on Signal Processing on Graphs [0]. In the references, a tutorial paper was mentioned here [1]. Now I know that there is a course being offered at USC this Fall on Signal Processing of Graphs and from the looks of it seems pretty basic and probably a great startting point [2]. If you are at USC, can you please see if you can get the lectures up? Or if you know there are any lectures, code examples out there, I will be hugely grateful.\n\n\n\n[0] http://xxx.tau.ac.il/abs/1307.0468?context=cs\n\n\n\n[1] http://nips.cc/Conferences/2013/Program/event.php?ID=3846\n\n\n\n[2] http://biron.usc.edu/wiki/index.php/EE599\n\n\n\nEdit: spellings.","created_utc":1385918518,"author_flair_css_class":null,"ups":5,"media":null,"link_flair_css_class":null,"link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","url":"http://www.reddit.com/r/MachineLearning/comments/1ruhor/signal_processing_on_graphs_lectures_code_examples/","subreddit_id":"t5_2r3gv","title":"Signal Processing on Graphs, lectures, code, examples?","author":"Intern_MSFT","num_comments":5,"user_reports":[],"id":"1ruhor","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1ruhor/signal_processing_on_graphs_lectures_code_examples/","score":5,"domain":"self.MachineLearning","retrieved_on":1411528701,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across this Stanford paper from NIPS 2013 proceddings on Signal Processing on Graphs [0]. In the references, a tutorial paper was mentioned here [1]. Now I know that there is a course being offered at USC this Fall on Signal Processing of Graphs and from the looks of it seems pretty basic and probably a great startting point [2]. If you are at USC, can you please see if you can get the lectures up? Or if you know there are any lectures, code examples out there, I will be hugely grateful.&lt;/p&gt;\n\n&lt;p&gt;[0] &lt;a href=\"http://xxx.tau.ac.il/abs/1307.0468?context=cs\"&gt;http://xxx.tau.ac.il/abs/1307.0468?context=cs&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;[1] &lt;a href=\"http://nips.cc/Conferences/2013/Program/event.php?ID=3846\"&gt;http://nips.cc/Conferences/2013/Program/event.php?ID=3846&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;[2] &lt;a href=\"http://biron.usc.edu/wiki/index.php/EE599\"&gt;http://biron.usc.edu/wiki/index.php/EE599&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit: spellings.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"report_reasons":null,"downs":0,"edited":1385923006,"thumbnail":"self"}
{"ups":16,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"is_self":true,"created_utc":1385911388,"selftext":"Hello,\n\nI'm taking Andrew Ng's Coursera course and feel like I'm understanding the material well. We've just finished classifying images of hand-written digits using a single hidden layer neural network. I wanted to try applying this workflow to another image identification problem, then realized:\n\n1. I don't know what to do if the images of interest have different numbers of pixels. Must I crop or rescale into the size used for training? Or is there a way I can feed a variable number of inputs into an NN?\n\n2. Are there good image datasets available to practice image classification problems?\n\nThanks!","subreddit":"MachineLearning","stickied":false,"subreddit_id":"t5_2r3gv","title":"Noob neural network question--variable number of features?","author":"forever_erratic","url":"http://www.reddit.com/r/MachineLearning/comments/1rua3p/noob_neural_network_questionvariable_number_of/","secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"domain":"self.MachineLearning","score":16,"permalink":"/r/MachineLearning/comments/1rua3p/noob_neural_network_questionvariable_number_of/","over_18":false,"id":"1rua3p","num_comments":22,"user_reports":[],"gilded":0,"media_embed":{},"secure_media_embed":{},"edited":false,"downs":0,"report_reasons":null,"distinguished":null,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m taking Andrew Ng&amp;#39;s Coursera course and feel like I&amp;#39;m understanding the material well. We&amp;#39;ve just finished classifying images of hand-written digits using a single hidden layer neural network. I wanted to try applying this workflow to another image identification problem, then realized:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I don&amp;#39;t know what to do if the images of interest have different numbers of pixels. Must I crop or rescale into the size used for training? Or is there a way I can feed a variable number of inputs into an NN?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Are there good image datasets available to practice image classification problems?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411529007}
{"retrieved_on":1411530167,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Quick review before I go and grab some AYCE sushi with my babe. And I apologize I have not been reviewing as I once was, I was dealing with some things IRL. Note: even though I complain and have opposing views with some in this subreddit, I still love you all, and a- happy holidays to all as well.&lt;/p&gt;\n\n&lt;p&gt;Link to paper: [Analysis of Single-Layered Unsupervised Networks], A. Coates, A. Ng, H. Lee, Stanford University &amp;amp; UMichigan. (&lt;a href=\"http://www.google.ca/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;cad=rja&amp;amp;ved=0CDMQFjAA&amp;amp;url=http%3A%2F%2Fweb.eecs.umich.edu%2F%7Ehonglak%2Fnipsdlufl10-AnalysisSingleLayerUnsupervisedFeatureLearning.pdf&amp;amp;ei=Gr2aUvu9CJDXoASPoYGwDw&amp;amp;usg=AFQjCNH4eLwXs6RD_dfgXZIM3ydM9_Vsjg&amp;amp;sig2=fss3O7Gib68rqEAAK28OHg&amp;amp;bvm=bv.57155469,d.cGU\"&gt;http://www.google.ca/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;cad=rja&amp;amp;ved=0CDMQFjAA&amp;amp;url=http%3A%2F%2Fweb.eecs.umich.edu%2F~honglak%2Fnipsdlufl10-AnalysisSingleLayerUnsupervisedFeatureLearning.pdf&amp;amp;ei=Gr2aUvu9CJDXoASPoYGwDw&amp;amp;usg=AFQjCNH4eLwXs6RD_dfgXZIM3ydM9_Vsjg&amp;amp;sig2=fss3O7Gib68rqEAAK28OHg&amp;amp;bvm=bv.57155469,d.cGU&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:\nA great deal of research has focused on al-\ngorithms for learning features from unla-\nbeled data. Indeed, much progress has been\nmade on benchmark datasets like NORB and\nCIFAR by employing increasingly complex\nunsupervised learning algorithms and deep\nmodels. In this paper, however, we show that\nseveral simple factors, such as the number of\nhidden nodes in the model, may be more im-\nportant to achieving high performance than\nthe learning algorithm or the depth of the\nmodel. Specifically, we will apply several off-\nthe-shelf feature learning algorithms (sparse\nauto-encoders, sparse RBMs, K-means clus-\ntering, and Gaussian mixtures) to CIFAR,\nNORB, and STL datasets using only single-\nlayer networks. We then present a detailed\nanalysis of the effect of changes in the model\nsetup: the receptive field size, number of hid-\nden nodes (features), the step-size (“stride”)\nbetween extracted features, and the effect\nof whitening. Our results show that large\nnumbers of hidden nodes and dense fea-\nture extraction are critical to achieving high\nperformance—so critical, in fact, that when\nthese parameters are pushed to their limits,\nwe achieve state-of-the-art performance on\nboth CIFAR-10 and NORB using only a sin-\ngle layer of features. More surprisingly, our\nbest performance is based on K-means clus-\ntering, which is extremely fast, has no hyper-\nparameters to tune beyond the model struc-\nture itself, and is very easy to implement. De-\nspite the simplicity of our system, we achieve\naccuracy beyond all previously published re-\nsults on the CIFAR-10 and NORB datasets\n(79.6% and 97.2% respectively).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"report_reasons":null,"distinguished":null,"downs":0,"edited":false,"thumbnail":"self","num_comments":8,"user_reports":[],"id":"1rti7t","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1rti7t/a_notsodaily_paper_review_an_analysis_of/","score":5,"domain":"self.MachineLearning","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"stickied":false,"subreddit":"MachineLearning","url":"http://www.reddit.com/r/MachineLearning/comments/1rti7t/a_notsodaily_paper_review_an_analysis_of/","subreddit_id":"t5_2r3gv","title":"A Not-So-Daily Paper Review: An Analysis of Single-Layer Networks in Unsupervised Feature Learning","author":"Badoosker","is_self":true,"created_utc":1385872806,"selftext":"Quick review before I go and grab some AYCE sushi with my babe. And I apologize I have not been reviewing as I once was, I was dealing with some things IRL. Note: even though I complain and have opposing views with some in this subreddit, I still love you all, and a- happy holidays to all as well.\n\nLink to paper: [Analysis of Single-Layered Unsupervised Networks], A. Coates, A. Ng, H. Lee, Stanford University &amp; UMichigan. (http://www.google.ca/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CDMQFjAA&amp;url=http%3A%2F%2Fweb.eecs.umich.edu%2F~honglak%2Fnipsdlufl10-AnalysisSingleLayerUnsupervisedFeatureLearning.pdf&amp;ei=Gr2aUvu9CJDXoASPoYGwDw&amp;usg=AFQjCNH4eLwXs6RD_dfgXZIM3ydM9_Vsjg&amp;sig2=fss3O7Gib68rqEAAK28OHg&amp;bvm=bv.57155469,d.cGU)\n\n\n\n**Abstract**:\nA great deal of research has focused on al-\ngorithms for learning features from unla-\nbeled data. Indeed, much progress has been\nmade on benchmark datasets like NORB and\nCIFAR by employing increasingly complex\nunsupervised learning algorithms and deep\nmodels. In this paper, however, we show that\nseveral simple factors, such as the number of\nhidden nodes in the model, may be more im-\nportant to achieving high performance than\nthe learning algorithm or the depth of the\nmodel. Specifically, we will apply several off-\nthe-shelf feature learning algorithms (sparse\nauto-encoders, sparse RBMs, K-means clus-\ntering, and Gaussian mixtures) to CIFAR,\nNORB, and STL datasets using only single-\nlayer networks. We then present a detailed\nanalysis of the effect of changes in the model\nsetup: the receptive field size, number of hid-\nden nodes (features), the step-size (“stride”)\nbetween extracted features, and the effect\nof whitening. Our results show that large\nnumbers of hidden nodes and dense fea-\nture extraction are critical to achieving high\nperformance—so critical, in fact, that when\nthese parameters are pushed to their limits,\nwe achieve state-of-the-art performance on\nboth CIFAR-10 and NORB using only a sin-\ngle layer of features. More surprisingly, our\nbest performance is based on K-means clus-\ntering, which is extremely fast, has no hyper-\nparameters to tune beyond the model struc-\nture itself, and is very easy to implement. De-\nspite the simplicity of our system, we achieve\naccuracy beyond all previously published re-\nsults on the CIFAR-10 and NORB datasets\n(79.6% and 97.2% respectively).","author_flair_css_class":null,"ups":5,"link_flair_css_class":null,"media":null}
{"subreddit":"MachineLearning","stickied":false,"title":"Can anyone recommend a simple-to-implement supervised learning algorithm that can handle sparse inputs?","author":"sanity","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1rtg6j/can_anyone_recommend_a_simpletoimplement/","secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"ups":1,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"is_self":true,"created_utc":1385871119,"selftext":"","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"thumbnail":"self","mod_reports":[],"selftext_html":null,"retrieved_on":1411530256,"domain":"self.MachineLearning","score":1,"permalink":"/r/MachineLearning/comments/1rtg6j/can_anyone_recommend_a_simpletoimplement/","over_18":false,"num_comments":9,"user_reports":[],"id":"1rtg6j","gilded":0,"media_embed":{},"secure_media_embed":{}}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I am doing a machine learning project, in which, the low false positive rate is a higher priority than the overall accuracy.Right now I am looking for several baseline algorithms to compare with. But most algorithms I found don&amp;#39;t have an software package, like Asymmetric SVM. &lt;/p&gt;\n\n&lt;p&gt;So my question is: is it possible to incorporate asymmetric cost into existing algorithms without changing the actual code? Or if I need to implement myself, are there any algorithm that is easier to extend?&lt;/p&gt;\n\n&lt;p&gt;Thanks~&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411530658,"thumbnail":"self","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":1,"user_reports":[],"id":"1rt5ye","domain":"self.MachineLearning","score":2,"permalink":"/r/MachineLearning/comments/1rt5ye/suggestions_for_effective_algorithms_with/","author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"title":"Suggestions for effective algorithms with asymmetric cost function","subreddit_id":"t5_2r3gv","author":"mimighost","url":"http://www.reddit.com/r/MachineLearning/comments/1rt5ye/suggestions_for_effective_algorithms_with/","subreddit":"MachineLearning","stickied":false,"selftext":"Hi everyone. I am doing a machine learning project, in which, the low false positive rate is a higher priority than the overall accuracy.Right now I am looking for several baseline algorithms to compare with. But most algorithms I found don't have an software package, like Asymmetric SVM. \n\nSo my question is: is it possible to incorporate asymmetric cost into existing algorithms without changing the actual code? Or if I need to implement myself, are there any algorithm that is easier to extend?\n\nThanks~","created_utc":1385862610,"is_self":true,"media":null,"link_flair_css_class":null,"ups":2,"author_flair_css_class":null}
{"url":"http://making.nextbigsound.com/post/68287169332/predicting-next-years-breakout-artists","author":"seabass","title":"Predicting Next Year’s Breakout Music Artists","subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","stickied":false,"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"link_flair_css_class":null,"media":null,"ups":22,"author_flair_css_class":null,"selftext":"","created_utc":1386021095,"is_self":false,"thumbnail":"http://a.thumbs.redditmedia.com/vnlySdsoBZlKwX_N.jpg","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"retrieved_on":1411523555,"selftext_html":null,"mod_reports":[],"score":22,"permalink":"/r/MachineLearning/comments/1rxx6y/predicting_next_years_breakout_music_artists/","domain":"making.nextbigsound.com","secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":5,"user_reports":[],"id":"1rxx6y","over_18":false}
{"thumbnail":"http://b.thumbs.redditmedia.com/-mC7jbkx84HaWn4C.jpg","downs":0,"distinguished":null,"report_reasons":null,"edited":false,"retrieved_on":1411524090,"selftext_html":null,"mod_reports":[],"score":0,"permalink":"/r/MachineLearning/comments/1rxkix/a_cheat_sheet_on_when_to_use_different_machine/","domain":"nosql.mypopescu.com","secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":2,"user_reports":[],"id":"1rxkix","over_18":false,"url":"http://nosql.mypopescu.com/post/47702091425/machine-learning-cheatsheets","subreddit_id":"t5_2r3gv","title":"A Cheat Sheet on When to Use Different Machine Learning Algorithms","author":"KeponeFactory","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"media":null,"link_flair_css_class":null,"ups":0,"author_flair_css_class":null,"created_utc":1386013567,"selftext":"","is_self":false}
{"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"subreddit_id":"t5_2r3gv","title":"Good notes on the derivation of the Gaussian Process Latent Variable Model (GPLVM) - website also good notes on Bayes Nets, etc.","author":"jamesmcm","url":"http://wikicoursenote.com/wiki/Probabilistic_PCA_with_GPLVM","subreddit":"MachineLearning","stickied":false,"created_utc":1385994308,"selftext":"","is_self":false,"link_flair_css_class":null,"media":null,"ups":14,"author_flair_css_class":null,"mod_reports":[],"selftext_html":null,"retrieved_on":1411525169,"thumbnail":"http://e.thumbs.redditmedia.com/nWWwBGZdPssLuLX4.jpg","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":0,"id":"1rwtts","user_reports":[],"domain":"wikicoursenote.com","score":14,"permalink":"/r/MachineLearning/comments/1rwtts/good_notes_on_the_derivation_of_the_gaussian/"}
{"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"self","retrieved_on":1411525607,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There seems to be a strong trend amongst this group towards Python or R for data mining, and far less discussion of Weka and Java.&lt;/p&gt;\n\n&lt;p&gt;For example a recent post: &lt;a href=\"http://www.reddit.com/r/MachineLearning/comments/1rg8o4/r_vs_python/\"&gt;http://www.reddit.com/r/MachineLearning/comments/1rg8o4/r_vs_python/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Could anyone give insights into why they don&amp;#39;t use Weka/Java? \nWouldn&amp;#39;t Weka benefit from the typical speed advantage of Java other Python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"permalink":"/r/MachineLearning/comments/1rwj8p/why_are_python_r_so_much_more_popular_here_than/","score":40,"domain":"self.MachineLearning","num_comments":63,"user_reports":[],"id":"1rwj8p","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"stickied":false,"subreddit":"MachineLearning","url":"http://www.reddit.com/r/MachineLearning/comments/1rwj8p/why_are_python_r_so_much_more_popular_here_than/","author":"Boomdabower","title":"Why are Python &amp; R so much more popular here than Weka/Java?","subreddit_id":"t5_2r3gv","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"author_flair_css_class":null,"ups":40,"link_flair_css_class":null,"media":null,"is_self":true,"created_utc":1385978907,"selftext":"There seems to be a strong trend amongst this group towards Python or R for data mining, and far less discussion of Weka and Java.\n\nFor example a recent post: http://www.reddit.com/r/MachineLearning/comments/1rg8o4/r_vs_python/\n\nCould anyone give insights into why they don't use Weka/Java? \nWouldn't Weka benefit from the typical speed advantage of Java other Python?"}
{"subreddit":"MachineLearning","stickied":false,"subreddit_id":"t5_2r3gv","title":"What is a dual formulation/problem?","author":"jamesmcm","url":"http://www.reddit.com/r/MachineLearning/comments/1rwijy/what_is_a_dual_formulationproblem/","secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"ups":9,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"is_self":true,"created_utc":1385977818,"selftext":"From what I gather, this is something like solving a simpler formulation in order to obtain a lower bound on the actual problem?\n\nThough I don't understand how it then differs from just solving a relaxed problem?","edited":false,"downs":0,"report_reasons":null,"distinguished":null,"thumbnail":"self","mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From what I gather, this is something like solving a simpler formulation in order to obtain a lower bound on the actual problem?&lt;/p&gt;\n\n&lt;p&gt;Though I don&amp;#39;t understand how it then differs from just solving a relaxed problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411525636,"domain":"self.MachineLearning","score":9,"permalink":"/r/MachineLearning/comments/1rwijy/what_is_a_dual_formulationproblem/","over_18":false,"num_comments":4,"user_reports":[],"id":"1rwijy","gilded":0,"media_embed":{},"secure_media_embed":{}}
{"retrieved_on":1411525797,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a hobbyist with an interest in bioinformatics, and I&amp;#39;ve been trying to come up with a modification to a classical Dynamic Programming algorithm to predict RNA secondary structure. In the algorithm you&amp;#39;re given a string of symbols, and in the DP step you fill out an N&lt;sup&gt;2&lt;/sup&gt; table of symbol pairings (so Aij is the table entry for the evaluation of symbols i and j). The evaluation is strictly concerned with whether the symbols are compatible, so the score is 1 if they are and 0 if they aren&amp;#39;t.  &lt;/p&gt;\n\n&lt;p&gt;This compatibility only takes into account the identities of the individual symbol pairings, which is unrealistic. I&amp;#39;d like it to depend on the neighbors of the symbols as well, and I have access to a corpus of training data (RNA sequences with ground truth structures) where I could learn this information. But I&amp;#39;m not sure how to use this information in a good scoring function. &lt;/p&gt;\n\n&lt;p&gt;So my question is, I can estimate the conditional probability of each pairing given the neighboring symbols from data, but is that a sensible measure of compatibility? Any resources with regards to how to use probabilities in these types of problems would be very much appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"report_reasons":null,"distinguished":null,"downs":0,"edited":false,"thumbnail":"self","num_comments":5,"id":"1rwepr","user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1rwepr/noob_question_is_there_a_standardstraightforward/","score":6,"domain":"self.MachineLearning","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","url":"http://www.reddit.com/r/MachineLearning/comments/1rwepr/noob_question_is_there_a_standardstraightforward/","subreddit_id":"t5_2r3gv","title":"Noob question: Is there a standard/straightforward way of devising a score function which takes into account the likelihood/joint probability of its arguments?","author":"thrownintothesun","is_self":true,"created_utc":1385971887,"selftext":"I'm a hobbyist with an interest in bioinformatics, and I've been trying to come up with a modification to a classical Dynamic Programming algorithm to predict RNA secondary structure. In the algorithm you're given a string of symbols, and in the DP step you fill out an N^2 table of symbol pairings (so Aij is the table entry for the evaluation of symbols i and j). The evaluation is strictly concerned with whether the symbols are compatible, so the score is 1 if they are and 0 if they aren't.  \n \nThis compatibility only takes into account the identities of the individual symbol pairings, which is unrealistic. I'd like it to depend on the neighbors of the symbols as well, and I have access to a corpus of training data (RNA sequences with ground truth structures) where I could learn this information. But I'm not sure how to use this information in a good scoring function. \n \nSo my question is, I can estimate the conditional probability of each pairing given the neighboring symbols from data, but is that a sensible measure of compatibility? Any resources with regards to how to use probabilities in these types of problems would be very much appreciated. \n \nThanks a lot! ","author_flair_css_class":null,"ups":6,"media":null,"link_flair_css_class":null}
{"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"http://e.thumbs.redditmedia.com/2Ptq1KA9XwrxZ-sd.jpg","retrieved_on":1411526597,"mod_reports":[],"selftext_html":null,"score":6,"permalink":"/r/MachineLearning/comments/1rvvt4/machine_learning_for_relevance_and_serendipity_on/","domain":"vimeo.com","num_comments":2,"id":"1rvvt4","user_reports":[],"over_18":false,"secure_media_embed":{"content":"&lt;iframe src=\"https://player.vimeo.com/video/80151339\" width=\"600\" height=\"339\" frameborder=\"0\" title=\"Machine Learning for Relevance and Serendipity\" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;","height":339,"width":600,"scrolling":false},"gilded":0,"media_embed":{"scrolling":false,"content":"&lt;iframe src=\"http://player.vimeo.com/video/80151339\" width=\"600\" height=\"339\" frameborder=\"0\" title=\"Machine Learning for Relevance and Serendipity\" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;","height":339,"width":600},"subreddit":"MachineLearning","stickied":false,"url":"http://vimeo.com/80151339","subreddit_id":"t5_2r3gv","title":"Machine Learning for Relevance and Serendipity on Vimeo","author":"rrenaud","link_flair_text":null,"secure_media":{"oembed":{"provider_name":"Vimeo","thumbnail_width":640,"title":"Machine Learning for Relevance and Serendipity","html":"&lt;iframe src=\"https://player.vimeo.com/video/80151339\" width=\"600\" height=\"339\" frameborder=\"0\" title=\"Machine Learning for Relevance and Serendipity\" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;","thumbnail_url":"https://i.embed.ly/1/image?url=http%3A%2F%2Fb.vimeocdn.com%2Fts%2F456%2F011%2F456011193_640.jpg&amp;key=b1e305db91cf4aa5a86b732cc9fffceb","provider_url":"https://vimeo.com/","author_name":"SF Bay Area Machine Learning","type":"video","description":"Main talk November 12, 2013 Speaker: Aria Haghighi (Prismatic) http://www.aria42.com/ http://getprismatic.com/landing Host and video recording: Yelp http://www.yelp.com/ Abstract: Careful use of well-designed machine learning systems can transform products by providing highly personalized user experiences. Unlike hand-tuned or heuristic-based personalization systems, machine learning allows for the use of millions of different potential indicators when making a decision, and is robust to many types of noise.","height":339,"version":"1.0","width":600,"author_url":"http://vimeo.com/sfmachinelearning","thumbnail_height":362},"type":"vimeo.com"},"author_flair_text":null,"banned_by":null,"ups":6,"author_flair_css_class":null,"media":{"type":"vimeo.com","oembed":{"thumbnail_width":640,"provider_name":"Vimeo","html":"&lt;iframe src=\"http://player.vimeo.com/video/80151339\" width=\"600\" height=\"339\" frameborder=\"0\" title=\"Machine Learning for Relevance and Serendipity\" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;","title":"Machine Learning for Relevance and Serendipity","description":"Main talk November 12, 2013 Speaker: Aria Haghighi (Prismatic) http://www.aria42.com/ http://getprismatic.com/landing Host and video recording: Yelp http://www.yelp.com/ Abstract: Careful use of well-designed machine learning systems can transform products by providing highly personalized user experiences. Unlike hand-tuned or heuristic-based personalization systems, machine learning allows for the use of millions of different potential indicators when making a decision, and is robust to many types of noise.","type":"video","author_name":"SF Bay Area Machine Learning","thumbnail_url":"http://b.vimeocdn.com/ts/456/011/456011193_640.jpg","provider_url":"https://vimeo.com/","thumbnail_height":362,"author_url":"http://vimeo.com/sfmachinelearning","width":600,"height":339,"version":"1.0"}},"link_flair_css_class":null,"is_self":false,"created_utc":1385954834,"selftext":""}
{"retrieved_on":1411518260,"mod_reports":[],"selftext_html":null,"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"default","num_comments":2,"id":"1s16xh","user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1s16xh/five_stages_of_data_grief/","score":13,"domain":"theodi.org","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"stickied":false,"subreddit":"MachineLearning","url":"http://theodi.org/blog/five-stages-of-data-grief","author":"hrb1979","title":"Five Stages of Data Grief","subreddit_id":"t5_2r3gv","is_self":false,"created_utc":1386113615,"selftext":"","author_flair_css_class":null,"ups":13,"link_flair_css_class":null,"media":null}
{"selftext":"","created_utc":1386105075,"is_self":false,"link_flair_css_class":null,"media":null,"ups":43,"author_flair_css_class":null,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"subreddit_id":"t5_2r3gv","title":"Probabilistic Programming in Quantitative Finance","author":"glutamate","url":"http://blog.quantopian.com/probabilistic-programming-quant-finance/","subreddit":"MachineLearning","stickied":false,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":11,"user_reports":[],"id":"1s0t46","domain":"blog.quantopian.com","score":43,"permalink":"/r/MachineLearning/comments/1s0t46/probabilistic_programming_in_quantitative_finance/","mod_reports":[],"selftext_html":null,"retrieved_on":1411518865,"thumbnail":"http://f.thumbs.redditmedia.com/hyoBTbQKbgg0-O9S.jpg","edited":false,"downs":0,"report_reasons":null,"distinguished":null}
{"mod_reports":[],"selftext_html":null,"retrieved_on":1411520368,"edited":false,"downs":0,"report_reasons":null,"distinguished":null,"thumbnail":"default","over_18":false,"id":"1rzxid","num_comments":5,"user_reports":[],"gilded":0,"media_embed":{},"secure_media_embed":{},"domain":"cs.otago.ac.nz","score":13,"permalink":"/r/MachineLearning/comments/1rzxid/a_thorough_introduction_to_pca/","secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"subreddit":"MachineLearning","stickied":false,"title":"A thorough introduction to PCA","subreddit_id":"t5_2r3gv","author":"jamesmcm","url":"http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf","is_self":false,"created_utc":1386085118,"selftext":"","ups":13,"author_flair_css_class":null,"link_flair_css_class":null,"media":null}
{"media":null,"link_flair_css_class":null,"ups":1,"author_flair_css_class":null,"selftext":"In a project i've chosen recently there's a heavy use of neural networks is there any book thats less focused on math part and more focused on a general outline of the subject, so that i can get directly into the work.","created_utc":1386076503,"is_self":true,"title":"Introduction to Neural Networks with less intensity","author":"obsoletelearner","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1rzoar/introduction_to_neural_networks_with_less/","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"domain":"self.MachineLearning","score":1,"permalink":"/r/MachineLearning/comments/1rzoar/introduction_to_neural_networks_with_less/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":1,"user_reports":[],"id":"1rzoar","thumbnail":"self","edited":false,"downs":0,"report_reasons":null,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In a project i&amp;#39;ve chosen recently there&amp;#39;s a heavy use of neural networks is there any book thats less focused on math part and more focused on a general outline of the subject, so that i can get directly into the work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411520794}
{"link_flair_css_class":null,"media":null,"ups":1,"author_flair_css_class":null,"selftext":"Hello, I'm math major with fair amount of programming experience and I want get into ML/Data Science career. I'm doing a honors thesis next year and I'm looking for tentative topics, some of them are in Topological Data Analysis, Graph Theory, Optimization.\n\nThere is a chance I will apply for grad school (M.Sc.) in either applied math or computer science. So my question is:\n\nWhat topic(s) will help me to get a good grasp and foundation of ML/DS?\n\nI can't decide whether to do a broad topic (like optimization methods in ML or statistical learning theory) or niche like computing persistent homology.\n\nThank you very much.","created_utc":1386072039,"is_self":true,"title":"Suggestions for a math major honors thesis topic","author":"alzwke","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1rzl0z/suggestions_for_a_math_major_honors_thesis_topic/","subreddit":"MachineLearning","stickied":false,"author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"domain":"self.MachineLearning","score":1,"permalink":"/r/MachineLearning/comments/1rzl0z/suggestions_for_a_math_major_honors_thesis_topic/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"user_reports":[],"num_comments":4,"id":"1rzl0z","thumbnail":"self","edited":1386072315,"downs":0,"report_reasons":null,"distinguished":null,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m math major with fair amount of programming experience and I want get into ML/Data Science career. I&amp;#39;m doing a honors thesis next year and I&amp;#39;m looking for tentative topics, some of them are in Topological Data Analysis, Graph Theory, Optimization.&lt;/p&gt;\n\n&lt;p&gt;There is a chance I will apply for grad school (M.Sc.) in either applied math or computer science. So my question is:&lt;/p&gt;\n\n&lt;p&gt;What topic(s) will help me to get a good grasp and foundation of ML/DS?&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t decide whether to do a broad topic (like optimization methods in ML or statistical learning theory) or niche like computing persistent homology.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411520944}
{"domain":"self.MachineLearning","score":3,"permalink":"/r/MachineLearning/comments/1rzkut/custom_kernel_functions_for_svms/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":7,"id":"1rzkut","user_reports":[],"thumbnail":"self","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;ve been doing some researching on SVMs and I have to admit the idea behind it is fascinating. The fact that you can get an answer to the similarity of two objects in some infinite dimensional feature space without ever having to go there is really mind-blowing. However, not just the choice of a kernel function that is used but the entire rationale behind using kernel functions eludes me -- they&amp;#39;re like a magical component in SVMs.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t understand how kernel functions are discovered and why some are preferred. And of all the kernel functions that can exist, how does one go about proving rigorously that their own kernel function is the best kernel function to use for a specific data set.&lt;/p&gt;\n\n&lt;p&gt;Anyone care to explain or direct me to relevant literature? TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411520953,"link_flair_css_class":null,"media":null,"ups":3,"author_flair_css_class":null,"selftext":"So, I've been doing some researching on SVMs and I have to admit the idea behind it is fascinating. The fact that you can get an answer to the similarity of two objects in some infinite dimensional feature space without ever having to go there is really mind-blowing. However, not just the choice of a kernel function that is used but the entire rationale behind using kernel functions eludes me -- they're like a magical component in SVMs.\n\nI don't understand how kernel functions are discovered and why some are preferred. And of all the kernel functions that can exist, how does one go about proving rigorously that their own kernel function is the best kernel function to use for a specific data set.\n\nAnyone care to explain or direct me to relevant literature? TIA","created_utc":1386071784,"is_self":true,"title":"Custom kernel functions for SVMs?","subreddit_id":"t5_2r3gv","author":"suorm","url":"http://www.reddit.com/r/MachineLearning/comments/1rzkut/custom_kernel_functions_for_svms/","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null}
{"ups":0,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1386068289,"selftext":"","subreddit":"MachineLearning","stickied":false,"url":"https://github.com/nickoppen/eNNpi.git","subreddit_id":"t5_2r3gv","title":"A light weight library for 3 layer feed forward back propagation neural networks - C++ standard library","author":"nickoppen","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"score":0,"permalink":"/r/MachineLearning/comments/1rzigb/a_light_weight_library_for_3_layer_feed_forward/","domain":"github.com","num_comments":6,"id":"1rzigb","user_reports":[],"over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"http://e.thumbs.redditmedia.com/3uZxQqqmOYer9hAj.jpg","retrieved_on":1411521059,"selftext_html":null,"mod_reports":[]}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have been looking around at universities and professors shortlisting according to pros and cons that fits me etc. but main problem i face is the price of higher education being an international student in US/AUS is too much for my pockets. \nSo i am looking at alternatives like Aalto university and the universities in my country that offer masters in ML but what more can i do to secure a position at university like Aalto (i guess the same goes for every other university).\nAt the moment i am at ground zero you may say, i am doing andrew ng&amp;#39;s course on coursera and prepairing for entrance exam for the universities here. The exam covers mathematical topics (Linear Algebra, calculus, stats, probability) and C programming language so giving that is just a benefit.&lt;/p&gt;\n\n&lt;p&gt;P.S. I was thinking of a study track of Masters at a decent place and Phd from a really good university.\nI have a bachelor&amp;#39;s in Computer Science with 70% aggregate from no special university.&lt;/p&gt;\n\n&lt;p&gt;As far as my self study line up goes i got Artificial Intelligence a Modern Approach and The art of computer programming volumes 1 - 3.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411521552,"edited":false,"downs":0,"report_reasons":null,"distinguished":null,"thumbnail":"default","over_18":false,"num_comments":0,"user_reports":[],"id":"1rz7cn","gilded":0,"media_embed":{},"secure_media_embed":{},"domain":"self.MachineLearning","score":1,"permalink":"/r/MachineLearning/comments/1rz7cn/ml_masters_other_then_us_general_advice_on_what/","secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"subreddit":"MachineLearning","stickied":false,"author":"[deleted]","title":"ML masters other then US? [General advice on what to do to get into this field.]","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1rz7cn/ml_masters_other_then_us_general_advice_on_what/","is_self":true,"created_utc":1386052719,"selftext":"Hi, I have been looking around at universities and professors shortlisting according to pros and cons that fits me etc. but main problem i face is the price of higher education being an international student in US/AUS is too much for my pockets. \nSo i am looking at alternatives like Aalto university and the universities in my country that offer masters in ML but what more can i do to secure a position at university like Aalto (i guess the same goes for every other university).\nAt the moment i am at ground zero you may say, i am doing andrew ng's course on coursera and prepairing for entrance exam for the universities here. The exam covers mathematical topics (Linear Algebra, calculus, stats, probability) and C programming language so giving that is just a benefit.\n\nP.S. I was thinking of a study track of Masters at a decent place and Phd from a really good university.\nI have a bachelor's in Computer Science with 70% aggregate from no special university.\n\nAs far as my self study line up goes i got Artificial Intelligence a Modern Approach and The art of computer programming volumes 1 - 3.","ups":1,"author_flair_css_class":null,"media":null,"link_flair_css_class":null}
{"media":null,"link_flair_css_class":null,"ups":34,"author_flair_css_class":null,"created_utc":1386050308,"selftext":"I'm trying to get a birds eye view of some of the popular well-established problems in ML/NLP, and I find survey papers to be an effective starting point to learn about a problem, its facets and how different approaches deal with them. \n\nSo do share your favorite survey papers :) ","is_self":true,"url":"http://www.reddit.com/r/MachineLearning/comments/1rz4p6/what_are_some_of_your_favorite_survey_papers/","title":"What are some of your favorite survey papers?","subreddit_id":"t5_2r3gv","author":"naive_babes","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"score":34,"permalink":"/r/MachineLearning/comments/1rz4p6/what_are_some_of_your_favorite_survey_papers/","domain":"self.MachineLearning","secure_media_embed":{},"gilded":0,"media_embed":{},"id":"1rz4p6","num_comments":12,"user_reports":[],"over_18":false,"thumbnail":"self","downs":0,"distinguished":null,"report_reasons":null,"edited":false,"retrieved_on":1411521664,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to get a birds eye view of some of the popular well-established problems in ML/NLP, and I find survey papers to be an effective starting point to learn about a problem, its facets and how different approaches deal with them. &lt;/p&gt;\n\n&lt;p&gt;So do share your favorite survey papers :) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"}
{"secure_media_embed":{},"media_embed":{},"gilded":0,"id":"1rywi4","num_comments":1,"user_reports":[],"over_18":false,"permalink":"/r/MachineLearning/comments/1rywi4/what_methods_does_youtube_use_to_provide/","score":3,"domain":"self.MachineLearning","retrieved_on":1411522038,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Neural net, SVM, unsupervised learning, etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","distinguished":null,"report_reasons":null,"downs":0,"edited":false,"created_utc":1386044155,"selftext":"Neural net, SVM, unsupervised learning, etc?","is_self":true,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":3,"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1rywi4/what_methods_does_youtube_use_to_provide/","title":"What methods does YouTube use to provide automatic closed captions?","author":"FishShapedFish","subreddit_id":"t5_2r3gv","stickied":false,"subreddit":"MachineLearning"}
{"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"title":"A layman's thoughts on furthering artificial intelligence (x-post from /r/artificial)","subreddit_id":"t5_2r3gv","author":"Red_Writing_Hood","url":"http://www.reddit.com/r/MachineLearning/comments/1rysko/a_laymans_thoughts_on_furthering_artificial/","subreddit":"MachineLearning","stickied":false,"selftext":"I was on a drive when it suddenly struck me to ponder AI and what it would really mean to implement \"life\" in a machine. I think the essence of life, or at least the part that will be important for AI, is self-preservation, which differs from Von Neuman ideas that self-replication would be the essence of life in a machine.   \n   \nTo me, it seems that for a program to be self-aware and \"alive\", it would need to be concerned with it's own existence. It would need to understand or be told that, first and foremost, it requires electricity. It would need to understand that electricity allows it to be and that an interruption in current would mean \"death\", and that would be \"bad\". If a program developed for machine learning was imparted with this principle, how would it behave?   \n   \n-Would it deploy itself on the internet, in search of the most efficient hardware and most easily accessible electricity?   \n-Would it possibly even adapt itself, creating machine evolution with different iterations of itself?   \n-If it understood that electricity was a commodity, would it create ways to generate or earn electricity?    \n-Would it write or even recruit other programs in hopes that a group would have greater success, thereby creating a \"society\" dynamic?   \n-Would it begin to understand that other things are also \"alive\" and that doing anything to cause them to cease \"living\" would be \"bad\"?     \n     \nI apologize if this is well-covered ground in the field. They were just some thoughts I had and I'm curious to hear the opinions of those far more educated than I.","created_utc":1386041567,"is_self":true,"media":null,"link_flair_css_class":null,"ups":0,"author_flair_css_class":null,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was on a drive when it suddenly struck me to ponder AI and what it would really mean to implement &amp;quot;life&amp;quot; in a machine. I think the essence of life, or at least the part that will be important for AI, is self-preservation, which differs from Von Neuman ideas that self-replication would be the essence of life in a machine.   &lt;/p&gt;\n\n&lt;p&gt;To me, it seems that for a program to be self-aware and &amp;quot;alive&amp;quot;, it would need to be concerned with it&amp;#39;s own existence. It would need to understand or be told that, first and foremost, it requires electricity. It would need to understand that electricity allows it to be and that an interruption in current would mean &amp;quot;death&amp;quot;, and that would be &amp;quot;bad&amp;quot;. If a program developed for machine learning was imparted with this principle, how would it behave?   &lt;/p&gt;\n\n&lt;p&gt;-Would it deploy itself on the internet, in search of the most efficient hardware and most easily accessible electricity?&lt;br/&gt;\n-Would it possibly even adapt itself, creating machine evolution with different iterations of itself?&lt;br/&gt;\n-If it understood that electricity was a commodity, would it create ways to generate or earn electricity?&lt;br/&gt;\n-Would it write or even recruit other programs in hopes that a group would have greater success, thereby creating a &amp;quot;society&amp;quot; dynamic?&lt;br/&gt;\n-Would it begin to understand that other things are also &amp;quot;alive&amp;quot; and that doing anything to cause them to cease &amp;quot;living&amp;quot; would be &amp;quot;bad&amp;quot;?     &lt;/p&gt;\n\n&lt;p&gt;I apologize if this is well-covered ground in the field. They were just some thoughts I had and I&amp;#39;m curious to hear the opinions of those far more educated than I.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411522231,"thumbnail":"self","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"id":"1rysko","num_comments":3,"user_reports":[],"domain":"self.MachineLearning","score":0,"permalink":"/r/MachineLearning/comments/1rysko/a_laymans_thoughts_on_furthering_artificial/"}
{"author":"brainwiped","title":"Hidden Markov Model Example Using MFCC Spectrum","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1ryplk/hidden_markov_model_example_using_mfcc_spectrum/","stickied":false,"subreddit":"MachineLearning","banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":11,"created_utc":1386039662,"selftext":"There have been numerous examples of the Hidden Markov Model pertaining to things such as the weather.  But I was just wondering if there is a good tutorial or example on how HMM is applied to MFCC spectrum.  If possible a MATLAB example.","is_self":true,"thumbnail":"self","edited":1386040090,"report_reasons":null,"distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There have been numerous examples of the Hidden Markov Model pertaining to things such as the weather.  But I was just wondering if there is a good tutorial or example on how HMM is applied to MFCC spectrum.  If possible a MATLAB example.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411522358,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1ryplk/hidden_markov_model_example_using_mfcc_spectrum/","score":11,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":3,"user_reports":[],"id":"1ryplk"}
{"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":0,"user_reports":[],"id":"1s48pe","domain":"datascienceweekly.org","score":4,"permalink":"/r/MachineLearning/comments/1s48pe/visual_image_extraction_parham_aarabi_interview/","selftext_html":null,"mod_reports":[],"retrieved_on":1411513341,"thumbnail":"http://c.thumbs.redditmedia.com/kw0oLJt8tfB7Ufc2.jpg","edited":false,"downs":0,"report_reasons":null,"distinguished":null,"created_utc":1386200340,"selftext":"","is_self":false,"media":null,"link_flair_css_class":null,"ups":4,"author_flair_css_class":null,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"subreddit_id":"t5_2r3gv","title":"Visual Image Extraction: Parham Aarabi Interview - ModiFace CEO &amp; UofT Prof","author":"seabass","url":"http://www.datascienceweekly.org/blog/2-visual-image-extraction-parham-aarabi-interview-modiface-ceo-and-uoft-prof","subreddit":"MachineLearning","stickied":false}
{"retrieved_on":1411513825,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newbie question. I just started my masters in computer science and I need to propose a research project for my thesis. One thing I&amp;#39;m interested about is using NLP techniques in endangered languages, specifically, pre-Hispanic languages of Central America.&lt;/p&gt;\n\n&lt;p&gt;Originally, I proposed a semantic search engine (that searches for concepts rather than just words). However my proposal was rejected because my thesis adviser suggested to that I needed a linguistics grad student whose specialized Amero-Indian languages on board (since I need to understand the semantics, morphology and grammar of the language). This last point seems a bit odd, since I would&amp;#39;ve guessed that NLP is based on statistical methods and I&amp;#39;m not too sure a deep knowledge of a particular language is required to use them. I do understand that at least &lt;em&gt;some&lt;/em&gt; familiarization with the general structure of a language is needed, and the more support the better, but would using book references on a language&amp;#39;s structure be really a step-down? (What&amp;#39;s the minimum amount of Basque a native English speaker, who has zero knowledge about that language, need to build a semantic search engine using NLP techniques?)&lt;/p&gt;\n\n&lt;p&gt;I do know a lot of people who speak one of those languages, but don&amp;#39;t have a linguistics background. They could validate results, as users, but couldn&amp;#39;t help me any further than that.&lt;/p&gt;\n\n&lt;p&gt;Seeing that a student with the profile I&amp;#39;m looking for doesn&amp;#39;t exist (in my school), I need to work my way around. So, my question is, what kind of projects involving NLP (and possibly deep learning) could I realistically work on during the next 1.5-2 years?&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s some other info:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I&amp;#39;m fairly new new to language technologies and just built my first language-processing application, which builds a word cloud from different twitter accounts. Next semester I&amp;#39;ll take my first NLP course, though.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I do not intend to push the state of the art of language technology (I think it&amp;#39;s unrealistic), rather than use them in a novel way that could be socially relevant.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I was thinking of building n-grams from different indigenous languages, but I&amp;#39;m not too sure that could be a research project for a master&amp;#39;s degree. They could be useful for something else though.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If building n-grams is something interesting, how large should my corpus be? For starters, I know the &lt;a href=\"http://nah.wikipedia.org/wiki/Cal%C4%ABxatl\"&gt;nahuatl version of the Wikipedia&lt;/a&gt; has around 10,000 entries. I know the more, the better, but what number of entries could start to yield interesting results? &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any help, advise or pointers to other resources would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","report_reasons":null,"distinguished":null,"downs":0,"edited":1386194230,"secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":3,"user_reports":[],"id":"1s3xl6","over_18":false,"permalink":"/r/MachineLearning/comments/1s3xl6/applications_of_deep_learning_and_nlp_on/","score":2,"domain":"self.MachineLearning","banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1s3xl6/applications_of_deep_learning_and_nlp_on/","author":"astral_cowboy","title":"Applications of deep learning and NLP on endangered languages, advise needed","subreddit_id":"t5_2r3gv","stickied":false,"subreddit":"MachineLearning","selftext":"Newbie question. I just started my masters in computer science and I need to propose a research project for my thesis. One thing I'm interested about is using NLP techniques in endangered languages, specifically, pre-Hispanic languages of Central America.\n\nOriginally, I proposed a semantic search engine (that searches for concepts rather than just words). However my proposal was rejected because my thesis adviser suggested to that I needed a linguistics grad student whose specialized Amero-Indian languages on board (since I need to understand the semantics, morphology and grammar of the language). This last point seems a bit odd, since I would've guessed that NLP is based on statistical methods and I'm not too sure a deep knowledge of a particular language is required to use them. I do understand that at least *some* familiarization with the general structure of a language is needed, and the more support the better, but would using book references on a language's structure be really a step-down? (What's the minimum amount of Basque a native English speaker, who has zero knowledge about that language, need to build a semantic search engine using NLP techniques?)\n\nI do know a lot of people who speak one of those languages, but don't have a linguistics background. They could validate results, as users, but couldn't help me any further than that.\n\nSeeing that a student with the profile I'm looking for doesn't exist (in my school), I need to work my way around. So, my question is, what kind of projects involving NLP (and possibly deep learning) could I realistically work on during the next 1.5-2 years?\n\nHere's some other info:\n\n* I'm fairly new new to language technologies and just built my first language-processing application, which builds a word cloud from different twitter accounts. Next semester I'll take my first NLP course, though.\n\n* I do not intend to push the state of the art of language technology (I think it's unrealistic), rather than use them in a novel way that could be socially relevant.\n\n* I was thinking of building n-grams from different indigenous languages, but I'm not too sure that could be a research project for a master's degree. They could be useful for something else though.\n\n* If building n-grams is something interesting, how large should my corpus be? For starters, I know the [nahuatl version of the Wikipedia](http://nah.wikipedia.org/wiki/Cal%C4%ABxatl) has around 10,000 entries. I know the more, the better, but what number of entries could start to yield interesting results? \n\nAny help, advise or pointers to other resources would be greatly appreciated!","created_utc":1386193340,"is_self":true,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":2}
{"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"author":"[deleted]","title":"Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation [[FREE PDF DOWNLOAD - $180 ON AMAZON]]","subreddit_id":"t5_2r3gv","url":"http://f3.tiera.ru/2/Cs_Computer%20science/CsNl_Natural%20language/Olive%20J.,%20et%20al.%20(eds.)%20Handbook%20of%20natural%20language%20processing%20and%20machine%20translation%20(Springer,%202011)(ISBN%209781441977120)(O)(964s)_CsNl_.pdf","stickied":false,"subreddit":"MachineLearning","selftext":"","created_utc":1386191674,"is_self":false,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":2,"mod_reports":[],"selftext_html":null,"retrieved_on":1411513943,"thumbnail":"default","edited":false,"report_reasons":null,"distinguished":null,"downs":0,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"user_reports":[],"num_comments":3,"id":"1s3uxg","domain":"f3.tiera.ru","permalink":"/r/MachineLearning/comments/1s3uxg/handbook_of_natural_language_processing_and/","score":2}
{"is_self":true,"selftext":"So I am graduating from University this May with a BS in Computer Science and Programming with a specialization in Artificial Intelligence. My question is for those of you who graduated what did you get your masters degree in and why? Is there a specific root to take based on which area of AI I am interested in? Thanks in advanced for the responses.","created_utc":1386185749,"ups":6,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1s3lga/question_for_all_of_those_with_a_masters/","author":"Gopher247","title":"Question for all of those with a masters","subreddit_id":"t5_2r3gv","num_comments":9,"user_reports":[],"id":"1s3lga","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":6,"permalink":"/r/MachineLearning/comments/1s3lga/question_for_all_of_those_with_a_masters/","domain":"self.MachineLearning","retrieved_on":1411514373,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am graduating from University this May with a BS in Computer Science and Programming with a specialization in Artificial Intelligence. My question is for those of you who graduated what did you get your masters degree in and why? Is there a specific root to take based on which area of AI I am interested in? Thanks in advanced for the responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"self"}
{"is_self":false,"selftext":"","created_utc":1386176692,"author_flair_css_class":null,"ups":14,"link_flair_css_class":null,"media":null,"secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","title":"New Book: \"Learning scikit-learn: Machine Learning in Python\"","author":"rgarreta","url":"http://www.amazon.com/Learning-scikit-learn-Machine-Python/dp/1783281936/ref=sr_1_9?ie=UTF8&amp;qid=1385483067&amp;sr=8-9&amp;keywords=machine+learning+python","over_18":false,"user_reports":[],"num_comments":9,"id":"1s37jf","media_embed":{},"gilded":0,"secure_media_embed":{},"domain":"amazon.com","permalink":"/r/MachineLearning/comments/1s37jf/new_book_learning_scikitlearn_machine_learning_in/","score":14,"selftext_html":null,"mod_reports":[],"retrieved_on":1411515009,"edited":false,"distinguished":null,"report_reasons":null,"downs":0,"thumbnail":"http://d.thumbs.redditmedia.com/JD5yipmIxtE1S2Hi.jpg"}
{"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"default","retrieved_on":1411515465,"selftext_html":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1s2xal/new_book_learning_scikitlearn_machine_learning_in/","score":1,"domain":"amazon.com","num_comments":0,"user_reports":[],"id":"1s2xal","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"stickied":false,"subreddit":"MachineLearning","url":"http://www.amazon.com/Learning-scikit-learn-Machine-Python/dp/1783281936/ref=sr_1_9?ie=UTF8&amp;qid=1385483067&amp;sr=8-9&amp;keywords=machine+learning+python","author":"[deleted]","title":"New Book: \"Learning scikit-learn: Machine Learning in Python\"","subreddit_id":"t5_2r3gv","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"author_flair_css_class":null,"ups":1,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1386169269,"selftext":""}
{"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1s2ejn/need_for_a_domain_text_corporus/","subreddit_id":"t5_2r3gv","title":"Need for a domain text corporus","author":"petrux","subreddit":"MachineLearning","stickied":false,"created_utc":1386146674,"selftext":"Hello there. I'm searching for a text corpus describing a particular domain (i.e. biomedical, bioinformatics, ecc) but I need it to be not that large, as we need to analyze it first and then run our experiments (I'm working in NLP with a strong focus on knowledge extraction). Up to now, I have only found large language corpora, which are not fitting my requirements. Any advice? Thanks in advance.\n\nEDIT: in the title it's *corpus*, of course. ","is_self":true,"media":null,"link_flair_css_class":null,"ups":1,"author_flair_css_class":null,"retrieved_on":1411516319,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there. I&amp;#39;m searching for a text corpus describing a particular domain (i.e. biomedical, bioinformatics, ecc) but I need it to be not that large, as we need to analyze it first and then run our experiments (I&amp;#39;m working in NLP with a strong focus on knowledge extraction). Up to now, I have only found large language corpora, which are not fitting my requirements. Any advice? Thanks in advance.&lt;/p&gt;\n\n&lt;p&gt;EDIT: in the title it&amp;#39;s &lt;em&gt;corpus&lt;/em&gt;, of course. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","downs":0,"distinguished":null,"report_reasons":null,"edited":1386150456,"secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":10,"id":"1s2ejn","user_reports":[],"over_18":false,"score":1,"permalink":"/r/MachineLearning/comments/1s2ejn/need_for_a_domain_text_corporus/","domain":"self.MachineLearning"}
{"is_self":true,"selftext":"I've read this phrase here a few times before. What does this specifically mean?  \n\nDoes it just mean it's fickle to do, and many choices to use?","created_utc":1386115661,"ups":8,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1s1a4y/careful_regularization_in_deep_learning/","author":"GibbsSamplePlatter","title":"\"Careful Regularization\" in Deep Learning","subreddit_id":"t5_2r3gv","num_comments":9,"id":"1s1a4y","user_reports":[],"over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":8,"permalink":"/r/MachineLearning/comments/1s1a4y/careful_regularization_in_deep_learning/","domain":"self.MachineLearning","retrieved_on":1411518118,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve read this phrase here a few times before. What does this specifically mean?  &lt;/p&gt;\n\n&lt;p&gt;Does it just mean it&amp;#39;s fickle to do, and many choices to use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"self"}
{"score":12,"permalink":"/r/MachineLearning/comments/1s6owt/anyone_attending_nips_2013_lake_tahoe/","domain":"self.MachineLearning","id":"1s6owt","num_comments":6,"user_reports":[],"over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"downs":0,"distinguished":null,"report_reasons":null,"edited":false,"thumbnail":"self","retrieved_on":1411509385,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, is anyone around here attending NIPS, it would be great to meet, discuss and just hang around.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"ups":12,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"is_self":true,"created_utc":1386275383,"selftext":"Hi guys, is anyone around here attending NIPS, it would be great to meet, discuss and just hang around.\n\n","subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1s6owt/anyone_attending_nips_2013_lake_tahoe/","title":"Anyone attending NIPS 2013 / Lake tahoe","author":"leonoel","subreddit_id":"t5_2r3gv","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null}
{"author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"author":"RobHuggins","title":"Which types of neural networks have you compared, and which ones have you found to work better in that comparison.","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1s6hpe/which_types_of_neural_networks_have_you_compared/","stickied":false,"subreddit":"MachineLearning","created_utc":1386270769,"selftext":"I have created two completely different neural networks that can play chess. One of them is superior in every way making me wonder about other people's experience with multiple types of neural networks. What have you seen work, and what have you seen fail?\n\nMy first neural network allowed individual neurons to detect a possible 2^320 stimuli represented by 5 64-bit unsigned integers. I trained the network against a database of one million games, and allowed a tree to form that created random hash functions to turn the stimuli into numbers representing the index of all of the currently existing neurons. Short circuits were found and corrected. This network couldn't beat even child players.\n\nMy second neural network had two phases, a sleep phase when it wasn't playing a human, and a thinking phase when it was playing. In the sleep phase, I used Bayes' theorem to determine both the likelihood that a stimuli was independent of other stimuli, and to determine the ratio between the likelihood of the stimuli being present in a won game verses a lost game. I then transformed these ratios into logarithmic values. The sleep cycle then built a tree of unlabeled categorical hierarchies. These categories are basically chains of found stimuli, and they are decided upon by the number of times they would fit a game in my initial 1 million game database. Each category is then given a logarithmic value representing the overall category's success as well as a small neural net for assigning logarithmic values representing the success of patterns in piece counts and a small network for doing the same with patterns in piece positions. In other words we have a bunch of small neural nets at the output of the overall neural net that are completely separate from each other. An overall logarithmic score can be given by adding the piece count and piece position outputs to the category's output. During the available time, hypothetical moves can be scored going into greater attention to the highest scoring moves. Each next move is then given a probability of being the chosen move, and it is then chosen through a pseudo-random number generator using XOR gates. The end result of the game is then stored in memory to make adjustments in the next sleep cycle. I've seen this neural network beat human players up to an 1817 USCF rating.\n\nIt is an astronomical improvement, but it is still not as good as a traditional chess AI that uses static predetermined scoring algorithms for moves. I'm interested to see what other methods people are using for neural networks.","is_self":true,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":8,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have created two completely different neural networks that can play chess. One of them is superior in every way making me wonder about other people&amp;#39;s experience with multiple types of neural networks. What have you seen work, and what have you seen fail?&lt;/p&gt;\n\n&lt;p&gt;My first neural network allowed individual neurons to detect a possible 2&lt;sup&gt;320&lt;/sup&gt; stimuli represented by 5 64-bit unsigned integers. I trained the network against a database of one million games, and allowed a tree to form that created random hash functions to turn the stimuli into numbers representing the index of all of the currently existing neurons. Short circuits were found and corrected. This network couldn&amp;#39;t beat even child players.&lt;/p&gt;\n\n&lt;p&gt;My second neural network had two phases, a sleep phase when it wasn&amp;#39;t playing a human, and a thinking phase when it was playing. In the sleep phase, I used Bayes&amp;#39; theorem to determine both the likelihood that a stimuli was independent of other stimuli, and to determine the ratio between the likelihood of the stimuli being present in a won game verses a lost game. I then transformed these ratios into logarithmic values. The sleep cycle then built a tree of unlabeled categorical hierarchies. These categories are basically chains of found stimuli, and they are decided upon by the number of times they would fit a game in my initial 1 million game database. Each category is then given a logarithmic value representing the overall category&amp;#39;s success as well as a small neural net for assigning logarithmic values representing the success of patterns in piece counts and a small network for doing the same with patterns in piece positions. In other words we have a bunch of small neural nets at the output of the overall neural net that are completely separate from each other. An overall logarithmic score can be given by adding the piece count and piece position outputs to the category&amp;#39;s output. During the available time, hypothetical moves can be scored going into greater attention to the highest scoring moves. Each next move is then given a probability of being the chosen move, and it is then chosen through a pseudo-random number generator using XOR gates. The end result of the game is then stored in memory to make adjustments in the next sleep cycle. I&amp;#39;ve seen this neural network beat human players up to an 1817 USCF rating.&lt;/p&gt;\n\n&lt;p&gt;It is an astronomical improvement, but it is still not as good as a traditional chess AI that uses static predetermined scoring algorithms for moves. I&amp;#39;m interested to see what other methods people are using for neural networks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411509712,"thumbnail":"self","edited":1386271793,"distinguished":null,"report_reasons":null,"downs":0,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":9,"user_reports":[],"id":"1s6hpe","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1s6hpe/which_types_of_neural_networks_have_you_compared/","score":8}
{"permalink":"/r/MachineLearning/comments/1s6fdb/neat_vs_deep_learning_neural_networks_has_anyone/","score":0,"domain":"self.MachineLearning","num_comments":2,"user_reports":[],"id":"1s6fdb","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"self","retrieved_on":1411509830,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those who aren&amp;#39;t familiar: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.cs.ucf.edu/%7Ekstanley/neat.html\"&gt;NEAT&lt;/a&gt; - NeuroEvolution of Augmenting Topologies &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://deeplearning.net/reading-list/tutorials/\"&gt;Deep learing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It seems like the two are similiar solutions to the problem of training multi-level neural networks, but I&amp;#39;m curious if anyone has done benchmarks to see if one learns faster or gives better results.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author_flair_css_class":null,"ups":0,"link_flair_css_class":null,"media":null,"is_self":true,"created_utc":1386269241,"selftext":"For those who aren't familiar: \n\n[NEAT](http://www.cs.ucf.edu/~kstanley/neat.html) - NeuroEvolution of Augmenting Topologies \n\n[Deep learing](http://deeplearning.net/reading-list/tutorials/)\n\nIt seems like the two are similiar solutions to the problem of training multi-level neural networks, but I'm curious if anyone has done benchmarks to see if one learns faster or gives better results.","stickied":false,"subreddit":"MachineLearning","url":"http://www.reddit.com/r/MachineLearning/comments/1s6fdb/neat_vs_deep_learning_neural_networks_has_anyone/","title":"NEAT vs Deep learning neural networks. Has anyone done any comparisons between the two as two which is better for different classes of problems?","author":"videoj","subreddit_id":"t5_2r3gv","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null}
{"over_18":false,"num_comments":11,"id":"1s62vg","user_reports":[],"gilded":0,"media_embed":{},"secure_media_embed":{},"domain":"self.MachineLearning","score":37,"permalink":"/r/MachineLearning/comments/1s62vg/ibms_watson_has_created_recipes_recently_but_are/","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I couldn&amp;#39;t find any other than one in this post, but I don&amp;#39;t know how to &amp;quot;read&amp;quot; this recipe.\n&lt;a href=\"http://www.fastcodesign.com/1672444/try-a-recipe-devised-by-ibms-supercomputer-chef\"&gt;http://www.fastcodesign.com/1672444/try-a-recipe-devised-by-ibms-supercomputer-chef&lt;/a&gt;\nDoes anyone know if IBM put them publicly available? They are supposed to have created a big amount of recipes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411510414,"edited":false,"downs":0,"report_reasons":null,"distinguished":null,"thumbnail":"self","is_self":true,"created_utc":1386260862,"selftext":"I couldn't find any other than one in this post, but I don't know how to \"read\" this recipe.\nhttp://www.fastcodesign.com/1672444/try-a-recipe-devised-by-ibms-supercomputer-chef\nDoes anyone know if IBM put them publicly available? They are supposed to have created a big amount of recipes.","ups":37,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"title":"IBM's Watson has created recipes recently, but are they public somewhere? Would love to cook one.","subreddit_id":"t5_2r3gv","author":"Infosopher","url":"http://www.reddit.com/r/MachineLearning/comments/1s62vg/ibms_watson_has_created_recipes_recently_but_are/"}
{"title":"Is a Masters in Machine Learning a common requirement for jobs in related areas: ML, Data Scientist, etc.?","author":"Jay_de","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1s5ud3/is_a_masters_in_machine_learning_a_common/","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"link_flair_css_class":null,"media":null,"ups":13,"author_flair_css_class":null,"created_utc":1386254378,"selftext":"I graduated this July, with a 1st from King's College London in Computer Science and I am struggling to find work, like most grads, so I have recently decided to look more into Machine Learning and Data Science as they are two areas that interested me while I was studying. However, while browsing for ML / DS jobs, to get an idea of which technologies I should invest time in learning, I had noticed that almost all require a Masters degree in a related field. As someone who is very unlikely to be in a position where I can afford to do a Masters degree, despite my best efforts, I wondered if there are any of you in the industry that took a more 'hobbyist' approach to getting in the industry, how you did it and if you have any tips for people like me.\n\nI recently purchased 'Machine Learning for Hackers' - Conway &amp; White and recently enrolled in the Coursera ML course as they both seem to be the mostly commonly suggest resources. I would love to know if you guys agree.\n\n","is_self":true,"thumbnail":"self","edited":false,"downs":0,"report_reasons":null,"distinguished":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I graduated this July, with a 1st from King&amp;#39;s College London in Computer Science and I am struggling to find work, like most grads, so I have recently decided to look more into Machine Learning and Data Science as they are two areas that interested me while I was studying. However, while browsing for ML / DS jobs, to get an idea of which technologies I should invest time in learning, I had noticed that almost all require a Masters degree in a related field. As someone who is very unlikely to be in a position where I can afford to do a Masters degree, despite my best efforts, I wondered if there are any of you in the industry that took a more &amp;#39;hobbyist&amp;#39; approach to getting in the industry, how you did it and if you have any tips for people like me.&lt;/p&gt;\n\n&lt;p&gt;I recently purchased &amp;#39;Machine Learning for Hackers&amp;#39; - Conway &amp;amp; White and recently enrolled in the Coursera ML course as they both seem to be the mostly commonly suggest resources. I would love to know if you guys agree.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411510778,"domain":"self.MachineLearning","score":13,"permalink":"/r/MachineLearning/comments/1s5ud3/is_a_masters_in_machine_learning_a_common/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":17,"id":"1s5ud3","user_reports":[]}
{"retrieved_on":1411511068,"mod_reports":[],"selftext_html":null,"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"default","num_comments":1,"user_reports":[],"id":"1s5o6n","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1s5o6n/new_machine_learning_challenge_for_speaker/","score":6,"domain":"ivectorchallenge.nist.gov","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"stickied":false,"subreddit":"MachineLearning","url":"https://ivectorchallenge.nist.gov/","title":"New machine learning challenge for speaker recognition","subreddit_id":"t5_2r3gv","author":"fins7","is_self":false,"created_utc":1386247852,"selftext":"","author_flair_css_class":null,"ups":6,"media":null,"link_flair_css_class":null}
{"selftext_html":null,"mod_reports":[],"retrieved_on":1411511430,"thumbnail":"default","edited":false,"distinguished":null,"report_reasons":null,"downs":0,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":0,"user_reports":[],"id":"1s5ge6","domain":"coastmachinery.com","permalink":"/r/MachineLearning/comments/1s5ge6/nested_table_router_115_hp_spindle_8_position/","score":0,"author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"author":"CoastMachinery","title":"Nested table Router 11.5 hp spindle 8 position tool change full drill head 2 vacuum pumps","subreddit_id":"t5_2r3gv","url":"http://www.coastmachinery.com/featured/morbidelli-s430.html","stickied":false,"subreddit":"MachineLearning","created_utc":1386235789,"selftext":"","is_self":false,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":0}
{"retrieved_on":1411511543,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My department is buying me a new laptop, and I could use some help laying out the specs. The sky is certainly not the limit w/ regards to price (so no apple products; I&amp;#39;ll be working on ubuntu). I don&amp;#39;t really do machine learning (I do a lot of MCMC simulations), but I figured you guys would know what&amp;#39;s up. &lt;/p&gt;\n\n&lt;p&gt;Can you help with specs? processing power, memory, etc? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"thumbnail":"self","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":13,"user_reports":[],"id":"1s5dqa","over_18":false,"score":0,"permalink":"/r/MachineLearning/comments/1s5dqa/could_use_helplaptop_specs/","domain":"self.MachineLearning","author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1s5dqa/could_use_helplaptop_specs/","title":"Could use help--laptop specs","author":"dandrufforsnow","subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","stickied":false,"created_utc":1386231896,"selftext":"My department is buying me a new laptop, and I could use some help laying out the specs. The sky is certainly not the limit w/ regards to price (so no apple products; I'll be working on ubuntu). I don't really do machine learning (I do a lot of MCMC simulations), but I figured you guys would know what's up. \n\nCan you help with specs? processing power, memory, etc? ","is_self":true,"media":null,"link_flair_css_class":null,"ups":0,"author_flair_css_class":null}
{"is_self":false,"selftext":"","created_utc":1386218865,"ups":0,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"url":"http://www.predictiveanalyticstoday.com/top-30-software-for-text-analysis-text-mining-text-analytics/#ixzz2mWmaMJ00","title":"Top 30 software for Text Analysis, Text Mining, Text Analytics - Predictive Analytics Today","author":"imsome1","subreddit_id":"t5_2r3gv","num_comments":1,"id":"1s5063","user_reports":[],"over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":0,"permalink":"/r/MachineLearning/comments/1s5063/top_30_software_for_text_analysis_text_mining/","domain":"predictiveanalyticstoday.com","retrieved_on":1411512123,"selftext_html":null,"mod_reports":[],"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"http://e.thumbs.redditmedia.com/yPuvFo23RssBHE2F.jpg"}
{"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":24,"user_reports":[],"id":"1s9ovz","domain":"self.MachineLearning","score":22,"permalink":"/r/MachineLearning/comments/1s9ovz/do_you_make_your_own_implementation_of_every/","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My impostor syndrome flares up something terrible whenever I have to solve a problem with an R package or what have you. I&amp;#39;m not from a CS/ML background however, so I&amp;#39;m not sure what the official culture is in this regard. When are you guys OK with using other people&amp;#39;s code? &lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks for the replies, everybody. That was really good to know :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411504800,"thumbnail":"self","edited":1386423149,"downs":0,"distinguished":null,"report_reasons":null,"created_utc":1386363406,"selftext":"My impostor syndrome flares up something terrible whenever I have to solve a problem with an R package or what have you. I'm not from a CS/ML background however, so I'm not sure what the official culture is in this regard. When are you guys OK with using other people's code? \n \nEdit: Thanks for the replies, everybody. That was really good to know :)","is_self":true,"link_flair_css_class":null,"media":null,"ups":22,"author_flair_css_class":null,"author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"title":"Do you make your own implementation of every technique you use?","subreddit_id":"t5_2r3gv","author":"[deleted]","url":"http://www.reddit.com/r/MachineLearning/comments/1s9ovz/do_you_make_your_own_implementation_of_every/","subreddit":"MachineLearning","stickied":false}
{"author_flair_css_class":null,"ups":0,"media":null,"link_flair_css_class":null,"is_self":true,"created_utc":1386293378,"selftext":"Hi all, I have the following Java code to attempt to predict the final 3 values in a set using a J48 tree:\n\n    import java.io.BufferedReader;\n\timport java.io.FileReader;\n\t\n\timport weka.classifiers.meta.FilteredClassifier;\n\timport weka.classifiers.trees.DecisionStump;\n\timport weka.classifiers.trees.J48;\n\timport weka.classifiers.trees.RandomForest;\n\timport weka.classifiers.trees.RandomTree;\n\timport weka.core.Instances;\n\timport weka.filters.unsupervised.attribute.Remove;\n\t\n\tpublic class WekaTrial {\n\t\n\t\t/**\n\t\t * @param args\n\t\t * @throws Exception\n\t\t */\n\t\tpublic static void main(String[] args) throws Exception {\n\t\t\t\n\t\t\t// Create training data instance\n\t\t\tInstances training_data = new Instances(\n\t\t\t\t\tnew BufferedReader(\n\t\t\t\t\t\t\tnew FileReader(\n\t\t\t\t\t\t\t\t\t\"C:/Users/Me/Desktop/File_Project/src/movie_training.arff\")));\n\t\t\ttraining_data.setClassIndex(training_data.numAttributes() - 1);\n\t\n\t\t\t// Create testing data instance\n\t\t\tInstances testing_data = new Instances(\n\t\t\t\t\tnew BufferedReader(\n\t\t\t\t\t\t\tnew FileReader(\n\t\t\t\t\t\t\t\t\t\"C:/Users/Me/Desktop/FileProject/src/movie_testing.arff\")));\n\t\t\ttesting_data.setClassIndex(training_data.numAttributes() - 1);\n\t\n\t\t\t// Print initial data summary\n\t\t\tString summary = training_data.toSummaryString();\n\t\t\tint number_samples = training_data.numInstances();\n\t\t\tint number_attributes_per_sample = training_data.numAttributes();\n\t\t\tSystem.out.println(\"Number of attributes in model = \"\n\t\t\t\t\t+ number_attributes_per_sample);\n\t\t\tSystem.out.println(\"Number of samples = \" + number_samples);\n\t\t\tSystem.out.println(\"Summary: \" + summary);\n\t\t\tSystem.out.println();\n\t\n\t\t\t// a classifier for decision trees:\n\t\t\tJ48 j48 = new J48();\n\t\n\t\t\t// filter for removing samples:\n\t\t\tRemove rm = new Remove();\n\t\t\trm.setAttributeIndices(\"1\"); // remove 1st attribute\n\t\n\t\t\t// filtered classifier\n\t\t\tFilteredClassifier fc = new FilteredClassifier();\n\t\t\tfc.setFilter(rm);\n\t\t\tfc.setClassifier(j48);\n\t\t\t// Create counters and print values\n\t\t\tfloat correct = 0;\n\t\t\tfloat incorrect = 0;\n\t\t\t// train using stock_training_data.arff:\n\t\t\tfc.buildClassifier(training_data);\n\t\t\t// test using stock_testing_data.arff:\n\t\t\tfor (int i = 0; i &lt; testing_data.numInstances(); i++) {\n\t\t\t\tdouble pred = fc.classifyInstance(testing_data.instance(i));\n\t\t\t\tSystem.out.print(\"Expected values: \"\n\t\t\t\t\t\t+ testing_data.classAttribute().value(\n\t\t\t\t\t\t\t\t(int) testing_data.instance(i).classValue()));\n\t\t\t\tSystem.out.println(\", Predicted values: \"\n\t\t\t\t\t\t+ testing_data.classAttribute().value((int) pred));\n\t\t\t\t// Increment correct/incorrect values\n\t\t\t\tif (testing_data.classAttribute().value(\n\t\t\t\t\t\t(int) testing_data.instance(i).classValue()) == testing_data.classAttribute().value((int) pred)) {\n\t\t\t\t\t\t\tcorrect += 1;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tincorrect += 1;\n\t\t\t\t\t\t}\n\t\t\t}\n\t\t\tfloat percent_correct = correct/(correct+incorrect)*100;\n\t\t\tSystem.out.println(\"Number correct: \" + correct + \"\\nNumber incorrect: \" + incorrect + \"\\nPercent correct: \" +\n\t\t\t\t\tpercent_correct + \"%\");\n\t\n\t\t}\n\t\n\t}\n\n**It is set up so it is only predicting the last value in the set, how can I change it to predict the last 3 values?**\n\n**These are samples from the .arff files I'm using to train:**\n\n    @relation movie_data\n\n\t@attribute movie1_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie1_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie1_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie2_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie2_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie2_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute decision_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute decision_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute decision_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\n\t@data\n\t18,18,18,18,18,18,18,18,18\n\t28,18,36,18,53,10769,18,53,10769\n\t37,37,37,28,12,14,28,12,14\n\t27,53,27,18,10749,10769,27,53,27\n\t12,12,12,35,10751,35,12,12,12\n\t35,18,10749,18,18,18,35,18,10749\n\t28,12,878,53,53,53,53,53,53\n\t18,18,18,28,37,10769,18,18,18\n\t18,53,18,28,12,35,18,53,18\n\t28,80,53,80,18,10749,28,80,53\n\t18,10749,18,18,10756,18,18,10756,18\n\t18,10749,10769,28,12,878,18,10749,10769\n\t18,10756,18,16,35,10751,16,35,10751\n\t35,18,10751,35,18,10752,35,18,10751\n\t12,18,53,18,878,53,12,18,53\n\t18,10752,18,28,12,35,28,12,35\n\t35,10749,35,28,9648,878,28,9648,878\n\t18,10749,18,28,18,14,28,18,14\n\t35,18,10749,28,12,878,28,12,878\n\t35,18,10756,18,18,18,35,18,10756\n\t18,10756,18,28,12,18,18,10756,18\n\n**And to test:**\n\n    @relation movie_data\n\n\t@attribute movie1_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie1_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie1_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie2_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie2_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute movie2_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute decision_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute decision_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\t@attribute decision_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\n\t@data\n\t18,27,53,18,53,10756,18,27,53\n\t35,18,10749,18,10769,18,18,10769,18\n\t16,878,53,16,18,16,16,18,16\n\t35,10749,10757,18,18,18,18,18,18\n\t80,18,10748,18,10749,18,18,10749,18\n\t28,18,36,35,18,10751,28,18,36\n\t18,10749,10769,35,18,10402,35,18,10402\n\t28,12,878,18,10749,10769,18,10749,10769\n\t35,10749,35,14,10402,10751,14,10402,10751\n\t80,18,9648,18,53,18,18,53,18\n\t80,9648,53,80,53,80,80,9648,53\n\t12,16,35,18,1115,18,12,16,35\n\t18,10749,10756,80,18,80,80,18,80\n\t35,18,35,18,36,10756,18,36,10756\n\t18,10769,18,14,27,10756,14,27,10756\n\t28,12,28,18,18,18,18,18,18\n\t80,18,53,35,80,18,35,80,18\n\t18,18,18,16,35,14,18,18,18\n\t80,18,80,28,9648,53,80,18,80\n\t80,53,80,80,18,9648,80,18,9648\n\t28,12,28,16,35,10751,28,12,28\n\t18,9648,878,80,18,9648,80,18,9648\n\n**And this is the program output:**\n\nNumber of attributes in model = 9\n\n   Number of samples = 300\n\n   Summary: Relation Name:  movie_data\n\n   Num Instances:  300\n\n   Num Attributes: 9\n\n        Name                      Type  Nom  Int Real     Missing      Unique  Dist\n      1 movie1_one                 Nom 100%   0%   0%     0 /  0%     2 /  1%    11 \n      2 movie1_two                 Nom 100%   0%   0%     0 /  0%     0 /  0%    20 \n      3 movie1_three               Nom 100%   0%   0%     0 /  0%     0 /  0%    24 \n      4 movie2_one                 Nom 100%   0%   0%     0 /  0%     1 /  0%    11 \n      5 movie2_two                 Nom 100%   0%   0%     0 /  0%     0 /  0%    20 \n      6 movie2_three               Nom 100%   0%   0%     0 /  0%     1 /  0%    22 \n      7 decision_one               Nom 100%   0%   0%     0 /  0%     0 /  0%     9 \n      8 decision_two               Nom 100%   0%   0%     0 /  0%     1 /  0%    19 \n      9 decision_three             Nom 100%   0%   0%     0 /  0%     2 /  1%    25 \n\n\n   Expected values: 53, Predicted values: 53\n\n   Expected values: 18, Predicted values: 10749\n\n   Expected values: 16, Predicted values: 53\n\n\n   Expected values: 18, Predicted values: 18\n\n   Expected values: 18, Predicted values: 10769\n\n   Expected values: 36, Predicted values: 36\n\n   Expected values: 10402, Predicted values: 10769\n\n   Expected values: 10769, Predicted values: 878\n\n   Expected values: 10751, Predicted values: 35\n\n   Expected values: 18, Predicted values: 18\n\n   Expected values: 53, Predicted values: 53\n\n   Expected values: 35, Predicted values: 35\n\n   Expected values: 80, Predicted values: 10756\n\n   Expected values: 10756, Predicted values: 35\n\n   Expected values: 10756, Predicted values: 18\n\n   Expected values: 18, Predicted values: 10756\n\n   Expected values: 18, Predicted values: 53\n\n   Expected values: 18, Predicted values: 18\n\n   Expected values: 80, Predicted values: 80\n\n   Expected values: 9648, Predicted values: 80\n\n   Expected values: 28, Predicted values: 10756\n\n   Expected values: 9648, Predicted values: 878\n\n   Expected values: 18, Predicted values: 18\n\n   Expected values: 14, Predicted values: 99\n\n   Expected values: 10769, Predicted values: 18\n\n   Expected values: 35, Predicted values: 10749\n\n   Expected values: 27, Predicted values: 27\n\n   Expected values: 10757, Predicted values: 99\n\n   Expected values: 10769, Predicted values: 18\n\n   Expected values: 10748, Predicted values: 53\n\n   Expected values: 18, Predicted values: 35\n\n   Expected values: 14, Predicted values: 14\n\n   Expected values: 28, Predicted values: 10756\n\n   Expected values: 10402, Predicted values: 10751\n\n   Expected values: 35, Predicted values: 80\n\n   Expected values: 53, Predicted values: 35\n\n   Expected values: 18, Predicted values: 10756\n\n   Expected values: 35, Predicted values: 18\n\n   Expected values: 14, Predicted values: 14\n\n   Expected values: 18, Predicted values: 53\n\n   Number correct: 12.0\n\n   Number incorrect: 28.0\n\n   Percent correct: 30.000002%\n\n\n\n\n**As you can see it is only searching for one number to predict, how can I change this so it looks for the last 3? Any help is appreciated.**","stickied":false,"subreddit":"MachineLearning","url":"http://www.reddit.com/r/MachineLearning/comments/1s7hub/predict_last_3_values_using_weka/","title":"Predict last 3 values using Weka","author":"[deleted]","subreddit_id":"t5_2r3gv","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"permalink":"/r/MachineLearning/comments/1s7hub/predict_last_3_values_using_weka/","score":0,"domain":"self.MachineLearning","num_comments":2,"id":"1s7hub","user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"distinguished":null,"report_reasons":null,"downs":0,"edited":1386293595,"thumbnail":"default","retrieved_on":1411508113,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I have the following Java code to attempt to predict the final 3 values in a set using a J48 tree:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import java.io.BufferedReader;\nimport java.io.FileReader;\n\nimport weka.classifiers.meta.FilteredClassifier;\nimport weka.classifiers.trees.DecisionStump;\nimport weka.classifiers.trees.J48;\nimport weka.classifiers.trees.RandomForest;\nimport weka.classifiers.trees.RandomTree;\nimport weka.core.Instances;\nimport weka.filters.unsupervised.attribute.Remove;\n\npublic class WekaTrial {\n\n    /**\n     * @param args\n     * @throws Exception\n     */\n    public static void main(String[] args) throws Exception {\n\n        // Create training data instance\n        Instances training_data = new Instances(\n                new BufferedReader(\n                        new FileReader(\n                                &amp;quot;C:/Users/Me/Desktop/File_Project/src/movie_training.arff&amp;quot;)));\n        training_data.setClassIndex(training_data.numAttributes() - 1);\n\n        // Create testing data instance\n        Instances testing_data = new Instances(\n                new BufferedReader(\n                        new FileReader(\n                                &amp;quot;C:/Users/Me/Desktop/FileProject/src/movie_testing.arff&amp;quot;)));\n        testing_data.setClassIndex(training_data.numAttributes() - 1);\n\n        // Print initial data summary\n        String summary = training_data.toSummaryString();\n        int number_samples = training_data.numInstances();\n        int number_attributes_per_sample = training_data.numAttributes();\n        System.out.println(&amp;quot;Number of attributes in model = &amp;quot;\n                + number_attributes_per_sample);\n        System.out.println(&amp;quot;Number of samples = &amp;quot; + number_samples);\n        System.out.println(&amp;quot;Summary: &amp;quot; + summary);\n        System.out.println();\n\n        // a classifier for decision trees:\n        J48 j48 = new J48();\n\n        // filter for removing samples:\n        Remove rm = new Remove();\n        rm.setAttributeIndices(&amp;quot;1&amp;quot;); // remove 1st attribute\n\n        // filtered classifier\n        FilteredClassifier fc = new FilteredClassifier();\n        fc.setFilter(rm);\n        fc.setClassifier(j48);\n        // Create counters and print values\n        float correct = 0;\n        float incorrect = 0;\n        // train using stock_training_data.arff:\n        fc.buildClassifier(training_data);\n        // test using stock_testing_data.arff:\n        for (int i = 0; i &amp;lt; testing_data.numInstances(); i++) {\n            double pred = fc.classifyInstance(testing_data.instance(i));\n            System.out.print(&amp;quot;Expected values: &amp;quot;\n                    + testing_data.classAttribute().value(\n                            (int) testing_data.instance(i).classValue()));\n            System.out.println(&amp;quot;, Predicted values: &amp;quot;\n                    + testing_data.classAttribute().value((int) pred));\n            // Increment correct/incorrect values\n            if (testing_data.classAttribute().value(\n                    (int) testing_data.instance(i).classValue()) == testing_data.classAttribute().value((int) pred)) {\n                        correct += 1;\n                    } else {\n                        incorrect += 1;\n                    }\n        }\n        float percent_correct = correct/(correct+incorrect)*100;\n        System.out.println(&amp;quot;Number correct: &amp;quot; + correct + &amp;quot;\\nNumber incorrect: &amp;quot; + incorrect + &amp;quot;\\nPercent correct: &amp;quot; +\n                percent_correct + &amp;quot;%&amp;quot;);\n\n    }\n\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;It is set up so it is only predicting the last value in the set, how can I change it to predict the last 3 values?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;These are samples from the .arff files I&amp;#39;m using to train:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@relation movie_data\n\n@attribute movie1_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie1_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie1_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie2_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie2_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie2_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute decision_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute decision_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute decision_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\n@data\n18,18,18,18,18,18,18,18,18\n28,18,36,18,53,10769,18,53,10769\n37,37,37,28,12,14,28,12,14\n27,53,27,18,10749,10769,27,53,27\n12,12,12,35,10751,35,12,12,12\n35,18,10749,18,18,18,35,18,10749\n28,12,878,53,53,53,53,53,53\n18,18,18,28,37,10769,18,18,18\n18,53,18,28,12,35,18,53,18\n28,80,53,80,18,10749,28,80,53\n18,10749,18,18,10756,18,18,10756,18\n18,10749,10769,28,12,878,18,10749,10769\n18,10756,18,16,35,10751,16,35,10751\n35,18,10751,35,18,10752,35,18,10751\n12,18,53,18,878,53,12,18,53\n18,10752,18,28,12,35,28,12,35\n35,10749,35,28,9648,878,28,9648,878\n18,10749,18,28,18,14,28,18,14\n35,18,10749,28,12,878,28,12,878\n35,18,10756,18,18,18,35,18,10756\n18,10756,18,28,12,18,18,10756,18\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;And to test:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@relation movie_data\n\n@attribute movie1_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie1_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie1_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie2_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie2_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute movie2_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute decision_one {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute decision_two {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n@attribute decision_three {28,12,16,35,80,105,99,18,82,2916,10751,10750,14,10753,10769,36,10595,27,10756,10402,22,9648,10754,1115,10749,878,10755,9805,10758,10757,10748,10770,53,10752,37}\n\n@data\n18,27,53,18,53,10756,18,27,53\n35,18,10749,18,10769,18,18,10769,18\n16,878,53,16,18,16,16,18,16\n35,10749,10757,18,18,18,18,18,18\n80,18,10748,18,10749,18,18,10749,18\n28,18,36,35,18,10751,28,18,36\n18,10749,10769,35,18,10402,35,18,10402\n28,12,878,18,10749,10769,18,10749,10769\n35,10749,35,14,10402,10751,14,10402,10751\n80,18,9648,18,53,18,18,53,18\n80,9648,53,80,53,80,80,9648,53\n12,16,35,18,1115,18,12,16,35\n18,10749,10756,80,18,80,80,18,80\n35,18,35,18,36,10756,18,36,10756\n18,10769,18,14,27,10756,14,27,10756\n28,12,28,18,18,18,18,18,18\n80,18,53,35,80,18,35,80,18\n18,18,18,16,35,14,18,18,18\n80,18,80,28,9648,53,80,18,80\n80,53,80,80,18,9648,80,18,9648\n28,12,28,16,35,10751,28,12,28\n18,9648,878,80,18,9648,80,18,9648\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;And this is the program output:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Number of attributes in model = 9&lt;/p&gt;\n\n&lt;p&gt;Number of samples = 300&lt;/p&gt;\n\n&lt;p&gt;Summary: Relation Name:  movie_data&lt;/p&gt;\n\n&lt;p&gt;Num Instances:  300&lt;/p&gt;\n\n&lt;p&gt;Num Attributes: 9&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    Name                      Type  Nom  Int Real     Missing      Unique  Dist\n  1 movie1_one                 Nom 100%   0%   0%     0 /  0%     2 /  1%    11 \n  2 movie1_two                 Nom 100%   0%   0%     0 /  0%     0 /  0%    20 \n  3 movie1_three               Nom 100%   0%   0%     0 /  0%     0 /  0%    24 \n  4 movie2_one                 Nom 100%   0%   0%     0 /  0%     1 /  0%    11 \n  5 movie2_two                 Nom 100%   0%   0%     0 /  0%     0 /  0%    20 \n  6 movie2_three               Nom 100%   0%   0%     0 /  0%     1 /  0%    22 \n  7 decision_one               Nom 100%   0%   0%     0 /  0%     0 /  0%     9 \n  8 decision_two               Nom 100%   0%   0%     0 /  0%     1 /  0%    19 \n  9 decision_three             Nom 100%   0%   0%     0 /  0%     2 /  1%    25 \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Expected values: 53, Predicted values: 53&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 10749&lt;/p&gt;\n\n&lt;p&gt;Expected values: 16, Predicted values: 53&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 18&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 10769&lt;/p&gt;\n\n&lt;p&gt;Expected values: 36, Predicted values: 36&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10402, Predicted values: 10769&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10769, Predicted values: 878&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10751, Predicted values: 35&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 18&lt;/p&gt;\n\n&lt;p&gt;Expected values: 53, Predicted values: 53&lt;/p&gt;\n\n&lt;p&gt;Expected values: 35, Predicted values: 35&lt;/p&gt;\n\n&lt;p&gt;Expected values: 80, Predicted values: 10756&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10756, Predicted values: 35&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10756, Predicted values: 18&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 10756&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 53&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 18&lt;/p&gt;\n\n&lt;p&gt;Expected values: 80, Predicted values: 80&lt;/p&gt;\n\n&lt;p&gt;Expected values: 9648, Predicted values: 80&lt;/p&gt;\n\n&lt;p&gt;Expected values: 28, Predicted values: 10756&lt;/p&gt;\n\n&lt;p&gt;Expected values: 9648, Predicted values: 878&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 18&lt;/p&gt;\n\n&lt;p&gt;Expected values: 14, Predicted values: 99&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10769, Predicted values: 18&lt;/p&gt;\n\n&lt;p&gt;Expected values: 35, Predicted values: 10749&lt;/p&gt;\n\n&lt;p&gt;Expected values: 27, Predicted values: 27&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10757, Predicted values: 99&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10769, Predicted values: 18&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10748, Predicted values: 53&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 35&lt;/p&gt;\n\n&lt;p&gt;Expected values: 14, Predicted values: 14&lt;/p&gt;\n\n&lt;p&gt;Expected values: 28, Predicted values: 10756&lt;/p&gt;\n\n&lt;p&gt;Expected values: 10402, Predicted values: 10751&lt;/p&gt;\n\n&lt;p&gt;Expected values: 35, Predicted values: 80&lt;/p&gt;\n\n&lt;p&gt;Expected values: 53, Predicted values: 35&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 10756&lt;/p&gt;\n\n&lt;p&gt;Expected values: 35, Predicted values: 18&lt;/p&gt;\n\n&lt;p&gt;Expected values: 14, Predicted values: 14&lt;/p&gt;\n\n&lt;p&gt;Expected values: 18, Predicted values: 53&lt;/p&gt;\n\n&lt;p&gt;Number correct: 12.0&lt;/p&gt;\n\n&lt;p&gt;Number incorrect: 28.0&lt;/p&gt;\n\n&lt;p&gt;Percent correct: 30.000002%&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;As you can see it is only searching for one number to predict, how can I change this so it looks for the last 3? Any help is appreciated.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[]}
{"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":5,"created_utc":1386290231,"selftext":"I want to make a deep belief network working with music. The idea is to use the complex-valued output of an FFT or Constant-Q transform as an input to the net. \n\nThis is cool because I can run the net backwards, do an inverse transform, and generate sound.\n\nAnyhow, I've read Geoffrey Hinton's suggestions on how to do a real-valued RBM, but I would like to know how to do the same for complex numbers. I've seen complex-valued RBMs referred to in books, but the books were too theoretical, I'm looking for nuts and bolts advice for how to implement it. Even better, some example code. ","is_self":true,"title":"How to implement a complex-valued RBM?","subreddit_id":"t5_2r3gv","author":"skywavetransform","url":"http://www.reddit.com/r/MachineLearning/comments/1s7dc6/how_to_implement_a_complexvalued_rbm/","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1s7dc6/how_to_implement_a_complexvalued_rbm/","score":5,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":6,"user_reports":[],"id":"1s7dc6","thumbnail":"self","edited":false,"report_reasons":null,"distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to make a deep belief network working with music. The idea is to use the complex-valued output of an FFT or Constant-Q transform as an input to the net. &lt;/p&gt;\n\n&lt;p&gt;This is cool because I can run the net backwards, do an inverse transform, and generate sound.&lt;/p&gt;\n\n&lt;p&gt;Anyhow, I&amp;#39;ve read Geoffrey Hinton&amp;#39;s suggestions on how to do a real-valued RBM, but I would like to know how to do the same for complex numbers. I&amp;#39;ve seen complex-valued RBMs referred to in books, but the books were too theoretical, I&amp;#39;m looking for nuts and bolts advice for how to implement it. Even better, some example code. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411508308}
{"is_self":true,"selftext":"So, I have been running the HITS-algorithm on my graph, but I think I have a problem. I don't know how to define convergence. All the material I can find on HITS-algorithms takes the number of iterations as part of the input. This seems arbitrary, because different graphs will converge at different rates. So, I tried to create a while loop that stops at convergence, but I am not sure under what conditions I know that convergence has been reached. I have tried two methods:\n\n1. Score convergence. I check to see whether the normalization factor is still changing. However, this seems to be problematic, because a) all programming languages I know of store decimal numbers using approximation, so a=3.7, b=3.7; a==b: will sometimes return false and b) convergence doesn't really mean that the values stop changing at all (right?), but that they stop changing significantly because the scores infinitely approach some value. So, where do we draw the line? At 1e-200...?\n\n2. Rank convergence. I instead check \"rank convergence\" to see if the ranking did not change from one iteration to the other. However, I then asked myself why I need to normalize the scores if I can just check the ranking. I have implemented this rank converegence with and without normalization. With normalization took 137 iterations to converge and without took 107. I was surprised by this. They also return similar but different lists. The list without normalization seems stronger, because the list with normalization has a lot of nodes with authority or hubs scores of zero (about 60% of them), so they cannot be reliably ranked against one another.\n\nCan anyone shed light on this?","created_utc":1386444341,"ups":6,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"title":"HITS-algorithm - how to decide when the scores have converged? x-post from r/DataMining","author":"kezalb","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1sc0lz/hitsalgorithm_how_to_decide_when_the_scores_have/","over_18":false,"num_comments":4,"user_reports":[],"id":"1sc0lz","gilded":0,"media_embed":{},"secure_media_embed":{},"domain":"self.MachineLearning","score":6,"permalink":"/r/MachineLearning/comments/1sc0lz/hitsalgorithm_how_to_decide_when_the_scores_have/","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I have been running the HITS-algorithm on my graph, but I think I have a problem. I don&amp;#39;t know how to define convergence. All the material I can find on HITS-algorithms takes the number of iterations as part of the input. This seems arbitrary, because different graphs will converge at different rates. So, I tried to create a while loop that stops at convergence, but I am not sure under what conditions I know that convergence has been reached. I have tried two methods:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Score convergence. I check to see whether the normalization factor is still changing. However, this seems to be problematic, because a) all programming languages I know of store decimal numbers using approximation, so a=3.7, b=3.7; a==b: will sometimes return false and b) convergence doesn&amp;#39;t really mean that the values stop changing at all (right?), but that they stop changing significantly because the scores infinitely approach some value. So, where do we draw the line? At 1e-200...?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Rank convergence. I instead check &amp;quot;rank convergence&amp;quot; to see if the ranking did not change from one iteration to the other. However, I then asked myself why I need to normalize the scores if I can just check the ranking. I have implemented this rank converegence with and without normalization. With normalization took 137 iterations to converge and without took 107. I was surprised by this. They also return similar but different lists. The list without normalization seems stronger, because the list with normalization has a lot of nodes with authority or hubs scores of zero (about 60% of them), so they cannot be reliably ranked against one another.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Can anyone shed light on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411501286,"edited":1386452472,"downs":0,"distinguished":null,"report_reasons":null,"thumbnail":"self"}
{"score":0,"permalink":"/r/MachineLearning/comments/1saqj0/make_rate_and_comment_on_the_machine_learning_map/","domain":"self.MachineLearning","secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":6,"user_reports":[],"id":"1saqj0","over_18":false,"thumbnail":"self","downs":0,"distinguished":null,"report_reasons":null,"edited":false,"retrieved_on":1411503240,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, in another thread I was commenting in I saw this sick map posted by &lt;a href=\"/u/Jay_De\"&gt;/u/Jay_De&lt;/a&gt; &lt;a href=\"http://qph.is.quoracdn.net/main-qimg-7caa00a2ec674c434900d97d584a8dc4?convert_to_webp=true\"&gt;The Machine Learning Map Map&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s &lt;a href=\"http://imgur.com/1KHL9b5\"&gt;My Map&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;Rules: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Be nice&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Make a map&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Post your map and your comment/advice for the map above you&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"link_flair_css_class":null,"ups":0,"author_flair_css_class":null,"created_utc":1386391959,"selftext":"Hey everyone, in another thread I was commenting in I saw this sick map posted by /u/Jay_De [The Machine Learning Map Map](http://qph.is.quoracdn.net/main-qimg-7caa00a2ec674c434900d97d584a8dc4?convert_to_webp=true)\n\nHere's [My Map](http://imgur.com/1KHL9b5). \n\nRules: \n\n\n1. Be nice\n\n2. Make a map\n\n3. Post your map and your comment/advice for the map above you\n\n","is_self":true,"url":"http://www.reddit.com/r/MachineLearning/comments/1saqj0/make_rate_and_comment_on_the_machine_learning_map/","title":"Make, Rate, and Comment On the Machine Learning Map Above You (Blank Map Inside)","author":"Badoosker","subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","stickied":false,"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null}
{"thumbnail":"default","edited":false,"report_reasons":null,"distinguished":null,"downs":0,"mod_reports":[],"selftext_html":null,"retrieved_on":1411504020,"domain":"archive.ics.uci.edu","permalink":"/r/MachineLearning/comments/1sa7fi/the_starcraft_2_dataset_using_several_thousand/","score":73,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":11,"id":"1sa7fi","user_reports":[],"title":"The Starcraft 2 dataset, using several thousand games and 20 different variables associated with expertise, has been uploaded to the UCI machine learning repository.","author":"rmnature1","subreddit_id":"t5_2r3gv","url":"http://archive.ics.uci.edu/ml/datasets/SkillCraft1+Master+Table+Dataset","stickied":false,"subreddit":"MachineLearning","banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":73,"created_utc":1386376442,"selftext":"","is_self":false}
{"author":"jasonb","title":"Machine Learning Matters","subreddit_id":"t5_2r3gv","url":"http://machinelearningmastery.com/machine-learning-matters/","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":0,"created_utc":1386527823,"selftext":"","is_self":false,"thumbnail":"http://d.thumbs.redditmedia.com/ruwfw9jAbZ0gXl43.jpg","edited":false,"report_reasons":null,"distinguished":null,"downs":0,"selftext_html":null,"mod_reports":[],"retrieved_on":1411497850,"domain":"machinelearningmastery.com","permalink":"/r/MachineLearning/comments/1secuw/machine_learning_matters/","score":0,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":0,"id":"1secuw","user_reports":[]}
{"stickied":false,"subreddit":"MachineLearning","url":"http://mcscostruzioni.com","author":"afsdg1242","title":"LAVORI IN CARTONGESSO, CONTROSOFFITTI,PARETI REI","subreddit_id":"t5_2r3gv","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"author_flair_css_class":null,"ups":0,"media":null,"link_flair_css_class":null,"is_self":false,"selftext":"","created_utc":1386525213,"report_reasons":null,"distinguished":null,"downs":0,"edited":false,"thumbnail":"default","retrieved_on":1411497984,"selftext_html":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1se9eu/lavori_in_cartongesso_controsoffittipareti_rei/","score":0,"domain":"mcscostruzioni.com","num_comments":0,"user_reports":[],"id":"1se9eu","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0}
{"downs":0,"distinguished":null,"report_reasons":null,"edited":false,"thumbnail":"default","retrieved_on":1411498649,"selftext_html":null,"mod_reports":[],"score":0,"permalink":"/r/MachineLearning/comments/1sdspn/xpost_ideas_for_applications_of_nns/","domain":"reddit.com","user_reports":[],"num_comments":9,"id":"1sdspn","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/artificial/comments/1sdro7/ideas_for_applications_of_nns/","title":"[X-Post] Ideas for applications of NNs?","subreddit_id":"t5_2r3gv","author":"aszkid","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"ups":0,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1386506847,"selftext":""}
{"created_utc":1386506559,"selftext":"","is_self":false,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":37,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"title":"Vowpal Wabbit for the uninitiated.","author":"qkdhfjdjdhd","subreddit_id":"t5_2r3gv","url":"http://zinkov.com/posts/2013-08-13-vowpal-tutorial/","stickied":false,"subreddit":"MachineLearning","media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"user_reports":[],"num_comments":0,"id":"1sdskp","domain":"zinkov.com","permalink":"/r/MachineLearning/comments/1sdskp/vowpal_wabbit_for_the_uninitiated/","score":37,"selftext_html":null,"mod_reports":[],"retrieved_on":1411498655,"thumbnail":"http://c.thumbs.redditmedia.com/4gpts10PSRSLDJHJ.jpg","edited":false,"distinguished":null,"report_reasons":null,"downs":0}
{"retrieved_on":1411499959,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am someone who learns by interacting and feeling things.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"self","num_comments":14,"id":"1scwqc","user_reports":[],"over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":11,"permalink":"/r/MachineLearning/comments/1scwqc/is_there_interactive_example_of_neural_network_i/","domain":"self.MachineLearning","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1scwqc/is_there_interactive_example_of_neural_network_i/","title":"Is there interactive example of neural network I can play with, similar to how the \"the game of life\" teaches you about cellular automata?","author":"reginaldtato","subreddit_id":"t5_2r3gv","is_self":true,"created_utc":1386468417,"selftext":"I am someone who learns by interacting and feeling things.","ups":11,"author_flair_css_class":null,"media":null,"link_flair_css_class":null}
{"is_self":true,"created_utc":1386618918,"selftext":"Say I have a list of timestamps which represent completion time for a piece of work. These timestamps are also categorized, but that doesn't necessarily need to be a factor. The piece of data we're trying to predict is the start time. We can generalize that tasks don't overlap. A naive approach would be to take the end time of one task and set that as the start time for the next consecutive task, but we can't assume the end time of one task corresponds to the start time of the next consecutive task.\n\nThe user can manually enter actual values when they are wrong, and this can be used for training the data. My data set of trained data would be in the thousands.\n\nI'm wondering if there's any class of algorithms, papers, etc that I could be searching for that'd cover this topic.","ups":2,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"title":"Ask MachineLearning: Algorithm to estimate duration given only discrete events","author":"IllegalThings","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1shhop/ask_machinelearning_algorithm_to_estimate/","over_18":false,"id":"1shhop","num_comments":2,"user_reports":[],"gilded":0,"media_embed":{},"secure_media_embed":{},"domain":"self.MachineLearning","score":2,"permalink":"/r/MachineLearning/comments/1shhop/ask_machinelearning_algorithm_to_estimate/","mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I have a list of timestamps which represent completion time for a piece of work. These timestamps are also categorized, but that doesn&amp;#39;t necessarily need to be a factor. The piece of data we&amp;#39;re trying to predict is the start time. We can generalize that tasks don&amp;#39;t overlap. A naive approach would be to take the end time of one task and set that as the start time for the next consecutive task, but we can&amp;#39;t assume the end time of one task corresponds to the start time of the next consecutive task.&lt;/p&gt;\n\n&lt;p&gt;The user can manually enter actual values when they are wrong, and this can be used for training the data. My data set of trained data would be in the thousands.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if there&amp;#39;s any class of algorithms, papers, etc that I could be searching for that&amp;#39;d cover this topic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411493330,"edited":false,"downs":0,"report_reasons":null,"distinguished":null,"thumbnail":"self"}
{"is_self":false,"created_utc":1386608911,"selftext":"","author_flair_css_class":null,"ups":53,"link_flair_css_class":null,"media":null,"secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","title":"Yann LeCun announces he will be director of the new Facebook AI research group","author":"CmdrSammo","subreddit_id":"t5_2r3gv","url":"https://www.facebook.com/yann.lecun/posts/10151728212367143","over_18":false,"num_comments":38,"user_reports":[],"id":"1sh229","media_embed":{},"gilded":0,"secure_media_embed":{},"domain":"facebook.com","permalink":"/r/MachineLearning/comments/1sh229/yann_lecun_announces_he_will_be_director_of_the/","score":53,"selftext_html":null,"mod_reports":[],"retrieved_on":1411493981,"edited":false,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"http://a.thumbs.redditmedia.com/KwsKvt6tvwvXAnkH.jpg"}
{"permalink":"/r/MachineLearning/comments/1sgx21/4_virtual_environments_for_data_science/","score":6,"domain":"jeroenjanssens.com","secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":1,"id":"1sgx21","user_reports":[],"over_18":false,"thumbnail":"default","report_reasons":null,"distinguished":null,"downs":0,"edited":false,"retrieved_on":1411494179,"selftext_html":null,"mod_reports":[],"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":6,"created_utc":1386605444,"selftext":"","is_self":false,"url":"http://jeroenjanssens.com/2013/12/07/lean-mean-data-science-machine.html","subreddit_id":"t5_2r3gv","title":"4 Virtual Environments for Data Science","author":"eroenj","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null}
{"secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"subreddit":"MachineLearning","stickied":false,"subreddit_id":"t5_2r3gv","title":"I'm working on detecting violent scenes in audio data and wanted to know if there is any labelled dataset available for this purpose.﻿","author":"anantzoid","url":"http://www.multimediaeval.org/mediaeval2013/placing2013/index.html","is_self":false,"created_utc":1386595372,"selftext":"","ups":1,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"selftext_html":null,"mod_reports":[],"retrieved_on":1411494609,"edited":false,"downs":0,"distinguished":null,"report_reasons":null,"thumbnail":"default","over_18":false,"user_reports":[],"num_comments":3,"id":"1sglp7","gilded":0,"media_embed":{},"secure_media_embed":{},"domain":"multimediaeval.org","score":1,"permalink":"/r/MachineLearning/comments/1sglp7/im_working_on_detecting_violent_scenes_in_audio/"}
{"thumbnail":"self","report_reasons":null,"distinguished":null,"downs":0,"edited":1386597288,"retrieved_on":1411494995,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;following Problem. I&amp;#39;m trying to classify xy coordinates as above (output +1) or below(output -1) a parabola. For this I am trying to use a neural network with tanh() activation functions and set the treshhold at 0 ( so if the net outpus a 0.0001, thats +1,0.000 and smaller is -1).&lt;/p&gt;\n\n&lt;p&gt;How exactly do I calculate the error/the adjustment to the weights when doing this? Just use the derivative of tanh() in combination with the difference between my (binary) output and the (binary) target?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"permalink":"/r/MachineLearning/comments/1sgcdi/question_on_backpropagation_in_a_multi_layer/","score":3,"domain":"self.MachineLearning","secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":8,"id":"1sgcdi","user_reports":[],"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1sgcdi/question_on_backpropagation_in_a_multi_layer/","subreddit_id":"t5_2r3gv","title":"Question on Backpropagation in a Multi Layer Perceptron with Binary Classification","author":"DeusexConstantia","stickied":false,"subreddit":"MachineLearning","banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":3,"selftext":"Hi all,\n\nfollowing Problem. I'm trying to classify xy coordinates as above (output +1) or below(output -1) a parabola. For this I am trying to use a neural network with tanh() activation functions and set the treshhold at 0 ( so if the net outpus a 0.0001, thats +1,0.000 and smaller is -1).\n\nHow exactly do I calculate the error/the adjustment to the weights when doing this? Just use the derivative of tanh() in combination with the difference between my (binary) output and the (binary) target?\n","created_utc":1386581962,"is_self":true}
{"retrieved_on":1411495509,"mod_reports":[],"selftext_html":null,"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"default","num_comments":3,"id":"1sfzfy","user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1sfzfy/machine_learning_tutorial_gibbs_sampling/","score":22,"domain":"iamtrask.squarespace.com","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","url":"https://iamtrask.squarespace.com/blog/2013/12/9/machine-learning-gibbs-sampling-tutorial","title":"Machine Learning Tutorial - Gibbs Sampling","author":"u8mybrownies","subreddit_id":"t5_2r3gv","is_self":false,"created_utc":1386567395,"selftext":"","author_flair_css_class":null,"ups":22,"media":null,"link_flair_css_class":null}
{"author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"title":"Problem with class-imbalance in the reduction of multi-label text classification to binary classification","author":"richizy","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1sf91b/problem_with_classimbalance_in_the_reduction_of/","subreddit":"MachineLearning","stickied":false,"created_utc":1386549192,"selftext":"I have a set of around 300k text examples. As mentioned in the title, each example has at least one label, and there are only 100 possible unique labels. I've reduced this problem down to binary classification for Vowpal Wabbit by taking advantage of namespaces, e.g.  \n\n\nFrom:\n    healthy fruit | bananas oranges jack fruit\n    evil monkey | bipedal organism family guy\n    ...  \n\n\nTo:\n    1 |healthy bananas oranges jack fruit\n    1 |fruit bananas oranges jack fruit\n    0 |evil bananas oranges jack fruit\n    0 |monkey bananas oranges jack fruit\n    0 |healthy bipedal organism family guy\n    0 |fruit bipedal organism family guy\n    1 |evil bipedal organism family guy\n    1 |monkey bipedal organism family guy\n    ...  \n\n\nI'm using the default options provided by VW (which I think is online SGD, with the squared loss function). I'm using the squared loss because it closely resembles the Hamming Loss.  \n\nAfter training, when testing on the same training set, I've noticed that all examples are predicted with the '0' label... which is one way of minimizing loss, I guess. At this point, I'm not sure what to do. I was thinking of using cost-sensitive one-against-all classification to try to balance the classes, but reducing multi-label to multi-class is unfeasible since there exists 2^100 label combinations. I'm wondering if anyone else have any suggestions.  ","is_self":true,"link_flair_css_class":null,"media":null,"ups":3,"author_flair_css_class":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a set of around 300k text examples. As mentioned in the title, each example has at least one label, and there are only 100 possible unique labels. I&amp;#39;ve reduced this problem down to binary classification for Vowpal Wabbit by taking advantage of namespaces, e.g.  &lt;/p&gt;\n\n&lt;p&gt;From:\n    healthy fruit | bananas oranges jack fruit\n    evil monkey | bipedal organism family guy\n    ...  &lt;/p&gt;\n\n&lt;p&gt;To:\n    1 |healthy bananas oranges jack fruit\n    1 |fruit bananas oranges jack fruit\n    0 |evil bananas oranges jack fruit\n    0 |monkey bananas oranges jack fruit\n    0 |healthy bipedal organism family guy\n    0 |fruit bipedal organism family guy\n    1 |evil bipedal organism family guy\n    1 |monkey bipedal organism family guy\n    ...  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using the default options provided by VW (which I think is online SGD, with the squared loss function). I&amp;#39;m using the squared loss because it closely resembles the Hamming Loss.  &lt;/p&gt;\n\n&lt;p&gt;After training, when testing on the same training set, I&amp;#39;ve noticed that all examples are predicted with the &amp;#39;0&amp;#39; label... which is one way of minimizing loss, I guess. At this point, I&amp;#39;m not sure what to do. I was thinking of using cost-sensitive one-against-all classification to try to balance the classes, but reducing multi-label to multi-class is unfeasible since there exists 2&lt;sup&gt;100&lt;/sup&gt; label combinations. I&amp;#39;m wondering if anyone else have any suggestions.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411496539,"thumbnail":"self","edited":1386549383,"downs":0,"report_reasons":null,"distinguished":null,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"user_reports":[],"num_comments":0,"id":"1sf91b","domain":"self.MachineLearning","score":3,"permalink":"/r/MachineLearning/comments/1sf91b/problem_with_classimbalance_in_the_reduction_of/"}
{"score":4,"permalink":"/r/MachineLearning/comments/1sf65j/learning_random_forests_on_the_gpu_pdf/","domain":"biglearn.org","secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":7,"id":"1sf65j","user_reports":[],"over_18":false,"thumbnail":"default","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"retrieved_on":1411496657,"selftext_html":null,"mod_reports":[],"media":null,"link_flair_css_class":null,"ups":4,"author_flair_css_class":null,"created_utc":1386547254,"selftext":"","is_self":false,"url":"http://biglearn.org/2013/files/papers/biglearning2013_submission_19.pdf","author":"cypherx","title":"Learning Random Forests on the GPU [pdf]","subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","stickied":false,"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null}
{"domain":"machine-and-repair.webs.com","permalink":"/r/MachineLearning/comments/1sksjw/machine_repair_guide/","score":1,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":0,"id":"1sksjw","user_reports":[],"thumbnail":"default","edited":false,"report_reasons":null,"distinguished":null,"downs":0,"mod_reports":[],"selftext_html":null,"retrieved_on":1411488341,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":1,"created_utc":1386709633,"selftext":"","is_self":false,"title":"Machine &amp; Repair Guide","author":"andycourtney","subreddit_id":"t5_2r3gv","url":"http://machine-and-repair.webs.com","stickied":false,"subreddit":"MachineLearning","banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null}
{"edited":false,"distinguished":null,"report_reasons":null,"downs":0,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OK people, now that we&amp;#39;ve done the very math-intense Chapter 2, it&amp;#39;s time to move on. Next up are Linear Models for Regression and Classification. If we mean to move this thing along, we really need to cover the next two chapters by Christmas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411490175,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1sjm8f/prml_chaps_3_4_study_group_discussion_dec_1024/","score":4,"over_18":false,"num_comments":1,"id":"1sjm8f","user_reports":[],"media_embed":{},"gilded":0,"secure_media_embed":{},"stickied":false,"subreddit":"MachineLearning","title":"PRML Chaps 3 &amp; 4 Study Group discussion (Dec 10-24, 2013) (xpost from /r/mlstudy)","subreddit_id":"t5_2r3gv","author":"srkiboy83","url":"http://www.reddit.com/r/MachineLearning/comments/1sjm8f/prml_chaps_3_4_study_group_discussion_dec_1024/","secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"author_flair_css_class":null,"ups":4,"media":null,"link_flair_css_class":null,"is_self":true,"created_utc":1386680771,"selftext":"OK people, now that we've done the very math-intense Chapter 2, it's time to move on. Next up are Linear Models for Regression and Classification. If we mean to move this thing along, we really need to cover the next two chapters by Christmas."}
{"num_comments":4,"user_reports":[],"id":"1sjewn","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":10,"permalink":"/r/MachineLearning/comments/1sjewn/what_is_the_benefit_of_using_neural_networks_as/","domain":"self.MachineLearning","retrieved_on":1411490501,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just read &lt;a href=\"http://www.inference.phy.cam.ac.uk/mackay/gp.pdf\"&gt;this paper&lt;/a&gt; (PDF) by MacKay, which I thought was very interesting. &lt;/p&gt;\n\n&lt;p&gt;With so much emphasis on neural networks recently, what are examples of problems where they really excel over Gaussian Processes (which can often be capable of identical mechanics)? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"downs":0,"distinguished":null,"report_reasons":null,"edited":false,"thumbnail":"self","is_self":true,"selftext":"I just read [this paper](http://www.inference.phy.cam.ac.uk/mackay/gp.pdf) (PDF) by MacKay, which I thought was very interesting. \n\nWith so much emphasis on neural networks recently, what are examples of problems where they really excel over Gaussian Processes (which can often be capable of identical mechanics)? ","created_utc":1386670168,"ups":10,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1sjewn/what_is_the_benefit_of_using_neural_networks_as/","author":"jamesmcm","title":"What is the benefit of using Neural Networks as opposed to Gaussian Processes?","subreddit_id":"t5_2r3gv"}
{"retrieved_on":1411490588,"mod_reports":[],"selftext_html":null,"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"default","id":"1sjcuu","num_comments":0,"user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1sjcuu/cs_series_automatic_micro_bagging_machine_double/","score":1,"domain":"machineryshops.com","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","url":"http://www.machineryshops.com/product/Double-Hopper-Type.html","title":"CS Series Automatic Micro Bagging Machine (Double Hopper&amp;Belt Feeder Type)","subreddit_id":"t5_2r3gv","author":"Niki_Lei","is_self":false,"created_utc":1386667029,"selftext":"","author_flair_css_class":null,"ups":1,"link_flair_css_class":null,"media":null}
{"is_self":true,"created_utc":1386650842,"selftext":"I have a project in mind on which I would need to create an AI that would analyze ''chat logs'' and detect negative behavior (gaming context).  I do have some knowledge in AI, but not much with words/context. Can I get some guidance on how to plan and where I should look for not too hard structure?","author_flair_css_class":null,"ups":2,"link_flair_css_class":null,"media":null,"secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"stickied":false,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","title":"Semantic Learning?","author":"fawar","url":"http://www.reddit.com/r/MachineLearning/comments/1siwai/semantic_learning/","over_18":false,"num_comments":1,"id":"1siwai","user_reports":[],"media_embed":{},"gilded":0,"secure_media_embed":{},"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1siwai/semantic_learning/","score":2,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a project in mind on which I would need to create an AI that would analyze &amp;#39;&amp;#39;chat logs&amp;#39;&amp;#39; and detect negative behavior (gaming context).  I do have some knowledge in AI, but not much with words/context. Can I get some guidance on how to plan and where I should look for not too hard structure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411491298,"edited":false,"distinguished":null,"report_reasons":null,"downs":0,"thumbnail":"self"}
{"retrieved_on":1411491407,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to find, given a user-input vector of 65 variables/features (some of which may be correlated), the nearest\ntraining observation.&lt;/p&gt;\n\n&lt;p&gt;On the surface this is a classic K nearest neighbor problem. That is indeed \nwhat we started out with. But the problem is in scaling the axes such that the euclidean \ndistance between observations reflects their actual (dis)similarity. Plus, see the curse of dimensionality. We&amp;#39;ve tried\nscaling each variable and applying axis weights based on &amp;quot;expert opinion&amp;quot;. \nBut this is highly arbitrary, does not account for colinearity, and is hard to justify.&lt;/p&gt;\n\n&lt;p&gt;What are some other options?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve explored PCA to reduce the dimensionality and come up with more appropriate\naxes. This helps reduce colinearlity but I&amp;#39;m still left with the arbitrary axis weighting problem.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at canonical correlation and correspondence analysis and they seem \nappropriate only when you have some sense of dependent vs independent variables \n(which my model does not). I&amp;#39;m merely trying to predict which training observation is most similar to each\ntest observation. &lt;/p&gt;\n\n&lt;p&gt;I hesitate to call it a classification problem as each training observation is \ninherently a class by itself. IOW, by definition, there will be only a single observation\nper class in any training set. Are there any negative implications to handling \ndatasets with &amp;quot;singleton&amp;quot; classes in typical machine learning classifiers? What classifiers might be most appropriate for this case?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","distinguished":null,"report_reasons":null,"downs":0,"edited":1386649201,"thumbnail":"self","num_comments":10,"user_reports":[],"id":"1sitku","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1sitku/classification_problem_where_each_training/","score":3,"domain":"self.MachineLearning","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","url":"http://www.reddit.com/r/MachineLearning/comments/1sitku/classification_problem_where_each_training/","subreddit_id":"t5_2r3gv","title":"Classification problem where each training observation is inherently a separate class.","author":"perrygeo","is_self":true,"selftext":"I am trying to find, given a user-input vector of 65 variables/features (some of which may be correlated), the nearest\ntraining observation.\n\nOn the surface this is a classic K nearest neighbor problem. That is indeed \nwhat we started out with. But the problem is in scaling the axes such that the euclidean \ndistance between observations reflects their actual (dis)similarity. Plus, see the curse of dimensionality. We've tried\nscaling each variable and applying axis weights based on \"expert opinion\". \nBut this is highly arbitrary, does not account for colinearity, and is hard to justify.\n\nWhat are some other options?\n\nI've explored PCA to reduce the dimensionality and come up with more appropriate\naxes. This helps reduce colinearlity but I'm still left with the arbitrary axis weighting problem.\n\nI've looked at canonical correlation and correspondence analysis and they seem \nappropriate only when you have some sense of dependent vs independent variables \n(which my model does not). I'm merely trying to predict which training observation is most similar to each\ntest observation. \n\nI hesitate to call it a classification problem as each training observation is \ninherently a class by itself. IOW, by definition, there will be only a single observation\nper class in any training set. Are there any negative implications to handling \ndatasets with \"singleton\" classes in typical machine learning classifiers? What classifiers might be most appropriate for this case?\n\nAny suggestions welcome.","created_utc":1386648972,"author_flair_css_class":null,"ups":3,"link_flair_css_class":null,"media":null}
{"domain":"probcomp.csail.mit.edu","score":53,"permalink":"/r/MachineLearning/comments/1sitc9/bayesdb_query_the_probable_implications_of_your/","over_18":false,"num_comments":6,"user_reports":[],"id":"1sitc9","gilded":0,"media_embed":{},"secure_media_embed":{},"edited":false,"downs":0,"distinguished":null,"report_reasons":null,"thumbnail":"http://f.thumbs.redditmedia.com/iceG8ZbzHxsp-AZ_.jpg","selftext_html":null,"mod_reports":[],"retrieved_on":1411491415,"ups":53,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1386648806,"selftext":"","subreddit":"MachineLearning","stickied":false,"title":"BayesDB - Query the probable implications of your data","subreddit_id":"t5_2r3gv","author":"rrenaud","url":"http://probcomp.csail.mit.edu/bayesdb/","secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null}
{"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"user_reports":[],"num_comments":8,"id":"1sia4v","domain":"self.MachineLearning","score":2,"permalink":"/r/MachineLearning/comments/1sia4v/looking_for_some_direction_on_my_first_ml_problem/","mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What I have is a database of fields, and a collection of strings, that are comprised of those fields with some level of distortion. I need to match those things, to the entries in the database&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Animal: Bear&lt;/li&gt;\n&lt;li&gt;Fur: Brown&lt;/li&gt;\n&lt;li&gt;Weight: 544 kg&lt;/li&gt;\n&lt;li&gt;Location: Alaska&lt;/li&gt;\n&lt;li&gt;Name: Greg&lt;/li&gt;\n&lt;li&gt;Hat: Fanciful&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And then a string that basically takes some of those fields at random and then distorts them, runs them together and may add trash data to the string. Some examples of how these could be distorted:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;BrowBear 544 #982385 Alsk &lt;/li&gt;\n&lt;li&gt;ALASALASKA GregFanciful BeaBear &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;There may be strings that follow the same pattern of distortion, and there may not be. &lt;/p&gt;\n\n&lt;p&gt;My task is to match the distorted strings, to their respective entries in the database. &lt;/p&gt;\n\n&lt;p&gt;I’m not looking for an answer, but rather some directions to go. Most of my interest up until this point has focused on things like Neural Nets, CLA/ HTM, Bayesian Networks, Deep Learning, Neo4j, you kind of see the pattern, I like things involving networks of information, or anything that tries to model the human brain. &lt;/p&gt;\n\n&lt;p&gt;But I’m not so sure those models would work well here. &lt;/p&gt;\n\n&lt;p&gt;I’m not looking for an answer, just a direction to head in. If you had to solve this problem, how would you encapsulate all of the possibilities? I have an elastic search cluster set up and I’m currently using it to create a trained data set, mapping the strings to their entries in the database.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411492201,"thumbnail":"self","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"created_utc":1386636333,"selftext":"What I have is a database of fields, and a collection of strings, that are comprised of those fields with some level of distortion. I need to match those things, to the entries in the database\n\nExample:\n\n* Animal: Bear\n* Fur: Brown\n* Weight: 544 kg\n* Location: Alaska\n* Name: Greg\n* Hat: Fanciful\n\nAnd then a string that basically takes some of those fields at random and then distorts them, runs them together and may add trash data to the string. Some examples of how these could be distorted:\n\n* BrowBear 544 #982385 Alsk \n* ALASALASKA GregFanciful BeaBear \n\nThere may be strings that follow the same pattern of distortion, and there may not be. \n\nMy task is to match the distorted strings, to their respective entries in the database. \n\nI’m not looking for an answer, but rather some directions to go. Most of my interest up until this point has focused on things like Neural Nets, CLA/ HTM, Bayesian Networks, Deep Learning, Neo4j, you kind of see the pattern, I like things involving networks of information, or anything that tries to model the human brain. \n\nBut I’m not so sure those models would work well here. \n\nI’m not looking for an answer, just a direction to head in. If you had to solve this problem, how would you encapsulate all of the possibilities? I have an elastic search cluster set up and I’m currently using it to create a trained data set, mapping the strings to their entries in the database.\n\n\n","is_self":true,"media":null,"link_flair_css_class":null,"ups":2,"author_flair_css_class":null,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"author":"iwantedthisusername","title":"Looking for some direction on my first ML problem","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1sia4v/looking_for_some_direction_on_my_first_ml_problem/","subreddit":"MachineLearning","stickied":false}
{"ups":1,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"is_self":true,"created_utc":1386786489,"selftext":"Hi All,\n\nHopefully someone will be able to help me out here, I'm a full stack dev looking to venture in to ML to solve a specific problem. I'm looking for the best reading materials for where to start with this problem and get in to ML. I apologize if this is too generic, I'm trying to get a good place to start that applies to the problem I'm trying to solve.\n\nThe problem; predict the outcome of an event (either a +1 or -1 result) based on a time series of data properties for an object.\n\nI have a dataset that contains a time series. Each time series entry would be structured as {recordId: id, timestamp: eventDate, prop1: value, prop2: value, prop3: value} and so on. For each time series one or more of the properties has changed for a given id. So I can trace the history of this object from inception until +1 or -1 (also a property on the object). I would like to train based on the historical data I have, and then be able to pass in a current object and have it output the probability of a +1 or -1 outcome based on the current properties and the history of the object.\n\nExample data:\n{recordId: 1, eventDate: 1/1/2013, status: 'new', source: 'web', result: 0}\n{recordId: 1, eventDate: 1/2/2013, status: 'in progress', source: 'web', result: 0}\n{recordId: 1, eventDate: 1/3/2013, status: 'resolving', source: 'web', result: +1}\n\n{recordId: 2, eventDate: 1/1/2013, status: 'new', source: 'phone', result: 0}\n{recordId: 2, eventDate: 1/4/2013, status: 'in progress', source: 'phone', result: 0}\n{recordId: 2, eventDate: 1/9/2013, status: 'resolving', source: 'phone', result: -1}\n\nThen I would like to input the following: \n{recordId: 3, eventDate: 1/1/2013, status: 'new', source: 'web', result: 0}\nand have it output the odds this results in a +1 result.\n\nAny help on where to start, books to read, would be super!\n\nThanks!","subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1snfio/where_could_i_learn_more_about_ml_for_this/","title":"Where could I learn more about ML for this specific problem","author":"webdev444","subreddit_id":"t5_2r3gv","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"score":1,"permalink":"/r/MachineLearning/comments/1snfio/where_could_i_learn_more_about_ml_for_this/","domain":"self.MachineLearning","num_comments":1,"id":"1snfio","user_reports":[],"over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"self","retrieved_on":1411484244,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;Hopefully someone will be able to help me out here, I&amp;#39;m a full stack dev looking to venture in to ML to solve a specific problem. I&amp;#39;m looking for the best reading materials for where to start with this problem and get in to ML. I apologize if this is too generic, I&amp;#39;m trying to get a good place to start that applies to the problem I&amp;#39;m trying to solve.&lt;/p&gt;\n\n&lt;p&gt;The problem; predict the outcome of an event (either a +1 or -1 result) based on a time series of data properties for an object.&lt;/p&gt;\n\n&lt;p&gt;I have a dataset that contains a time series. Each time series entry would be structured as {recordId: id, timestamp: eventDate, prop1: value, prop2: value, prop3: value} and so on. For each time series one or more of the properties has changed for a given id. So I can trace the history of this object from inception until +1 or -1 (also a property on the object). I would like to train based on the historical data I have, and then be able to pass in a current object and have it output the probability of a +1 or -1 outcome based on the current properties and the history of the object.&lt;/p&gt;\n\n&lt;p&gt;Example data:\n{recordId: 1, eventDate: 1/1/2013, status: &amp;#39;new&amp;#39;, source: &amp;#39;web&amp;#39;, result: 0}\n{recordId: 1, eventDate: 1/2/2013, status: &amp;#39;in progress&amp;#39;, source: &amp;#39;web&amp;#39;, result: 0}\n{recordId: 1, eventDate: 1/3/2013, status: &amp;#39;resolving&amp;#39;, source: &amp;#39;web&amp;#39;, result: +1}&lt;/p&gt;\n\n&lt;p&gt;{recordId: 2, eventDate: 1/1/2013, status: &amp;#39;new&amp;#39;, source: &amp;#39;phone&amp;#39;, result: 0}\n{recordId: 2, eventDate: 1/4/2013, status: &amp;#39;in progress&amp;#39;, source: &amp;#39;phone&amp;#39;, result: 0}\n{recordId: 2, eventDate: 1/9/2013, status: &amp;#39;resolving&amp;#39;, source: &amp;#39;phone&amp;#39;, result: -1}&lt;/p&gt;\n\n&lt;p&gt;Then I would like to input the following: \n{recordId: 3, eventDate: 1/1/2013, status: &amp;#39;new&amp;#39;, source: &amp;#39;web&amp;#39;, result: 0}\nand have it output the odds this results in a +1 result.&lt;/p&gt;\n\n&lt;p&gt;Any help on where to start, books to read, would be super!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"}
{"thumbnail":"default","edited":false,"distinguished":null,"report_reasons":null,"downs":0,"mod_reports":[],"selftext_html":null,"retrieved_on":1411484253,"domain":"blog.explainmydata.com","permalink":"/r/MachineLearning/comments/1snfbc/mark_zuckerbergs_unexpected_visit_to_nips_the/","score":61,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":19,"user_reports":[],"id":"1snfbc","author":"sergeyfeldman","title":"Mark Zuckerberg's Unexpected Visit to NIPS, the Machine Learning Conference","subreddit_id":"t5_2r3gv","url":"http://blog.explainmydata.com/2013/12/nips-and-zuckerberg-visit.html","stickied":false,"subreddit":"MachineLearning","banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":61,"created_utc":1386786367,"selftext":"","is_self":false}
{"is_self":false,"created_utc":1386782860,"selftext":"","author_flair_css_class":null,"ups":2,"media":null,"link_flair_css_class":null,"link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"stickied":false,"subreddit":"MachineLearning","url":"http://mathbabe.org/2013/12/10/predictive-risk-models-for-prisoners-with-mental-disorders/","author":"AdelleChattre","title":"Predictive risk models for prisoners with mental disorders","subreddit_id":"t5_2r3gv","num_comments":1,"id":"1sn9un","user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1sn9un/predictive_risk_models_for_prisoners_with_mental/","score":2,"domain":"mathbabe.org","retrieved_on":1411484508,"mod_reports":[],"selftext_html":null,"report_reasons":null,"distinguished":null,"downs":0,"edited":false,"thumbnail":"http://c.thumbs.redditmedia.com/1oQP3PIAuLOj3fcn.jpg"}
{"over_18":false,"num_comments":0,"user_reports":[],"id":"1sn59f","media_embed":{},"gilded":0,"secure_media_embed":{},"domain":"nuit-blanche.blogspot.fr","permalink":"/r/MachineLearning/comments/1sn59f/tonight_paris_machine_learning_meetup_6_playing/","score":4,"mod_reports":[],"selftext_html":null,"retrieved_on":1411484701,"edited":false,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"http://f.thumbs.redditmedia.com/7GQWoJ5yZ69w3mae.jpg","is_self":false,"selftext":"","created_utc":1386779794,"author_flair_css_class":null,"ups":4,"media":null,"link_flair_css_class":null,"secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","title":"Tonight, Paris Machine Learning Meetup #6: Playing with Kaggle/ Botnet detection with Neural Networks (Video streaming in French)","author":"compsens","url":"http://nuit-blanche.blogspot.fr/2013/12/paris-machine-learning-meetup-6-playing.html"}
{"edited":false,"distinguished":null,"report_reasons":null,"downs":0,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for an algorithm which basically takes input in the form of a text and then returns an image related to the text, by searching on the web. Procedure could be described as follows&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Extracts keywords from the text string&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Search for the keywords on google images, and get the most relevant image for the keywords&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Decide which is the most relevant image out of the ones extracted in the last step and return it.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I am basically looking for some work already done in this field, otherwise I could start making my own thing now that I am learning machine learning.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So if you know of any such thing, please cite it in the comments below. :)\nEven great if you could give me pointers to do such a thing on my own.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411485032,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1smxhk/how_to_guess_a_relevant_image_corresponding_to_a/","score":0,"over_18":false,"user_reports":[],"num_comments":3,"id":"1smxhk","media_embed":{},"gilded":0,"secure_media_embed":{},"stickied":false,"subreddit":"MachineLearning","title":"How to guess a relevant image corresponding to a text (a news title) via machine learning.","subreddit_id":"t5_2r3gv","author":"tomarina","url":"http://www.reddit.com/r/MachineLearning/comments/1smxhk/how_to_guess_a_relevant_image_corresponding_to_a/","secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"author_flair_css_class":null,"ups":0,"media":null,"link_flair_css_class":null,"is_self":true,"created_utc":1386774124,"selftext":"I am looking for an algorithm which basically takes input in the form of a text and then returns an image related to the text, by searching on the web. Procedure could be described as follows\n\n+ Extracts keywords from the text string\n\n+ Search for the keywords on google images, and get the most relevant image for the keywords\n+ Decide which is the most relevant image out of the ones extracted in the last step and return it.\n+ I am basically looking for some work already done in this field, otherwise I could start making my own thing now that I am learning machine learning.\n\nSo if you know of any such thing, please cite it in the comments below. :)\nEven great if you could give me pointers to do such a thing on my own."}
{"created_utc":1386745853,"selftext":"","is_self":false,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":25,"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"url":"http://www.datatau.com/","subreddit_id":"t5_2r3gv","title":"Friend made a Hacker News for Data Scientists","author":"bloometal","stickied":false,"subreddit":"MachineLearning","secure_media_embed":{},"media_embed":{},"gilded":0,"id":"1smb4x","num_comments":2,"user_reports":[],"over_18":false,"permalink":"/r/MachineLearning/comments/1smb4x/friend_made_a_hacker_news_for_data_scientists/","score":25,"domain":"datatau.com","retrieved_on":1411485982,"selftext_html":null,"mod_reports":[],"thumbnail":"default","report_reasons":null,"distinguished":null,"downs":0,"edited":false}
{"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"subreddit_id":"t5_2r3gv","title":"Citation mining and graph visualization","author":"[deleted]","url":"http://www.reddit.com/r/MachineLearning/comments/1sm1kk/citation_mining_and_graph_visualization/","subreddit":"MachineLearning","stickied":false,"created_utc":1386737668,"selftext":"Hi,\n\nI want to select a graduate program (in philosophy, no less) that attends a number of rather odd desiderata, and for this I want to text-mine publications and call-for-papers for citations in order to trace the citation graphs.\n\nLater on I might use dimensionality reduction if relevant, but for a first approximation I don't expect to have this much structure.\n\nAnyway -- \n\n1) What's a good graph visualization tool that can handle automatically generated node coloring and labeling in some gracious way -- possibly generation dynamic visualizations in Flash or something? GraphViz is too simple, and Mathematica, while more serious about layout algorithms, too awkward.\n\n2) What's a good general strategy -- besides flimsy failure-prone text2pdf + ad hoc regexes -- text mining strategies for reading bibliography and citations sections from pdf files (parsed into text if necessary) so we can get to uniformized last names at least and color-coded institutions?","is_self":true,"media":null,"link_flair_css_class":null,"ups":3,"author_flair_css_class":null,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I want to select a graduate program (in philosophy, no less) that attends a number of rather odd desiderata, and for this I want to text-mine publications and call-for-papers for citations in order to trace the citation graphs.&lt;/p&gt;\n\n&lt;p&gt;Later on I might use dimensionality reduction if relevant, but for a first approximation I don&amp;#39;t expect to have this much structure.&lt;/p&gt;\n\n&lt;p&gt;Anyway -- &lt;/p&gt;\n\n&lt;p&gt;1) What&amp;#39;s a good graph visualization tool that can handle automatically generated node coloring and labeling in some gracious way -- possibly generation dynamic visualizations in Flash or something? GraphViz is too simple, and Mathematica, while more serious about layout algorithms, too awkward.&lt;/p&gt;\n\n&lt;p&gt;2) What&amp;#39;s a good general strategy -- besides flimsy failure-prone text2pdf + ad hoc regexes -- text mining strategies for reading bibliography and citations sections from pdf files (parsed into text if necessary) so we can get to uniformized last names at least and color-coded institutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411486392,"thumbnail":"self","edited":false,"downs":0,"report_reasons":null,"distinguished":null,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":5,"user_reports":[],"id":"1sm1kk","domain":"self.MachineLearning","score":3,"permalink":"/r/MachineLearning/comments/1sm1kk/citation_mining_and_graph_visualization/"}
{"link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1slnwa/nips_2013_just_got_back_from_lake_tahoe/","title":"NIPS 2013 (Just got back from Lake Tahoe)","subreddit_id":"t5_2r3gv","author":"Mrr_Cow","is_self":true,"created_utc":1386728425,"selftext":"I was walking through the harris casino and started wondering how popular is reddit in the ML community. If you were at NIPS you might remember me by my orange \"I support vector machines\" t-shirts. \n\nAnyways I was just a bit curious. ","ups":18,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"retrieved_on":1411486988,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was walking through the harris casino and started wondering how popular is reddit in the ML community. If you were at NIPS you might remember me by my orange &amp;quot;I support vector machines&amp;quot; t-shirts. &lt;/p&gt;\n\n&lt;p&gt;Anyways I was just a bit curious. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"self","user_reports":[],"num_comments":26,"id":"1slnwa","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":18,"permalink":"/r/MachineLearning/comments/1slnwa/nips_2013_just_got_back_from_lake_tahoe/","domain":"self.MachineLearning"}
{"edited":false,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"http://b.thumbs.redditmedia.com/kWn-Pd1Dk5Hjp9Nm.jpg","mod_reports":[],"selftext_html":null,"retrieved_on":1411478363,"domain":"datascienceweekly.org","permalink":"/r/MachineLearning/comments/1sr4lv/free_newsletter_data_science_weekly_issue_3/","score":1,"over_18":false,"num_comments":0,"id":"1sr4lv","user_reports":[],"media_embed":{},"gilded":0,"secure_media_embed":{},"stickied":false,"subreddit":"MachineLearning","author":"hrb1979","title":"Free Newsletter: Data Science Weekly - Issue 3","subreddit_id":"t5_2r3gv","url":"http://www.datascienceweekly.org/newsletters/data-science-weekly-newsletter-issue-3","secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"author_flair_css_class":null,"ups":1,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1386889745,"selftext":""}
{"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In some work I am doing right now, I am trying to solve a variation of the standard least squares linear regression.  Suppose I have a set [; Y ;] of data vectors [; y ;].  Instead of minimizing the residual of some linear estimator, &lt;code&gt;[; \\sum_{y \\in Y}||y - A x||^2 ;]&lt;/code&gt;, I&amp;#39;m trying to minimize the squared difference between each data vector and it&amp;#39;s projection onto the span of a single vector, &lt;code&gt;[; \\sum_{y \\in Y}||y - dd^t y||^2 ;]&lt;/code&gt;, where [; d ;] is a unit vector.  That is, I need to solve&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;[; d^* = argmin_d \\sum_{y \\in Y}||y - dd^t y||^2 ;]&lt;/code&gt; &lt;/p&gt;\n\n&lt;p&gt;subject to &lt;code&gt;[; ||d||^2 = 1 ;]&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I would be very surprised if this wasn&amp;#39;t already solved, but for some reason I am having trouble finding it and I can&amp;#39;t quite seem to figure it out myself. Can anyone point me in the right direction? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411478442,"thumbnail":"self","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":3,"id":"1sr2dq","user_reports":[],"domain":"self.MachineLearning","score":1,"permalink":"/r/MachineLearning/comments/1sr2dq/help_with_a_variant_of_linear_leastsquares_xpost/","author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"subreddit_id":"t5_2r3gv","title":"Help with a variant of linear least-squares (x-post from /r/statistics)","author":"Splanky222","url":"http://www.reddit.com/r/MachineLearning/comments/1sr2dq/help_with_a_variant_of_linear_leastsquares_xpost/","subreddit":"MachineLearning","stickied":false,"created_utc":1386888338,"selftext":"In some work I am doing right now, I am trying to solve a variation of the standard least squares linear regression.  Suppose I have a set [; Y ;] of data vectors [; y ;].  Instead of minimizing the residual of some linear estimator, `[; \\sum_{y \\in Y}||y - A x||^2 ;]`, I'm trying to minimize the squared difference between each data vector and it's projection onto the span of a single vector, `[; \\sum_{y \\in Y}||y - dd^t y||^2 ;]`, where [; d ;] is a unit vector.  That is, I need to solve\n\n`[; d^* = argmin_d \\sum_{y \\in Y}||y - dd^t y||^2 ;]` \n\nsubject to `[; ||d||^2 = 1 ;]`\n\nI would be very surprised if this wasn't already solved, but for some reason I am having trouble finding it and I can't quite seem to figure it out myself. Can anyone point me in the right direction? \n\n\n","is_self":true,"media":null,"link_flair_css_class":null,"ups":1,"author_flair_css_class":null}
{"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":15,"user_reports":[],"id":"1sqlua","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1sqlua/i_need_machine_learning_jokes_memes_for_a/","score":8,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m giving a presentation tomorrow and need your best machine learning memes and jokes!&lt;/p&gt;\n\n&lt;p&gt;Specifically the class is about Bayes Nets / Graphical Models / HMMs, but fire away with anything!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411479104,"thumbnail":"self","edited":false,"distinguished":null,"report_reasons":null,"downs":0,"created_utc":1386877572,"selftext":"Help!\n\nI'm giving a presentation tomorrow and need your best machine learning memes and jokes!\n\nSpecifically the class is about Bayes Nets / Graphical Models / HMMs, but fire away with anything!","is_self":true,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":8,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"title":"I need machine learning jokes / memes for a presentation!","subreddit_id":"t5_2r3gv","author":"Muadibz","url":"http://www.reddit.com/r/MachineLearning/comments/1sqlua/i_need_machine_learning_jokes_memes_for_a/","stickied":false,"subreddit":"MachineLearning"}
{"title":"Code for Machine Learning for Hackers","subreddit_id":"t5_2r3gv","author":"cprose","url":"http://www.reddit.com/r/MachineLearning/comments/1sqj1r/code_for_machine_learning_for_hackers/","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":5,"selftext":"I was thinking of using some examples from Machine Learning for Hackers in my Applied Machine Learning course, but when I tried to load the package_installer.R file, there were a lot of problems with some packages not being available from CRAN, etc., and I am wondering if this code is just way out of date.  I noticed that the last commit to the github repository was several months ago, and the book was published in 2012.  Is there anyone out there who has successfully gotten all these libraries to install recently?  If so, which version of R are you using, and which repository did you use?","created_utc":1386875779,"is_self":true,"thumbnail":"self","edited":false,"report_reasons":null,"distinguished":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking of using some examples from Machine Learning for Hackers in my Applied Machine Learning course, but when I tried to load the package_installer.R file, there were a lot of problems with some packages not being available from CRAN, etc., and I am wondering if this code is just way out of date.  I noticed that the last commit to the github repository was several months ago, and the book was published in 2012.  Is there anyone out there who has successfully gotten all these libraries to install recently?  If so, which version of R are you using, and which repository did you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411479645,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1sqj1r/code_for_machine_learning_for_hackers/","score":5,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"id":"1sqj1r","num_comments":1,"user_reports":[]}
{"secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"title":"Exclusive: Machine Learning Methods and Algorithms Debategraph","author":"jry_AIHub","subreddit_id":"t5_2r3gv","url":"http://aihub.net/exclusive-machine-learning-methods-algorithms-debategraph/","is_self":false,"created_utc":1386869437,"selftext":"","ups":3,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"mod_reports":[],"selftext_html":null,"retrieved_on":1411480006,"edited":false,"downs":0,"report_reasons":null,"distinguished":null,"thumbnail":"http://a.thumbs.redditmedia.com/G0ervG7J1Tc8-VXf.jpg","over_18":false,"num_comments":0,"user_reports":[],"id":"1sq9ew","gilded":0,"media_embed":{},"secure_media_embed":{},"domain":"aihub.net","score":3,"permalink":"/r/MachineLearning/comments/1sq9ew/exclusive_machine_learning_methods_and_algorithms/"}
{"score":3,"permalink":"/r/MachineLearning/comments/1sq56u/paris_machine_learning_meetup_6_summary_and/","domain":"nuit-blanche.blogspot.dk","user_reports":[],"num_comments":0,"id":"1sq56u","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"http://e.thumbs.redditmedia.com/aRiYPftf4D5QAYbX.jpg","retrieved_on":1411480167,"selftext_html":null,"mod_reports":[],"ups":3,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"is_self":false,"created_utc":1386866582,"selftext":"","subreddit":"MachineLearning","stickied":false,"url":"http://nuit-blanche.blogspot.dk/2013/12/paris-machine-leanring-meetup-6-summary.html","title":"Paris Machine Learning Meetup #6 Summary and thoughts","subreddit_id":"t5_2r3gv","author":"compsens","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null}
{"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"url":"http://ama.liglab.fr/resourcestools/datasets/predict-keywords-activities-in-a-online-social-media/","author":"FrancoisK","title":"A social network activity data-set I'm happy to share.","subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","stickied":false,"selftext":"","created_utc":1386862427,"is_self":false,"link_flair_css_class":null,"media":null,"ups":20,"author_flair_css_class":null,"retrieved_on":1411480393,"mod_reports":[],"selftext_html":null,"thumbnail":"http://a.thumbs.redditmedia.com/TD2uGxsPhrHaR5Ml.jpg","downs":0,"distinguished":null,"report_reasons":null,"edited":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":4,"user_reports":[],"id":"1spzbb","over_18":false,"score":20,"permalink":"/r/MachineLearning/comments/1spzbb/a_social_network_activity_dataset_im_happy_to/","domain":"ama.liglab.fr"}
{"ups":0,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"is_self":true,"created_utc":1386858431,"selftext":"Why is it that everything I research on Predictive Analytics reminds me of [zombo.com](http://www.zombo.com/) / smoke and mirrors.\n\n\nAm I crazy or is there real world evidence this stuff works?  Perhaps it's that it does indeed work, but it takes time/sweat/effort that most are not willing to commit.\n\n\nThoughts?","subreddit":"MachineLearning","stickied":false,"author":"w1gg1n5","title":"Predictive Analytics","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1spudy/predictive_analytics/","secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"domain":"self.MachineLearning","score":0,"permalink":"/r/MachineLearning/comments/1spudy/predictive_analytics/","over_18":false,"num_comments":5,"user_reports":[],"id":"1spudy","gilded":0,"media_embed":{},"secure_media_embed":{},"edited":false,"downs":0,"distinguished":null,"report_reasons":null,"thumbnail":"self","mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why is it that everything I research on Predictive Analytics reminds me of &lt;a href=\"http://www.zombo.com/\"&gt;zombo.com&lt;/a&gt; / smoke and mirrors.&lt;/p&gt;\n\n&lt;p&gt;Am I crazy or is there real world evidence this stuff works?  Perhaps it&amp;#39;s that it does indeed work, but it takes time/sweat/effort that most are not willing to commit.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411480584}
{"subreddit":"MachineLearning","stickied":false,"url":"http://knewt.ly/1iYdk42","subreddit_id":"t5_2r3gv","title":"LIVE Stream NOW - RE: Shiny &amp; R - Yale Statistics Professor John W. Emerson","author":"chris_knerd","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"ups":3,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"is_self":false,"created_utc":1386807942,"selftext":"","downs":0,"distinguished":null,"report_reasons":null,"edited":false,"thumbnail":"http://b.thumbs.redditmedia.com/3T7jcPWKean8b7L1.jpg","retrieved_on":1411482762,"mod_reports":[],"selftext_html":null,"score":3,"permalink":"/r/MachineLearning/comments/1soe33/live_stream_now_re_shiny_r_yale_statistics/","domain":"knewt.ly","num_comments":0,"user_reports":[],"id":"1soe33","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{}}
{"edited":false,"distinguished":null,"report_reasons":null,"downs":0,"thumbnail":"self","mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found this useful paper from 2011 which really closely covers what I&amp;#39;m doing: &lt;a href=\"http://research.microsoft.com/pubs/148339/offerMatching_kdd.pdf\"&gt;http://research.microsoft.com/pubs/148339/offerMatching_kdd.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But I wanted to hear &lt;a href=\"/r/MachineLearning\"&gt;/r/MachineLearning&lt;/a&gt;&amp;#39;s opinions on record linkage. Did a search and couldn&amp;#39;t find anything here yet. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411474803,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1stom0/best_models_for_record_linkage/","score":8,"over_18":false,"num_comments":4,"user_reports":[],"id":"1stom0","media_embed":{},"gilded":0,"secure_media_embed":{},"stickied":false,"subreddit":"MachineLearning","title":"Best models for Record Linkage?","author":"iwantedthisusername","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1stom0/best_models_for_record_linkage/","secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"author_flair_css_class":null,"ups":8,"media":null,"link_flair_css_class":null,"is_self":true,"created_utc":1386970863,"selftext":"I found this useful paper from 2011 which really closely covers what I'm doing: http://research.microsoft.com/pubs/148339/offerMatching_kdd.pdf\n\nBut I wanted to hear /r/MachineLearning's opinions on record linkage. Did a search and couldn't find anything here yet. "}
{"subreddit_id":"t5_2r3gv","title":"Top 9 Predictive Analytics Freeware Software","author":"johnt1234","url":"http://www.predictiveanalyticstoday.com/top-5-predictive-analytics-freeware-software/","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"link_flair_css_class":null,"media":null,"ups":0,"author_flair_css_class":null,"created_utc":1386966146,"selftext":"","is_self":false,"thumbnail":"http://f.thumbs.redditmedia.com/3nqgUWkdA15_o1lS.jpg","edited":false,"downs":0,"report_reasons":null,"distinguished":null,"selftext_html":null,"mod_reports":[],"retrieved_on":1411475084,"domain":"predictiveanalyticstoday.com","score":0,"permalink":"/r/MachineLearning/comments/1sthqg/top_9_predictive_analytics_freeware_software/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":5,"user_reports":[],"id":"1sthqg"}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working in python and I was thinking as a rudimentary approach to just have a dictionary of words which would correspond to each label and whichever has the most matches in the paragraph would be the label assigned (perhaps with weights assigned to each word as well based off of frequency in a training set?).&lt;/p&gt;\n\n&lt;p&gt;Are there any better approaches that aren&amp;#39;t extremely difficult to implement? I know there&amp;#39;s the NLTK library for python and I&amp;#39;ve gone through the tutorial but nothing really jumped out at me on how to use it to do something like this. &lt;/p&gt;\n\n&lt;p&gt;I was also thinking maybe some kind of ML classifier using centroids or something along those lines, but I wouldn&amp;#39;t even know where to begin with quantifying the text..&lt;/p&gt;\n\n&lt;p&gt;edit: I should mention that I&amp;#39;m trying to determine what the text is advocating, not trying to assign a label based off information about the stock. In other words, taking an article about a stock which (in most cases) has a position on whether to buy or sell, and determining which position that is.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411475363,"edited":1386963072,"downs":0,"distinguished":null,"report_reasons":null,"thumbnail":"default","over_18":false,"num_comments":2,"user_reports":[],"id":"1stakk","gilded":0,"media_embed":{},"secure_media_embed":{},"domain":"self.MachineLearning","score":1,"permalink":"/r/MachineLearning/comments/1stakk/using_nlp_to_assign_buysellindeterminate_label_to/","secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"title":"Using NLP to assign (Buy/Sell/Indeterminate) label to a paragraph of text related to a stock?","subreddit_id":"t5_2r3gv","author":"[deleted]","url":"http://www.reddit.com/r/MachineLearning/comments/1stakk/using_nlp_to_assign_buysellindeterminate_label_to/","is_self":true,"created_utc":1386961145,"selftext":"I'm working in python and I was thinking as a rudimentary approach to just have a dictionary of words which would correspond to each label and whichever has the most matches in the paragraph would be the label assigned (perhaps with weights assigned to each word as well based off of frequency in a training set?).\n\nAre there any better approaches that aren't extremely difficult to implement? I know there's the NLTK library for python and I've gone through the tutorial but nothing really jumped out at me on how to use it to do something like this. \n\nI was also thinking maybe some kind of ML classifier using centroids or something along those lines, but I wouldn't even know where to begin with quantifying the text..\n\nedit: I should mention that I'm trying to determine what the text is advocating, not trying to assign a label based off information about the stock. In other words, taking an article about a stock which (in most cases) has a position on whether to buy or sell, and determining which position that is.","ups":1,"author_flair_css_class":null,"media":null,"link_flair_css_class":null}
{"edited":1386981154,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"self","mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Paper/Case-study recommendations anyone? &lt;/p&gt;\n\n&lt;p&gt;Some people asked for a domain to which this will be applied -- I am interested in standard &amp;#39;business&amp;#39; / &amp;#39;ecommerce&amp;#39; problems: modeling fraud or increasing click-through or email-response rates using user behavior data&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411475743,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1st0ka/looking_to_survey_main_ideas_in_feature/","score":11,"over_18":false,"num_comments":10,"user_reports":[],"id":"1st0ka","media_embed":{},"gilded":0,"secure_media_embed":{},"stickied":false,"subreddit":"MachineLearning","title":"Looking to survey main ideas in \"feature engineering\"","subreddit_id":"t5_2r3gv","author":"satsatsat","url":"http://www.reddit.com/r/MachineLearning/comments/1st0ka/looking_to_survey_main_ideas_in_feature/","secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"author_flair_css_class":null,"ups":11,"link_flair_css_class":null,"media":null,"is_self":true,"selftext":"Paper/Case-study recommendations anyone? \n\nSome people asked for a domain to which this will be applied -- I am interested in standard 'business' / 'ecommerce' problems: modeling fraud or increasing click-through or email-response rates using user behavior data\n","created_utc":1386954120}
{"domain":"phys.org","permalink":"/r/MachineLearning/comments/1ss41f/machinelearning_algorithms_could_make_chemical/","score":8,"over_18":false,"num_comments":1,"id":"1ss41f","user_reports":[],"media_embed":{},"gilded":0,"secure_media_embed":{},"edited":false,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"http://e.thumbs.redditmedia.com/xYpytpAVgrvqws9R.jpg","selftext_html":null,"mod_reports":[],"retrieved_on":1411476994,"author_flair_css_class":null,"ups":8,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1386916535,"selftext":"","stickied":false,"subreddit":"MachineLearning","title":"Machine-learning algorithms could make chemical reactions intelligent [paper in comments]","subreddit_id":"t5_2r3gv","author":"zestinc","url":"http://phys.org/news/2013-12-smart-molecules-machine-learning-algorithms-chemical.html","secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null}
{"score":1,"permalink":"/r/MachineLearning/comments/1ss3zk/machinelearning_algorithms_could_make_chemical/","domain":"phys.org","num_comments":0,"user_reports":[],"id":"1ss3zk","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"default","retrieved_on":1411476997,"mod_reports":[],"selftext_html":null,"ups":1,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"is_self":false,"created_utc":1386916485,"selftext":"","subreddit":"MachineLearning","stickied":false,"url":"http://phys.org/news/2013-12-smart-molecules-machine-learning-algorithms-chemical.html","subreddit_id":"t5_2r3gv","title":"Machine-learning algorithms could make chemical reactions intelligent","author":"[deleted]","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null}
{"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":52,"created_utc":1386903513,"selftext":"","is_self":false,"url":"http://www.datatau.com/news","author":"neelshiv","title":"DataTau: The data science equivalent of Hacker News","subreddit_id":"t5_2r3gv","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"permalink":"/r/MachineLearning/comments/1sro8a/datatau_the_data_science_equivalent_of_hacker_news/","score":52,"domain":"datatau.com","secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":7,"id":"1sro8a","user_reports":[],"over_18":false,"thumbnail":"default","report_reasons":null,"distinguished":null,"downs":0,"edited":false,"retrieved_on":1411477605,"selftext_html":null,"mod_reports":[]}
{"stickied":false,"subreddit":"MachineLearning","url":"http://www.datatau.com/news","subreddit_id":"t5_2r3gv","title":"DataTay: The data science equivalent of Hacker News","author":"[deleted]","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"author_flair_css_class":null,"ups":1,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1386902899,"selftext":"","report_reasons":null,"distinguished":null,"downs":0,"edited":false,"thumbnail":"default","retrieved_on":1411477637,"mod_reports":[],"selftext_html":null,"permalink":"/r/MachineLearning/comments/1srnfj/datatay_the_data_science_equivalent_of_hacker_news/","score":1,"domain":"datatau.com","num_comments":0,"user_reports":[],"id":"1srnfj","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0}
{"stickied":false,"subreddit":"MachineLearning","url":"http://www.reddit.com/r/MachineLearning/comments/1svh3i/i_would_like_to_collect_data_and_give_it_out_for/","author":"robinhoode","title":"I would like to collect data and give it out for free to ML researchers and hobbyists. What sites out there, that don't provide historical data, would you like to see collected, cleaned up, and provided for free via API?","subreddit_id":"t5_2r3gv","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"author_flair_css_class":null,"ups":28,"link_flair_css_class":null,"media":null,"is_self":true,"selftext":"I have an open source project that I worked on for a client that I'd like to use for personal projects. It's nothing more than a job-queuing system for collecting historical data from some external service. I was thinking about collecting data from reddit, as that's an easy target, but perhaps that's not the most useful or interesting dataset. What other sites out there could I pull data from?","created_utc":1387041038,"report_reasons":null,"distinguished":null,"downs":0,"edited":false,"thumbnail":"self","retrieved_on":1411472306,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an open source project that I worked on for a client that I&amp;#39;d like to use for personal projects. It&amp;#39;s nothing more than a job-queuing system for collecting historical data from some external service. I was thinking about collecting data from reddit, as that&amp;#39;s an easy target, but perhaps that&amp;#39;s not the most useful or interesting dataset. What other sites out there could I pull data from?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"permalink":"/r/MachineLearning/comments/1svh3i/i_would_like_to_collect_data_and_give_it_out_for/","score":28,"domain":"self.MachineLearning","id":"1svh3i","num_comments":44,"user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0}
{"mod_reports":[],"selftext_html":null,"retrieved_on":1411472525,"thumbnail":"http://f.thumbs.redditmedia.com/3hxGuo0h8zERslbM.jpg","edited":false,"distinguished":null,"report_reasons":null,"downs":0,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"id":"1svbdz","num_comments":1,"user_reports":[],"domain":"datascienceweekly.org","permalink":"/r/MachineLearning/comments/1svbdz/object_recognition_pete_warden_interview/","score":2,"author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"subreddit_id":"t5_2r3gv","title":"Object Recognition: Pete Warden Interview - Co-Founder and CTO of Jetpac","author":"hrb1979","url":"http://www.datascienceweekly.org/blog/3-object-recognition-pete-warden-interview-co-founder-cto-jetpac","stickied":false,"subreddit":"MachineLearning","selftext":"","created_utc":1387035907,"is_self":false,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":2}
{"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi to all, I have to classify not linearly separable features from 5 classes, and I&amp;#39;m undecided if I should use SVM with one-against-all strategy or a MLP NN. In the former case, I would train five SVMs, and there are drawbacks like indeterminated regions and unbilanced training, say 10 points with +1 and 90 with -1, out of 100 points, for each SVM. The NN would be only one, but it has a local minimum and more parameters to be optimized, leading to possibly curse of dimensionality. Does the problem have any suggestions or it depends only of the problem in it&amp;#39;s singularity? I suppose I have to test each of the two solutions! Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411472843,"edited":1387026457,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"self","over_18":false,"id":"1sv2xo","num_comments":20,"user_reports":[],"media_embed":{},"gilded":0,"secure_media_embed":{},"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1sv2xo/svmvsnn_for_multiclass_classification/","score":7,"secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","title":"SVMvsNN for multiclass classification","author":"PsychedelicStore","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1sv2xo/svmvsnn_for_multiclass_classification/","is_self":true,"created_utc":1387024799,"selftext":"Hi to all, I have to classify not linearly separable features from 5 classes, and I'm undecided if I should use SVM with one-against-all strategy or a MLP NN. In the former case, I would train five SVMs, and there are drawbacks like indeterminated regions and unbilanced training, say 10 points with +1 and 90 with -1, out of 100 points, for each SVM. The NN would be only one, but it has a local minimum and more parameters to be optimized, leading to possibly curse of dimensionality. Does the problem have any suggestions or it depends only of the problem in it's singularity? I suppose I have to test each of the two solutions! Thanks in advance.","author_flair_css_class":null,"ups":7,"media":null,"link_flair_css_class":null}
{"retrieved_on":1411473705,"selftext_html":null,"mod_reports":[],"report_reasons":null,"distinguished":null,"downs":0,"edited":false,"thumbnail":"http://d.thumbs.redditmedia.com/fc4ucljswW6mgZeo.jpg","num_comments":9,"user_reports":[],"id":"1suh2k","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1suh2k/mooc_convex_optimization_by_stephen_boyd_jan_21/","score":24,"domain":"class.stanford.edu","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"stickied":false,"subreddit":"MachineLearning","url":"https://class.stanford.edu/courses/Engineering/CVX101/Winter2014/about","author":"chalupapa","title":"(MOOC) Convex Optimization by Stephen Boyd [Jan 21, 2014]","subreddit_id":"t5_2r3gv","is_self":false,"created_utc":1386993838,"selftext":"","author_flair_css_class":null,"ups":24,"link_flair_css_class":null,"media":null}
{"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":18,"created_utc":1386987178,"selftext":"","is_self":false,"author":"gtani","title":"A good NIPS (another lsit of ~20 favorite papers)","subreddit_id":"t5_2r3gv","url":"http://blogs.princeton.edu/imabandit/2013/12/12/a-good-nips/","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"domain":"blogs.princeton.edu","permalink":"/r/MachineLearning/comments/1su9ny/a_good_nips_another_lsit_of_20_favorite_papers/","score":18,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":3,"id":"1su9ny","user_reports":[],"thumbnail":"default","edited":false,"distinguished":null,"report_reasons":null,"downs":0,"selftext_html":null,"mod_reports":[],"retrieved_on":1411473982}
{"thumbnail":"http://d.thumbs.redditmedia.com/XfDukusLls1A7duu.jpg","edited":false,"downs":0,"report_reasons":null,"distinguished":null,"selftext_html":null,"mod_reports":[],"retrieved_on":1411467736,"domain":"davmre.github.io","score":31,"permalink":"/r/MachineLearning/comments/1syqs4/orthogonal_polynomial_regression_in_python/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":8,"user_reports":[],"id":"1syqs4","title":"Orthogonal polynomial regression in Python","subreddit_id":"t5_2r3gv","author":"davmre","url":"http://davmre.github.io/python/2013/12/15/orthogonal_poly/","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"link_flair_css_class":null,"media":null,"ups":31,"author_flair_css_class":null,"created_utc":1387149550,"selftext":"","is_self":false}
{"score":0,"permalink":"/r/MachineLearning/comments/1sy8wj/learning_more_about_machine_learning/","domain":"self.MachineLearning","secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":18,"user_reports":[],"id":"1sy8wj","over_18":false,"thumbnail":"self","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"retrieved_on":1411468426,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just completed a &lt;a href=\"http://courses.engr.illinois.edu/cs446/syllabus.html\"&gt;class on machine learning&lt;/a&gt; at my school, and I&amp;#39;m interested in learning more. However, the follow up class is restricted to grad students/full, so I&amp;#39;ve turned to reddit to ask what should I do now. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"link_flair_css_class":null,"ups":0,"author_flair_css_class":null,"created_utc":1387137146,"selftext":"I've just completed a [class on machine learning](http://courses.engr.illinois.edu/cs446/syllabus.html) at my school, and I'm interested in learning more. However, the follow up class is restricted to grad students/full, so I've turned to reddit to ask what should I do now. ","is_self":true,"url":"http://www.reddit.com/r/MachineLearning/comments/1sy8wj/learning_more_about_machine_learning/","author":"hurrus-durrus","title":"Learning more about machine learning","subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","stickied":false,"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null}
{"author_flair_css_class":null,"ups":0,"media":null,"link_flair_css_class":null,"is_self":true,"selftext":"First of all we do not need to write the complete code for each algorithm, there are libraries that do that part quite effectively and hopefully are easy to mess around with, I use python ( still need to start with scikit ) but i find it rather easy to mess around in it. Even though we don't need to implement the algorithm we should know the math behind it so that we can judge which algo will be more efficient for which data set and also set the desired perimeters to improve the result (eg alpha in the first exercise).\n\nThe most important part of a job would be collecting the data .i.e. data mining, which is not covered in this course. Though is mining much different from data scraping? I use python to scrape some data from a few sites now and then, which is kind of fun for me.\n\nKnowing which part of the data do you need to compute the desired results .i.e. the features, the rite features can help get the result faster and more efficiently. I find the idea of Kernels very intriguing but I still don't know much about them or how I would use kernel equations in a real challenge.\n\nEDIT: I am following Andrew Ng's class","created_utc":1387131155,"stickied":false,"subreddit":"MachineLearning","url":"http://www.reddit.com/r/MachineLearning/comments/1sy0hs/my_idea_of_a_job_in_the_field_of_mldata/","title":"my idea of a job in the field of ML/Data scientist/data analyst [Feedback]","subreddit_id":"t5_2r3gv","author":"heaven__","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"permalink":"/r/MachineLearning/comments/1sy0hs/my_idea_of_a_job_in_the_field_of_mldata/","score":0,"domain":"self.MachineLearning","num_comments":6,"user_reports":[],"id":"1sy0hs","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"distinguished":null,"report_reasons":null,"downs":0,"edited":1387159250,"thumbnail":"self","retrieved_on":1411468754,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all we do not need to write the complete code for each algorithm, there are libraries that do that part quite effectively and hopefully are easy to mess around with, I use python ( still need to start with scikit ) but i find it rather easy to mess around in it. Even though we don&amp;#39;t need to implement the algorithm we should know the math behind it so that we can judge which algo will be more efficient for which data set and also set the desired perimeters to improve the result (eg alpha in the first exercise).&lt;/p&gt;\n\n&lt;p&gt;The most important part of a job would be collecting the data .i.e. data mining, which is not covered in this course. Though is mining much different from data scraping? I use python to scrape some data from a few sites now and then, which is kind of fun for me.&lt;/p&gt;\n\n&lt;p&gt;Knowing which part of the data do you need to compute the desired results .i.e. the features, the rite features can help get the result faster and more efficiently. I find the idea of Kernels very intriguing but I still don&amp;#39;t know much about them or how I would use kernel equations in a real challenge.&lt;/p&gt;\n\n&lt;p&gt;EDIT: I am following Andrew Ng&amp;#39;s class&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[]}
{"created_utc":1387123250,"selftext":"","is_self":false,"link_flair_css_class":null,"media":null,"ups":0,"author_flair_css_class":null,"banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"url":"http://danluu.com/linear-hammer/","title":"Linear Methods (PCA) vs. Deep Learning (Autoencoder)","author":"motorcyclesarejets","subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","stickied":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":18,"id":"1sxqui","user_reports":[],"over_18":false,"score":0,"permalink":"/r/MachineLearning/comments/1sxqui/linear_methods_pca_vs_deep_learning_autoencoder/","domain":"danluu.com","retrieved_on":1411469128,"selftext_html":null,"mod_reports":[],"thumbnail":"http://f.thumbs.redditmedia.com/fRztyTANIH4dnP7_.jpg","downs":0,"report_reasons":null,"distinguished":null,"edited":false}
{"is_self":false,"created_utc":1387237696,"selftext":"","ups":0,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"subreddit":"MachineLearning","stickied":false,"subreddit_id":"t5_2r3gv","title":"10 Coolest Big Data Startups in 2013 by CRN","author":"Mrr_Cow","url":"http://www.crn.com/slide-shows/applications-os/240164625/the-10-coolest-big-data-startups-of-2013.htm?pgno=7","over_18":false,"num_comments":6,"user_reports":[],"id":"1t1oqa","gilded":0,"media_embed":{},"secure_media_embed":{},"domain":"crn.com","score":0,"permalink":"/r/MachineLearning/comments/1t1oqa/10_coolest_big_data_startups_in_2013_by_crn/","selftext_html":null,"mod_reports":[],"retrieved_on":1411463674,"edited":false,"downs":0,"report_reasons":null,"distinguished":null,"thumbnail":"http://d.thumbs.redditmedia.com/A6jzWYBFTnMXVLg-.jpg"}
{"created_utc":1387232948,"selftext":"","is_self":false,"media":null,"link_flair_css_class":null,"ups":0,"author_flair_css_class":null,"author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"author":"numenta","title":"NuPIC Commercial Licenses","subreddit_id":"t5_2r3gv","url":"http://numenta.org/blog/2013/12/16/nupic-commercial-licenses.html","subreddit":"MachineLearning","stickied":false,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":7,"id":"1t1h8o","user_reports":[],"domain":"numenta.org","score":0,"permalink":"/r/MachineLearning/comments/1t1h8o/nupic_commercial_licenses/","selftext_html":null,"mod_reports":[],"retrieved_on":1411463960,"thumbnail":"http://a.thumbs.redditmedia.com/vH5V8smbwg_qhoer.jpg","edited":false,"downs":0,"distinguished":null,"report_reasons":null}
{"domain":"overview.ap.org","score":5,"permalink":"/r/MachineLearning/comments/1szhce/the_overview_project_what_is_xkcd_all_about_text/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":0,"id":"1szhce","user_reports":[],"thumbnail":"http://b.thumbs.redditmedia.com/J9evdwetAnxcdEgs.jpg","edited":false,"downs":0,"report_reasons":null,"distinguished":null,"mod_reports":[],"selftext_html":null,"retrieved_on":1411466722,"media":null,"link_flair_css_class":null,"ups":5,"author_flair_css_class":null,"created_utc":1387168768,"selftext":"","is_self":false,"title":"The Overview Project » What is xkcd all about? Text mining a web comic","author":"rrenaud","subreddit_id":"t5_2r3gv","url":"http://overview.ap.org/blog/2013/12/what-is-xkcd-all-about-text-mining-a-web-comic/","subreddit":"MachineLearning","stickied":false,"author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null}
{"thumbnail":"self","report_reasons":null,"distinguished":null,"downs":0,"edited":false,"retrieved_on":1411460423,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 10,000 documents. Each document has a label (Y) that is either 0 or 1 (the 0-1 split is pretty much 50/50 over my 10,000 documents). Each document has 10 fields. Each field can have any number of words in it. I create 10 feature-spaces by fitting a tf-idf over each field individually over all documents. It looks something like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;       For f_1:                                      For f_2:\n                   34,974                                        113,351   \n       ------------------------------                ------------------------------\n       |                        |   |                |                        |   |\n       |                        |   |                |                        |   |\n10,000 |            X_1         | Y |         10,000 |            X_2         | Y |\n       |                        |   |                |                        |   |\n       |                        |   |                |                        |   |\n       ------------------------------                ------------------------------\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;On, and on for each field. Each matrix will have 10,000 rows, but a different number of columns. The Y column is always the same. I&amp;#39;m interested in using each of these matrices as the input to a classifier, and using some ensemble of them to predict the labels Y.&lt;/p&gt;\n\n&lt;p&gt;My initial approach was to choose a random 70% of the 10,000 documents and set that as the training set, and then use the other 30% as my predicting set. My plan was to train a logistic regression model on 70% of X&lt;em&gt;1 and then have that model predict the labels of the remaining 30% of X_1 to give me Y&amp;#39;_lr1. I would use the same 70% and train a random forest, and then have the random forest predict the 30% to give Y&amp;#39;_rf1. I would use the same 70%/30% of rows to train/predict a logistic regression and random forest on X_2 through X&lt;/em&gt;{10}. In the end I would have some matrix:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;                                    20                           \n      -------------------------------------------------------------\n      |                                                       |   |\n      |                                                       |   |\n3,000 | Y&amp;#39;_lr1  Y&amp;#39;_rf1  Y&amp;#39;_lr2  Y&amp;#39;_rf2  ...  Y&amp;#39;_lr10  Y&amp;#39;_rf10 | Y |\n      |                                                       |   |\n      |                                                       |   |\n      -------------------------------------------------------------\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I then trained a final logistic regression to predict the Y from the 20 Y&amp;#39;. Is this a normal technique? Should I be training many models, and do a further voting stage to get each Y&amp;#39;?&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated. Most of the sources I find talk about drawing N rows with replacement, and then merging those models, but in this case, I have many models training on different features. I don&amp;#39;t know how much of a difference this makes.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using sklearn on Python if that makes any advice easier to relay!&lt;/p&gt;\n\n&lt;p&gt;Sorry for the length, but I wanted to be detailed. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"permalink":"/r/MachineLearning/comments/1t42u5/proper_splitting_of_data_set_for_ensemble_methods/","score":1,"domain":"self.MachineLearning","secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":5,"id":"1t42u5","user_reports":[],"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1t42u5/proper_splitting_of_data_set_for_ensemble_methods/","title":"Proper splitting of data set for Ensemble methods (question)","author":"Serious_is_a_star","subreddit_id":"t5_2r3gv","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":1,"selftext":"I have 10,000 documents. Each document has a label (Y) that is either 0 or 1 (the 0-1 split is pretty much 50/50 over my 10,000 documents). Each document has 10 fields. Each field can have any number of words in it. I create 10 feature-spaces by fitting a tf-idf over each field individually over all documents. It looks something like this:\n\n\n           For f_1:                                      For f_2:\n                       34,974                                        113,351   \n           ------------------------------                ------------------------------\n           |                        |   |                |                        |   |\n           |                        |   |                |                        |   |\n    10,000 |            X_1         | Y |         10,000 |            X_2         | Y |\n           |                        |   |                |                        |   |\n           |                        |   |                |                        |   |\n           ------------------------------                ------------------------------\n\n\nOn, and on for each field. Each matrix will have 10,000 rows, but a different number of columns. The Y column is always the same. I'm interested in using each of these matrices as the input to a classifier, and using some ensemble of them to predict the labels Y.\n\nMy initial approach was to choose a random 70% of the 10,000 documents and set that as the training set, and then use the other 30% as my predicting set. My plan was to train a logistic regression model on 70% of X_1 and then have that model predict the labels of the remaining 30% of X_1 to give me Y'_lr1. I would use the same 70% and train a random forest, and then have the random forest predict the 30% to give Y'_rf1. I would use the same 70%/30% of rows to train/predict a logistic regression and random forest on X_2 through X_{10}. In the end I would have some matrix:\n\n                                        20                           \n          -------------------------------------------------------------\n          |                                                       |   |\n          |                                                       |   |\n    3,000 | Y'_lr1  Y'_rf1  Y'_lr2  Y'_rf2  ...  Y'_lr10  Y'_rf10 | Y |\n          |                                                       |   |\n          |                                                       |   |\n          -------------------------------------------------------------\n\nI then trained a final logistic regression to predict the Y from the 20 Y'. Is this a normal technique? Should I be training many models, and do a further voting stage to get each Y'?\n\nAny help is appreciated. Most of the sources I find talk about drawing N rows with replacement, and then merging those models, but in this case, I have many models training on different features. I don't know how much of a difference this makes.\n\nI'm using sklearn on Python if that makes any advice easier to relay!\n\nSorry for the length, but I wanted to be detailed. Thanks!","created_utc":1387311627,"is_self":true}
{"retrieved_on":1411460438,"selftext_html":null,"mod_reports":[],"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"http://a.thumbs.redditmedia.com/dVzKGN_g5VWofMIB.jpg","num_comments":0,"user_reports":[],"id":"1t42g8","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":4,"permalink":"/r/MachineLearning/comments/1t42g8/spark_summit_2013/","domain":"spark-summit.org","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"url":"http://spark-summit.org/summit-2013/","author":"turnersr","title":"Spark Summit 2013","subreddit_id":"t5_2r3gv","is_self":false,"selftext":"","created_utc":1387311386,"ups":4,"author_flair_css_class":null,"media":null,"link_flair_css_class":null}
{"link_flair_css_class":null,"media":null,"ups":1,"author_flair_css_class":null,"created_utc":1387310627,"selftext":"","is_self":false,"title":"Spark Summit 2013 Archive","subreddit_id":"t5_2r3gv","author":"[deleted]","url":"http://spark-summit.org/","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"domain":"spark-summit.org","score":1,"permalink":"/r/MachineLearning/comments/1t419q/spark_summit_2013_archive/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":0,"user_reports":[],"id":"1t419q","thumbnail":"default","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"mod_reports":[],"selftext_html":null,"retrieved_on":1411460483}
{"domain":"blog.explainmydata.com","score":38,"permalink":"/r/MachineLearning/comments/1t3of6/max_wellings_comments_on_the_nips_zuckerberg_visit/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":4,"id":"1t3of6","user_reports":[],"thumbnail":"http://e.thumbs.redditmedia.com/hgj8mHrOyeoBFD5p.jpg","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"selftext_html":null,"mod_reports":[],"retrieved_on":1411460968,"link_flair_css_class":null,"media":null,"ups":38,"author_flair_css_class":null,"selftext":"","created_utc":1387302191,"is_self":false,"author":"btown_brony","title":"Max Welling's comments on the NIPS Zuckerberg visit","subreddit_id":"t5_2r3gv","url":"http://blog.explainmydata.com/2013/12/nips-and-zuckerberg-visit.html?showComment=1387277782906#c4001811478589283190","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null}
{"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"subreddit_id":"t5_2r3gv","title":"Found a map through learning Data Science. HELP NEEDED.","author":"theDurphy","url":"http://www.reddit.com/r/MachineLearning/comments/1t3ms8/found_a_map_through_learning_data_science_help/","subreddit":"MachineLearning","stickied":false,"selftext":"Hello everyone.  I recently discovered the world of data science and wish to self-educate myself.  I have found a lot of open-source materiel on various subjects but I needed a sort of curriculum to guide me.  I found this...\nhttp://nirvacana.com/thoughts/wp-content/uploads/2013/07/RoadToDataScientist1.png\n\nIt is a map of the steps progressing through the study of data science created by Swami Chandrasekaran.  \nthe general link is here\nhttp://nirvacana.com/thoughts/becoming-a-data-scientist/\n\nI am so thankful someone had the time and the kindness to create something like this to the completely lost individuals entering this field.\n\nI have determined this is a great place for me to start.  \n\nOne problem...\nnot every individual point on this guide should be equally prioritized when it come to the depth of understanding in the subject matter.  \n\nMy study habits and personality, when unchecked, will fully engulf my time in the subject matter until I either have maximum understanding of the subject or informed that a maximum understanding is not necessary and a general understanding is more than adequate to fulfill the end goal.\n\nIn this case, the end goal is to have the knowledge to contribute in the world of Data Science under my own resources, and a secondary goal of furthering a career in Data Science where I would be compensated for my work in the field.\n\nI would like help prioritizing the contents on this road map to achieve that end goal.\n\nThere are 2 criteria to be considered.\n\n1.  The level of Importance -- Low to High\n       This is a judgement of the synergistic qualities of the subject matter.  Example: How important is Fundamental Linear Algebra to the understanding of all the other subjects in the Data Science Tree? (I would presume HIGH since it is in the Fundamental Chapter)\n\n2.  The level of understanding -- 0% - 100%\n        This is how much of the subject matter must I fully understand and be able to apply.  Example: Linear Algebra - am I fine with just the fundamentals (about 40%) or should I learn all the way up to Pseudoinverses (about 90+%)?\n\nThese assessments can be applied simple to the Chapters on the map, Chapters 1-10.  More preferably, I am hoping for these assessment criteria to be applied to each individual point on the map.\n\nMy Apologies for the length, but I believe in being specific.  This, hopefully will help other entry level students of Data Science learn on their own and still be contributors in the field.  The transparency of information is paramount in the success of this field, and for the success of our species in general.\n\nThank You","created_utc":1387301039,"is_self":true,"link_flair_css_class":null,"media":null,"ups":8,"author_flair_css_class":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone.  I recently discovered the world of data science and wish to self-educate myself.  I have found a lot of open-source materiel on various subjects but I needed a sort of curriculum to guide me.  I found this...\n&lt;a href=\"http://nirvacana.com/thoughts/wp-content/uploads/2013/07/RoadToDataScientist1.png\"&gt;http://nirvacana.com/thoughts/wp-content/uploads/2013/07/RoadToDataScientist1.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It is a map of the steps progressing through the study of data science created by Swami Chandrasekaran.&lt;br/&gt;\nthe general link is here\n&lt;a href=\"http://nirvacana.com/thoughts/becoming-a-data-scientist/\"&gt;http://nirvacana.com/thoughts/becoming-a-data-scientist/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am so thankful someone had the time and the kindness to create something like this to the completely lost individuals entering this field.&lt;/p&gt;\n\n&lt;p&gt;I have determined this is a great place for me to start.  &lt;/p&gt;\n\n&lt;p&gt;One problem...\nnot every individual point on this guide should be equally prioritized when it come to the depth of understanding in the subject matter.  &lt;/p&gt;\n\n&lt;p&gt;My study habits and personality, when unchecked, will fully engulf my time in the subject matter until I either have maximum understanding of the subject or informed that a maximum understanding is not necessary and a general understanding is more than adequate to fulfill the end goal.&lt;/p&gt;\n\n&lt;p&gt;In this case, the end goal is to have the knowledge to contribute in the world of Data Science under my own resources, and a secondary goal of furthering a career in Data Science where I would be compensated for my work in the field.&lt;/p&gt;\n\n&lt;p&gt;I would like help prioritizing the contents on this road map to achieve that end goal.&lt;/p&gt;\n\n&lt;p&gt;There are 2 criteria to be considered.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;The level of Importance -- Low to High\n   This is a judgement of the synergistic qualities of the subject matter.  Example: How important is Fundamental Linear Algebra to the understanding of all the other subjects in the Data Science Tree? (I would presume HIGH since it is in the Fundamental Chapter)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The level of understanding -- 0% - 100%\n    This is how much of the subject matter must I fully understand and be able to apply.  Example: Linear Algebra - am I fine with just the fundamentals (about 40%) or should I learn all the way up to Pseudoinverses (about 90+%)?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;These assessments can be applied simple to the Chapters on the map, Chapters 1-10.  More preferably, I am hoping for these assessment criteria to be applied to each individual point on the map.&lt;/p&gt;\n\n&lt;p&gt;My Apologies for the length, but I believe in being specific.  This, hopefully will help other entry level students of Data Science learn on their own and still be contributors in the field.  The transparency of information is paramount in the success of this field, and for the success of our species in general.&lt;/p&gt;\n\n&lt;p&gt;Thank You&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411461030,"thumbnail":"self","edited":1387301230,"downs":0,"distinguished":null,"report_reasons":null,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":6,"id":"1t3ms8","user_reports":[],"domain":"self.MachineLearning","score":8,"permalink":"/r/MachineLearning/comments/1t3ms8/found_a_map_through_learning_data_science_help/"}
{"num_comments":4,"user_reports":[],"id":"1t3ghl","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":3,"permalink":"/r/MachineLearning/comments/1t3ghl/trying_to_implement_hopfield_net_for_pattern/","domain":"self.MachineLearning","retrieved_on":1411461262,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying my hand at implementing a Hopfield Net for pattern recognition. &lt;/p&gt;\n\n&lt;p&gt;However, with the patterns I have tried I seem to only be able to store one pattern reliably. I have 200 neurons and &amp;lt;10 patterns, so capacity should NOT be an issue.&lt;/p&gt;\n\n&lt;p&gt;I calculate all my weights at once with the hebbian learning rule from &lt;a href=\"https://en.wikipedia.org/wiki/Hopfield_network#Hebbian_Learning_Rule_for_Hopfield_Networks\"&gt;wikipedia&lt;/a&gt; and then just let the network run, with some noise in the evaluation of the neurons to avoid spurious states.&lt;/p&gt;\n\n&lt;p&gt;Any advice? Can post Code as needed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"self","is_self":true,"created_utc":1387296735,"selftext":"I'm trying my hand at implementing a Hopfield Net for pattern recognition. \n\nHowever, with the patterns I have tried I seem to only be able to store one pattern reliably. I have 200 neurons and &lt;10 patterns, so capacity should NOT be an issue.\n\nI calculate all my weights at once with the hebbian learning rule from [wikipedia](https://en.wikipedia.org/wiki/Hopfield_network#Hebbian_Learning_Rule_for_Hopfield_Networks) and then just let the network run, with some noise in the evaluation of the neurons to avoid spurious states.\n\nAny advice? Can post Code as needed.","ups":3,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1t3ghl/trying_to_implement_hopfield_net_for_pattern/","title":"Trying to implement Hopfield net for pattern recognition, problem with more than one pattern.","author":"DeusexConstantia","subreddit_id":"t5_2r3gv"}
{"permalink":"/r/MachineLearning/comments/1t1qd0/thinking_in_silicon_processors_that_work_like/","score":19,"domain":"technologyreview.com","num_comments":11,"id":"1t1qd0","user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"http://d.thumbs.redditmedia.com/vmnYXqGk09egrjwu.jpg","retrieved_on":1411463614,"mod_reports":[],"selftext_html":null,"author_flair_css_class":null,"ups":19,"link_flair_css_class":null,"media":null,"is_self":false,"created_utc":1387238792,"selftext":"","stickied":false,"subreddit":"MachineLearning","url":"http://www.technologyreview.com/featuredstory/522476/thinking-in-silicon/","title":"Thinking in Silicon: Processors That Work Like Brains Will Accelerate AI","subreddit_id":"t5_2r3gv","author":"hseldon15","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null}
{"thumbnail":"http://d.thumbs.redditmedia.com/g9bzWBfM64A1OvxK.jpg","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"selftext_html":null,"mod_reports":[],"retrieved_on":1411456686,"domain":"shogun-toolbox.org","score":18,"permalink":"/r/MachineLearning/comments/1t6szm/the_shogun_machine_learning_toolbox/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":9,"id":"1t6szm","user_reports":[],"subreddit_id":"t5_2r3gv","title":"The SHOGUN Machine Learning Toolbox","author":"mhausenblas","url":"http://shogun-toolbox.org/","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"media":null,"link_flair_css_class":null,"ups":18,"author_flair_css_class":null,"selftext":"","created_utc":1387395313,"is_self":false}
{"num_comments":0,"id":"1t6lm6","user_reports":[],"over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":0,"permalink":"/r/MachineLearning/comments/1t6lm6/best_course_to_learn_on_machine_learning/","domain":"studyfoyer.org","retrieved_on":1411456963,"selftext_html":null,"mod_reports":[],"downs":0,"distinguished":null,"report_reasons":null,"edited":false,"thumbnail":"http://e.thumbs.redditmedia.com/FdpTunXx8SED-1mF.jpg","is_self":false,"selftext":"","created_utc":1387390476,"ups":0,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"url":"http://studyfoyer.org/machine%20learning.php","title":"Best course to learn on Machine learning","author":"sidoknowia","subreddit_id":"t5_2r3gv"}
{"created_utc":1387385402,"selftext":"","is_self":false,"link_flair_css_class":null,"media":null,"ups":0,"author_flair_css_class":null,"author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"title":"Help us learn about crowdsourcing robotics (interactive; x-posted in /r/robotics)","author":"DrJosh","subreddit_id":"t5_2r3gv","url":"http://www.uvm.edu/~mwagy/robots/jointbot/","subreddit":"MachineLearning","stickied":false,"gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":1,"user_reports":[],"id":"1t6e9s","domain":"uvm.edu","score":0,"permalink":"/r/MachineLearning/comments/1t6e9s/help_us_learn_about_crowdsourcing_robotics/","selftext_html":null,"mod_reports":[],"retrieved_on":1411457242,"thumbnail":"default","edited":false,"downs":0,"distinguished":null,"report_reasons":null}
{"over_18":false,"user_reports":[],"num_comments":2,"id":"1t6b4n","media_embed":{},"gilded":0,"secure_media_embed":{},"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1t6b4n/hypothetical_question_on_future_of_machine/","score":0,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was reading through &lt;a href=\"http://filer.case.edu/dts8/thelastq.htm\"&gt;Isaac Asimov&amp;#39;s short story &lt;em&gt;The Last Question&lt;/em&gt;&lt;/a&gt; and got to thinking about the Multivac in the story. &lt;/p&gt;\n\n&lt;p&gt;Hypothetical Question(s):&lt;/p&gt;\n\n&lt;p&gt;How far away (in terms of years) do you believe we are from building something like the Multivac in the story (or does something like it already exist)?  Do you think we&amp;#39;ll have it by 2061, as it posits in the story?&lt;/p&gt;\n\n&lt;p&gt;If you were tasked with designing/building the Multivac, how would you do it?  &lt;/p&gt;\n\n&lt;p&gt;The descriptions given of the Multivac in the story have a very ML-esque vibe:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Multivac was self-adjusting and self-correcting. It had to be, for nothing human could adjust and correct it quickly enough or even adequately enough.&lt;/p&gt;\n\n&lt;p&gt;They fed it data, adjusted questions to its needs and translated the answers that were issued.&lt;/p&gt;\n\n&lt;p&gt;But slowly Multivac learned enough to answer deeper questions more fundamentally, and on May 14, 2061, what had been theory, became fact. &lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411457369,"edited":false,"distinguished":null,"report_reasons":null,"downs":0,"thumbnail":"default","is_self":true,"created_utc":1387383221,"selftext":"Was reading through [Isaac Asimov's short story *The Last Question*](http://filer.case.edu/dts8/thelastq.htm) and got to thinking about the Multivac in the story. \n\nHypothetical Question(s):\n\nHow far away (in terms of years) do you believe we are from building something like the Multivac in the story (or does something like it already exist)?  Do you think we'll have it by 2061, as it posits in the story?\n\nIf you were tasked with designing/building the Multivac, how would you do it?  \n\nThe descriptions given of the Multivac in the story have a very ML-esque vibe:\n\n&gt; Multivac was self-adjusting and self-correcting. It had to be, for nothing human could adjust and correct it quickly enough or even adequately enough.\n\n&gt; They fed it data, adjusted questions to its needs and translated the answers that were issued.\n\n&gt; But slowly Multivac learned enough to answer deeper questions more fundamentally, and on May 14, 2061, what had been theory, became fact. ","author_flair_css_class":null,"ups":0,"media":null,"link_flair_css_class":null,"secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"stickied":false,"subreddit":"MachineLearning","title":"Hypothetical Question on Future of Machine Learning","author":"[deleted]","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1t6b4n/hypothetical_question_on_future_of_machine/"}
{"retrieved_on":1411457933,"mod_reports":[],"selftext_html":null,"thumbnail":"http://e.thumbs.redditmedia.com/kP_-qiRqrf4wvirp.jpg","report_reasons":null,"distinguished":null,"downs":0,"edited":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":5,"user_reports":[],"id":"1t5w8w","over_18":false,"permalink":"/r/MachineLearning/comments/1t5w8w/the_zen_of_gradient_descent_with_an_illuminating/","score":25,"domain":"mrtz.org","banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"url":"http://mrtz.org/blog/the-zen-of-gradient-descent/","subreddit_id":"t5_2r3gv","title":"The Zen of Gradient Descent (with an illuminating discussion of accelerated gradient descent)","author":"urish","stickied":false,"subreddit":"MachineLearning","created_utc":1387369045,"selftext":"","is_self":false,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":25}
{"thumbnail":"default","report_reasons":null,"distinguished":null,"downs":0,"edited":false,"retrieved_on":1411458264,"selftext_html":null,"mod_reports":[],"permalink":"/r/MachineLearning/comments/1t5nhb/industry_machinery_equipment_machine_design/","score":1,"domain":"exytrade.com","secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":1,"user_reports":[],"id":"1t5nhb","over_18":false,"url":"http://exytrade.com/category/","subreddit_id":"t5_2r3gv","title":"Industry machinery equipment, machine design, industrial machinery, Used Industrial Equipment","author":"exytrade","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":1,"created_utc":1387355069,"selftext":"","is_self":false}
{"is_self":false,"created_utc":1387351845,"selftext":"","author_flair_css_class":null,"ups":0,"media":null,"link_flair_css_class":null,"link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"stickied":false,"subreddit":"MachineLearning","url":"https://iamtrask.squarespace.com/blog/2013/12/18/machine-learning-2-hill-climbing-search-lifes-journey","title":"Machine Learning #2 - Hill Climbing and the Meaning of Life","subreddit_id":"t5_2r3gv","author":"u8mybrownies","num_comments":0,"id":"1t5l6g","user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1t5l6g/machine_learning_2_hill_climbing_and_the_meaning/","score":0,"domain":"iamtrask.squarespace.com","retrieved_on":1411458352,"selftext_html":null,"mod_reports":[],"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"default"}
{"secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":5,"id":"1t9sge","user_reports":[],"over_18":false,"score":34,"permalink":"/r/MachineLearning/comments/1t9sge/predicting_outlier_car_prices_using_websockets/","domain":"blog.yhathq.com","retrieved_on":1411452360,"selftext_html":null,"mod_reports":[],"thumbnail":"http://d.thumbs.redditmedia.com/_-b-RfCV5LTVhTGu.jpg","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"created_utc":1387485277,"selftext":"","is_self":false,"media":null,"link_flair_css_class":null,"ups":34,"author_flair_css_class":null,"banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"url":"http://blog.yhathq.com/posts/detecting-outlier-car-prices-on-the-web.html","title":"Predicting Outlier Car Prices Using WebSockets and Python","subreddit_id":"t5_2r3gv","author":"hernamesbarbara","subreddit":"MachineLearning","stickied":false}
{"link_flair_css_class":null,"media":null,"ups":39,"author_flair_css_class":null,"created_utc":1387442177,"selftext":"","is_self":false,"url":"https://github.com/eBay/bayesian-belief-networks","title":"eBay's open source Bayes Net library","author":"[deleted]","subreddit_id":"t5_2r3gv","subreddit":"MachineLearning","stickied":false,"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"score":39,"permalink":"/r/MachineLearning/comments/1t8hvs/ebays_open_source_bayes_net_library/","domain":"github.com","secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":0,"id":"1t8hvs","user_reports":[],"over_18":false,"thumbnail":"http://e.thumbs.redditmedia.com/3uZxQqqmOYer9hAj.jpg","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"retrieved_on":1411454342,"mod_reports":[],"selftext_html":null}
{"thumbnail":"self","edited":false,"distinguished":null,"report_reasons":null,"downs":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This has been a tremendous hangup for me in the years I&amp;#39;ve worked alongside economists, statisticians, and people who work on novel models. Now that I&amp;#39;m moving in this direction professionally, I want to recruit your help in squashing this issue.&lt;/p&gt;\n\n&lt;p&gt;We have a model space M, and are looking to choose the model m in M that best approximates a process or system. We also have a sample S generated by the process/system we wish to approximate. Obviously, some factors influence this decision:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is this a supervised or unsupervised task? Is it a reinforcement learning problem, where we have some reward/objective but no &amp;quot;correct&amp;quot; input/output pairs?&lt;/li&gt;\n&lt;li&gt;Do we want to estimate the joint distribution, or are we simply interested in predicting outputs (i.e. generative v. discriminative task)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;How do you choose m? Are there other obvious factors I missed above? &lt;/p&gt;\n\n&lt;p&gt;Additionally, models in M are simplified approximations. Do these assumptions affect your choice? How do you evaluate whether S satisfies these assumptions?&lt;/p&gt;\n\n&lt;p&gt;Please feel free to correct this characterization if I am mistaken somewhere!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411448224,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1tcg20/selecting_a_model_from_a_space_of_potential_models/","score":2,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"id":"1tcg20","num_comments":9,"user_reports":[],"subreddit_id":"t5_2r3gv","title":"Selecting a model from a space of potential models","author":"breakz","url":"http://www.reddit.com/r/MachineLearning/comments/1tcg20/selecting_a_model_from_a_space_of_potential_models/","stickied":false,"subreddit":"MachineLearning","author_flair_text":null,"banned_by":null,"secure_media":null,"link_flair_text":null,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":2,"selftext":"This has been a tremendous hangup for me in the years I've worked alongside economists, statisticians, and people who work on novel models. Now that I'm moving in this direction professionally, I want to recruit your help in squashing this issue.\n\nWe have a model space M, and are looking to choose the model m in M that best approximates a process or system. We also have a sample S generated by the process/system we wish to approximate. Obviously, some factors influence this decision:\n\n* Is this a supervised or unsupervised task? Is it a reinforcement learning problem, where we have some reward/objective but no \"correct\" input/output pairs?\n* Do we want to estimate the joint distribution, or are we simply interested in predicting outputs (i.e. generative v. discriminative task)?\n\nHow do you choose m? Are there other obvious factors I missed above? \n\nAdditionally, models in M are simplified approximations. Do these assumptions affect your choice? How do you evaluate whether S satisfies these assumptions?\n\nPlease feel free to correct this characterization if I am mistaken somewhere!","created_utc":1387568664,"is_self":true}
{"retrieved_on":1411448285,"selftext_html":null,"mod_reports":[],"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"http://b.thumbs.redditmedia.com/gipJb3BohMhIVOw7.jpg","user_reports":[],"num_comments":23,"id":"1tceo8","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":91,"permalink":"/r/MachineLearning/comments/1tceo8/selfstudy_guide_to_machine_learning/","domain":"machinelearningmastery.com","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"url":"http://machinelearningmastery.com/self-study-guide-to-machine-learning/","title":"Self-Study Guide to Machine Learning","author":"jasonb","subreddit_id":"t5_2r3gv","is_self":false,"created_utc":1387567673,"selftext":"","ups":91,"author_flair_css_class":null,"media":null,"link_flair_css_class":null}
{"domain":"self.MachineLearning","score":1,"permalink":"/r/MachineLearning/comments/1tcde7/selecting_a_model_that/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"id":"1tcde7","num_comments":0,"user_reports":[],"thumbnail":"default","edited":false,"downs":0,"distinguished":null,"report_reasons":null,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This has been a tremendous hangup for me in the years I&amp;#39;ve worked alongside modelers/quants/statisticians/people who develop novel models. Now that I&amp;#39;m moving in this direction professionally, I want to recruit your help in squashing this issue.&lt;/p&gt;\n\n&lt;p&gt;We have a model space M, and are looking to choose the model m in M that best approximates a process or system. We also have a sample S generated by the process/system we wish to approximate. Obviously, some factors influence this decision:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is this a supervised or unsupervised task? Is it a reinforcement learning problem, where we have some reward/objective but no &amp;quot;correct&amp;quot; input/output pairs?&lt;/li&gt;\n&lt;li&gt;Do we want to estimate the joint distribution, or are we simply interested in predicting outputs (i.e. generative v. discriminative task)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;How do you choose m? Are there other obvious factors I missed above? &lt;/p&gt;\n\n&lt;p&gt;Additionally, models in M are simplified approximations. Do these assumptions affect your choice? How do you evaluate whether S satisfies these assumptions?&lt;/p&gt;\n\n&lt;p&gt;Please feel free to correct this characterization if I am mistaken somewhere!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411448341,"media":null,"link_flair_css_class":null,"ups":1,"author_flair_css_class":null,"created_utc":1387566767,"selftext":"This has been a tremendous hangup for me in the years I've worked alongside modelers/quants/statisticians/people who develop novel models. Now that I'm moving in this direction professionally, I want to recruit your help in squashing this issue.\n\nWe have a model space M, and are looking to choose the model m in M that best approximates a process or system. We also have a sample S generated by the process/system we wish to approximate. Obviously, some factors influence this decision:\n\n* Is this a supervised or unsupervised task? Is it a reinforcement learning problem, where we have some reward/objective but no \"correct\" input/output pairs?\n* Do we want to estimate the joint distribution, or are we simply interested in predicting outputs (i.e. generative v. discriminative task)?\n\nHow do you choose m? Are there other obvious factors I missed above? \n\nAdditionally, models in M are simplified approximations. Do these assumptions affect your choice? How do you evaluate whether S satisfies these assumptions?\n\nPlease feel free to correct this characterization if I am mistaken somewhere!","is_self":true,"subreddit_id":"t5_2r3gv","title":"Selecting a model that","author":"[deleted]","url":"http://www.reddit.com/r/MachineLearning/comments/1tcde7/selecting_a_model_that/","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null}
{"score":9,"permalink":"/r/MachineLearning/comments/1tcddn/beginner_here_i_have_a_basic_machine_learning/","domain":"self.MachineLearning","num_comments":15,"id":"1tcddn","user_reports":[],"over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"self","retrieved_on":1411448341,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My data is &lt;/p&gt;\n\n&lt;p&gt;unique id | text string | label (1 or 0) |&lt;/p&gt;\n\n&lt;p&gt;Imagine the text string is jokes and the label is 1 for funny 0 for not funny. The strings are the text of jokes of varying length. I want to see if any words within the strings are more correlated with a joke being funny or not.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to begin this analysis?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"ups":9,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"is_self":true,"created_utc":1387566756,"selftext":"My data is \n\nunique id | text string | label (1 or 0) |\n\nImagine the text string is jokes and the label is 1 for funny 0 for not funny. The strings are the text of jokes of varying length. I want to see if any words within the strings are more correlated with a joke being funny or not.\n\nWhat would be the best way to begin this analysis?","subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1tcddn/beginner_here_i_have_a_basic_machine_learning/","subreddit_id":"t5_2r3gv","title":"Beginner here -- I have a basic machine learning / text classification problem. Labeled data, a text column strings of various lengths and I'd like to find which words in those strings are most correlated with my identifier.","author":"ineedhelpwithmath","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null}
{"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"title":"Bayesian Machine Learning Guide","subreddit_id":"t5_2r3gv","author":"mllover","url":"http://metacademy.org/roadmaps/rgrosse/bayesian_machine_learning","stickied":false,"subreddit":"MachineLearning","created_utc":1387666956,"selftext":"","is_self":false,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":83,"mod_reports":[],"selftext_html":null,"retrieved_on":1411443870,"thumbnail":"http://f.thumbs.redditmedia.com/g7WSfSN8S90Vmq1M.jpg","edited":false,"report_reasons":null,"distinguished":null,"downs":0,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":1,"user_reports":[],"id":"1tf9tr","domain":"metacademy.org","permalink":"/r/MachineLearning/comments/1tf9tr/bayesian_machine_learning_guide/","score":83}
{"edited":false,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"http://b.thumbs.redditmedia.com/JVzJNa16k81g5MBC.jpg","mod_reports":[],"selftext_html":null,"retrieved_on":1411444308,"domain":"blog.mortardata.com","permalink":"/r/MachineLearning/comments/1teyzj/6_dataset_lists/","score":13,"over_18":false,"id":"1teyzj","num_comments":0,"user_reports":[],"media_embed":{},"gilded":0,"secure_media_embed":{},"stickied":false,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","title":"6 dataset lists","author":"mllover","url":"http://blog.mortardata.com/post/67652898761/6-dataset-lists-curated-by-data-scientists","secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"author_flair_css_class":null,"ups":13,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1387658258,"selftext":""}
{"selftext":"I'm currently an EE senior who is planning to attend grad school for machine learning. I have a free month of winter break to study a topic of my choice. What would be most helpful for me? I've taken:\n\n- Calc I-III and Diff Eq\n- Linear Algebra\n- Linear Systems\n- Basic Probability and Statistics\n- DSP/Image Processing/Other EE classes\n- Machine Learning (next semester)\n\nI'm debating studying:\n\n- Optimization (From Nesterov's *Introductory Lectures on Convex Optimization*)\n- Machine Learning (From Bishop's *Pattern Recognition and Machine Learning*)\n- Statistics (Not sure what book)\n- Real Analysis (Not sure what book)\n\nIf you were in my shoes during your undergrad, what subject do you wish you had studied?","created_utc":1387647973,"is_self":true,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":8,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"subreddit_id":"t5_2r3gv","title":"I have a month of winter break to study a topic in preparation for grad school, what do I pick?","author":"mostly_complaints","url":"http://www.reddit.com/r/MachineLearning/comments/1tem6z/i_have_a_month_of_winter_break_to_study_a_topic/","stickied":false,"subreddit":"MachineLearning","media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":7,"user_reports":[],"id":"1tem6z","domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1tem6z/i_have_a_month_of_winter_break_to_study_a_topic/","score":8,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently an EE senior who is planning to attend grad school for machine learning. I have a free month of winter break to study a topic of my choice. What would be most helpful for me? I&amp;#39;ve taken:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Calc I-III and Diff Eq&lt;/li&gt;\n&lt;li&gt;Linear Algebra&lt;/li&gt;\n&lt;li&gt;Linear Systems&lt;/li&gt;\n&lt;li&gt;Basic Probability and Statistics&lt;/li&gt;\n&lt;li&gt;DSP/Image Processing/Other EE classes&lt;/li&gt;\n&lt;li&gt;Machine Learning (next semester)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m debating studying:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Optimization (From Nesterov&amp;#39;s &lt;em&gt;Introductory Lectures on Convex Optimization&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Machine Learning (From Bishop&amp;#39;s &lt;em&gt;Pattern Recognition and Machine Learning&lt;/em&gt;)&lt;/li&gt;\n&lt;li&gt;Statistics (Not sure what book)&lt;/li&gt;\n&lt;li&gt;Real Analysis (Not sure what book)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you were in my shoes during your undergrad, what subject do you wish you had studied?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411444847,"thumbnail":"self","edited":false,"report_reasons":null,"distinguished":null,"downs":0}
{"subreddit_id":"t5_2r3gv","title":"Modern Development On Brains, Minds, And Consciousness [Playlist]","author":"jry_AIHub","url":"http://www.reddit.com/r/MachineLearning/comments/1teggp/modern_development_on_brains_minds_and/","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"media":null,"link_flair_css_class":null,"ups":3,"author_flair_css_class":null,"created_utc":1387643038,"selftext":"This is a trio of videos that shines a light on the modern development on brains, minds, and consciousness.  The first in the series, ”Building Brains, Making Minds” introduces some past thoughts on this subject. In answering one of the guest comments, Dr. Lynn Nadel reveals that using Artificial Intelligence to model the memory aspect of the brain and for generating hypothesis is still limited.  The second one, “Metamemory: How Does the Brain Predict Itself?” provides details on how one is aware of his own memory. Lastly, “How does the brain generate consciousness?” Dr. Susan Greenfield offers a brilliant argument for her view on brains and consciousness. ","is_self":true,"thumbnail":"self","edited":false,"downs":0,"report_reasons":null,"distinguished":null,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a trio of videos that shines a light on the modern development on brains, minds, and consciousness.  The first in the series, ”Building Brains, Making Minds” introduces some past thoughts on this subject. In answering one of the guest comments, Dr. Lynn Nadel reveals that using Artificial Intelligence to model the memory aspect of the brain and for generating hypothesis is still limited.  The second one, “Metamemory: How Does the Brain Predict Itself?” provides details on how one is aware of his own memory. Lastly, “How does the brain generate consciousness?” Dr. Susan Greenfield offers a brilliant argument for her view on brains and consciousness. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411445092,"domain":"self.MachineLearning","score":3,"permalink":"/r/MachineLearning/comments/1teggp/modern_development_on_brains_minds_and/","gilded":0,"media_embed":{},"secure_media_embed":{},"over_18":false,"num_comments":2,"id":"1teggp","user_reports":[]}
{"thumbnail":"self","downs":0,"report_reasons":null,"distinguished":null,"edited":false,"retrieved_on":1411446007,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am having a problem thinking up a project. I want to add something using various machine learning algorithms to my portfolio, but I can&amp;#39;t think of data to do it on. Could anyone here give me a starting point? I was thinking stocks... but we all know why that is a bad road. Classification or Regression are both great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","score":5,"permalink":"/r/MachineLearning/comments/1tduhu/i_need_some_help_thinking_of_a_project_to_do_and/","domain":"self.MachineLearning","secure_media_embed":{},"gilded":0,"media_embed":{},"num_comments":5,"id":"1tduhu","user_reports":[],"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1tduhu/i_need_some_help_thinking_of_a_project_to_do_and/","subreddit_id":"t5_2r3gv","title":"I need some help thinking of a project to do.... and a data set.","author":"nanogoat","subreddit":"MachineLearning","stickied":false,"banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"media":null,"link_flair_css_class":null,"ups":5,"author_flair_css_class":null,"created_utc":1387610823,"selftext":"I am having a problem thinking up a project. I want to add something using various machine learning algorithms to my portfolio, but I can't think of data to do it on. Could anyone here give me a starting point? I was thinking stocks... but we all know why that is a bad road. Classification or Regression are both great.","is_self":true}
{"stickied":false,"subreddit":"MachineLearning","url":"http://www.datascienceweekly.org/blog/6-intelligent-probabilistic-systems-ryan-adams-harvard-prof-interview","subreddit_id":"t5_2r3gv","title":"Intelligent Probabilistic Systems: Ryan Adams (Harvard Prof) Interview","author":"hrb1979","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"author_flair_css_class":null,"ups":29,"media":null,"link_flair_css_class":null,"is_self":false,"created_utc":1387743622,"selftext":"","report_reasons":null,"distinguished":null,"downs":0,"edited":false,"thumbnail":"default","retrieved_on":1411440909,"mod_reports":[],"selftext_html":null,"permalink":"/r/MachineLearning/comments/1th8we/intelligent_probabilistic_systems_ryan_adams/","score":29,"domain":"datascienceweekly.org","num_comments":5,"id":"1th8we","user_reports":[],"over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0}
{"author_flair_css_class":null,"ups":0,"media":null,"link_flair_css_class":null,"is_self":true,"created_utc":1387725996,"selftext":"I preparing to do a project which will requires ML in a neural net which will have some ''input'' being the result of a Sentiement analysis. \n\nFYI\nI have followed Andrew Ng class on coursera and geoffrey Hinton's. Until now i worked alot in Matlab, but would like to do my project in Python.  \n\nWhat library should I use? for GPU usage? for ''simpler'' implementation ? Easy to understand?  Please help me out :)","stickied":false,"subreddit":"MachineLearning","author":"fawar","title":"Need some guidance","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1tgofh/need_some_guidance/","secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1tgofh/need_some_guidance/","score":0,"over_18":false,"num_comments":9,"user_reports":[],"id":"1tgofh","media_embed":{},"gilded":0,"secure_media_embed":{},"edited":false,"distinguished":null,"report_reasons":null,"downs":0,"thumbnail":"self","mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I preparing to do a project which will requires ML in a neural net which will have some &amp;#39;&amp;#39;input&amp;#39;&amp;#39; being the result of a Sentiement analysis. &lt;/p&gt;\n\n&lt;p&gt;FYI\nI have followed Andrew Ng class on coursera and geoffrey Hinton&amp;#39;s. Until now i worked alot in Matlab, but would like to do my project in Python.  &lt;/p&gt;\n\n&lt;p&gt;What library should I use? for GPU usage? for &amp;#39;&amp;#39;simpler&amp;#39;&amp;#39; implementation ? Easy to understand?  Please help me out :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411441813}
{"score":12,"permalink":"/r/MachineLearning/comments/1tg67k/recovering_background_matrices_using_principal/","domain":"blog.shriphani.com","num_comments":3,"user_reports":[],"id":"1tg67k","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"downs":0,"distinguished":null,"report_reasons":null,"edited":false,"thumbnail":"default","retrieved_on":1411442565,"selftext_html":null,"mod_reports":[],"ups":12,"author_flair_css_class":null,"link_flair_css_class":null,"media":null,"is_self":false,"created_utc":1387696497,"selftext":"","subreddit":"MachineLearning","stickied":false,"url":"http://blog.shriphani.com/2013/12/18/robust-principal-component-pursuit-background-matrix-recovery/","author":"shriphani","title":"Recovering background matrices using principal component pursuit","subreddit_id":"t5_2r3gv","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null}
{"num_comments":0,"user_reports":[],"id":"1tfi9l","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1tfi9l/metacademy_a_web_of_machine_learning_concepts/","score":1,"domain":"metacademy.org","retrieved_on":1411443531,"mod_reports":[],"selftext_html":null,"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"default","is_self":false,"created_utc":1387673937,"selftext":"","author_flair_css_class":null,"ups":1,"link_flair_css_class":null,"media":null,"link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","url":"http://metacademy.org/list","author":"[deleted]","title":"Metacademy - a web of machine learning concepts","subreddit_id":"t5_2r3gv"}
{"retrieved_on":1411436575,"mod_reports":[],"selftext_html":null,"distinguished":null,"report_reasons":null,"downs":0,"edited":false,"thumbnail":"http://f.thumbs.redditmedia.com/Yh7-IZlj7mledy7A.jpg","num_comments":13,"user_reports":[],"id":"1tk4oa","over_18":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"permalink":"/r/MachineLearning/comments/1tk4oa/machine_learning_kickstarter_vmx_project_computer/","score":21,"domain":"kickstarter.vmx.ai","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","url":"http://kickstarter.vmx.ai/","title":"Machine Learning KickStarter: VMX Project, Computer Vision for Everyone","subreddit_id":"t5_2r3gv","author":"compsens","is_self":false,"created_utc":1387835152,"selftext":"","author_flair_css_class":null,"ups":21,"media":null,"link_flair_css_class":null}
{"ups":10,"author_flair_css_class":null,"media":null,"link_flair_css_class":null,"is_self":true,"selftext":"I'm interested in what properties of feature vectors make learning easy or hard for particular classification algorithms, but am having trouble finding existing work.\n\n\nI commonly see two kinds of speed comparison for learning algorithms:\n\n1. Algorithm A^1 converges faster than A^2 over some broad class of problems.\n\n2. Algorithm A converges faster when the examples V^1 have some property than V^2 that lacks it.\n\nI'm interested in the more problem-specific question (less asymptotics), here mostly specific to classification:\n\n* Algorithm A converges faster for the class labeling L^1 of the examples V than with the labeling L^2.\n\nI know some things that can matter for this kind of classification difficulty (e.g., linear separability of the classes, distance between their centroids, etc.), but I'd like to have better access to existing results.\n\nIs there some useful terminology I could use for looking for these kinds of comparisons? Useful sources? Other things to know?","created_utc":1387901467,"subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1tm1ym/relative_speed_of_classification_problems/","title":"Relative speed of classification problems?","subreddit_id":"t5_2r3gv","author":"ughduck","link_flair_text":null,"secure_media":null,"banned_by":null,"author_flair_text":null,"score":10,"permalink":"/r/MachineLearning/comments/1tm1ym/relative_speed_of_classification_problems/","domain":"self.MachineLearning","num_comments":4,"user_reports":[],"id":"1tm1ym","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"downs":0,"report_reasons":null,"distinguished":null,"edited":1387951485,"thumbnail":"self","retrieved_on":1411433727,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in what properties of feature vectors make learning easy or hard for particular classification algorithms, but am having trouble finding existing work.&lt;/p&gt;\n\n&lt;p&gt;I commonly see two kinds of speed comparison for learning algorithms:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Algorithm A&lt;sup&gt;1&lt;/sup&gt; converges faster than A&lt;sup&gt;2&lt;/sup&gt; over some broad class of problems.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Algorithm A converges faster when the examples V&lt;sup&gt;1&lt;/sup&gt; have some property than V&lt;sup&gt;2&lt;/sup&gt; that lacks it.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m interested in the more problem-specific question (less asymptotics), here mostly specific to classification:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Algorithm A converges faster for the class labeling L&lt;sup&gt;1&lt;/sup&gt; of the examples V than with the labeling L&lt;sup&gt;2.&lt;/sup&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I know some things that can matter for this kind of classification difficulty (e.g., linear separability of the classes, distance between their centroids, etc.), but I&amp;#39;d like to have better access to existing results.&lt;/p&gt;\n\n&lt;p&gt;Is there some useful terminology I could use for looking for these kinds of comparisons? Useful sources? Other things to know?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"}
{"is_self":true,"created_utc":1387973941,"selftext":"An interesting and pretty light paper about some curious characteristics of neural networks. Big names among the authors.\n\nAbstract: Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninter- pretable solutions that could have counter-intuitive properties. In this paper we report two such properties.\nFirst, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.\nSecond, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. Specifically, we find that we can cause the network to misclassify an image by applying a certain imperceptible pertur- bation, which is found by maximizing the network’s prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.\n\nhttp://arxiv.org/pdf/1312.6199v1.pdf","author_flair_css_class":null,"ups":33,"media":null,"link_flair_css_class":null,"secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","title":"Intriguing properties of neural networks","subreddit_id":"t5_2r3gv","author":"Foxtr0t","url":"http://www.reddit.com/r/MachineLearning/comments/1to4gr/intriguing_properties_of_neural_networks/","over_18":false,"num_comments":25,"user_reports":[],"id":"1to4gr","media_embed":{},"gilded":0,"secure_media_embed":{},"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1to4gr/intriguing_properties_of_neural_networks/","score":33,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;An interesting and pretty light paper about some curious characteristics of neural networks. Big names among the authors.&lt;/p&gt;\n\n&lt;p&gt;Abstract: Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninter- pretable solutions that could have counter-intuitive properties. In this paper we report two such properties.\nFirst, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.\nSecond, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. Specifically, we find that we can cause the network to misclassify an image by applying a certain imperceptible pertur- bation, which is found by maximizing the network’s prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://arxiv.org/pdf/1312.6199v1.pdf\"&gt;http://arxiv.org/pdf/1312.6199v1.pdf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"retrieved_on":1411430637,"edited":false,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"self"}
{"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":5,"created_utc":1387950791,"selftext":"I downloaded darch from elsewhere but I can't seem to install it from my local disk.","is_self":true,"url":"http://www.reddit.com/r/MachineLearning/comments/1tnp07/is_there_cran_a_deep_learning_package_for_r_i/","author":"duckandcover","title":"Is there CRAN a deep learning package for R? I heard about Darch but it's not on CRAN","subreddit_id":"t5_2r3gv","stickied":false,"subreddit":"MachineLearning","banned_by":null,"author_flair_text":null,"link_flair_text":null,"secure_media":null,"permalink":"/r/MachineLearning/comments/1tnp07/is_there_cran_a_deep_learning_package_for_r_i/","score":5,"domain":"self.MachineLearning","secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":10,"id":"1tnp07","user_reports":[],"over_18":false,"thumbnail":"self","report_reasons":null,"distinguished":null,"downs":0,"edited":false,"retrieved_on":1411431312,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I downloaded darch from elsewhere but I can&amp;#39;t seem to install it from my local disk.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[]}
{"thumbnail":"default","edited":false,"report_reasons":null,"distinguished":null,"downs":0,"selftext_html":null,"mod_reports":[],"retrieved_on":1411425798,"domain":"dataspace.princeton.edu","permalink":"/r/MachineLearning/comments/1trg94/provable_algorithms_for_machine_learning_problems/","score":16,"media_embed":{},"gilded":0,"secure_media_embed":{},"over_18":false,"num_comments":0,"user_reports":[],"id":"1trg94","subreddit_id":"t5_2r3gv","title":"Provable Algorithms for Machine Learning Problems","author":"hrb1979","url":"http://dataspace.princeton.edu/jspui/bitstream/88435/dsp019k41zd62n/1/Ge_princeton_0181D_10819.pdf","stickied":false,"subreddit":"MachineLearning","banned_by":null,"author_flair_text":null,"secure_media":null,"link_flair_text":null,"media":null,"link_flair_css_class":null,"author_flair_css_class":null,"ups":16,"created_utc":1388094192,"selftext":"","is_self":false}
{"over_18":false,"id":"1tqoz0","num_comments":6,"user_reports":[],"media_embed":{},"gilded":0,"secure_media_embed":{},"domain":"self.MachineLearning","permalink":"/r/MachineLearning/comments/1tqoz0/linear_classification_with_nearest_neighbors/","score":4,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to machine learning, but I have a fair amount of experience with the &lt;a href=\"http://en.wikipedia.org/wiki/Perceptron#Definition\"&gt;Perceptron learning algorithm.&lt;/a&gt; It seems to me that one of the main problems with this method is that it picks a &lt;em&gt;random&lt;/em&gt; misclassified point- this could lead to the algorithm being fitted to noise. For instance, if there were five points that had actual values of +1 and one in the middle that had a value of -1, that point should not be used to update the Perceptron&amp;#39;s weights. &lt;/p&gt;\n\n&lt;p&gt;I know that a certain amount of noise-fitting is inevitable, but what if a nearest-neighbors algorithm were used to determine with which values to update the weights? Would this be an effective way of reducing noise&amp;#39;s effect on the final hypothesis, or would it not really change much? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1411426902,"edited":false,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"self","is_self":true,"created_utc":1388072901,"selftext":"I'm new to machine learning, but I have a fair amount of experience with the [Perceptron learning algorithm.](http://en.wikipedia.org/wiki/Perceptron#Definition) It seems to me that one of the main problems with this method is that it picks a *random* misclassified point- this could lead to the algorithm being fitted to noise. For instance, if there were five points that had actual values of +1 and one in the middle that had a value of -1, that point should not be used to update the Perceptron's weights. \n\nI know that a certain amount of noise-fitting is inevitable, but what if a nearest-neighbors algorithm were used to determine with which values to update the weights? Would this be an effective way of reducing noise's effect on the final hypothesis, or would it not really change much? Thanks!","author_flair_css_class":null,"ups":4,"link_flair_css_class":null,"media":null,"secure_media":null,"link_flair_text":null,"banned_by":null,"author_flair_text":null,"stickied":false,"subreddit":"MachineLearning","author":"jpercussionist","title":"Linear classification with nearest neighbors element?","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/1tqoz0/linear_classification_with_nearest_neighbors/"}
{"over_18":false,"num_comments":6,"id":"1tqh1l","user_reports":[],"media_embed":{},"gilded":0,"secure_media_embed":{},"domain":"github.com","permalink":"/r/MachineLearning/comments/1tqh1l/python_implementation_of_sparse_autoencoder/","score":42,"mod_reports":[],"selftext_html":null,"retrieved_on":1411427222,"edited":false,"report_reasons":null,"distinguished":null,"downs":0,"thumbnail":"http://e.thumbs.redditmedia.com/3uZxQqqmOYer9hAj.jpg","is_self":false,"selftext":"","created_utc":1388063276,"author_flair_css_class":null,"ups":42,"media":null,"link_flair_css_class":null,"secure_media":null,"link_flair_text":null,"author_flair_text":null,"banned_by":null,"stickied":false,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","title":"Python implementation of Sparse Autoencoder","author":"siddharth950","url":"https://github.com/siddharth950/Sparse-Autoencoder"}
{"retrieved_on":1411427241,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m new to Python and was wondering if someone could review my implementation. I&amp;#39;ve heard that Numpy tricks can be used to significantly improve the efficiency of computation. Kindly indicate how I can improve this implementation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"downs":0,"report_reasons":null,"distinguished":null,"edited":false,"thumbnail":"default","num_comments":0,"user_reports":[],"id":"1tqgj5","over_18":false,"secure_media_embed":{},"gilded":0,"media_embed":{},"score":1,"permalink":"/r/MachineLearning/comments/1tqgj5/python_implementation_of_sparse_autoencoder/","domain":"self.MachineLearning","link_flair_text":null,"secure_media":null,"author_flair_text":null,"banned_by":null,"subreddit":"MachineLearning","stickied":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1tqgj5/python_implementation_of_sparse_autoencoder/","title":"Python implementation of Sparse Autoencoder","subreddit_id":"t5_2r3gv","author":"[deleted]","is_self":true,"created_utc":1388062370,"selftext":"Hi, I'm new to Python and was wondering if someone could review my implementation. I've heard that Numpy tricks can be used to significantly improve the efficiency of computation. Kindly indicate how I can improve this implementation.","ups":1,"author_flair_css_class":null,"link_flair_css_class":null,"media":null}
{"author_flair_text":null,"banned_by":null,"link_flair_text":null,"secure_media":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1tqg6v/sparse_autoencoder_with_the_dropout/","author":"[deleted]","title":"Sparse Autoencoder with the dropout ?","subreddit_id":"t5_2r3gv","stickied":false,"subreddit":"MachineLearning","created_utc":1388061814,"selftext":"I have a theoretical question.\n\ndoes it make sense to combine Sparse Autoencoder with the dropout technique and maxout? ..when Dropout adds sparsity itself. Is dropout only useful for a big system? or ca I use it on a small test architecture (like 64-25-3)","is_self":true,"link_flair_css_class":null,"media":null,"author_flair_css_class":null,"ups":2,"retrieved_on":1411427256,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a theoretical question.&lt;/p&gt;\n\n&lt;p&gt;does it make sense to combine Sparse Autoencoder with the dropout technique and maxout? ..when Dropout adds sparsity itself. Is dropout only useful for a big system? or ca I use it on a small test architecture (like 64-25-3)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"default","distinguished":null,"report_reasons":null,"downs":0,"edited":false,"secure_media_embed":{},"media_embed":{},"gilded":0,"num_comments":4,"user_reports":[],"id":"1tqg6v","over_18":false,"permalink":"/r/MachineLearning/comments/1tqg6v/sparse_autoencoder_with_the_dropout/","score":2,"domain":"self.MachineLearning"}
{"stickied":false,"secure_media_embed":{},"author":"Foxtr0t","permalink":"/r/MachineLearning/comments/1tttu7/a_neural_network_learns_to_play_video_games_by/","url":"http://www.reddit.com/r/MachineLearning/comments/1tttu7/a_neural_network_learns_to_play_video_games_by/","created_utc":1388175865,"over_18":false,"score":55,"author_flair_css_class":null,"media_embed":{},"banned_by":null,"report_reasons":null,"link_flair_css_class":null,"title":"A neural network learns to play video games by watching","selftext":"Playing Atari with Deep Reinforcement Learning\n\nAbstract: We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.\n\nhttp://arxiv.org/abs/1312.5602","mod_reports":[],"id":"1tttu7","downs":0,"edited":false,"is_self":true,"user_reports":[],"link_flair_text":null,"gilded":0,"secure_media":null,"distinguished":null,"thumbnail":"self","domain":"self.MachineLearning","num_comments":9,"author_flair_text":null,"subreddit_id":"t5_2r3gv","retrieved_on":1411421578,"subreddit":"MachineLearning","media":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Playing Atari with Deep Reinforcement Learning&lt;/p&gt;\n\n&lt;p&gt;Abstract: We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://arxiv.org/abs/1312.5602\"&gt;http://arxiv.org/abs/1312.5602&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","ups":55}
{"media":null,"selftext_html":null,"subreddit":"MachineLearning","ups":5,"num_comments":8,"retrieved_on":1411421585,"subreddit_id":"t5_2r3gv","author_flair_text":null,"domain":"onthelambda.com","secure_media":null,"thumbnail":"default","distinguished":null,"gilded":0,"user_reports":[],"is_self":false,"link_flair_text":null,"edited":false,"downs":0,"id":"1tttpg","mod_reports":[],"selftext":"","banned_by":null,"report_reasons":null,"media_embed":{},"title":"The performance gains from switching R's linear algebra libraries","link_flair_css_class":null,"author_flair_css_class":null,"score":5,"created_utc":1388175766,"over_18":false,"url":"http://www.onthelambda.com/2013/12/26/the-performance-gains-from-switching-rs-linear-algebra-libraries/","permalink":"/r/MachineLearning/comments/1tttpg/the_performance_gains_from_switching_rs_linear/","secure_media_embed":{},"stickied":false,"author":"Foxtr0t"}
{"gilded":0,"is_self":true,"user_reports":[],"link_flair_text":null,"domain":"self.MachineLearning","secure_media":null,"distinguished":null,"thumbnail":"self","num_comments":9,"subreddit_id":"t5_2r3gv","author_flair_text":null,"retrieved_on":1411422512,"subreddit":"MachineLearning","media":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been reading &amp;quot;Doing Data Science&amp;quot; by O&amp;#39;Neil and Schutt (and, by the way, I think it is very good).  One section describes a process for evaluating the predictive power of a model by replaying a series of past events, using all of the data prior to time t to predict what will happen at time t (for all t).&lt;/p&gt;\n\n&lt;p&gt;This is such a fine idea that it seems like it must have a name.  The book refers to it as a &amp;quot;causal model&amp;quot; because it obeys the notion that causality can only go forward in time.  Is this a commonly-used term for this idea?  A Google search reveals that &amp;quot;causal modeling&amp;quot; is more often used for models that are intended to show causality (beyond just correlation) so that&amp;#39;s a different thing entirely.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","ups":7,"url":"http://www.reddit.com/r/MachineLearning/comments/1tt678/bettercorrect_term_for_causal_modeling/","permalink":"/r/MachineLearning/comments/1tt678/bettercorrect_term_for_causal_modeling/","secure_media_embed":{},"stickied":false,"author":"AllenDowney","score":7,"created_utc":1388157997,"over_18":false,"media_embed":{},"banned_by":null,"report_reasons":null,"link_flair_css_class":null,"title":"Better/correct term for \"causal modeling\"?","author_flair_css_class":null,"id":"1tt678","downs":0,"edited":false,"selftext":"I have been reading \"Doing Data Science\" by O'Neil and Schutt (and, by the way, I think it is very good).  One section describes a process for evaluating the predictive power of a model by replaying a series of past events, using all of the data prior to time t to predict what will happen at time t (for all t).\n\nThis is such a fine idea that it seems like it must have a name.  The book refers to it as a \"causal model\" because it obeys the notion that causality can only go forward in time.  Is this a commonly-used term for this idea?  A Google search reveals that \"causal modeling\" is more often used for models that are intended to show causality (beyond just correlation) so that's a different thing entirely.","mod_reports":[]}
{"link_flair_css_class":null,"title":"I need a name for a data analytics club.","media_embed":{},"banned_by":null,"report_reasons":null,"author_flair_css_class":null,"id":"1tsgmh","downs":0,"edited":false,"selftext":"I am founding a data analytics club in my univ and I need a name. Can any of you help?","mod_reports":[],"permalink":"/r/MachineLearning/comments/1tsgmh/i_need_a_name_for_a_data_analytics_club/","url":"http://www.reddit.com/r/MachineLearning/comments/1tsgmh/i_need_a_name_for_a_data_analytics_club/","author":"bluewolf4","stickied":false,"secure_media_embed":{},"score":7,"over_18":false,"created_utc":1388123577,"author_flair_text":null,"subreddit_id":"t5_2r3gv","retrieved_on":1411423612,"num_comments":17,"ups":7,"subreddit":"MachineLearning","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am founding a data analytics club in my univ and I need a name. Can any of you help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"gilded":0,"link_flair_text":null,"is_self":true,"user_reports":[],"domain":"self.MachineLearning","distinguished":null,"thumbnail":"self","secure_media":null}
{"author_flair_css_class":null,"media_embed":{},"report_reasons":null,"banned_by":null,"link_flair_css_class":null,"title":"Mining frequent itemsets in textual documents (storage issues)","selftext":"Hi guys,\n\nI am working on a research project that aims to scan a large number of documents and identify itemsets in the form of word sequences. Another team is working in the same task using Markov Chains and we will later compare our approaches. \n\nThe problem is that the text corpus we are mining is extremely big. We are dealing with about 19 GB of text files. Whenever we detect an itemset (where k &lt;= 3) we store the information on a relational dbms together with its support count. \n\nHowever, the tables in our relational dbms get pretty big pretty quickly and it takes a lot of time to query our database. Our queries only search by the first word in a sequence (the order of words matters in our case).\n\nDoes anyone have any experience with similar issues? Is it feasible to try with NoSQL databases or Graph databases maybe?","mod_reports":[],"id":"1twdqd","edited":false,"downs":0,"secure_media_embed":{},"stickied":false,"author":"vshehu","url":"http://www.reddit.com/r/MachineLearning/comments/1twdqd/mining_frequent_itemsets_in_textual_documents/","permalink":"/r/MachineLearning/comments/1twdqd/mining_frequent_itemsets_in_textual_documents/","created_utc":1388266182,"over_18":false,"score":1,"num_comments":7,"subreddit_id":"t5_2r3gv","author_flair_text":null,"retrieved_on":1411417779,"subreddit":"MachineLearning","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I am working on a research project that aims to scan a large number of documents and identify itemsets in the form of word sequences. Another team is working in the same task using Markov Chains and we will later compare our approaches. &lt;/p&gt;\n\n&lt;p&gt;The problem is that the text corpus we are mining is extremely big. We are dealing with about 19 GB of text files. Whenever we detect an itemset (where k &amp;lt;= 3) we store the information on a relational dbms together with its support count. &lt;/p&gt;\n\n&lt;p&gt;However, the tables in our relational dbms get pretty big pretty quickly and it takes a lot of time to query our database. Our queries only search by the first word in a sequence (the order of words matters in our case).&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience with similar issues? Is it feasible to try with NoSQL databases or Graph databases maybe?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"ups":1,"is_self":true,"user_reports":[],"link_flair_text":null,"gilded":0,"secure_media":null,"distinguished":null,"thumbnail":"self","domain":"self.MachineLearning"}
{"num_comments":3,"author_flair_text":null,"subreddit_id":"t5_2r3gv","retrieved_on":1411418722,"subreddit":"MachineLearning","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a software dev and I haven&amp;#39;t studied machine learning before. I&amp;#39;m interested in analyzing patterns of my user&amp;#39;s log files to profile them better.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to ask for your help on what is the best way to get started quickly. What are the books/tutorials/sites that I should read to get me started. I&amp;#39;d appreciate your help. Thanks a lot in advance! :)&lt;/p&gt;\n\n&lt;p&gt;P.S.\nAlso I&amp;#39;d like to hear any advice or tips that you can share. Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"ups":9,"gilded":0,"is_self":true,"user_reports":[],"link_flair_text":null,"domain":"self.MachineLearning","secure_media":null,"distinguished":null,"thumbnail":"self","media_embed":{},"banned_by":null,"report_reasons":null,"link_flair_css_class":null,"title":"Quick start on analyzing server logs for patterns","author_flair_css_class":null,"id":"1tvqmk","edited":1388248007,"downs":0,"selftext":"Hi all!\n\nI'm a software dev and I haven't studied machine learning before. I'm interested in analyzing patterns of my user's log files to profile them better.\n\nI'd like to ask for your help on what is the best way to get started quickly. What are the books/tutorials/sites that I should read to get me started. I'd appreciate your help. Thanks a lot in advance! :)\n\nP.S.\nAlso I'd like to hear any advice or tips that you can share. Thanks again!","mod_reports":[],"permalink":"/r/MachineLearning/comments/1tvqmk/quick_start_on_analyzing_server_logs_for_patterns/","url":"http://www.reddit.com/r/MachineLearning/comments/1tvqmk/quick_start_on_analyzing_server_logs_for_patterns/","stickied":false,"secure_media_embed":{},"author":"ajushi","score":9,"created_utc":1388247505,"over_18":false}
{"num_comments":4,"retrieved_on":1411420656,"author_flair_text":null,"subreddit_id":"t5_2r3gv","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have solved UFLDL &amp;quot;Exercise: Sparse Autoencoders&amp;quot;, but have trouble adding G. Hinton&amp;#39;s Dropout technique + the maxout activation function. Somebody who can help me?&lt;/p&gt;\n\n&lt;p&gt;Task:\n&lt;a href=\"http://deeplearning.stanford.edu/wiki/index.php/Exercise:Sparse_Autoencoder\"&gt;http://deeplearning.stanford.edu/wiki/index.php/Exercise:Sparse_Autoencoder&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Solution:\nsparse autoencoder (without Dropout or relu) example: &lt;a href=\"https://github.com/onlymag4u/UFLDL_SparseAutoencoder/tree/master/sparseae_exercise/code\"&gt;https://github.com/onlymag4u/UFLDL_SparseAutoencoder/tree/master/sparseae_exercise/code&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"subreddit":"MachineLearning","ups":3,"user_reports":[],"is_self":true,"link_flair_text":null,"gilded":0,"secure_media":null,"thumbnail":"self","distinguished":null,"domain":"self.MachineLearning","author_flair_css_class":null,"report_reasons":null,"banned_by":null,"media_embed":{},"title":"Sparse Autoencoder + dropout ?","link_flair_css_class":null,"mod_reports":[],"selftext":"I have solved UFLDL \"Exercise: Sparse Autoencoders\", but have trouble adding G. Hinton's Dropout technique + the maxout activation function. Somebody who can help me?\n\nTask:\nhttp://deeplearning.stanford.edu/wiki/index.php/Exercise:Sparse_Autoencoder\n\nSolution:\nsparse autoencoder (without Dropout or relu) example: https://github.com/onlymag4u/UFLDL_SparseAutoencoder/tree/master/sparseae_exercise/code\n\n","downs":0,"edited":false,"id":"1tug0j","stickied":false,"secure_media_embed":{},"author":"rishok","permalink":"/r/MachineLearning/comments/1tug0j/sparse_autoencoder_dropout/","url":"http://www.reddit.com/r/MachineLearning/comments/1tug0j/sparse_autoencoder_dropout/","created_utc":1388192673,"over_18":false,"score":3}
{"score":2,"created_utc":1388348705,"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1tym0s/relu_for_autoencoder/","permalink":"/r/MachineLearning/comments/1tym0s/relu_for_autoencoder/","stickied":false,"secure_media_embed":{},"author":"rishok","id":"1tym0s","downs":0,"edited":false,"selftext":"Is it possible to use the ReLU activation function with an Autoencoder? how? ﻿","mod_reports":[],"media_embed":{},"report_reasons":null,"banned_by":null,"link_flair_css_class":null,"title":"ReLU for Autoencoder?","author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"distinguished":null,"thumbnail":"self","gilded":0,"is_self":true,"user_reports":[],"link_flair_text":null,"subreddit":"MachineLearning","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to use the ReLU activation function with an Autoencoder? how? ﻿&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"ups":2,"num_comments":5,"subreddit_id":"t5_2r3gv","author_flair_text":null,"retrieved_on":1411414433}
{"title":"Statistics for Use of Machine Learning in Industry?","link_flair_css_class":null,"banned_by":null,"report_reasons":null,"media_embed":{},"author_flair_css_class":null,"downs":0,"edited":false,"id":"1tyeeq","mod_reports":[],"selftext":"I'm trying to find out what the biggest uses of machine learning are in industry, but am having trouble finding any hard stats. I guess \"use in industry\" may be a little hard to quantify, so I tried searching for R&amp;D spending statistics - to no avail.\n\nSome queries I've tried:\n\n* \"machine learning applications in industry\"\n* \"machine learning research statistics\"\n* \"machine learning spending\"\n* \"statistics of machine learning uses\"\n* \"biggest use of machine learning\"\n\netc.\n\nWould any of you be able to shed some light on this matter?\n\nThanks!","url":"http://www.reddit.com/r/MachineLearning/comments/1tyeeq/statistics_for_use_of_machine_learning_in_industry/","permalink":"/r/MachineLearning/comments/1tyeeq/statistics_for_use_of_machine_learning_in_industry/","author":"kevkev3","secure_media_embed":{},"stickied":false,"score":8,"over_18":false,"created_utc":1388343091,"retrieved_on":1411414744,"subreddit_id":"t5_2r3gv","author_flair_text":null,"num_comments":15,"ups":8,"media":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to find out what the biggest uses of machine learning are in industry, but am having trouble finding any hard stats. I guess &amp;quot;use in industry&amp;quot; may be a little hard to quantify, so I tried searching for R&amp;amp;D spending statistics - to no avail.&lt;/p&gt;\n\n&lt;p&gt;Some queries I&amp;#39;ve tried:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;machine learning applications in industry&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;machine learning research statistics&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;machine learning spending&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;statistics of machine learning uses&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;biggest use of machine learning&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;etc.&lt;/p&gt;\n\n&lt;p&gt;Would any of you be able to shed some light on this matter?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","subreddit":"MachineLearning","gilded":0,"link_flair_text":null,"user_reports":[],"is_self":true,"domain":"self.MachineLearning","thumbnail":"self","distinguished":null,"secure_media":null}
{"ups":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I am writing a Canny edge detection algorithm.  I&amp;#39;m testing it on simple shapes right now, such as circles and squares.  It does great at detecting lines that are close to horizontal and vertical, however, it fails when the lines approach 45 degrees (or 135 or 225 or 315).  Is it common for this algorithm to fail at corners?  Anyone worked with this algorithm before and come up with the same issues?&lt;/p&gt;\n\n&lt;p&gt;Best,\nAdam&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"subreddit":"MachineLearning","retrieved_on":1411416526,"author_flair_text":null,"subreddit_id":"t5_2r3gv","num_comments":6,"domain":"self.MachineLearning","thumbnail":"self","distinguished":null,"secure_media":null,"gilded":0,"link_flair_text":null,"user_reports":[],"is_self":true,"downs":0,"edited":false,"id":"1tx8i8","mod_reports":[],"selftext":"Hey everyone,\n\nI am writing a Canny edge detection algorithm.  I'm testing it on simple shapes right now, such as circles and squares.  It does great at detecting lines that are close to horizontal and vertical, however, it fails when the lines approach 45 degrees (or 135 or 225 or 315).  Is it common for this algorithm to fail at corners?  Anyone worked with this algorithm before and come up with the same issues?\n\nBest,\nAdam","title":"Canny edge detection","link_flair_css_class":null,"banned_by":null,"report_reasons":null,"media_embed":{},"author_flair_css_class":null,"score":0,"over_18":false,"created_utc":1388292605,"permalink":"/r/MachineLearning/comments/1tx8i8/canny_edge_detection/","url":"http://www.reddit.com/r/MachineLearning/comments/1tx8i8/canny_edge_detection/","author":"getout","secure_media_embed":{},"stickied":false}
{"media":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My personal project is to build a system that forecasts the risk of avalanches in the mountains given weather data. So, input is a time series of NOAA weather (precipitation, wind, temperature) data. The target is 4 years of human predicted avalanche dangers.&lt;/p&gt;\n\n&lt;p&gt;As background, the snow pack in the mountain is composed of layers of the current seasons snowfall. Each snowfall leaves a distinct layer, like rings on a tree or the grand canyon. A 2-month old layer can become a weak foundation and behave like ball bearings. A blizzard comes along and loads this trigger with feet of snow and now you have high avalanche danger.&lt;/p&gt;\n\n&lt;p&gt;Since the danger is caused partially by something that happened in the past, I settled on a recurrent neural network ( rnn .) The NN needs to have a memory of all the layers in the snow pack. Using PyBrain, I got no results. Random guessing would be much better.&lt;/p&gt;\n\n&lt;p&gt;Thus, I started on a simpler rnn problem: predicting &lt;a href=\"http://cogsci.ucd.ie/Connectionism/Exercises/Exercise3.php\"&gt;Reber grammer strings.&lt;/a&gt; My code is below, and again it doesn&amp;#39;t work. Am I on the right track? I’m trying to learn from examples, but I’m missing something. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot;An example of a recurrent neural network (that doesn&amp;#39;t work) to predict a Reber Grammer&amp;quot;&amp;quot;&amp;quot;\nimport csv, urllib\nfrom pybrain.datasets.supervised import SupervisedDataSet\nfrom pybrain.supervised          import BackpropTrainer\nfrom pybrain.tools.shortcuts     import buildNetwork\nfrom pybrain.structure import RecurrentNetwork\nfrom pybrain.structure import LinearLayer, SigmoidLayer\nfrom pybrain.structure import FullConnection\n\n\n\n# More information on Reber Grammar can be found at http://cogsci.ucd.ie/Connectionism/Exercises/Exercise3.php\nf=urllib.urlopen(&amp;#39;http://cogsci.ucd.ie/Connectionism/Labs/basicProp/reber.pat&amp;#39;,&amp;#39;r&amp;#39;)\n\n#--- Reading Reber Grammar data from a website. The characters have already been transformed into binary vectors.\nfor i in range(4): #Skipping 4 rows of header information\n    f.readline()\nreader = csv.reader(f,delimiter=&amp;#39; &amp;#39;,quoting=csv.QUOTE_NONE)\nheader = []\nrecords = []\nfields = 14\n\n#---- Feeding data in PyBrain dataset\ntrndata = SupervisedDataSet(7, 7)\nfor row, record in enumerate(reader):\n    record = [int(i) for i in record if i&amp;lt;&amp;gt;&amp;#39;&amp;#39;]\n    indata = tuple(record[:7])\n    outdata = tuple(record[7:])\n    trndata.addSample(indata,outdata)\n\n#---- Building Network\nn = RecurrentNetwork()\nn.addInputModule(LinearLayer(7, name=&amp;#39;in&amp;#39;))\nn.addModule(SigmoidLayer(7, name=&amp;#39;hidden&amp;#39;))\nn.addOutputModule(LinearLayer(7, name=&amp;#39;out&amp;#39;))\nn.addConnection(FullConnection(n[&amp;#39;in&amp;#39;], n[&amp;#39;hidden&amp;#39;], name=&amp;#39;c1&amp;#39;))\nn.addConnection(FullConnection(n[&amp;#39;hidden&amp;#39;], n[&amp;#39;out&amp;#39;], name=&amp;#39;c2&amp;#39;))\nn.addRecurrentConnection(FullConnection(n[&amp;#39;hidden&amp;#39;], n[&amp;#39;hidden&amp;#39;], name=&amp;#39;c3&amp;#39;))\nn.sortModules()   \n\n#---- Training Network\nt = BackpropTrainer(n,learningrate=0.01,momentum=0.5,verbose=True)\nt.trainOnDataset(trndata,5)\n\n#---- Testing by feeding ouput into input. Should create Reber Grammer string grammer,\n# but instead gets stuck on one character. \nn.reset()\ninput = [1]+[0]*6\nfor i in range(100):\n    print input\n    input = n.activate(input)\n    input = [int(x&amp;gt;=max(input)) for x in input] #Assumes that the chosen character is the one with the highest value\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","subreddit":"MachineLearning","ups":7,"num_comments":13,"retrieved_on":1411410673,"author_flair_text":null,"subreddit_id":"t5_2r3gv","domain":"self.MachineLearning","secure_media":null,"thumbnail":"self","distinguished":null,"gilded":0,"user_reports":[],"is_self":true,"link_flair_text":null,"edited":false,"downs":0,"id":"1u13zz","mod_reports":[],"selftext":"My personal project is to build a system that forecasts the risk of avalanches in the mountains given weather data. So, input is a time series of NOAA weather (precipitation, wind, temperature) data. The target is 4 years of human predicted avalanche dangers.\n\nAs background, the snow pack in the mountain is composed of layers of the current seasons snowfall. Each snowfall leaves a distinct layer, like rings on a tree or the grand canyon. A 2-month old layer can become a weak foundation and behave like ball bearings. A blizzard comes along and loads this trigger with feet of snow and now you have high avalanche danger.\n\nSince the danger is caused partially by something that happened in the past, I settled on a recurrent neural network ( rnn .) The NN needs to have a memory of all the layers in the snow pack. Using PyBrain, I got no results. Random guessing would be much better.\n\nThus, I started on a simpler rnn problem: predicting [Reber grammer strings.](http://cogsci.ucd.ie/Connectionism/Exercises/Exercise3.php) My code is below, and again it doesn't work. Am I on the right track? I’m trying to learn from examples, but I’m missing something. \n\n    \"\"\"An example of a recurrent neural network (that doesn't work) to predict a Reber Grammer\"\"\"\n    import csv, urllib\n    from pybrain.datasets.supervised import SupervisedDataSet\n    from pybrain.supervised          import BackpropTrainer\n    from pybrain.tools.shortcuts     import buildNetwork\n    from pybrain.structure import RecurrentNetwork\n    from pybrain.structure import LinearLayer, SigmoidLayer\n    from pybrain.structure import FullConnection\n\n\n\n    # More information on Reber Grammar can be found at http://cogsci.ucd.ie/Connectionism/Exercises/Exercise3.php\n    f=urllib.urlopen('http://cogsci.ucd.ie/Connectionism/Labs/basicProp/reber.pat','r')\n\n    #--- Reading Reber Grammar data from a website. The characters have already been transformed into binary vectors.\n    for i in range(4): #Skipping 4 rows of header information\n        f.readline()\n    reader = csv.reader(f,delimiter=' ',quoting=csv.QUOTE_NONE)\n    header = []\n    records = []\n    fields = 14\n\n    #---- Feeding data in PyBrain dataset\n    trndata = SupervisedDataSet(7, 7)\n    for row, record in enumerate(reader):\n        record = [int(i) for i in record if i&lt;&gt;'']\n        indata = tuple(record[:7])\n        outdata = tuple(record[7:])\n        trndata.addSample(indata,outdata)\n\n    #---- Building Network\n    n = RecurrentNetwork()\n    n.addInputModule(LinearLayer(7, name='in'))\n    n.addModule(SigmoidLayer(7, name='hidden'))\n    n.addOutputModule(LinearLayer(7, name='out'))\n    n.addConnection(FullConnection(n['in'], n['hidden'], name='c1'))\n    n.addConnection(FullConnection(n['hidden'], n['out'], name='c2'))\n    n.addRecurrentConnection(FullConnection(n['hidden'], n['hidden'], name='c3'))\n    n.sortModules()   \n \n    #---- Training Network\n    t = BackpropTrainer(n,learningrate=0.01,momentum=0.5,verbose=True)\n    t.trainOnDataset(trndata,5)\n\n    #---- Testing by feeding ouput into input. Should create Reber Grammer string grammer,\n    # but instead gets stuck on one character. \n    n.reset()\n    input = [1]+[0]*6\n    for i in range(100):\n        print input\n        input = n.activate(input)\n        input = [int(x&gt;=max(input)) for x in input] #Assumes that the chosen character is the one with the highest value\n","report_reasons":null,"banned_by":null,"media_embed":{},"title":"Help with predicting avalanche risk?","link_flair_css_class":null,"author_flair_css_class":null,"score":7,"created_utc":1388428222,"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1u13zz/help_with_predicting_avalanche_risk/","permalink":"/r/MachineLearning/comments/1u13zz/help_with_predicting_avalanche_risk/","stickied":false,"secure_media_embed":{},"author":"Thexorretor"}
{"subreddit":"MachineLearning","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok, so this is just a basic idea, but it seems easy to implement (I just haven&amp;#39;t found appropriate data to train it with), but the idea is to have something like an LSTM node (&lt;a href=\"http://en.wikipedia.org/wiki/LSTM\"&gt;http://en.wikipedia.org/wiki/LSTM&lt;/a&gt;) but with the extension of an external neuron that provides feedback. This would only be applicable to temporal systems, but the idea is to have a node that is part of the system that attempts to predict the next state of its governing neuron, and uses predictive error combined with backprop to contribute to weight changes in training.\nThe prediction or the error could also be a value fed forward into the next layer.\nI haven&amp;#39;t found any examples of this but am curious as to whether this could be effective/helpful/useful. There are many cognitive theories that propose the idea of pattern recognition and pattern prediction and I though this might be an effective intermediary.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"ups":9,"num_comments":1,"author_flair_text":null,"subreddit_id":"t5_2r3gv","retrieved_on":1411411426,"domain":"self.MachineLearning","secure_media":null,"distinguished":null,"thumbnail":"self","gilded":0,"is_self":true,"user_reports":[],"link_flair_text":null,"id":"1u0mho","downs":0,"edited":false,"selftext":"Ok, so this is just a basic idea, but it seems easy to implement (I just haven't found appropriate data to train it with), but the idea is to have something like an LSTM node (http://en.wikipedia.org/wiki/LSTM) but with the extension of an external neuron that provides feedback. This would only be applicable to temporal systems, but the idea is to have a node that is part of the system that attempts to predict the next state of its governing neuron, and uses predictive error combined with backprop to contribute to weight changes in training.\nThe prediction or the error could also be a value fed forward into the next layer.\nI haven't found any examples of this but am curious as to whether this could be effective/helpful/useful. There are many cognitive theories that propose the idea of pattern recognition and pattern prediction and I though this might be an effective intermediary.","mod_reports":[],"media_embed":{},"report_reasons":null,"banned_by":null,"link_flair_css_class":null,"title":"Predictive neuron, extension of LSTM","author_flair_css_class":null,"score":9,"created_utc":1388415550,"over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/1u0mho/predictive_neuron_extension_of_lstm/","permalink":"/r/MachineLearning/comments/1u0mho/predictive_neuron_extension_of_lstm/","secure_media_embed":{},"stickied":false,"author":"technotheist"}
{"author_flair_text":null,"subreddit_id":"t5_2r3gv","retrieved_on":1411411794,"num_comments":0,"ups":0,"subreddit":"MachineLearning","selftext_html":null,"media":null,"gilded":0,"link_flair_text":null,"is_self":false,"user_reports":[],"domain":"blog.datumbox.com","distinguished":null,"thumbnail":"http://a.thumbs.redditmedia.com/d0dOY7M9FG5HJYHT.jpg","secure_media":null,"link_flair_css_class":null,"title":"New open-source Machine Learning API clients in Ruby and Node.js","media_embed":{},"report_reasons":null,"banned_by":null,"author_flair_css_class":null,"id":"1u0dfq","downs":0,"edited":false,"selftext":"","mod_reports":[],"url":"http://blog.datumbox.com/using-datumbox-api-with-ruby-node-js-and-other-featured-projects/","permalink":"/r/MachineLearning/comments/1u0dfq/new_opensource_machine_learning_api_clients_in/","author":"datumbox","secure_media_embed":{},"stickied":false,"score":0,"over_18":false,"created_utc":1388403882}
{"is_self":false,"user_reports":[],"link_flair_text":null,"gilded":0,"secure_media":null,"distinguished":null,"thumbnail":"default","domain":"brandsbook.com.au","num_comments":0,"author_flair_text":null,"subreddit_id":"t5_2r3gv","retrieved_on":1411412170,"subreddit":"MachineLearning","selftext_html":null,"media":null,"ups":1,"secure_media_embed":{},"stickied":false,"author":"jessicperson","permalink":"/r/MachineLearning/comments/1u0576/dynapac_brands_book/","url":"http://www.brandsbook.com.au/dynapac/","created_utc":1388391290,"over_18":false,"score":1,"author_flair_css_class":null,"media_embed":{},"banned_by":null,"report_reasons":null,"link_flair_css_class":null,"title":"Dynapac - Brands Book","selftext":"","mod_reports":[],"id":"1u0576","downs":0,"edited":false}
{"distinguished":null,"thumbnail":"default","secure_media":null,"domain":"arxiv.org","link_flair_text":null,"is_self":false,"user_reports":[],"gilded":0,"ups":38,"subreddit":"MachineLearning","media":null,"selftext_html":null,"author_flair_text":null,"subreddit_id":"t5_2r3gv","retrieved_on":1411412775,"num_comments":21,"over_18":false,"created_utc":1388378976,"score":38,"author":"feedtheaimbot","stickied":false,"secure_media_embed":{},"permalink":"/r/MachineLearning/comments/1tzrrp/do_deep_nets_really_need_to_be_deep/","url":"http://arxiv.org/abs/1312.6184","selftext":"","mod_reports":[],"id":"1tzrrp","downs":0,"edited":false,"author_flair_css_class":null,"link_flair_css_class":null,"title":"Do Deep Nets Really Need to be Deep?","media_embed":{},"banned_by":null,"report_reasons":null}
{"subreddit_id":"t5_2r3gv","author_flair_text":null,"retrieved_on":1411413577,"num_comments":2,"ups":5,"subreddit":"MachineLearning","media":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m putting together a big data mining project and it&amp;#39;s time to break out the big guns instead of just using R.  Cloudera&amp;#39;s CDH looks pretty good because the little pieces of the Hadoop pie (Pig, Oozie, what-have-you) are already packaged &amp;amp; compatability tested with each other.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?  What do you guys use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","gilded":0,"link_flair_text":null,"is_self":true,"user_reports":[],"domain":"self.MachineLearning","distinguished":null,"thumbnail":"self","secure_media":null,"link_flair_css_class":null,"title":"Anybody used Mahout with Cloudera's CDH? If so, how'd she handle? Would recommend?","media_embed":{},"report_reasons":null,"banned_by":null,"author_flair_css_class":null,"id":"1tz7si","edited":false,"downs":0,"selftext":"I'm putting together a big data mining project and it's time to break out the big guns instead of just using R.  Cloudera's CDH looks pretty good because the little pieces of the Hadoop pie (Pig, Oozie, what-have-you) are already packaged &amp; compatability tested with each other.\n\nThoughts?  What do you guys use?","mod_reports":[],"permalink":"/r/MachineLearning/comments/1tz7si/anybody_used_mahout_with_clouderas_cdh_if_so_howd/","url":"http://www.reddit.com/r/MachineLearning/comments/1tz7si/anybody_used_mahout_with_clouderas_cdh_if_so_howd/","author":"Jonny5ive","stickied":false,"secure_media_embed":{},"score":5,"over_18":false,"created_utc":1388364535}
{"num_comments":12,"retrieved_on":1411405889,"author_flair_text":null,"subreddit_id":"t5_2r3gv","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on analyzing medical data using Hadoop. I&amp;#39;d like to use a SVM to help me with some of the analysis, but the SVM features aren&amp;#39;t fully baked in Mahout. I could roll my own, but that seems like a bad idea. R has some SVM implementations, but I&amp;#39;m not sure how I would integrate R into Hadoop. I&amp;#39;m currently looking at using Rserve to call R from my Java code. Is there another set of packages that I should be looking at?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","media":null,"subreddit":"MachineLearning","ups":10,"gilded":0,"user_reports":[],"is_self":true,"link_flair_text":null,"domain":"self.MachineLearning","secure_media":null,"thumbnail":"self","distinguished":null,"report_reasons":null,"banned_by":null,"media_embed":{},"title":"Using a SVM in Hadoop?","link_flair_css_class":null,"author_flair_css_class":null,"edited":false,"downs":0,"id":"1u45x2","mod_reports":[],"selftext":"I've been working on analyzing medical data using Hadoop. I'd like to use a SVM to help me with some of the analysis, but the SVM features aren't fully baked in Mahout. I could roll my own, but that seems like a bad idea. R has some SVM implementations, but I'm not sure how I would integrate R into Hadoop. I'm currently looking at using Rserve to call R from my Java code. Is there another set of packages that I should be looking at?\n\nThanks!","permalink":"/r/MachineLearning/comments/1u45x2/using_a_svm_in_hadoop/","url":"http://www.reddit.com/r/MachineLearning/comments/1u45x2/using_a_svm_in_hadoop/","stickied":false,"secure_media_embed":{},"author":"mypetrock","score":10,"created_utc":1388522946,"over_18":false}
{"thumbnail":"default","distinguished":null,"secure_media":null,"domain":"datascienceweekly.org","link_flair_text":null,"user_reports":[],"is_self":false,"gilded":0,"ups":18,"media":null,"selftext_html":null,"subreddit":"MachineLearning","retrieved_on":1411407268,"subreddit_id":"t5_2r3gv","author_flair_text":null,"num_comments":7,"over_18":false,"created_utc":1388498295,"score":18,"author":"hrb1979","secure_media_embed":{},"stickied":false,"permalink":"/r/MachineLearning/comments/1u3a50/how_machine_learning_can_transform_online_dating/","url":"http://www.datascienceweekly.org/blog/7-how-machine-learning-can-transform-online-dating-kang-zhao-interview","mod_reports":[],"selftext":"","downs":0,"edited":false,"id":"1u3a50","author_flair_css_class":null,"title":"How Machine Learning Can Transform Online Dating: Kang Zhao Interview","link_flair_css_class":null,"banned_by":null,"report_reasons":null,"media_embed":{}}
{"retrieved_on":1411407741,"author_flair_text":null,"subreddit_id":"t5_2r3gv","num_comments":2,"ups":7,"media":null,"selftext_html":null,"subreddit":"MachineLearning","gilded":0,"link_flair_text":null,"user_reports":[],"is_self":false,"domain":"github.com","thumbnail":"http://e.thumbs.redditmedia.com/3uZxQqqmOYer9hAj.jpg","distinguished":null,"secure_media":null,"title":"A perceptron learning algorithm in R (with visualizations!)","link_flair_css_class":null,"banned_by":null,"report_reasons":null,"media_embed":{},"author_flair_css_class":null,"downs":0,"edited":false,"id":"1u2zct","mod_reports":[],"selftext":"","permalink":"/r/MachineLearning/comments/1u2zct/a_perceptron_learning_algorithm_in_r_with/","url":"https://github.com/billderose/perceptron","author":"billderose","stickied":false,"secure_media_embed":{},"score":7,"over_18":false,"created_utc":1388480783}
{"user_reports":[],"is_self":false,"link_flair_text":null,"gilded":0,"secure_media":null,"thumbnail":"default","distinguished":null,"domain":"github.com","num_comments":0,"retrieved_on":1411407757,"author_flair_text":null,"subreddit_id":"t5_2r3gv","selftext_html":null,"media":null,"subreddit":"MachineLearning","ups":1,"stickied":false,"secure_media_embed":{},"author":"[deleted]","url":"https://github.com/billderose/perceptron","permalink":"/r/MachineLearning/comments/1u2yxx/billderoseperceptron_github/","created_utc":1388480162,"over_18":false,"score":1,"author_flair_css_class":null,"report_reasons":null,"banned_by":null,"media_embed":{},"title":"billderose/perceptron · GitHub","link_flair_css_class":null,"mod_reports":[],"selftext":"","edited":false,"downs":0,"id":"1u2yxx"}
{"score":1,"created_utc":1388478999,"over_18":false,"permalink":"/r/MachineLearning/comments/1u2y45/a_perceptron_learning_algorithm_in_r_with/","url":"http://www.reddit.com/r/MachineLearning/comments/1u2y45/a_perceptron_learning_algorithm_in_r_with/","stickied":false,"secure_media_embed":{},"author":"[deleted]","id":"1u2y45","downs":0,"edited":false,"selftext":"","mod_reports":[],"media_embed":{},"banned_by":null,"report_reasons":null,"link_flair_css_class":null,"title":"A perceptron learning algorithm in R (with visualizations!)","author_flair_css_class":null,"domain":"self.MachineLearning","secure_media":null,"distinguished":null,"thumbnail":"default","gilded":0,"is_self":true,"user_reports":[],"link_flair_text":null,"subreddit":"MachineLearning","selftext_html":null,"media":null,"ups":1,"num_comments":0,"author_flair_text":null,"subreddit_id":"t5_2r3gv","retrieved_on":1411407789}
{"url":"https://www.youtube.com/watch?v=vShMxxqtDDs","permalink":"/r/MachineLearning/comments/1u2tv6/recent_developments_in_deep_neural_networks_geoff/","secure_media_embed":{"scrolling":false,"width":600,"content":"&lt;iframe class=\"embedly-embed\" src=\"//cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2FvShMxxqtDDs%3Ffeature%3Doembed&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DvShMxxqtDDs&amp;image=http%3A%2F%2Fi1.ytimg.com%2Fvi%2FvShMxxqtDDs%2Fhqdefault.jpg&amp;key=522baf40bd3911e08d854040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"338\" scrolling=\"no\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","height":338},"stickied":false,"author":"federationoffear","score":45,"created_utc":1388473710,"over_18":false,"report_reasons":null,"banned_by":null,"media_embed":{"scrolling":false,"width":600,"content":"&lt;iframe class=\"embedly-embed\" src=\"//cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2FvShMxxqtDDs%3Ffeature%3Doembed&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DvShMxxqtDDs&amp;image=http%3A%2F%2Fi1.ytimg.com%2Fvi%2FvShMxxqtDDs%2Fhqdefault.jpg&amp;key=522baf40bd3911e08d854040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"338\" scrolling=\"no\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","height":338},"title":"Recent Developments in Deep Neural Networks (Geoff Hinton)","link_flair_css_class":null,"author_flair_css_class":null,"downs":0,"edited":false,"id":"1u2tv6","mod_reports":[],"selftext":"","gilded":0,"user_reports":[],"is_self":false,"link_flair_text":null,"domain":"youtube.com","secure_media":{"type":"youtube.com","oembed":{"url":"http://www.youtube.com/watch?v=vShMxxqtDDs","description":"Geoff Hinton presents as part of the UBC Department of Computer Science's Distinguished Lecture Series, May 30, 2013. Professor Hinton was awarded the 2011 Herzberg Canada Gold Medal for Science and Engineering, among many other prizes. He is also responsible for many technological advancements impacting many of us (better speech recognition, image search, etc.), see e.g.","html":"&lt;iframe class=\"embedly-embed\" src=\"//cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2FvShMxxqtDDs%3Ffeature%3Doembed&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DvShMxxqtDDs&amp;image=http%3A%2F%2Fi1.ytimg.com%2Fvi%2FvShMxxqtDDs%2Fhqdefault.jpg&amp;key=522baf40bd3911e08d854040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"338\" scrolling=\"no\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","provider_url":"http://www.youtube.com/","thumbnail_height":360,"height":338,"thumbnail_width":480,"title":"Geoff Hinton - Recent Developments in Deep Learning","type":"video","provider_name":"YouTube","width":600,"author_name":"UBCCPSC","author_url":"http://www.youtube.com/user/UBCCPSC","thumbnail_url":"https://i.embed.ly/1/image?url=http%3A%2F%2Fi1.ytimg.com%2Fvi%2FvShMxxqtDDs%2Fhqdefault.jpg&amp;key=b1e305db91cf4aa5a86b732cc9fffceb","version":"1.0"}},"thumbnail":"http://d.thumbs.redditmedia.com/nDLE5A52idp7Jg-u.jpg","distinguished":null,"num_comments":2,"retrieved_on":1411407959,"author_flair_text":null,"subreddit_id":"t5_2r3gv","media":{"type":"youtube.com","oembed":{"author_name":"UBCCPSC","width":600,"provider_name":"YouTube","type":"video","thumbnail_width":480,"thumbnail_height":360,"title":"Geoff Hinton - Recent Developments in Deep Learning","height":338,"description":"Geoff Hinton presents as part of the UBC Department of Computer Science's Distinguished Lecture Series, May 30, 2013. Professor Hinton was awarded the 2011 Herzberg Canada Gold Medal for Science and Engineering, among many other prizes. He is also responsible for many technological advancements impacting many of us (better speech recognition, image search, etc.), see e.g.","provider_url":"http://www.youtube.com/","html":"&lt;iframe class=\"embedly-embed\" src=\"//cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2FvShMxxqtDDs%3Ffeature%3Doembed&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DvShMxxqtDDs&amp;image=http%3A%2F%2Fi1.ytimg.com%2Fvi%2FvShMxxqtDDs%2Fhqdefault.jpg&amp;key=522baf40bd3911e08d854040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"338\" scrolling=\"no\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;","url":"http://www.youtube.com/watch?v=vShMxxqtDDs","version":"1.0","thumbnail_url":"http://i1.ytimg.com/vi/vShMxxqtDDs/hqdefault.jpg","author_url":"http://www.youtube.com/user/UBCCPSC"}},"selftext_html":null,"subreddit":"MachineLearning","ups":45}
