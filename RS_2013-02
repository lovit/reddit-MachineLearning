{"secure_media":null,"thumbnail":"self","id":"17q0od","edited":false,"is_self":true,"over_18":false,"stickied":false,"media_embed":{},"secure_media_embed":{},"ups":2,"media":null,"report_reasons":null,"permalink":"/r/MachineLearning/comments/17q0od/new_to_ml_stupid_question/","num_comments":4,"mod_reports":[],"domain":"self.MachineLearning","author":"purpleladydragons","user_reports":[],"gilded":0,"score":2,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I apologize if this better belongs in r/learnprogramming or r/mlclass. I&amp;#39;m very new to machine learning and figured that a good way to learn would be to implement an agent that can predict illness spreading by using twitter. Right now, I don&amp;#39;t even know how to actually determine if someone is sick from his/her tweet. Obviously, if someone uses the phrase &amp;#39;sick of&amp;#39;, he probably doesn&amp;#39;t mean he is actually ill. But I&amp;#39;m sure there are plenty of other indicators that I&amp;#39;m unaware of. How would I or the program be able to discover these additional factors? &lt;/p&gt;\n\n&lt;p&gt;The closest thing I can think of is that I would train the program on hundreds of tweets that I would manually label as sick or not; it could then build up a probability model of words following &amp;#39;sick&amp;#39; to determine if the tweet is actually about illness, but I have no idea how I can get the program to pick up on other patterns like preceding words or friends that also used &amp;#39;sick&amp;#39; in their tweets without explicitly telling the program to look at those as well. I apologize for the stupid question, as I imagine this is probably a huge part of ML, but I couldn&amp;#39;t find anything through google.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author_flair_text":null,"link_flair_css_class":null,"link_flair_text":null,"distinguished":null,"title":"New to ML, stupid question","banned_by":null,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/17q0od/new_to_ml_stupid_question/","retrieved_on":1413137843,"author_flair_css_class":null,"selftext":"I apologize if this better belongs in r/learnprogramming or r/mlclass. I'm very new to machine learning and figured that a good way to learn would be to implement an agent that can predict illness spreading by using twitter. Right now, I don't even know how to actually determine if someone is sick from his/her tweet. Obviously, if someone uses the phrase 'sick of', he probably doesn't mean he is actually ill. But I'm sure there are plenty of other indicators that I'm unaware of. How would I or the program be able to discover these additional factors? \n\nThe closest thing I can think of is that I would train the program on hundreds of tweets that I would manually label as sick or not; it could then build up a probability model of words following 'sick' to determine if the tweet is actually about illness, but I have no idea how I can get the program to pick up on other patterns like preceding words or friends that also used 'sick' in their tweets without explicitly telling the program to look at those as well. I apologize for the stupid question, as I imagine this is probably a huge part of ML, but I couldn't find anything through google.","downs":0,"created_utc":1359759270}
{"num_comments":0,"mod_reports":[],"author":"Jmartin024","user_reports":[],"domain":"techtalks.tv","score":0,"gilded":0,"selftext_html":null,"link_flair_css_class":null,"author_flair_text":null,"distinguished":null,"link_flair_text":null,"subreddit":"MachineLearning","banned_by":null,"title":"NYU Course on Big Data, Large Scale Machine Learning","url":"http://techtalks.tv/nyu/nyu-course-on-large-scale-machine-learning/","subreddit_id":"t5_2r3gv","retrieved_on":1413138044,"downs":0,"selftext":"","author_flair_css_class":null,"created_utc":1359755500,"secure_media":null,"thumbnail":"http://e.thumbs.redditmedia.com/ZdTGz8JozhqZmNcR.jpg","id":"17pw2v","is_self":false,"edited":false,"media_embed":{},"over_18":false,"stickied":false,"ups":0,"media":null,"report_reasons":null,"secure_media_embed":{},"permalink":"/r/MachineLearning/comments/17pw2v/nyu_course_on_big_data_large_scale_machine/"}
{"url":"http://cilvr.cs.nyu.edu/doku.php?id=courses:bigdata:slides:start","subreddit_id":"t5_2r3gv","retrieved_on":1413138296,"downs":0,"selftext":"","author_flair_css_class":null,"created_utc":1359750916,"link_flair_css_class":null,"author_flair_text":null,"distinguished":null,"link_flair_text":null,"subreddit":"MachineLearning","title":"First video/slides from John Langford and Yann LeCun's large scale ML class","banned_by":null,"author":"rrenaud","user_reports":[],"domain":"cilvr.cs.nyu.edu","selftext_html":null,"score":32,"gilded":0,"num_comments":3,"mod_reports":[],"media_embed":{},"over_18":false,"stickied":false,"media":null,"ups":32,"report_reasons":null,"secure_media_embed":{},"permalink":"/r/MachineLearning/comments/17pqa3/first_videoslides_from_john_langford_and_yann/","id":"17pqa3","edited":false,"is_self":false,"secure_media":null,"thumbnail":"default"}
{"thumbnail":"http://b.thumbs.redditmedia.com/3ykxiAlJlDj2r2OU.jpg","secure_media":null,"permalink":"/r/MachineLearning/comments/17nzv9/text_classification_and_feature_hashing_sparse/","secure_media_embed":{},"report_reasons":null,"ups":18,"media":null,"over_18":false,"stickied":false,"media_embed":{},"edited":false,"is_self":false,"id":"17nzv9","score":18,"gilded":0,"selftext_html":null,"domain":"blog.newsle.com","author":"fusiformgyrus","user_reports":[],"mod_reports":[],"num_comments":5,"created_utc":1359681224,"selftext":"","author_flair_css_class":null,"downs":0,"retrieved_on":1413140792,"subreddit_id":"t5_2r3gv","url":"http://blog.newsle.com/2013/02/01/text-classification-and-feature-hashing-sparse-matrix-vector-multiplication-with-cython/","title":"Text Classification and Feature Hashing: Sparse Matrix-Vector Multiplication with Cython","banned_by":null,"subreddit":"MachineLearning","link_flair_text":null,"distinguished":null,"author_flair_text":null,"link_flair_css_class":null}
{"secure_media":null,"thumbnail":"self","permalink":"/r/MachineLearning/comments/17rz4m/does_anyone_know_of_a_free_open_korean_named/","media_embed":{},"stickied":false,"over_18":false,"ups":2,"report_reasons":null,"media":null,"secure_media_embed":{},"edited":false,"is_self":true,"id":"17rz4m","score":2,"selftext_html":null,"gilded":0,"author":"yukw777","user_reports":[],"domain":"self.MachineLearning","num_comments":5,"mod_reports":[],"downs":0,"selftext":"","author_flair_css_class":null,"created_utc":1359846253,"url":"http://www.reddit.com/r/MachineLearning/comments/17rz4m/does_anyone_know_of_a_free_open_korean_named/","subreddit_id":"t5_2r3gv","retrieved_on":1413134851,"distinguished":null,"link_flair_text":null,"subreddit":"MachineLearning","title":"Does anyone know of a free, open Korean named entity recognition tool or named entity corpus?","banned_by":null,"link_flair_css_class":null,"author_flair_text":null}
{"mod_reports":[],"num_comments":4,"author":"sanity","user_reports":[],"domain":"self.MachineLearning","gilded":0,"score":2,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in building a system which takes information about it&amp;#39;s environment, some notion of pleasure and pain, and then has some kind of output, which influences the environment.  &lt;/p&gt;\n\n&lt;p&gt;They system&amp;#39;s goal is, given what it knows of the environment from its inputs, influence the environment to seek pleasure, and avoid pain.&lt;/p&gt;\n\n&lt;p&gt;Can anyone point me to research in this area, particularly anything on how biological systems solve this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","link_flair_css_class":null,"author_flair_text":null,"subreddit":"MachineLearning","banned_by":null,"title":"Can anyone point me to work on a neural network that can respond to pleasure or pain?","distinguished":null,"link_flair_text":null,"retrieved_on":1413135470,"url":"http://www.reddit.com/r/MachineLearning/comments/17rka4/can_anyone_point_me_to_work_on_a_neural_network/","subreddit_id":"t5_2r3gv","created_utc":1359832533,"downs":0,"author_flair_css_class":null,"selftext":"I'm interested in building a system which takes information about it's environment, some notion of pleasure and pain, and then has some kind of output, which influences the environment.  \n\nThey system's goal is, given what it knows of the environment from its inputs, influence the environment to seek pleasure, and avoid pain.\n\nCan anyone point me to research in this area, particularly anything on how biological systems solve this problem?","thumbnail":"self","secure_media":null,"id":"17rka4","edited":false,"is_self":true,"ups":2,"media":null,"report_reasons":null,"secure_media_embed":{},"media_embed":{},"stickied":false,"over_18":false,"permalink":"/r/MachineLearning/comments/17rka4/can_anyone_point_me_to_work_on_a_neural_network/"}
{"secure_media":null,"thumbnail":"http://d.thumbs.redditmedia.com/TLp7r-2RtQLVAn0K.jpg","edited":false,"is_self":false,"id":"17r9dc","permalink":"/r/MachineLearning/comments/17r9dc/large_scale_malicious_domain_classification_using/","over_18":false,"stickied":false,"media_embed":{"height":356,"width":427,"scrolling":false,"content":"&lt;iframe src=\"http://www.slideshare.net/slideshow/embed_code/15940884\" width=\"427\" height=\"356\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\" allowfullscreen webkitallowfullscreen mozallowfullscreen&gt; &lt;/iframe&gt;"},"secure_media_embed":{},"report_reasons":null,"ups":16,"media":{"type":"slideshare.net","oembed":{"width":427,"thumbnail_width":1024,"author_url":"http://www.slideshare.net/jasontrost","author_name":"jasontrost","version":"1.0","thumbnail_url":"http://image.slidesharecdn.com/flocon-clairvoyantsquirrel-final-130110200749-phpapp01/95/slide-1-1024.jpg","title":"Clairvoyant Squirrel: Large Scale Malicious Domain Classification","provider_name":"SlideShare","provider_url":"http://www.slideshare.net","height":356,"type":"rich","thumbnail_height":769,"html":"&lt;iframe src=\"http://www.slideshare.net/slideshow/embed_code/15940884\" width=\"427\" height=\"356\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\" allowfullscreen webkitallowfullscreen mozallowfullscreen&gt; &lt;/iframe&gt;","description":"Clairvoyant Squirrel: Large Scale Malicious Domain Classification. Presentation from FloCon 2013"}},"num_comments":0,"mod_reports":[],"gilded":0,"score":16,"selftext_html":null,"domain":"slideshare.net","author":"rrenaud","user_reports":[],"link_flair_text":null,"distinguished":null,"banned_by":null,"title":"Large scale malicious domain classification using only textual features","subreddit":"MachineLearning","author_flair_text":null,"link_flair_css_class":null,"selftext":"","author_flair_css_class":null,"downs":0,"created_utc":1359821523,"subreddit_id":"t5_2r3gv","url":"http://www.slideshare.net/jasontrost/flo-con-clairvoyant-squirrel-final","retrieved_on":1413135924}
{"retrieved_on":1413133955,"url":"http://www.daterminal.com/dabizmo-web/DaTerminal","subreddit_id":"t5_2r3gv","created_utc":1359867354,"downs":0,"selftext":"","author_flair_css_class":null,"link_flair_css_class":null,"author_flair_text":null,"subreddit":"MachineLearning","title":"Machine Learning based Business News Platform","banned_by":null,"distinguished":null,"link_flair_text":null,"author":"[deleted]","user_reports":[],"domain":"daterminal.com","selftext_html":null,"score":1,"gilded":0,"mod_reports":[],"num_comments":0,"report_reasons":null,"ups":1,"media":null,"secure_media_embed":{},"media_embed":{},"stickied":false,"over_18":false,"permalink":"/r/MachineLearning/comments/17sk46/machine_learning_based_business_news_platform/","id":"17sk46","is_self":false,"edited":false,"thumbnail":"default","secure_media":null}
{"permalink":"/r/MachineLearning/comments/17sb87/dilberts_definition_of_machine_learning/","media_embed":{},"stickied":false,"over_18":false,"report_reasons":null,"ups":16,"media":null,"secure_media_embed":{},"edited":false,"is_self":false,"id":"17sb87","secure_media":null,"thumbnail":"http://a.thumbs.redditmedia.com/YdamtyR82n2OLyUT.jpg","downs":0,"selftext":"","author_flair_css_class":null,"created_utc":1359858171,"url":"http://dilbert.com/strips/comic/2013-02-02/","subreddit_id":"t5_2r3gv","retrieved_on":1413134323,"distinguished":null,"link_flair_text":null,"subreddit":"MachineLearning","banned_by":null,"title":"Dilbert's Definition of Machine Learning","link_flair_css_class":null,"author_flair_text":null,"score":16,"selftext_html":null,"gilded":0,"author":"derzelas","user_reports":[],"domain":"dilbert.com","num_comments":18,"mod_reports":[]}
{"secure_media":null,"thumbnail":"self","id":"17vkxd","is_self":true,"edited":false,"stickied":false,"over_18":false,"media_embed":{},"secure_media_embed":{},"report_reasons":null,"ups":8,"media":null,"permalink":"/r/MachineLearning/comments/17vkxd/looking_for_simple_algorithm_to_recognize_trigger/","num_comments":30,"mod_reports":[],"domain":"self.MachineLearning","author":"UserNotAvailable","user_reports":[],"gilded":0,"score":8,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While watching Dexter yesterday, I got the idea to build a &amp;quot;fucking&amp;quot; counter.&lt;/p&gt;\n\n&lt;p&gt;For those unfamiliar with the show: The characters on the show swear a lot. Especially the sister of the main character. I now want to automatically tag all the scenes in which a character uses the word &amp;quot;fuck&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I know speech recognition packages like CMU spinx exist, but I was wondering if for this task something simpler and more targeted would be appropriate. My previous ML experience is limited to computer vision, so my first instinct would be to train a linear SVM with a few dozen examples and see how well it does. However, I have no idea what kind of features I should use. Would a simple fourier transformation suffice?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have a problem with false positives, and I could easily retrain the algorithm over a few iterations, but I just don&amp;#39;t feel like watching the entire 56 hours of material.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author_flair_text":null,"link_flair_css_class":null,"link_flair_text":null,"distinguished":null,"title":"Looking for simple algorithm to recognize \"trigger words\" in audio.","banned_by":null,"subreddit":"MachineLearning","subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/17vkxd/looking_for_simple_algorithm_to_recognize_trigger/","retrieved_on":1413129390,"selftext":"While watching Dexter yesterday, I got the idea to build a \"fucking\" counter.\n\nFor those unfamiliar with the show: The characters on the show swear a lot. Especially the sister of the main character. I now want to automatically tag all the scenes in which a character uses the word \"fuck\".\n\nI know speech recognition packages like CMU spinx exist, but I was wondering if for this task something simpler and more targeted would be appropriate. My previous ML experience is limited to computer vision, so my first instinct would be to train a linear SVM with a few dozen examples and see how well it does. However, I have no idea what kind of features I should use. Would a simple fourier transformation suffice?\n\nI don't have a problem with false positives, and I could easily retrain the algorithm over a few iterations, but I just don't feel like watching the entire 56 hours of material.","author_flair_css_class":null,"downs":0,"created_utc":1360000503}
{"permalink":"/r/MachineLearning/comments/17vb08/dont_know_if_anyone_is_interested_but_the_midwest/","over_18":false,"stickied":false,"media_embed":{},"secure_media_embed":{},"ups":7,"report_reasons":null,"media":null,"is_self":false,"edited":false,"id":"17vb08","secure_media":null,"thumbnail":"default","author_flair_css_class":null,"selftext":"","downs":0,"created_utc":1359991407,"subreddit_id":"t5_2r3gv","url":"http://mall.psy.ohio-state.edu/mwcs/","retrieved_on":1413129795,"link_flair_text":null,"distinguished":null,"banned_by":null,"title":"Don't know if anyone is interested but the Midwest Cognitive Science Conference is at Ohio State University this year.","subreddit":"MachineLearning","author_flair_text":null,"link_flair_css_class":null,"score":7,"gilded":0,"selftext_html":null,"domain":"mall.psy.ohio-state.edu","author":"[deleted]","user_reports":[],"num_comments":1,"mod_reports":[]}
{"subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/17v4uc/stateoftheart_ensemble_diversity_methods/","retrieved_on":1413130039,"selftext":"I'm writing a short report on ensembles and diversity, and have been asked to outline current theory on diversity, as well as describe state-of-the-art methods and algorithms for constructing diverse ensembles.\n\nNow, I haven't had much problem with the theory-bit (much thanks to the hard work of Brown and Kuncheva), but am quite stumped regarding the actual methods. I'm aware of a number of ensemble algorithms/methods (e.g. bagging, boosting, rotation forest, random oracle, random subspace method), but I'm hesitant towards classifying these as state-of-the-art, seeing as they are all ~5-10 years old.\n\nSo, am I missing something obvious, or are the methods mentioned above what would be considered state-of-the-art? I'm not interested in specific implementations or variants (i.e. subagging, nice bagging), but rather would like to know if there's any overall paradigm I'm missing. I would especially appreciate hints at diversity-explicit ensemble methods, but I would of course also appreciate information on any implicit methods that I've overlooked.\n\nIf it's not too much to ask, links to related articles would be preferred over summarizing descriptions.","author_flair_css_class":null,"downs":0,"created_utc":1359983075,"author_flair_text":null,"link_flair_css_class":null,"link_flair_text":null,"distinguished":null,"title":"State-of-the-art Ensemble (Diversity) Methods?","banned_by":null,"subreddit":"MachineLearning","domain":"self.MachineLearning","author":"donlnz","user_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m writing a short report on ensembles and diversity, and have been asked to outline current theory on diversity, as well as describe state-of-the-art methods and algorithms for constructing diverse ensembles.&lt;/p&gt;\n\n&lt;p&gt;Now, I haven&amp;#39;t had much problem with the theory-bit (much thanks to the hard work of Brown and Kuncheva), but am quite stumped regarding the actual methods. I&amp;#39;m aware of a number of ensemble algorithms/methods (e.g. bagging, boosting, rotation forest, random oracle, random subspace method), but I&amp;#39;m hesitant towards classifying these as state-of-the-art, seeing as they are all ~5-10 years old.&lt;/p&gt;\n\n&lt;p&gt;So, am I missing something obvious, or are the methods mentioned above what would be considered state-of-the-art? I&amp;#39;m not interested in specific implementations or variants (i.e. subagging, nice bagging), but rather would like to know if there&amp;#39;s any overall paradigm I&amp;#39;m missing. I would especially appreciate hints at diversity-explicit ensemble methods, but I would of course also appreciate information on any implicit methods that I&amp;#39;ve overlooked.&lt;/p&gt;\n\n&lt;p&gt;If it&amp;#39;s not too much to ask, links to related articles would be preferred over summarizing descriptions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","score":1,"gilded":0,"num_comments":0,"mod_reports":[],"over_18":false,"stickied":false,"media_embed":{},"secure_media_embed":{},"report_reasons":null,"ups":1,"media":null,"permalink":"/r/MachineLearning/comments/17v4uc/stateoftheart_ensemble_diversity_methods/","id":"17v4uc","is_self":true,"edited":false,"secure_media":null,"thumbnail":"self"}
{"edited":false,"is_self":true,"id":"17v1xq","permalink":"/r/MachineLearning/comments/17v1xq/can_anybody_suggest_some_interesting_articles_on/","media_embed":{},"stickied":false,"over_18":false,"media":null,"ups":21,"report_reasons":null,"secure_media_embed":{},"secure_media":null,"thumbnail":"self","distinguished":null,"link_flair_text":null,"subreddit":"MachineLearning","title":"Can anybody suggest some interesting articles on Machine Learning?","banned_by":null,"link_flair_css_class":null,"author_flair_text":null,"downs":0,"author_flair_css_class":null,"selftext":"The place I work has sends around innovative articles each week, I've been asked to pick some for this week. I wanted to pick a few interesting ones on machine learning applications/successes/innovations in business. Can anyone suggest some good ones? \n\nOne good one I've found so far is http://swampland.time.com/2012/11/07/inside-the-secret-world-of-quants-and-data-crunchers-who-helped-obama-win/ but it's more about analytics than machine learning.","created_utc":1359977410,"url":"http://www.reddit.com/r/MachineLearning/comments/17v1xq/can_anybody_suggest_some_interesting_articles_on/","subreddit_id":"t5_2r3gv","retrieved_on":1413130166,"num_comments":15,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The place I work has sends around innovative articles each week, I&amp;#39;ve been asked to pick some for this week. I wanted to pick a few interesting ones on machine learning applications/successes/innovations in business. Can anyone suggest some good ones? &lt;/p&gt;\n\n&lt;p&gt;One good one I&amp;#39;ve found so far is &lt;a href=\"http://swampland.time.com/2012/11/07/inside-the-secret-world-of-quants-and-data-crunchers-who-helped-obama-win/\"&gt;http://swampland.time.com/2012/11/07/inside-the-secret-world-of-quants-and-data-crunchers-who-helped-obama-win/&lt;/a&gt; but it&amp;#39;s more about analytics than machine learning.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","score":21,"gilded":0,"author":"gerry87","user_reports":[],"domain":"self.MachineLearning"}
{"mod_reports":[],"num_comments":9,"score":5,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m involved with a startup that is working on some hard machine learning and image analysis problems. We&amp;#39;re looking for a student or freelancer to help us with one in particular. We want to estimate a person&amp;#39;s height based on rectified facial photos. Existing research shows this to be possible, but there are no good available implementations. We&amp;#39;ll gladly pay for your time and, if you&amp;#39;re a student, work with you to help you publish your work.&lt;/p&gt;\n\n&lt;p&gt;Is anyone interested? What&amp;#39;s the best way to seek someone for an academic/startup partnership like this?&lt;/p&gt;\n\n&lt;p&gt;Contact qe0akevaur8icxp@jetable.org if you&amp;#39;re interested or have advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","gilded":0,"author":"tectonic","user_reports":[],"domain":"self.MachineLearning","subreddit":"MachineLearning","banned_by":null,"title":"Seeking a student to help with machine learning projects","distinguished":null,"link_flair_text":null,"link_flair_css_class":null,"author_flair_text":null,"created_utc":1359936906,"downs":0,"selftext":"I'm involved with a startup that is working on some hard machine learning and image analysis problems. We're looking for a student or freelancer to help us with one in particular. We want to estimate a person's height based on rectified facial photos. Existing research shows this to be possible, but there are no good available implementations. We'll gladly pay for your time and, if you're a student, work with you to help you publish your work.\n\nIs anyone interested? What's the best way to seek someone for an academic/startup partnership like this?\n\nContact qe0akevaur8icxp@jetable.org if you're interested or have advice.","author_flair_css_class":null,"retrieved_on":1413131678,"url":"http://www.reddit.com/r/MachineLearning/comments/17u322/seeking_a_student_to_help_with_machine_learning/","subreddit_id":"t5_2r3gv","thumbnail":"self","secure_media":null,"is_self":true,"edited":false,"id":"17u322","permalink":"/r/MachineLearning/comments/17u322/seeking_a_student_to_help_with_machine_learning/","media":null,"ups":5,"report_reasons":null,"secure_media_embed":{},"media_embed":{},"over_18":false,"stickied":false}
{"thumbnail":"default","secure_media":null,"is_self":false,"edited":false,"id":"17xqhf","permalink":"/r/MachineLearning/comments/17xqhf/how_to_win_the_showdown_on_the_price_is_right/","ups":32,"report_reasons":null,"media":null,"secure_media_embed":{},"media_embed":{},"stickied":false,"over_18":false,"mod_reports":[],"num_comments":5,"score":32,"gilded":0,"selftext_html":null,"user_reports":[],"author":"HootBack","domain":"camdp.com","subreddit":"MachineLearning","title":"How to win the Showdown on the Price is Right.","banned_by":null,"distinguished":null,"link_flair_text":null,"link_flair_css_class":null,"author_flair_text":null,"created_utc":1360079583,"downs":0,"selftext":"","author_flair_css_class":null,"retrieved_on":1413126148,"url":"http://camdp.com/blogs/how-solve-price-rights-showdown","subreddit_id":"t5_2r3gv"}
{"secure_media_embed":{},"ups":1,"media":null,"report_reasons":null,"over_18":false,"stickied":false,"media_embed":{},"permalink":"/r/MachineLearning/comments/17xqf9/how_to_the_showdown_on_the_price_is_right/","id":"17xqf9","is_self":false,"edited":false,"thumbnail":"default","secure_media":null,"retrieved_on":1413126150,"subreddit_id":"t5_2r3gv","url":"http://camdp.com/blogs/how-solve-price-rights-showdown","created_utc":1360079532,"selftext":"","author_flair_css_class":null,"downs":0,"author_flair_text":null,"link_flair_css_class":null,"banned_by":null,"title":"How to the Showdown on The Price is Right","subreddit":"MachineLearning","link_flair_text":null,"distinguished":null,"domain":"camdp.com","author":"[deleted]","user_reports":[],"gilded":0,"score":1,"selftext_html":null,"mod_reports":[],"num_comments":0}
{"retrieved_on":1413091267,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"pulkitgoyal.in","stickied":false,"report_reasons":null,"link_flair_text":null,"mod_reports":[],"is_self":false,"thumbnail":"default","selftext_html":null,"title":"Similarity Metrics on Twitter","id":"185szw","distinguished":null,"media":null,"secure_media":null,"downs":0,"ups":7,"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":7,"selftext":"","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/185szw/similarity_metrics_on_twitter/","num_comments":0,"gilded":0,"media_embed":{},"over_18":false,"author":"winkywooster","url":"http://pulkitgoyal.in/2012/03/17/similarity-metrics-twitter/","banned_by":null,"created_utc":1360365120}
{"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":6,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/185m9h/is_there_an_ensemble_technique_package_for/","selftext":"I am trying to implement unsupervised learning algorithms on an unlabeled data set in R. I have used the algorithms like PCA and KNN, I want to see if I can further improve my results using ensemble methods. I am trying to search for a package that is already built for this purpose.\n\nAn example for a package for supervised learning is [Adaboost](http://rss.acs.unt.edu/Rdoc/library/boost/html/adaboost.html) for classification. I am looking for an equivalent for unsupervised learning. Please suggest packages you know or you have used.","link_flair_css_class":null,"url":"http://www.reddit.com/r/MachineLearning/comments/185m9h/is_there_an_ensemble_technique_package_for/","created_utc":1360359623,"banned_by":null,"author":"rightname","over_18":false,"gilded":0,"num_comments":8,"media_embed":{},"domain":"self.MachineLearning","user_reports":[],"stickied":false,"edited":1360369417,"retrieved_on":1413091534,"author_flair_text":null,"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to implement unsupervised learning algorithms on an unlabeled data set in R. I have used the algorithms like PCA and KNN, I want to see if I can further improve my results using ensemble methods. I am trying to search for a package that is already built for this purpose.&lt;/p&gt;\n\n&lt;p&gt;An example for a package for supervised learning is &lt;a href=\"http://rss.acs.unt.edu/Rdoc/library/boost/html/adaboost.html\"&gt;Adaboost&lt;/a&gt; for classification. I am looking for an equivalent for unsupervised learning. Please suggest packages you know or you have used.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","mod_reports":[],"report_reasons":null,"link_flair_text":null,"title":"Is there an ensemble technique package for unsupervised learning in R?","distinguished":null,"media":null,"id":"185m9h","secure_media":null,"downs":0,"ups":6}
{"ups":0,"downs":0,"secure_media":null,"id":"184tzf","distinguished":null,"media":null,"title":"How do you train a kernel support vector machine?","report_reasons":null,"link_flair_text":null,"mod_reports":[],"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit: I&amp;#39;ve found a &lt;a href=\"http://www.reddit.com/r/MachineLearning/comments/184tzf/how_do_you_train_a_kernel_support_vector_machine/c8bzffp\"&gt;solution&lt;/a&gt;.\nAnd I&amp;#39;ve written a &lt;a href=\"http://subtlearray.tumblr.com/post/42779370765\"&gt;tutorial&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author_flair_text":null,"retrieved_on":1413092668,"edited":1360874409,"stickied":false,"user_reports":[],"domain":"self.MachineLearning","num_comments":20,"gilded":0,"media_embed":{},"author":"subtlearray","over_18":false,"banned_by":null,"created_utc":1360336604,"url":"http://www.reddit.com/r/MachineLearning/comments/184tzf/how_do_you_train_a_kernel_support_vector_machine/","link_flair_css_class":null,"selftext":"Edit: I've found a [solution](http://www.reddit.com/r/MachineLearning/comments/184tzf/how_do_you_train_a_kernel_support_vector_machine/c8bzffp).\nAnd I've written a [tutorial](http://subtlearray.tumblr.com/post/42779370765).","permalink":"/r/MachineLearning/comments/184tzf/how_do_you_train_a_kernel_support_vector_machine/","subreddit_id":"t5_2r3gv","score":0,"secure_media_embed":{},"subreddit":"MachineLearning","author_flair_css_class":null}
{"subreddit":"MachineLearning","secure_media_embed":{},"score":2,"author_flair_css_class":null,"author":"dem358","over_18":false,"num_comments":0,"media_embed":{},"gilded":0,"url":"http://www.reddit.com/r/MachineLearning/comments/184hq0/my_r_script_has_been_running_for_almost_10_hours/","created_utc":1360317053,"banned_by":null,"selftext":"I am using R64, I am trying to cluster more than 10 thousand documents using k-medoids. I was trying out methods on a dataset quarter this one's size, and stopword removal used to take at least 45-55 minutes, I now let this run overnight and it is still busy. However, I am on a mac and I can see the spinning wheel, and the application is not responding. But I don't want to force quit it, since whenever R64 is busy with a bigger task, the application always stops responding until it is finished with the task. Do you think it is normal for clustering to take so long or has R really stopped working?","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/184hq0/my_r_script_has_been_running_for_almost_10_hours/","link_flair_text":null,"report_reasons":null,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using R64, I am trying to cluster more than 10 thousand documents using k-medoids. I was trying out methods on a dataset quarter this one&amp;#39;s size, and stopword removal used to take at least 45-55 minutes, I now let this run overnight and it is still busy. However, I am on a mac and I can see the spinning wheel, and the application is not responding. But I don&amp;#39;t want to force quit it, since whenever R64 is busy with a bigger task, the application always stops responding until it is finished with the task. Do you think it is normal for clustering to take so long or has R really stopped working?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"self","mod_reports":[],"edited":false,"retrieved_on":1413093132,"author_flair_text":null,"domain":"self.MachineLearning","user_reports":[],"stickied":false,"secure_media":null,"ups":2,"downs":0,"title":"My R script has been running for almost 10 hours now, is it normal?","media":null,"distinguished":null,"id":"184hq0"}
{"domain":"self.MachineLearning","user_reports":[],"author":"sculler","score":2,"gilded":0,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a project for my data mining and machine learning class and one thing I am interested in is sports betting.  I am sure there are many applications of machine learning within sports betting but as I look at &lt;a href=\"http://scholar.google.ca/scholar?hl=en&amp;amp;q=machine+learning+sports+betting&amp;amp;btnG=&amp;amp;as_sdt=1%2C5&amp;amp;as_sdtp=\"&gt;google scholar&lt;/a&gt; I am not really finding that many journals which really surprises me.&lt;/p&gt;\n\n&lt;p&gt;Do you know of any good resources on this topic that would help me flush out the topic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","num_comments":6,"mod_reports":[],"subreddit_id":"t5_2r3gv","url":"http://www.reddit.com/r/MachineLearning/comments/183qrp/sports_betting_and_machine_learning/","retrieved_on":1413118096,"selftext":"I am looking for a project for my data mining and machine learning class and one thing I am interested in is sports betting.  I am sure there are many applications of machine learning within sports betting but as I look at [google scholar](http://scholar.google.ca/scholar?hl=en&amp;q=machine+learning+sports+betting&amp;btnG=&amp;as_sdt=1%2C5&amp;as_sdtp=) I am not really finding that many journals which really surprises me.\n\nDo you know of any good resources on this topic that would help me flush out the topic?","author_flair_css_class":null,"downs":0,"created_utc":1360287762,"author_flair_text":null,"link_flair_css_class":null,"link_flair_text":null,"distinguished":null,"title":"Sports Betting and Machine Learning","banned_by":null,"subreddit":"MachineLearning","secure_media":null,"thumbnail":"self","stickied":false,"over_18":false,"media_embed":{},"secure_media_embed":{},"report_reasons":null,"ups":2,"media":null,"permalink":"/r/MachineLearning/comments/183qrp/sports_betting_and_machine_learning/","id":"183qrp","edited":false,"is_self":true}
{"selftext":"Just learning about neural nets and haven't really seen how/if the hidden units with sigmoid activation functions lead to the approximation of arbitrary nonlinear functions.\n\nAny intuition or proof is useful, thanks!","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/187c01/neural_nets_how_do_hidden_units_and_sigmoids/","num_comments":12,"media_embed":{},"gilded":0,"over_18":false,"author":"ace2525","url":"http://www.reddit.com/r/MachineLearning/comments/187c01/neural_nets_how_do_hidden_units_and_sigmoids/","banned_by":null,"created_utc":1360435576,"author_flair_css_class":null,"subreddit":"MachineLearning","score":5,"secure_media_embed":{},"title":"Neural Nets: how do hidden units and sigmoids approximate nonlinear functions?","id":"187c01","distinguished":null,"media":null,"secure_media":null,"downs":0,"ups":5,"retrieved_on":1413088953,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"self.MachineLearning","stickied":false,"link_flair_text":null,"report_reasons":null,"mod_reports":[],"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just learning about neural nets and haven&amp;#39;t really seen how/if the hidden units with sigmoid activation functions lead to the approximation of arbitrary nonlinear functions.&lt;/p&gt;\n\n&lt;p&gt;Any intuition or proof is useful, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self"}
{"user_reports":[],"domain":"self.MachineLearning","stickied":false,"retrieved_on":1413089353,"edited":1360426285,"author_flair_text":null,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As part of a marketing research at grad school, I have been given a huge data set with about a million observations. It is a result of rating collected by a questionnaire set up by a store to rate the customer experience from 1 to 10 with 1 being very poor to 10 being highly enjoyable with no other particular coding in-between. And the other accompanying data is the date when the rating was collected. Each observation has an unique customer id. Sometimes the same customer might have filled the form multiple times over the time(the data was collected over 20 years). &lt;/p&gt;\n\n&lt;p&gt;Questions I am trying to answer:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What is the appropriate cut-off to determine, the customer had a pleasant experience and can send discount  offers to them?&lt;/li&gt;\n&lt;li&gt;For a particular customer, what percentage of his total visits did he find it to be a pleasant experience?&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I can see that this is an unsupervised learning problem. But I am not sure which might be the correct technique. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"default","link_flair_text":null,"report_reasons":null,"title":"Suggest appropriate unsupervised methods for a two variable marketing problem. ","id":"1871k8","distinguished":null,"media":null,"secure_media":null,"ups":2,"downs":0,"author_flair_css_class":null,"subreddit":"MachineLearning","score":2,"secure_media_embed":{},"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/1871k8/suggest_appropriate_unsupervised_methods_for_a/","selftext":"As part of a marketing research at grad school, I have been given a huge data set with about a million observations. It is a result of rating collected by a questionnaire set up by a store to rate the customer experience from 1 to 10 with 1 being very poor to 10 being highly enjoyable with no other particular coding in-between. And the other accompanying data is the date when the rating was collected. Each observation has an unique customer id. Sometimes the same customer might have filled the form multiple times over the time(the data was collected over 20 years). \n\nQuestions I am trying to answer:\n\n* What is the appropriate cut-off to determine, the customer had a pleasant experience and can send discount  offers to them?\n* For a particular customer, what percentage of his total visits did he find it to be a pleasant experience?  \n\nI can see that this is an unsupervised learning problem. But I am not sure which might be the correct technique. ","link_flair_css_class":null,"url":"http://www.reddit.com/r/MachineLearning/comments/1871k8/suggest_appropriate_unsupervised_methods_for_a/","banned_by":null,"created_utc":1360425185,"num_comments":3,"media_embed":{},"gilded":0,"over_18":false,"author":"[deleted]"}
{"author_flair_text":null,"retrieved_on":1413090022,"edited":1360394905,"stickied":false,"user_reports":[],"domain":"self.MachineLearning","report_reasons":null,"link_flair_text":null,"mod_reports":[],"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In a learning task (web page classification), I have used 3 classifiers on a training set. Namely,&lt;/p&gt;\n\n&lt;p&gt;*classifier 1 uses feature set A (extracted with feature_extractor_A), eg. using features from HTML structure&lt;/p&gt;\n\n&lt;p&gt;*classifier 2 with feature set B (extracted with feature_extractor_B), eg. features from words in each page&lt;/p&gt;\n\n&lt;p&gt;*classifier 3 with feature set C (extracted with feature_extractor_C), eg. using features from byte contents of each page&lt;/p&gt;\n\n&lt;p&gt;As you see, all of the 3 classifiers are trained with the same instances, but using different feature extractors (and hence different feature sets).&lt;/p&gt;\n\n&lt;p&gt;I have then used the output of these 3 classifiers, and used them as inputs for a meta-classifier (i.e. random forest). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what is this system formally called in machine learning literature? I think the term &lt;em&gt;stacked generalization&lt;/em&gt; is used when their feature sets are the same for all classifiers (see figure 7. in this link: &lt;a href=\"http://www.scholarpedia.org/article/Ensemble_learning\"&gt;http://www.scholarpedia.org/article/Ensemble_learning&lt;/a&gt; ) &lt;/p&gt;\n\n&lt;p&gt;Is my method still called a stacked generalization method? If not, what is it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","id":"186m8o","distinguished":null,"media":null,"title":"Ensemble learning with multiple feature sets: what is it called?","downs":0,"ups":4,"secure_media":null,"author_flair_css_class":null,"secure_media_embed":{},"score":4,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"In a learning task (web page classification), I have used 3 classifiers on a training set. Namely,\n\n*classifier 1 uses feature set A (extracted with feature_extractor_A), eg. using features from HTML structure\n\n*classifier 2 with feature set B (extracted with feature_extractor_B), eg. features from words in each page\n\n*classifier 3 with feature set C (extracted with feature_extractor_C), eg. using features from byte contents of each page\n\nAs you see, all of the 3 classifiers are trained with the same instances, but using different feature extractors (and hence different feature sets).\n\nI have then used the output of these 3 classifiers, and used them as inputs for a meta-classifier (i.e. random forest). \n\nI'm wondering what is this system formally called in machine learning literature? I think the term *stacked generalization* is used when their feature sets are the same for all classifiers (see figure 7. in this link: http://www.scholarpedia.org/article/Ensemble_learning ) \n\nIs my method still called a stacked generalization method? If not, what is it?","permalink":"/r/MachineLearning/comments/186m8o/ensemble_learning_with_multiple_feature_sets_what/","subreddit_id":"t5_2r3gv","gilded":0,"num_comments":9,"media_embed":{},"author":"hadian","over_18":false,"banned_by":null,"created_utc":1360394725,"url":"http://www.reddit.com/r/MachineLearning/comments/186m8o/ensemble_learning_with_multiple_feature_sets_what/"}
{"id":"186gex","distinguished":null,"media":null,"title":"Big Data can produce Big Errors.","downs":0,"ups":34,"secure_media":null,"author_flair_text":null,"retrieved_on":1413090360,"edited":false,"stickied":false,"user_reports":[],"domain":"wired.com","report_reasons":null,"link_flair_text":null,"mod_reports":[],"is_self":false,"thumbnail":"http://b.thumbs.redditmedia.com/O0V2bc1NqX5SXbVy.jpg","selftext_html":null,"link_flair_css_class":null,"selftext":"","permalink":"/r/MachineLearning/comments/186gex/big_data_can_produce_big_errors/","subreddit_id":"t5_2r3gv","num_comments":16,"media_embed":{},"gilded":0,"author":"qkdhfjdjdhd","over_18":false,"banned_by":null,"created_utc":1360387178,"url":"http://www.wired.com/opinion/2013/02/big-data-means-big-errors-people/","author_flair_css_class":null,"secure_media_embed":{},"score":34,"subreddit":"MachineLearning"}
{"score":5,"secure_media_embed":{},"subreddit":"MachineLearning","author_flair_css_class":null,"banned_by":null,"created_utc":1360370418,"url":"http://www.reddit.com/r/MachineLearning/comments/185zfy/nonlinear_least_squares_and_machine_learning/","media_embed":{},"num_comments":8,"gilded":0,"over_18":false,"author":"dedekind_cutlet","permalink":"/r/MachineLearning/comments/185zfy/nonlinear_least_squares_and_machine_learning/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"My research group does work in nonlinear dynamics and parameter fitting.  We don't exactly approach the problem as one of machine learning though it arguably is a form of it.  Part of our work involves mapping vectors into a higher dimensional space, predicting forward in time in the higher dimensional space, and then converting those predictions back into the lower dimensional space (a classically ill-posed problem).  This last step seems to be an example of some form of non-linear regression, specifically NLLS (for us).  The wikipedia page doesn't seem to be very helpful, so I was curious if anyone here had a good reference or tutorial on the matter of non-linear least squares.","mod_reports":[],"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My research group does work in nonlinear dynamics and parameter fitting.  We don&amp;#39;t exactly approach the problem as one of machine learning though it arguably is a form of it.  Part of our work involves mapping vectors into a higher dimensional space, predicting forward in time in the higher dimensional space, and then converting those predictions back into the lower dimensional space (a classically ill-posed problem).  This last step seems to be an example of some form of non-linear regression, specifically NLLS (for us).  The wikipedia page doesn&amp;#39;t seem to be very helpful, so I was curious if anyone here had a good reference or tutorial on the matter of non-linear least squares.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","report_reasons":null,"link_flair_text":null,"stickied":false,"user_reports":[],"domain":"self.MachineLearning","author_flair_text":null,"retrieved_on":1413091026,"edited":false,"ups":5,"downs":0,"secure_media":null,"id":"185zfy","distinguished":null,"media":null,"title":"Non-linear least squares and machine learning"}
{"edited":1360424247,"retrieved_on":1413091132,"author_flair_text":null,"domain":"self.MachineLearning","user_reports":[],"stickied":false,"report_reasons":null,"link_flair_text":null,"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a MLP based neural network producing the following learning graph for the training &lt;em&gt;test&lt;/em&gt; sample:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://i.imgur.com/bi6cD6K.jpg\"&gt;http://i.imgur.com/bi6cD6K.jpg&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My understanding is that, as the number of training cycles increases, the error (squared difference between neural network output and target value) for the training sample should drop to a minimum while the error for the training &lt;em&gt;test&lt;/em&gt; sample should drop to a minimum and then rise (as the neural network becomes more schizophrenic).&lt;/p&gt;\n\n&lt;p&gt;The result I&amp;#39;m getting here for the training test sample has the error decrease, then increase, then decrease and stabilise near the minimum. Does anyone know what may be causing this behaviour?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","mod_reports":[],"title":"help with odd learning behaviour on MLP training test sample","distinguished":null,"media":null,"id":"185wkb","secure_media":null,"downs":0,"ups":3,"author_flair_css_class":null,"subreddit":"MachineLearning","score":3,"secure_media_embed":{},"selftext":"I have a MLP based neural network producing the following learning graph for the training *test* sample:\n\nhttp://i.imgur.com/bi6cD6K.jpg\n\nMy understanding is that, as the number of training cycles increases, the error (squared difference between neural network output and target value) for the training sample should drop to a minimum while the error for the training *test* sample should drop to a minimum and then rise (as the neural network becomes more schizophrenic).\n\nThe result I'm getting here for the training test sample has the error decrease, then increase, then decrease and stabilise near the minimum. Does anyone know what may be causing this behaviour?","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/185wkb/help_with_odd_learning_behaviour_on_mlp_training/","author":"d3pd","over_18":false,"media_embed":{},"num_comments":11,"gilded":0,"url":"http://www.reddit.com/r/MachineLearning/comments/185wkb/help_with_odd_learning_behaviour_on_mlp_training/","created_utc":1360368156,"banned_by":null}
{"score":0,"secure_media_embed":{},"subreddit":"MachineLearning","author_flair_css_class":null,"gilded":0,"num_comments":0,"media_embed":{},"over_18":false,"author":"[deleted]","banned_by":null,"created_utc":1360539619,"url":"http://www.reddit.com/r/MachineLearning/comments/189vby/what_method_best_to_use_for_online_learning_for/","link_flair_css_class":null,"selftext":"Hi,\nSo i was thinking of a small project,that would classify a person as being from a set group of categories ,based on what he says in a dialogue.Not doing any natural language  here ,the stuff a person says comes in as labeled data (+1 douche rating for example 0 Nice guy) .I know that i could use a simple naive Bayes to classify this ,but the thing is i would like it to learn over time with new dataset coming in at some points in time.\n\nSo any suggestions and maybe even implementations for the proposed method would be great.\n\nP.S . First post ...be gentle.\n\nEdit.Made a mistake in the title.","permalink":"/r/MachineLearning/comments/189vby/what_method_best_to_use_for_online_learning_for/","subreddit_id":"t5_2r3gv","link_flair_text":null,"report_reasons":null,"mod_reports":[],"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nSo i was thinking of a small project,that would classify a person as being from a set group of categories ,based on what he says in a dialogue.Not doing any natural language  here ,the stuff a person says comes in as labeled data (+1 douche rating for example 0 Nice guy) .I know that i could use a simple naive Bayes to classify this ,but the thing is i would like it to learn over time with new dataset coming in at some points in time.&lt;/p&gt;\n\n&lt;p&gt;So any suggestions and maybe even implementations for the proposed method would be great.&lt;/p&gt;\n\n&lt;p&gt;P.S . First post ...be gentle.&lt;/p&gt;\n\n&lt;p&gt;Edit.Made a mistake in the title.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"default","author_flair_text":null,"retrieved_on":1413085527,"edited":1360542697,"stickied":false,"user_reports":[],"domain":"self.MachineLearning","downs":0,"ups":0,"secure_media":null,"id":"189vby","distinguished":null,"media":null,"title":"What method best to use for On-Line learning for Human attitude classification"}
{"subreddit":"MachineLearning","secure_media_embed":{},"score":1,"author_flair_css_class":null,"url":"http://subtlearray.tumblr.com/post/42779370765","created_utc":1360533084,"banned_by":null,"author":"[deleted]","over_18":false,"num_comments":0,"gilded":0,"media_embed":{},"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/189nh5/support_vector_machines_a_stepbystep_introduction/","selftext":"","link_flair_css_class":null,"selftext_html":null,"is_self":false,"thumbnail":"default","mod_reports":[],"link_flair_text":null,"report_reasons":null,"domain":"subtlearray.tumblr.com","user_reports":[],"stickied":false,"edited":false,"retrieved_on":1413085811,"author_flair_text":null,"secure_media":null,"ups":1,"downs":0,"title":"Support Vector Machines: A Step-by-Step Introduction","distinguished":null,"media":null,"id":"189nh5"}
{"author_flair_text":null,"retrieved_on":1413086998,"edited":false,"stickied":false,"user_reports":[],"domain":"self.MachineLearning","link_flair_text":null,"report_reasons":null,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am trying to figure out which is the best document representation for an information retrieval (IR) system. There are two popular options at the state-of-the-art: (1) BOW (Bag Of Words), adopted by IR systems like Lucene (&lt;a href=\"http://lucene.apache.org/core/\"&gt;http://lucene.apache.org/core/&lt;/a&gt;); (2) BOF (Bag Of Features), exploited by LETOR (&lt;a href=\"http://research.microsoft.com/en-us/um/beijing/projects/letor/\"&gt;http://research.microsoft.com/en-us/um/beijing/projects/letor/&lt;/a&gt;).\nBOW is apparently able to capture documents semantic, but it only happens if you consider small vocabularies (eg., 5000 words), so it is not scalable. On the other hand, BOF is independent from the vocabulary size, and it may be easily combined to machine learning techniques to build an ad hoc ranking system, even though it is not able to capture the semantic. The question is: which is the most important feature for an IR system? Capturing the semantic or learning how to rank a document? Which basically means: which is the best representation between BOW and BOF?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"self","id":"188s60","distinguished":null,"media":null,"title":"Document representation for information retrieval systems","ups":7,"downs":0,"secure_media":null,"author_flair_css_class":null,"secure_media_embed":{},"score":7,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"Hi everyone, I am trying to figure out which is the best document representation for an information retrieval (IR) system. There are two popular options at the state-of-the-art: (1) BOW (Bag Of Words), adopted by IR systems like Lucene (http://lucene.apache.org/core/); (2) BOF (Bag Of Features), exploited by LETOR (http://research.microsoft.com/en-us/um/beijing/projects/letor/).\nBOW is apparently able to capture documents semantic, but it only happens if you consider small vocabularies (eg., 5000 words), so it is not scalable. On the other hand, BOF is independent from the vocabulary size, and it may be easily combined to machine learning techniques to build an ad hoc ranking system, even though it is not able to capture the semantic. The question is: which is the most important feature for an IR system? Capturing the semantic or learning how to rank a document? Which basically means: which is the best representation between BOW and BOF?","permalink":"/r/MachineLearning/comments/188s60/document_representation_for_information_retrieval/","subreddit_id":"t5_2r3gv","media_embed":{},"num_comments":2,"gilded":0,"author":"dtosato","over_18":false,"banned_by":null,"created_utc":1360496976,"url":"http://www.reddit.com/r/MachineLearning/comments/188s60/document_representation_for_information_retrieval/"}
{"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":1,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18bu8c/quality_score_for_mc_pagerank_approximation/","selftext":"Hey people, I'm implementing a Monte Carlo PageRank approximation. I want to measure it's accuracy when compared to the \"true\" scores that power iteration gets. So I have two probability distribution vectors that I compare.\n\nI'm trying to come up with a metric that should show what is expected for this method, that is that the values are close for the larger values in the vector (ir. more important PageRank values are approximated closer to their true value) and less so for the smaller PageRank values.\n\nAny ideas?\n","link_flair_css_class":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18bu8c/quality_score_for_mc_pagerank_approximation/","created_utc":1360614266,"banned_by":null,"author":"Barbas","over_18":false,"num_comments":3,"media_embed":{},"gilded":0,"domain":"self.MachineLearning","user_reports":[],"stickied":false,"edited":false,"retrieved_on":1413082890,"author_flair_text":null,"thumbnail":"self","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey people, I&amp;#39;m implementing a Monte Carlo PageRank approximation. I want to measure it&amp;#39;s accuracy when compared to the &amp;quot;true&amp;quot; scores that power iteration gets. So I have two probability distribution vectors that I compare.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to come up with a metric that should show what is expected for this method, that is that the values are close for the larger values in the vector (ir. more important PageRank values are approximated closer to their true value) and less so for the smaller PageRank values.&lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"report_reasons":null,"link_flair_text":null,"title":"Quality score for MC PageRank approximation","distinguished":null,"media":null,"id":"18bu8c","secure_media":null,"downs":0,"ups":1}
{"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":1,"selftext":"","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18bddf/support_vector_machines_a_stepbystep_introduction/","num_comments":0,"media_embed":{},"gilded":0,"author":"subtlearray","over_18":false,"url":"http://subtlearray.tumblr.com/post/42779370765","banned_by":null,"created_utc":1360600862,"retrieved_on":1413083497,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"subtlearray.tumblr.com","stickied":false,"link_flair_text":null,"report_reasons":null,"mod_reports":[],"is_self":false,"selftext_html":null,"thumbnail":"http://d.thumbs.redditmedia.com/br9TomOGjkCMOvfK.jpg","title":"Support Vector Machines: A Step-by-Step Introduction","id":"18bddf","distinguished":null,"media":null,"secure_media":null,"downs":0,"ups":1}
{"ups":20,"downs":0,"secure_media":null,"media":null,"distinguished":null,"id":"18ay0g","title":"What is the current state of artificial creativity?","link_flair_text":null,"report_reasons":null,"thumbnail":"self","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have no idea how are the developments in this area, and I&amp;#39;m willing to try emulating creativity (literature, music, painting... etc).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413084066,"stickied":false,"domain":"self.MachineLearning","user_reports":[],"over_18":false,"author":"MindArchitect","gilded":0,"num_comments":22,"media_embed":{},"created_utc":1360581540,"banned_by":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18ay0g/what_is_the_current_state_of_artificial_creativity/","link_flair_css_class":null,"selftext":"I have no idea how are the developments in this area, and I'm willing to try emulating creativity (literature, music, painting... etc).","permalink":"/r/MachineLearning/comments/18ay0g/what_is_the_current_state_of_artificial_creativity/","subreddit_id":"t5_2r3gv","secure_media_embed":{},"score":20,"subreddit":"MachineLearning","author_flair_css_class":null}
{"subreddit":"MachineLearning","secure_media_embed":{},"score":0,"author_flair_css_class":null,"num_comments":0,"media_embed":{},"gilded":0,"author":"myle","over_18":false,"url":"http://dimle.wordpress.com/2013/02/13/ml-estimators/","banned_by":null,"created_utc":1360708806,"selftext":"","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18elol/a_simplistic_introduction_to_ml_estimators/","link_flair_text":null,"report_reasons":null,"mod_reports":[],"selftext_html":null,"is_self":false,"thumbnail":"http://a.thumbs.redditmedia.com/djozo5rnz6ZtIbe6.jpg","retrieved_on":1413078968,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"dimle.wordpress.com","stickied":false,"secure_media":null,"ups":0,"downs":0,"title":"A simplistic introduction to ML estimators","id":"18elol","distinguished":null,"media":null}
{"author_flair_css_class":null,"score":40,"secure_media_embed":{},"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/18dwog/researchers_say_ai_prescribes_better_treatment/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"","banned_by":null,"created_utc":1360689233,"url":"http://gigaom.com/2013/02/11/researchers-say-ai-prescribes-better-treatment-than-doctors/","num_comments":16,"media_embed":{},"gilded":0,"author":"Barbas","over_18":false,"stickied":false,"user_reports":[],"domain":"gigaom.com","author_flair_text":null,"retrieved_on":1413080038,"edited":false,"mod_reports":[],"is_self":false,"thumbnail":"http://d.thumbs.redditmedia.com/h5NOsWj7o1uUb02E.jpg","selftext_html":null,"report_reasons":null,"link_flair_text":null,"id":"18dwog","distinguished":null,"media":null,"title":"Researchers say AI prescribes better treatment than doctors","ups":40,"downs":0,"secure_media":null}
{"secure_media":null,"ups":4,"downs":0,"title":"Darwin: framework for machine learning and computer vision research and development","id":"18durx","distinguished":null,"media":null,"mod_reports":[],"thumbnail":"http://a.thumbs.redditmedia.com/V9Qsqmud_EzXWWR0.jpg","is_self":false,"selftext_html":null,"link_flair_text":null,"report_reasons":null,"user_reports":[],"domain":"drwn.anu.edu.au","stickied":false,"retrieved_on":1413080118,"edited":false,"author_flair_text":null,"url":"http://drwn.anu.edu.au","banned_by":null,"created_utc":1360687558,"gilded":0,"num_comments":4,"media_embed":{},"author":"therobot24","over_18":false,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18durx/darwin_framework_for_machine_learning_and/","selftext":"","link_flair_css_class":null,"subreddit":"MachineLearning","score":4,"secure_media_embed":{},"author_flair_css_class":null}
{"title":"I've done a comparison of Mini Batch &amp; Elkan's k-Means","id":"18dtxy","distinguished":null,"media":null,"secure_media":null,"ups":2,"downs":0,"user_reports":[],"domain":"self.MachineLearning","stickied":false,"retrieved_on":1413080155,"edited":false,"author_flair_text":null,"mod_reports":[],"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve made this a text post since it seems submitting to your own blog is a no no. Its been a little sparse in here, so I figured I would submit some of my own investigation into &lt;a href=\"http://jsatml.blogspot.com/2013/02/mini-batch-k-means-vs-elkan.html\"&gt;Mini Batch k-Means and Elkan&amp;#39;s k-Means&lt;/a&gt;. Turns out the speed improvements are not quite as good as advertised when compared with more advanced exact k-Means implementations. &lt;/p&gt;\n\n&lt;p&gt;Any feed back on other things to investigate in the future is also welcome. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"self","link_flair_text":null,"report_reasons":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18dtxy/ive_done_a_comparison_of_mini_batch_elkans_kmeans/","selftext":"I've made this a text post since it seems submitting to your own blog is a no no. Its been a little sparse in here, so I figured I would submit some of my own investigation into [Mini Batch k-Means and Elkan's k-Means](http://jsatml.blogspot.com/2013/02/mini-batch-k-means-vs-elkan.html). Turns out the speed improvements are not quite as good as advertised when compared with more advanced exact k-Means implementations. \n\nAny feed back on other things to investigate in the future is also welcome. \n","link_flair_css_class":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18dtxy/ive_done_a_comparison_of_mini_batch_elkans_kmeans/","banned_by":null,"created_utc":1360686851,"num_comments":3,"media_embed":{},"gilded":0,"author":"EdwardRaff","over_18":false,"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":2}
{"author_flair_css_class":null,"secure_media_embed":{},"score":0,"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"We have a 300 x 300 element data set that represents some geographic area, where each element/pixel is about 1km on a side.  Each element holds one of two values:  clear or cloud.  The data is represented as a 2D array of 8-bit values.  The data set is updated every 10 minutes, and we already have about 5 months of historical data. \n\nThis data can be considered \"observed data\" or truth data, and we wish to use this data to forecast future situations.  Specifically, what sorts of ML algorithms/techniques could be used to forecast the future position of the cloud pixels in the dataset at times t=1, 2, ...n?  I've been working on an algorithm that utilizes something like an SVD, finding a linear transformation from the t=-1 and the current (t=0) data set, and then applying the transformation to the current data set to predict where the elements will be at t=1, 2, n.  A very early/rough implementation shows that it is very computationally expensive (which isn't a deal breaker, but is of moderate concern), and it seems to not perform that well when comparing the predicted positions of cloud pixels back to the truth/observed data that finally comes into the data set.\n\nAny ideas for alternative approaches?  Anyone know of any similar problems?  White papers, books?  Cheers!\n","permalink":"/r/MachineLearning/comments/18dqx2/askml_machine_learning_and_cloud_cover_forecasting/","subreddit_id":"t5_2r3gv","author":"metaobject","over_18":false,"media_embed":{},"num_comments":1,"gilded":0,"created_utc":1360684267,"banned_by":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18dqx2/askml_machine_learning_and_cloud_cover_forecasting/","author_flair_text":null,"edited":false,"retrieved_on":1413080272,"stickied":false,"domain":"self.MachineLearning","user_reports":[],"link_flair_text":null,"report_reasons":null,"thumbnail":"self","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a 300 x 300 element data set that represents some geographic area, where each element/pixel is about 1km on a side.  Each element holds one of two values:  clear or cloud.  The data is represented as a 2D array of 8-bit values.  The data set is updated every 10 minutes, and we already have about 5 months of historical data. &lt;/p&gt;\n\n&lt;p&gt;This data can be considered &amp;quot;observed data&amp;quot; or truth data, and we wish to use this data to forecast future situations.  Specifically, what sorts of ML algorithms/techniques could be used to forecast the future position of the cloud pixels in the dataset at times t=1, 2, ...n?  I&amp;#39;ve been working on an algorithm that utilizes something like an SVD, finding a linear transformation from the t=-1 and the current (t=0) data set, and then applying the transformation to the current data set to predict where the elements will be at t=1, 2, n.  A very early/rough implementation shows that it is very computationally expensive (which isn&amp;#39;t a deal breaker, but is of moderate concern), and it seems to not perform that well when comparing the predicted positions of cloud pixels back to the truth/observed data that finally comes into the data set.&lt;/p&gt;\n\n&lt;p&gt;Any ideas for alternative approaches?  Anyone know of any similar problems?  White papers, books?  Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"media":null,"distinguished":null,"id":"18dqx2","title":"AskML:  Machine Learning and Cloud Cover Forecasting","ups":0,"downs":0,"secure_media":null}
{"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":21,"selftext":"Hi all,\n\nI'm wondering what an entry level job for an ML career would look like. Embarrassingly, I actually have a Master's in ML, but I know I'm not qualified to tackle the ML jobs listed on Monster.com. I was lucky to survive with a diploma - I can program decently well, but I don't have the intuition behind the math (also, I believe it's hard to fail out of Master's programs in general because they are cash cows for Universities, and hence there is a general reluctance to punish people that are reasonably smart and paying a lot of money). And so I just don't have the confidence to tackle the Amazon/IBM type jobs that I often see. I've done some courses on Coursera (ML with Andrew Ng, which was awesome, and PGM, which is a total beast), and some self-study on statistics, but I would really like an entry level job in ML. However, the search terms \"entry level\" and \"machine learning\" don't really turn up sensible results when I use them. Is there another, easier job title that eventually leads to ML? Or, what else can I be doing to kick start a career in ML?\n\nI apologize if this is a noob/frequently posted query.\n\nEdit: Thanks all! I think I'll hang out here more often for inspiration and industry news. ","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18d6kj/entry_level_jobs_in_machine_learning/","num_comments":29,"gilded":0,"media_embed":{},"over_18":false,"author":"harfharf11","url":"http://www.reddit.com/r/MachineLearning/comments/18d6kj/entry_level_jobs_in_machine_learning/","banned_by":null,"created_utc":1360652512,"retrieved_on":1413081048,"edited":1360691433,"author_flair_text":null,"user_reports":[],"domain":"self.MachineLearning","stickied":false,"link_flair_text":null,"report_reasons":null,"mod_reports":[],"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what an entry level job for an ML career would look like. Embarrassingly, I actually have a Master&amp;#39;s in ML, but I know I&amp;#39;m not qualified to tackle the ML jobs listed on Monster.com. I was lucky to survive with a diploma - I can program decently well, but I don&amp;#39;t have the intuition behind the math (also, I believe it&amp;#39;s hard to fail out of Master&amp;#39;s programs in general because they are cash cows for Universities, and hence there is a general reluctance to punish people that are reasonably smart and paying a lot of money). And so I just don&amp;#39;t have the confidence to tackle the Amazon/IBM type jobs that I often see. I&amp;#39;ve done some courses on Coursera (ML with Andrew Ng, which was awesome, and PGM, which is a total beast), and some self-study on statistics, but I would really like an entry level job in ML. However, the search terms &amp;quot;entry level&amp;quot; and &amp;quot;machine learning&amp;quot; don&amp;#39;t really turn up sensible results when I use them. Is there another, easier job title that eventually leads to ML? Or, what else can I be doing to kick start a career in ML?&lt;/p&gt;\n\n&lt;p&gt;I apologize if this is a noob/frequently posted query.&lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks all! I think I&amp;#39;ll hang out here more often for inspiration and industry news. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","title":"Entry level jobs in Machine Learning?","id":"18d6kj","distinguished":null,"media":null,"secure_media":null,"downs":0,"ups":21}
{"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":0,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18h0et/support_vector_machines_a_stepbystep_introduction/","selftext":"I wrote a post to help beginners get better acquainted with support vector machines. If you see any errors, or have any suggestions on details I should add, please let me know.\n\n[Support Vector Machines: A Step-by-Step Introduction](http://subtlearray.tumblr.com/post/42779370765)\n\nMy next post will likely be on optimization theory.","link_flair_css_class":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18h0et/support_vector_machines_a_stepbystep_introduction/","created_utc":1360793710,"banned_by":null,"author":"subtlearray","over_18":false,"num_comments":0,"media_embed":{},"gilded":0,"domain":"self.MachineLearning","user_reports":[],"stickied":false,"edited":false,"retrieved_on":1413075326,"author_flair_text":null,"thumbnail":"self","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a post to help beginners get better acquainted with support vector machines. If you see any errors, or have any suggestions on details I should add, please let me know.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://subtlearray.tumblr.com/post/42779370765\"&gt;Support Vector Machines: A Step-by-Step Introduction&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My next post will likely be on optimization theory.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"report_reasons":null,"link_flair_text":null,"title":"Support Vector Machines: A Step-by-Step Introduction","media":null,"distinguished":null,"id":"18h0et","secure_media":null,"downs":0,"ups":0}
{"author_flair_css_class":null,"score":1,"secure_media_embed":{},"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/18grk6/aligning_new_sentence_pairs_with_the_berkeley/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"I'm trying to use the Aligner (unsupervised) to align Korean and English sentences. I see that when I run the aligner on the example data, it does the \"test\" step on the example test corpus. Based on this, I'm assuming the Aligner can align unknown pairs of sentences using the model obtained through the alignment process with the train corpus. However, I couldn't find a way to use the Aligner to align unknown parallel sentences. How can I perform this task? Poking around the code, I discovered an abstract class called WordAligner, but I'm not too sure how to load a model on to a class that implements it.  ","banned_by":null,"created_utc":1360787082,"url":"http://www.reddit.com/r/MachineLearning/comments/18grk6/aligning_new_sentence_pairs_with_the_berkeley/","num_comments":0,"gilded":0,"media_embed":{},"author":"yukw777","over_18":false,"stickied":false,"user_reports":[],"domain":"self.MachineLearning","author_flair_text":null,"retrieved_on":1413075705,"edited":false,"mod_reports":[],"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to use the Aligner (unsupervised) to align Korean and English sentences. I see that when I run the aligner on the example data, it does the &amp;quot;test&amp;quot; step on the example test corpus. Based on this, I&amp;#39;m assuming the Aligner can align unknown pairs of sentences using the model obtained through the alignment process with the train corpus. However, I couldn&amp;#39;t find a way to use the Aligner to align unknown parallel sentences. How can I perform this task? Poking around the code, I discovered an abstract class called WordAligner, but I&amp;#39;m not too sure how to load a model on to a class that implements it.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","link_flair_text":null,"report_reasons":null,"id":"18grk6","media":null,"distinguished":null,"title":"Aligning new sentence pairs with the Berkeley Aligner","ups":1,"downs":0,"secure_media":null}
{"author_flair_css_class":null,"subreddit":"MachineLearning","score":0,"secure_media_embed":{},"selftext":"I'm creating an audio comparison program that will take phraseA.wav, phraseB.wav, and assign them a similarity score out of 100. \n\nThe phrases should ideally be anywhere from \"How are you\" (3 syllables), to a longer sentence; but no more than 1 sentence. \n\nBut the database can't just be a bunch of phrases said only once - otherwise I can't learn how to identify the same phrase said slightly differently. So I'd need:\n\n- phrase1a.wav\n- phrase1b.wav\n- phrase1c.wav\n- phrase1d.wav (all the same sentence so far)\n\n...\n\n- phraseNa.wav\n- phraseNb.wav\n- phraseNc.wav\n- phraseNd.wav (e.g. each of the N phrases has 4 samples of it being said slightly different)\n\nThank you for any help, hopefully others can benefit too from these resources!","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18gqaz/request_database_of_spoken_english_phrases/","media_embed":{},"num_comments":0,"gilded":0,"author":"vcxzzxcv","over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/18gqaz/request_database_of_spoken_english_phrases/","banned_by":null,"created_utc":1360786142,"retrieved_on":1413075753,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"self.MachineLearning","stickied":false,"link_flair_text":null,"report_reasons":null,"mod_reports":[],"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m creating an audio comparison program that will take phraseA.wav, phraseB.wav, and assign them a similarity score out of 100. &lt;/p&gt;\n\n&lt;p&gt;The phrases should ideally be anywhere from &amp;quot;How are you&amp;quot; (3 syllables), to a longer sentence; but no more than 1 sentence. &lt;/p&gt;\n\n&lt;p&gt;But the database can&amp;#39;t just be a bunch of phrases said only once - otherwise I can&amp;#39;t learn how to identify the same phrase said slightly differently. So I&amp;#39;d need:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;phrase1a.wav&lt;/li&gt;\n&lt;li&gt;phrase1b.wav&lt;/li&gt;\n&lt;li&gt;phrase1c.wav&lt;/li&gt;\n&lt;li&gt;phrase1d.wav (all the same sentence so far)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;...&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;phraseNa.wav&lt;/li&gt;\n&lt;li&gt;phraseNb.wav&lt;/li&gt;\n&lt;li&gt;phraseNc.wav&lt;/li&gt;\n&lt;li&gt;phraseNd.wav (e.g. each of the N phrases has 4 samples of it being said slightly different)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you for any help, hopefully others can benefit too from these resources!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","title":"Request: database of spoken (English) phrases, including same phrase said multiple times","id":"18gqaz","distinguished":null,"media":null,"secure_media":null,"ups":0,"downs":0}
{"num_comments":18,"gilded":0,"media_embed":{},"author":"Foxtr0t","over_18":false,"banned_by":null,"created_utc":1360780925,"url":"http://fastml.com/the-secret-of-the-big-guys/","link_flair_css_class":null,"selftext":"","permalink":"/r/MachineLearning/comments/18gjdz/the_secret_of_the_big_guys_kmeans_clustering_a/","subreddit_id":"t5_2r3gv","secure_media_embed":{},"score":80,"subreddit":"MachineLearning","author_flair_css_class":null,"downs":0,"ups":80,"secure_media":null,"id":"18gjdz","distinguished":null,"media":null,"title":"The secret of the big guys: K-means clustering + a linear model = good results","link_flair_text":null,"report_reasons":null,"mod_reports":[],"selftext_html":null,"is_self":false,"thumbnail":"http://a.thumbs.redditmedia.com/p86vszMb1C-VR9WZ.jpg","author_flair_text":null,"retrieved_on":1413076049,"edited":false,"stickied":false,"user_reports":[],"domain":"fastml.com"}
{"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":0,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18g5l3/first_ukireland_ieeesmccls_2013_will_be_held_on/","selftext":"","link_flair_css_class":null,"url":"http://scm.ulster.ac.uk/IEEESMC-CLS2013/","banned_by":null,"created_utc":1360769549,"gilded":0,"num_comments":0,"media_embed":{},"author":"Zigus","over_18":false,"user_reports":[],"domain":"scm.ulster.ac.uk","stickied":false,"retrieved_on":1413076625,"edited":false,"author_flair_text":null,"mod_reports":[],"is_self":false,"thumbnail":"default","selftext_html":null,"link_flair_text":null,"report_reasons":null,"title":"First UK-Ireland IEEE-SMC-CLS 2013 will be held on 25 March 2013","id":"18g5l3","distinguished":null,"media":null,"secure_media":null,"downs":0,"ups":0}
{"secure_media":null,"downs":0,"ups":1,"title":"Explainlikeimfive: Jacobian factor","id":"18g0vl","distinguished":null,"media":null,"link_flair_text":null,"report_reasons":null,"mod_reports":[],"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m reading &amp;quot;Pattern Recognition and Machine Learning&amp;quot; of C. Bishop and somewhere he says &amp;quot;Under a nonlinear change of variable, a probability density transforms differently from a simple function, due to the Jacobian factor.&amp;quot; I looked at Wikipedia too but that just made me more confused. Can anybody explain this statement to me please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","retrieved_on":1413076820,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"self.MachineLearning","stickied":false,"gilded":0,"num_comments":1,"media_embed":{},"author":"coumineol","over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/18g0vl/explainlikeimfive_jacobian_factor/","banned_by":null,"created_utc":1360764674,"selftext":"I'm reading \"Pattern Recognition and Machine Learning\" of C. Bishop and somewhere he says \"Under a nonlinear change of variable, a probability density transforms differently from a simple function, due to the Jacobian factor.\" I looked at Wikipedia too but that just made me more confused. Can anybody explain this statement to me please?","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18g0vl/explainlikeimfive_jacobian_factor/","subreddit":"MachineLearning","score":1,"secure_media_embed":{},"author_flair_css_class":null}
{"selftext":"Hi,\n\nI'm a CS student majoring in ML and I'm searching for some thesis topic for next year.\n\nOne idea I have is to try to find methods to automatically link certain tweets to certain events (people tweeting about sports event, release of new iphone, ...). Does anyone know of research like this that I could use to start? I couldn't find much interesting research myself.","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18jg9m/thesis_linking_tweets_to_events/","gilded":0,"num_comments":5,"media_embed":{},"author":"Xochipilli","over_18":false,"url":"http://www.reddit.com/r/MachineLearning/comments/18jg9m/thesis_linking_tweets_to_events/","banned_by":null,"created_utc":1360877483,"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":4,"title":"Thesis: Linking tweets to events","id":"18jg9m","distinguished":null,"media":null,"secure_media":null,"ups":4,"downs":0,"retrieved_on":1413071832,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"self.MachineLearning","stickied":false,"link_flair_text":null,"report_reasons":null,"mod_reports":[],"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a CS student majoring in ML and I&amp;#39;m searching for some thesis topic for next year.&lt;/p&gt;\n\n&lt;p&gt;One idea I have is to try to find methods to automatically link certain tweets to certain events (people tweeting about sports event, release of new iphone, ...). Does anyone know of research like this that I could use to start? I couldn&amp;#39;t find much interesting research myself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self"}
{"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18jb1q/analyzing_imdb_reviews/","selftext":"","link_flair_css_class":null,"url":"http://blog.thegrandlocus.com/2012/07/The-geometry-of-style","banned_by":null,"created_utc":1360873902,"num_comments":4,"gilded":0,"media_embed":{},"over_18":false,"author":"winkywooster","author_flair_css_class":null,"subreddit":"MachineLearning","score":24,"secure_media_embed":{},"title":"Analyzing IMDB reviews","id":"18jb1q","distinguished":null,"media":null,"secure_media":null,"ups":24,"downs":0,"user_reports":[],"domain":"blog.thegrandlocus.com","stickied":false,"retrieved_on":1413072055,"edited":false,"author_flair_text":null,"mod_reports":[],"is_self":false,"selftext_html":null,"thumbnail":"http://e.thumbs.redditmedia.com/q573UNAzbO5Urgw4.jpg","link_flair_text":null,"report_reasons":null}
{"score":9,"secure_media_embed":{},"subreddit":"MachineLearning","author_flair_css_class":null,"media_embed":{},"num_comments":1,"gilded":0,"over_18":false,"author":"pulkit110","banned_by":null,"created_utc":1360857118,"url":"http://www.sapandiwakar.in/academics/analysis-of-fast-modularity-clustering-on-twitter/","link_flair_css_class":null,"selftext":"","permalink":"/r/MachineLearning/comments/18iowc/fast_modularity_clustering_for_twitter_users/","subreddit_id":"t5_2r3gv","report_reasons":null,"link_flair_text":null,"mod_reports":[],"is_self":false,"selftext_html":null,"thumbnail":"http://a.thumbs.redditmedia.com/EN9LOozX2VlY7xNZ.jpg","author_flair_text":null,"retrieved_on":1413072944,"edited":false,"stickied":false,"user_reports":[],"domain":"sapandiwakar.in","downs":0,"ups":9,"secure_media":null,"id":"18iowc","distinguished":null,"media":null,"title":"Fast Modularity Clustering for Twitter users"}
{"downs":0,"ups":1,"secure_media":null,"id":"18hi1z","distinguished":null,"media":null,"title":"Backpropagation neural network: choosing the number of input neurons and output neurons","mod_reports":[],"thumbnail":"default","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m building a 3-layer backprop neural network to help me transform a feature vector input of roughly 50 elements into a score from 0 - 100. EDIT - should mention I plan on having at least 1000 training vectors (depending on how many I can find lol).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found some good rules of thumb about choosing the number of neurons in the hidden layer: &lt;a href=\"http://www.heatonresearch.com/node/707\"&gt;http://www.heatonresearch.com/node/707&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But how should I go about choosing the number of input neurons, and the number of output neurons? It seems like such an obvious question but I haven&amp;#39;t seen it addressed in my research thus far. &lt;/p&gt;\n\n&lt;p&gt;Thanks for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","report_reasons":null,"link_flair_text":null,"stickied":false,"user_reports":[],"domain":"self.MachineLearning","author_flair_text":null,"retrieved_on":1413074605,"edited":false,"banned_by":null,"created_utc":1360807150,"url":"http://www.reddit.com/r/MachineLearning/comments/18hi1z/backpropagation_neural_network_choosing_the/","gilded":0,"num_comments":3,"media_embed":{},"over_18":false,"author":"[deleted]","permalink":"/r/MachineLearning/comments/18hi1z/backpropagation_neural_network_choosing_the/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"So I'm building a 3-layer backprop neural network to help me transform a feature vector input of roughly 50 elements into a score from 0 - 100. EDIT - should mention I plan on having at least 1000 training vectors (depending on how many I can find lol).\n\nI've found some good rules of thumb about choosing the number of neurons in the hidden layer: http://www.heatonresearch.com/node/707\n\nBut how should I go about choosing the number of input neurons, and the number of output neurons? It seems like such an obvious question but I haven't seen it addressed in my research thus far. \n\nThanks for any help.","score":1,"secure_media_embed":{},"subreddit":"MachineLearning","author_flair_css_class":null}
{"created_utc":1360801921,"banned_by":null,"url":"http://www.infocobuild.com/education/audio-video-courses/computer-science/cs156-spring2012-caltech.html","author":"seouldavid","over_18":false,"gilded":0,"num_comments":0,"media_embed":{},"permalink":"/r/MachineLearning/comments/18hbh0/an_introductory_course_on_machine_learning_that/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"","secure_media_embed":{},"score":0,"subreddit":"MachineLearning","author_flair_css_class":null,"downs":0,"ups":0,"secure_media":null,"distinguished":null,"media":null,"id":"18hbh0","title":"An introductory course on machine learning that covers the basic theory, algorithms, and applications (Caltech Lectures). ","thumbnail":"default","is_self":false,"selftext_html":null,"mod_reports":[],"report_reasons":null,"link_flair_text":null,"stickied":false,"domain":"infocobuild.com","user_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413074875}
{"id":"18ldxx","distinguished":null,"media":null,"title":"Suggestions for online courses in machine learning, AI and/or mathematical prequisites for such studies? (also posted to Compsci)","downs":0,"ups":10,"secure_media":null,"author_flair_text":null,"retrieved_on":1413068899,"edited":1361160454,"stickied":false,"user_reports":[],"domain":"self.MachineLearning","link_flair_text":null,"report_reasons":null,"mod_reports":[],"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My workplace (a history research institute) is asking me to submit right away (as in, today) a list of courses that I might like to take. I am a research technician with lots of programming experience but almost no formal studies in CS. I&amp;#39;ve almost finished a Ph. D. in Anthropology and develop computer programs for social science research, especially for modelling qualitative data, for which we&amp;#39;ve used the Semantic Web. I&amp;#39;d like to expand our work to include neural networks and other AI techniques. I was good at math in high school, but have not studied it since then... Any suggestions for interesting online courses would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m looking at both free and paid courses. The main reason my employer is asking me now is so they can set aside funds.&lt;/p&gt;\n\n&lt;p&gt;Edit: Anything that relates these topics to Cognitive Science in some way (does that make sense?) would also be fantastic, since I&amp;#39;m also interested in Cognitive Anthropology.&lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks for the great suggestions, everyone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","link_flair_css_class":null,"selftext":"My workplace (a history research institute) is asking me to submit right away (as in, today) a list of courses that I might like to take. I am a research technician with lots of programming experience but almost no formal studies in CS. I've almost finished a Ph. D. in Anthropology and develop computer programs for social science research, especially for modelling qualitative data, for which we've used the Semantic Web. I'd like to expand our work to include neural networks and other AI techniques. I was good at math in high school, but have not studied it since then... Any suggestions for interesting online courses would be greatly appreciated.\n\nEdit: I'm looking at both free and paid courses. The main reason my employer is asking me now is so they can set aside funds.\n\nEdit: Anything that relates these topics to Cognitive Science in some way (does that make sense?) would also be fantastic, since I'm also interested in Cognitive Anthropology.\n\nEdit: Thanks for the great suggestions, everyone!","permalink":"/r/MachineLearning/comments/18ldxx/suggestions_for_online_courses_in_machine/","subreddit_id":"t5_2r3gv","media_embed":{},"num_comments":19,"gilded":0,"over_18":false,"author":"locoDad","banned_by":null,"created_utc":1360954227,"url":"http://www.reddit.com/r/MachineLearning/comments/18ldxx/suggestions_for_online_courses_in_machine/","author_flair_css_class":null,"secure_media_embed":{},"score":10,"subreddit":"MachineLearning"}
{"stickied":false,"domain":"self.MachineLearning","user_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413066737,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry for the dumb questions. Basically I have the work of a former student and I&amp;#39;m trying to use it to get some quick results in my paper.&lt;/p&gt;\n\n&lt;p&gt;He has the neural net in a pmml file and I&amp;#39;m trying to figure out what software to use / how to use that.&lt;/p&gt;\n\n&lt;p&gt;Basically it models cost vs. different cpu architectural parameters. I&amp;#39;m trying to figure out how to use this pmml and input the parameters and get it to spit out a cost.&lt;/p&gt;\n\n&lt;p&gt;Any ideas? &lt;/p&gt;\n\n&lt;p&gt;As far as software, really need it to be free, and I have Ubuntu 12.04 and Windows 7 at my disposal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"self","mod_reports":[],"link_flair_text":null,"report_reasons":null,"distinguished":null,"media":null,"id":"18mtbg","title":"How to use a pmml and a neural net?","ups":0,"downs":0,"secure_media":null,"author_flair_css_class":null,"score":0,"secure_media_embed":{},"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/18mtbg/how_to_use_a_pmml_and_a_neural_net/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"Sorry for the dumb questions. Basically I have the work of a former student and I'm trying to use it to get some quick results in my paper.\n\nHe has the neural net in a pmml file and I'm trying to figure out what software to use / how to use that.\n\nBasically it models cost vs. different cpu architectural parameters. I'm trying to figure out how to use this pmml and input the parameters and get it to spit out a cost.\n\nAny ideas? \n\nAs far as software, really need it to be free, and I have Ubuntu 12.04 and Windows 7 at my disposal.","created_utc":1361012380,"banned_by":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18mtbg/how_to_use_a_pmml_and_a_neural_net/","author":"nerdmeister","over_18":false,"media_embed":{},"num_comments":1,"gilded":0}
{"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":2,"selftext":"","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18m79f/guess_awesome_network_graph_exploration_system/","num_comments":2,"gilded":0,"media_embed":{},"over_18":false,"author":"Keajer","url":"http://graphexploration.cond.org/index.html","banned_by":null,"created_utc":1360980754,"retrieved_on":1413067665,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"graphexploration.cond.org","stickied":false,"link_flair_text":null,"report_reasons":null,"mod_reports":[],"thumbnail":"default","is_self":false,"selftext_html":null,"title":"GUESS: Awesome Network Graph Exploration System","id":"18m79f","distinguished":null,"media":null,"secure_media":null,"ups":2,"downs":0}
{"subreddit":"MachineLearning","score":5,"secure_media_embed":{},"author_flair_css_class":null,"url":"http://readwrite.com/2013/02/14/microsoft-big-data-pick-oscar-winners","created_utc":1361092709,"banned_by":null,"author":"Barbas","over_18":false,"media_embed":{},"num_comments":4,"gilded":0,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18opa3/microsoft_big_data_pick_oscar_winners_and_they_are/","selftext":"","link_flair_css_class":null,"selftext_html":null,"is_self":false,"thumbnail":"http://d.thumbs.redditmedia.com/cQnMWXmMTBNs6hZ9.jpg","mod_reports":[],"report_reasons":null,"link_flair_text":null,"domain":"readwrite.com","user_reports":[],"stickied":false,"edited":false,"retrieved_on":1413063952,"author_flair_text":null,"secure_media":null,"downs":0,"ups":5,"title":"Microsoft, Big Data Pick Oscar Winners - And They Are...","distinguished":null,"media":null,"id":"18opa3"}
{"author_flair_css_class":null,"score":0,"secure_media_embed":{},"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"I learned some NLP techniques and want to apply them to the real world to enhance my skills. Can any one suggest some interesting topics for me please?","permalink":"/r/MachineLearning/comments/18o237/any_possible_interesting_project_topic_for_nlp/","subreddit_id":"t5_2r3gv","author":"Keajer","over_18":false,"num_comments":12,"media_embed":{},"gilded":0,"created_utc":1361064242,"banned_by":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18o237/any_possible_interesting_project_topic_for_nlp/","author_flair_text":null,"edited":false,"retrieved_on":1413064894,"stickied":false,"domain":"self.MachineLearning","user_reports":[],"link_flair_text":null,"report_reasons":null,"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I learned some NLP techniques and want to apply them to the real world to enhance my skills. Can any one suggest some interesting topics for me please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","mod_reports":[],"media":null,"distinguished":null,"id":"18o237","title":"Any possible interesting project topic for NLP?","downs":0,"ups":0,"secure_media":null}
{"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18rp2g/javascript_mcmc_demo_versus_twotailed_ttest/","selftext":"","link_flair_css_class":null,"url":"http://www.sumsar.net/best_online/","banned_by":null,"created_utc":1361217548,"num_comments":10,"gilded":0,"media_embed":{},"author":"b0b0b0b","over_18":false,"author_flair_css_class":null,"subreddit":"MachineLearning","score":31,"secure_media_embed":{},"title":"Javascript MCMC demo (versus two-tailed t-test)","id":"18rp2g","distinguished":null,"media":null,"secure_media":null,"downs":0,"ups":31,"user_reports":[],"domain":"sumsar.net","stickied":false,"retrieved_on":1413059828,"edited":false,"author_flair_text":null,"mod_reports":[],"selftext_html":null,"is_self":false,"thumbnail":"http://b.thumbs.redditmedia.com/7TyRDqjwzRHtD4js.jpg","report_reasons":null,"link_flair_text":null}
{"author_flair_css_class":null,"score":2,"secure_media_embed":{},"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/18ud4h/what_are_some_algorithms_for_feature_extraction/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"I am currently working on a voice identification project and my current dataset is a 250-dimensional vector of intensities at frequency intervals. This was calculated with FFT. Are there any recommended techniques for extracting important features of such data to improve classification and filter out noise?","created_utc":1361310410,"banned_by":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18ud4h/what_are_some_algorithms_for_feature_extraction/","over_18":false,"author":"ilikecomputahs","media_embed":{},"num_comments":6,"gilded":0,"stickied":false,"domain":"self.MachineLearning","user_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413056185,"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working on a voice identification project and my current dataset is a 250-dimensional vector of intensities at frequency intervals. This was calculated with FFT. Are there any recommended techniques for extracting important features of such data to improve classification and filter out noise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"report_reasons":null,"link_flair_text":null,"distinguished":null,"media":null,"id":"18ud4h","title":"What are some algorithms for feature extraction, particularly when dealing with frequency data of human voices?","downs":0,"ups":2,"secure_media":null}
{"link_flair_css_class":null,"selftext":"Hello, \n\nI'm having some problems with my backpropagation implementation. Background: I have feature vectors (inputs) of 40 elements each. I have only 1 output value which is to be a score from 0 to 100 (per feature vector). So I have 40 input nodes, 20 hidden nodes, and 1 output node. \n\nMy feature vectors have values from 0 to +1300, so when I take my weight matrix (initialized uniformly with the value 0.5) and multiply it by a layer's output, then take the sigmoid (activation function), I get numbers that saturate to 1. So my network doesn't learn. I've since tried dividing all feature numbers by 1000 to get over this, but I'm unsure if this is correct. \n\nIn terms of actually using the network: do I just save my trained-up weight matrices, and then do the feed-forward part of the algorithm with new data I wish to score? One last question - a recommended learning rate? From gradient descent I've seen people use 0.01 and the like, but some online examples of backprop I saw them use 0.9 and I don't know why. \n\nI can post my MATLAB code if it will help. Thanks.  ","permalink":"/r/MachineLearning/comments/18u65n/backpropagation_implementation_questions/","subreddit_id":"t5_2r3gv","author":"[deleted]","over_18":false,"media_embed":{},"num_comments":4,"gilded":0,"created_utc":1361305219,"banned_by":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18u65n/backpropagation_implementation_questions/","author_flair_css_class":null,"score":4,"secure_media_embed":{},"subreddit":"MachineLearning","distinguished":null,"media":null,"id":"18u65n","title":"Backpropagation implementation questions - normalizing data and using the net after training","downs":0,"ups":4,"secure_media":null,"author_flair_text":null,"edited":false,"retrieved_on":1413056447,"stickied":false,"domain":"self.MachineLearning","user_reports":[],"report_reasons":null,"link_flair_text":null,"is_self":true,"thumbnail":"default","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having some problems with my backpropagation implementation. Background: I have feature vectors (inputs) of 40 elements each. I have only 1 output value which is to be a score from 0 to 100 (per feature vector). So I have 40 input nodes, 20 hidden nodes, and 1 output node. &lt;/p&gt;\n\n&lt;p&gt;My feature vectors have values from 0 to +1300, so when I take my weight matrix (initialized uniformly with the value 0.5) and multiply it by a layer&amp;#39;s output, then take the sigmoid (activation function), I get numbers that saturate to 1. So my network doesn&amp;#39;t learn. I&amp;#39;ve since tried dividing all feature numbers by 1000 to get over this, but I&amp;#39;m unsure if this is correct. &lt;/p&gt;\n\n&lt;p&gt;In terms of actually using the network: do I just save my trained-up weight matrices, and then do the feed-forward part of the algorithm with new data I wish to score? One last question - a recommended learning rate? From gradient descent I&amp;#39;ve seen people use 0.01 and the like, but some online examples of backprop I saw them use 0.9 and I don&amp;#39;t know why. &lt;/p&gt;\n\n&lt;p&gt;I can post my MATLAB code if it will help. Thanks.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[]}
{"author_flair_css_class":null,"subreddit":"MachineLearning","score":10,"secure_media_embed":{},"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18txm7/predicting_closed_questions_on_stack_overflow/","selftext":"","link_flair_css_class":null,"url":"http://fastml.com/predicting-closed-questions-on-stack-overflow/","banned_by":null,"created_utc":1361298712,"gilded":0,"num_comments":1,"media_embed":{},"author":"winkywooster","over_18":false,"user_reports":[],"domain":"fastml.com","stickied":false,"retrieved_on":1413056767,"edited":false,"author_flair_text":null,"mod_reports":[],"is_self":false,"thumbnail":"default","selftext_html":null,"link_flair_text":null,"report_reasons":null,"title":"Predicting closed questions on Stack Overflow","id":"18txm7","distinguished":null,"media":null,"secure_media":null,"ups":10,"downs":0}
{"user_reports":[],"domain":"cds.nyu.edu","stickied":false,"retrieved_on":1413057038,"edited":false,"author_flair_text":null,"mod_reports":[],"is_self":false,"selftext_html":null,"thumbnail":"http://e.thumbs.redditmedia.com/QcF_JlfLES3fa2nX.jpg","report_reasons":null,"link_flair_text":null,"title":"NYU announces new Data Science department headed by Yann LeCun","id":"18tqa4","distinguished":null,"media":null,"secure_media":null,"ups":28,"downs":0,"author_flair_css_class":null,"subreddit":"MachineLearning","score":28,"secure_media_embed":{},"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18tqa4/nyu_announces_new_data_science_department_headed/","selftext":"","link_flair_css_class":null,"url":"http://cds.nyu.edu","banned_by":null,"created_utc":1361292795,"num_comments":22,"media_embed":{},"gilded":0,"over_18":false,"author":"rrenaud"}
{"mod_reports":[],"is_self":false,"selftext_html":null,"thumbnail":"default","link_flair_text":null,"report_reasons":null,"user_reports":[],"domain":"nytimes.com","stickied":false,"retrieved_on":1413057440,"edited":false,"author_flair_text":null,"secure_media":null,"downs":0,"ups":4,"title":"David Brooks, on \"What Data Can't Do\"","id":"18tfmb","distinguished":null,"media":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":4,"author_flair_css_class":null,"url":"http://www.nytimes.com/2013/02/19/opinion/brooks-what-data-cant-do.html","banned_by":null,"created_utc":1361282212,"media_embed":{},"num_comments":6,"gilded":0,"over_18":false,"author":"agconway","subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18tfmb/david_brooks_on_what_data_cant_do/","selftext":"","link_flair_css_class":null}
{"author":"jwgibbo","over_18":false,"gilded":0,"num_comments":9,"media_embed":{},"created_utc":1361390695,"banned_by":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18wlfx/recommendations_on_which_algorithms_in_weka/","link_flair_css_class":null,"selftext":"Hello /r/machinelearning,\n\nIf anyone has already been the through the gauntlet of working with data sets with underrepresented classes I'd be grateful for any recommendation on which algorithms and parameters you prefer.  \n\nI have a data set with about 10,000 samples and only 14 of a certain class.  So far, decision table, and SMO have been doing poorly at classifying the underrepresented class during the training phase.  I'll keep running it through the different classifiers.\n\nThanks in advance!","permalink":"/r/MachineLearning/comments/18wlfx/recommendations_on_which_algorithms_in_weka/","subreddit_id":"t5_2r3gv","secure_media_embed":{},"score":7,"subreddit":"MachineLearning","author_flair_css_class":null,"downs":0,"ups":7,"secure_media":null,"distinguished":null,"media":null,"id":"18wlfx","title":"Recommendations on which algorithms in WEKA perform well at classifier/clustering underrepresented classes in large data sets.","report_reasons":null,"link_flair_text":null,"thumbnail":"self","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/machinelearning\"&gt;/r/machinelearning&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;If anyone has already been the through the gauntlet of working with data sets with underrepresented classes I&amp;#39;d be grateful for any recommendation on which algorithms and parameters you prefer.  &lt;/p&gt;\n\n&lt;p&gt;I have a data set with about 10,000 samples and only 14 of a certain class.  So far, decision table, and SMO have been doing poorly at classifying the underrepresented class during the training phase.  I&amp;#39;ll keep running it through the different classifiers.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413053088,"stickied":false,"domain":"self.MachineLearning","user_reports":[]}
{"permalink":"/r/MachineLearning/comments/18vmyv/choosing_a_cloud_service_offering/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"","created_utc":1361352420,"banned_by":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18vmyv/choosing_a_cloud_service_offering/","over_18":false,"author":"AnkushPuri","num_comments":0,"gilded":0,"media_embed":{},"author_flair_css_class":null,"secure_media_embed":{},"score":1,"subreddit":"MachineLearning","distinguished":null,"media":null,"id":"18vmyv","title":"Choosing a Cloud Service Offering.","downs":0,"ups":1,"secure_media":null,"stickied":false,"domain":"self.MachineLearning","user_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413054400,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","is_self":true,"thumbnail":"default","mod_reports":[],"report_reasons":null,"link_flair_text":null}
{"secure_media":null,"downs":0,"ups":1,"title":"Random-walk domination in large graphs: problem definitions and fast solutions","distinguished":null,"media":null,"id":"18vbyz","is_self":false,"thumbnail":"default","selftext_html":null,"mod_reports":[],"report_reasons":null,"link_flair_text":null,"domain":"arxiv.org","user_reports":[],"stickied":false,"edited":false,"retrieved_on":1413054820,"author_flair_text":null,"url":"http://arxiv.org/abs/1302.4546","created_utc":1361337510,"banned_by":null,"over_18":false,"author":"StatML","gilded":0,"num_comments":0,"media_embed":{},"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18vbyz/randomwalk_domination_in_large_graphs_problem/","selftext":"","link_flair_css_class":null,"subreddit":"MachineLearning","score":1,"secure_media_embed":{},"author_flair_css_class":null}
{"report_reasons":null,"link_flair_text":null,"mod_reports":[],"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi r/machinelearning,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m experimenting with performing a sentiment analysis (positive/negative classification) on review text for a commercial application.&lt;/p&gt;\n\n&lt;p&gt;As a training set I have ~200k labeled reviews from a popular domain specific website. I intend to experiment with training a classifier at the sentence and at the paragraph (or complete review) level.&lt;/p&gt;\n\n&lt;p&gt;The data to be classified is ~300k labeled reviews from the same domain. Due to legal reasons I am not able to train my classifier(s) with this data.&lt;/p&gt;\n\n&lt;p&gt;The approaches I am considering for constructing the feature vectors include: uni/bigrams, parts of speech filtered uni/bigrams, and parts of speech tagged uni/bigrams.&lt;/p&gt;\n\n&lt;p&gt;Anyways, to my questions:&lt;/p&gt;\n\n&lt;p&gt;Is it even feasible to train a model with a feature vector so large? Imagine each review is only 100 words, then the feature space of my training set is as high as 20 million dimensions.&lt;/p&gt;\n\n&lt;p&gt;If my feature vectors are all essentially bags of words, how can I use a model trained on the words in my training set to classify the words in my test set? That is to say, will there not be an issue with finding overlap between the vocabulary in the review to be classified and the group of reviews used to train the model?&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","retrieved_on":1413049296,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"self.MachineLearning","stickied":false,"secure_media":null,"downs":0,"ups":15,"title":"Sentiment Analysis in the real world","id":"18zcme","distinguished":null,"media":null,"subreddit":"MachineLearning","score":15,"secure_media_embed":{},"author_flair_css_class":null,"num_comments":11,"media_embed":{},"gilded":0,"over_18":false,"author":"duckstreet","url":"http://www.reddit.com/r/MachineLearning/comments/18zcme/sentiment_analysis_in_the_real_world/","banned_by":null,"created_utc":1361485146,"selftext":"Hi r/machinelearning,\n\nI'm experimenting with performing a sentiment analysis (positive/negative classification) on review text for a commercial application.\n\nAs a training set I have ~200k labeled reviews from a popular domain specific website. I intend to experiment with training a classifier at the sentence and at the paragraph (or complete review) level.\n\nThe data to be classified is ~300k labeled reviews from the same domain. Due to legal reasons I am not able to train my classifier(s) with this data.\n\nThe approaches I am considering for constructing the feature vectors include: uni/bigrams, parts of speech filtered uni/bigrams, and parts of speech tagged uni/bigrams.\n\n\nAnyways, to my questions:\n\nIs it even feasible to train a model with a feature vector so large? Imagine each review is only 100 words, then the feature space of my training set is as high as 20 million dimensions.\n\nIf my feature vectors are all essentially bags of words, how can I use a model trained on the words in my training set to classify the words in my test set? That is to say, will there not be an issue with finding overlap between the vocabulary in the review to be classified and the group of reviews used to train the model?\n\nThanks :)","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18zcme/sentiment_analysis_in_the_real_world/"}
{"title":"Machine Learning: 5 examples of what it is and why you should care","id":"18xz2e","media":null,"distinguished":null,"secure_media":null,"downs":0,"ups":17,"retrieved_on":1413051177,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"refactorthis.net","stickied":false,"link_flair_text":null,"report_reasons":null,"mod_reports":[],"thumbnail":"http://d.thumbs.redditmedia.com/wlWAvZZUVcgSKH3E.jpg","is_self":false,"selftext_html":null,"selftext":"","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18xz2e/machine_learning_5_examples_of_what_it_is_and_why/","media_embed":{},"num_comments":7,"gilded":0,"over_18":false,"author":"buddybjames","url":"http://www.refactorthis.net/post/2013/02/19/Machine-Learning-5-examples-of-what-it-is-and-why-you-should-care.aspx","banned_by":null,"created_utc":1361432076,"author_flair_css_class":null,"subreddit":"MachineLearning","score":17,"secure_media_embed":{}}
{"report_reasons":null,"link_flair_text":null,"is_self":false,"thumbnail":"http://f.thumbs.redditmedia.com/IdKC4Ll_P-zy_cSY.jpg","selftext_html":null,"mod_reports":[],"edited":false,"retrieved_on":1413045917,"author_flair_text":null,"domain":"datalab.lu","user_reports":[],"stickied":false,"secure_media":null,"ups":23,"downs":0,"title":"From 1th to 15th at Kaggle challenge \"Event recommendation engine\"","distinguished":null,"media":null,"id":"191ns5","subreddit":"MachineLearning","score":23,"secure_media_embed":{},"author_flair_css_class":null,"over_18":false,"author":"kafka399","media_embed":{},"num_comments":7,"gilded":0,"url":"http://datalab.lu/blog/2013/02/21/kaggle-event-recommentation-engine/","created_utc":1361570246,"banned_by":null,"selftext":"","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/191ns5/from_1th_to_15th_at_kaggle_challenge_event/"}
{"stickied":false,"user_reports":[],"domain":"self.MachineLearning","author_flair_text":null,"retrieved_on":1413046158,"edited":false,"mod_reports":[],"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;For the last few weeks I&amp;#39;ve been working on a backprop network and posting a few questions to this forum; I thank you for all the help so far. I&amp;#39;ve gone from concept, to buggy implementation, to something that works. &lt;/p&gt;\n\n&lt;p&gt;As a quick recap of my network - my network takes input/feature vectors of length 43, has 25 nodes in the hidden layer (arbitrary parameter choice I can change), and has a single output node. I want to train my network to take the 43 features and output a single value between 0 and 100. &lt;/p&gt;\n\n&lt;p&gt;Unfortunately, I currently only have a very small pool or training data - 162 sets of feature vectors with corresponding scores out of 100 (I have to manually label this lol! Working on creating more data though obviously). So I take this limited training set, and here&amp;#39;s a snapshot of how well my network adapts to it:&lt;/p&gt;\n\n&lt;p&gt;Output value:0.90406 | Test value:0.9 (pretend to multiply all values by 100)&lt;/p&gt;\n\n&lt;p&gt;Output value:0.21558 | Test value:0.2 &lt;/p&gt;\n\n&lt;p&gt;Output value:0.60394 | Test value:0.6&lt;/p&gt;\n\n&lt;p&gt;Output value:0.79604 | Test value:0.8&lt;/p&gt;\n\n&lt;p&gt;Output value:0.99846 | Test value:0.85&lt;/p&gt;\n\n&lt;p&gt;Output value:0.23444 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.19609 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.88889 | Test value:0.9&lt;/p&gt;\n\n&lt;p&gt;Output value:0.19178 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.20549 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.63248 | Test value:0.64&lt;/p&gt;\n\n&lt;p&gt;Output value:0.74367 | Test value:0.74&lt;/p&gt;\n\n&lt;p&gt;Output value:0.15477 | Test value:0.17&lt;/p&gt;\n\n&lt;p&gt;Output value:0.17084 | Test value:0.18&lt;/p&gt;\n\n&lt;p&gt;Output value:0.21143 | Test value:0.19&lt;/p&gt;\n\n&lt;p&gt;Output value:0.16179 | Test value:0.17&lt;/p&gt;\n\n&lt;p&gt;Output value:0.081413 | Test value:0.18&lt;/p&gt;\n\n&lt;p&gt;Output value:0.18287 | Test value:0.19&lt;/p&gt;\n\n&lt;p&gt;Output value:0.19118 | Test value:0.17&lt;/p&gt;\n\n&lt;p&gt;Output value:0.20018 | Test value:0.18&lt;/p&gt;\n\n&lt;p&gt;Output value:0.19222 | Test value:0.19&lt;/p&gt;\n\n&lt;p&gt;Output value:0.20719 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.18718 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.18064 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.20925 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.20731 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.19914 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.6033 | Test value:0.6&lt;/p&gt;\n\n&lt;p&gt;Output value:0.63723 | Test value:0.64&lt;/p&gt;\n\n&lt;p&gt;Output value:0.77831 | Test value:0.78&lt;/p&gt;\n\n&lt;p&gt;Output value:0.23468 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.87713 | Test value:0.9&lt;/p&gt;\n\n&lt;p&gt;Output value:0.23822 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.18954 | Test value:0.15&lt;/p&gt;\n\n&lt;p&gt;Output value:0.19912 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;At first I&amp;#39;m like, &amp;quot;wow this is sick!&amp;quot; The results are much, much better than when I originally tried gradient descent on its own. Like, this is too good to be true. Hmm, maybe it is. So I decide to try something - use the same test/target values, but create 162 completely &lt;em&gt;random&lt;/em&gt; feature vectors. &lt;/p&gt;\n\n&lt;p&gt;Uh oh - my network was able to fit the random training data &lt;em&gt;even better&lt;/em&gt; than my actual training data! In fact, it fit the random data perfectly. Shit:&lt;/p&gt;\n\n&lt;p&gt;Output value:0.92 | Test value:0.92&lt;/p&gt;\n\n&lt;p&gt;Output value:0.2 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.2 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.2 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.2 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.2 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.2 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.2 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.2 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.2 | Test value:0.2&lt;/p&gt;\n\n&lt;p&gt;Output value:0.62 | Test value:0.62&lt;/p&gt;\n\n&lt;p&gt;Output value:0.7 | Test value:0.7&lt;/p&gt;\n\n&lt;p&gt;Output value:0.77 | Test value:0.77&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m thinking one of two possibilities:&lt;/p&gt;\n\n&lt;p&gt;1) Because I have so few training samples (only 162), my 3-layer network of 43-&amp;gt;25-&amp;gt;1 is able to over-fit the data with all its weights. &lt;/p&gt;\n\n&lt;p&gt;2) My original feature vectors are absolutely worthless, and just as good as inputting plain garbage. These feature vectors I hand-coded based on what I researched would be appropriate to my problem domain. &lt;/p&gt;\n\n&lt;p&gt;What do you guys think is going on, and will I only know once I have more training data? Given the topology of my network, any idea how much data I&amp;#39;ll actually need? &lt;/p&gt;\n\n&lt;p&gt;Cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","report_reasons":null,"link_flair_text":null,"id":"191hbc","distinguished":null,"media":null,"title":"Backpropagation - how much training data do I need?","downs":0,"ups":12,"secure_media":null,"author_flair_css_class":null,"score":12,"secure_media_embed":{},"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/191hbc/backpropagation_how_much_training_data_do_i_need/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"Hello, \n\nFor the last few weeks I've been working on a backprop network and posting a few questions to this forum; I thank you for all the help so far. I've gone from concept, to buggy implementation, to something that works. \n\nAs a quick recap of my network - my network takes input/feature vectors of length 43, has 25 nodes in the hidden layer (arbitrary parameter choice I can change), and has a single output node. I want to train my network to take the 43 features and output a single value between 0 and 100. \n\nUnfortunately, I currently only have a very small pool or training data - 162 sets of feature vectors with corresponding scores out of 100 (I have to manually label this lol! Working on creating more data though obviously). So I take this limited training set, and here's a snapshot of how well my network adapts to it:\n\nOutput value:0.90406 | Test value:0.9 (pretend to multiply all values by 100)\n\nOutput value:0.21558 | Test value:0.2 \n\nOutput value:0.60394 | Test value:0.6\n\nOutput value:0.79604 | Test value:0.8\n\nOutput value:0.99846 | Test value:0.85\n\nOutput value:0.23444 | Test value:0.2\n\nOutput value:0.19609 | Test value:0.2\n\nOutput value:0.88889 | Test value:0.9\n\nOutput value:0.19178 | Test value:0.2\n\nOutput value:0.20549 | Test value:0.2\n\nOutput value:0.63248 | Test value:0.64\n\nOutput value:0.74367 | Test value:0.74\n\nOutput value:0.15477 | Test value:0.17\n\nOutput value:0.17084 | Test value:0.18\n\nOutput value:0.21143 | Test value:0.19\n\nOutput value:0.16179 | Test value:0.17\n\nOutput value:0.081413 | Test value:0.18\n\nOutput value:0.18287 | Test value:0.19\n\nOutput value:0.19118 | Test value:0.17\n\nOutput value:0.20018 | Test value:0.18\n\nOutput value:0.19222 | Test value:0.19\n\nOutput value:0.20719 | Test value:0.2\n\nOutput value:0.18718 | Test value:0.2\n\nOutput value:0.18064 | Test value:0.2\n\nOutput value:0.20925 | Test value:0.2\n\nOutput value:0.20731 | Test value:0.2\n\nOutput value:0.19914 | Test value:0.2\n\nOutput value:0.6033 | Test value:0.6\n\nOutput value:0.63723 | Test value:0.64\n\nOutput value:0.77831 | Test value:0.78\n\nOutput value:0.23468 | Test value:0.2\n\nOutput value:0.87713 | Test value:0.9\n\nOutput value:0.23822 | Test value:0.2\n\nOutput value:0.18954 | Test value:0.15\n\nOutput value:0.19912 | Test value:0.2\n\nAt first I'm like, \"wow this is sick!\" The results are much, much better than when I originally tried gradient descent on its own. Like, this is too good to be true. Hmm, maybe it is. So I decide to try something - use the same test/target values, but create 162 completely *random* feature vectors. \n\nUh oh - my network was able to fit the random training data *even better* than my actual training data! In fact, it fit the random data perfectly. Shit:\n\nOutput value:0.92 | Test value:0.92\n\nOutput value:0.2 | Test value:0.2\n\nOutput value:0.2 | Test value:0.2\n\nOutput value:0.2 | Test value:0.2\n\nOutput value:0.2 | Test value:0.2\n\nOutput value:0.2 | Test value:0.2\n\nOutput value:0.2 | Test value:0.2\n\nOutput value:0.2 | Test value:0.2\n\nOutput value:0.2 | Test value:0.2\n\nOutput value:0.2 | Test value:0.2\n\nOutput value:0.62 | Test value:0.62\n\nOutput value:0.7 | Test value:0.7\n\nOutput value:0.77 | Test value:0.77\n\nNow I'm thinking one of two possibilities:\n\n1) Because I have so few training samples (only 162), my 3-layer network of 43-&gt;25-&gt;1 is able to over-fit the data with all its weights. \n\n2) My original feature vectors are absolutely worthless, and just as good as inputting plain garbage. These feature vectors I hand-coded based on what I researched would be appropriate to my problem domain. \n\nWhat do you guys think is going on, and will I only know once I have more training data? Given the topology of my network, any idea how much data I'll actually need? \n\nCheers.\n","banned_by":null,"created_utc":1361565092,"url":"http://www.reddit.com/r/MachineLearning/comments/191hbc/backpropagation_how_much_training_data_do_i_need/","gilded":0,"num_comments":10,"media_embed":{},"over_18":false,"author":"bvcxxcvb"}
{"author_flair_css_class":null,"subreddit":"MachineLearning","score":2,"secure_media_embed":{},"selftext":"I am a computer science student who would like to learn about predictive modeling from scratch(logistic regression models, linear regression models).\n\nI do not have much knowledge except basic statistics. Could someone please recommend me some good books/online resources?\n","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/190qig/learning_resources_for_predictive_modeling/","num_comments":4,"gilded":0,"media_embed":{},"over_18":false,"author":"sathish1","url":"http://www.reddit.com/r/MachineLearning/comments/190qig/learning_resources_for_predictive_modeling/","banned_by":null,"created_utc":1361541274,"retrieved_on":1413047233,"edited":false,"author_flair_text":null,"user_reports":[],"domain":"self.MachineLearning","stickied":false,"link_flair_text":null,"report_reasons":null,"mod_reports":[],"thumbnail":"self","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a computer science student who would like to learn about predictive modeling from scratch(logistic regression models, linear regression models).&lt;/p&gt;\n\n&lt;p&gt;I do not have much knowledge except basic statistics. Could someone please recommend me some good books/online resources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","title":"Learning resources for predictive modeling.","id":"190qig","distinguished":null,"media":null,"secure_media":null,"ups":2,"downs":0}
{"mod_reports":[],"is_self":false,"thumbnail":"http://d.thumbs.redditmedia.com/Y6C0R1I15o4-30mi.jpg","selftext_html":null,"link_flair_text":null,"report_reasons":null,"user_reports":[],"domain":"andybromberg.com","stickied":false,"retrieved_on":1413047629,"edited":false,"author_flair_text":null,"secure_media":null,"downs":0,"ups":1,"title":"Sentiment Analysis in Python","id":"190h60","distinguished":null,"media":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":1,"author_flair_css_class":null,"url":"http://andybromberg.com/sentiment-analysis-python/","banned_by":null,"created_utc":1361523721,"num_comments":0,"media_embed":{},"gilded":0,"author":"srkiboy83","over_18":false,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/190h60/sentiment_analysis_in_python/","selftext":"","link_flair_css_class":null}
{"domain":"self.MachineLearning","user_reports":[],"stickied":false,"edited":false,"retrieved_on":1413048670,"author_flair_text":null,"is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to find a better way of presenting results and metrics in a multi-class classification problem.&lt;/p&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"http://bit.ly/ZlnqOO\"&gt;link&lt;/a&gt; to the question&lt;/p&gt;\n\n&lt;p&gt;As I read somewhere, isn&amp;#39;t just presenting accuracy more easier/clearer way of doing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"default","mod_reports":[],"link_flair_text":null,"report_reasons":null,"title":"Results and Metrics in a multi-class classification problem","distinguished":null,"media":null,"id":"18zrxj","secure_media":null,"downs":0,"ups":1,"author_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":1,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/18zrxj/results_and_metrics_in_a_multiclass/","selftext":"I'm trying to find a better way of presenting results and metrics in a multi-class classification problem.\n\nHere is the [link](http://bit.ly/ZlnqOO) to the question\n\nAs I read somewhere, isn't just presenting accuracy more easier/clearer way of doing this?","link_flair_css_class":null,"url":"http://www.reddit.com/r/MachineLearning/comments/18zrxj/results_and_metrics_in_a_multiclass/","created_utc":1361497356,"banned_by":null,"author":"[deleted]","over_18":false,"gilded":0,"num_comments":0,"media_embed":{}}
{"score":35,"secure_media_embed":{},"subreddit":"MachineLearning","author_flair_css_class":null,"over_18":false,"author":"rrenaud","media_embed":{},"num_comments":1,"gilded":0,"created_utc":1361656825,"banned_by":null,"url":"http://arxiv.org/pdf/1302.4389v3","link_flair_css_class":null,"selftext":"","permalink":"/r/MachineLearning/comments/193lhb/maxout_new_deep_architecture_using_dropout_and/","subreddit_id":"t5_2r3gv","report_reasons":null,"link_flair_text":null,"selftext_html":null,"is_self":false,"thumbnail":"default","mod_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413042915,"stickied":false,"domain":"arxiv.org","user_reports":[],"downs":0,"ups":35,"secure_media":null,"distinguished":null,"media":null,"id":"193lhb","title":"MaxOut - new deep architecture using dropout and max units sets new records on a few data sets"}
{"domain":"refactorthis.net","user_reports":[],"stickied":false,"edited":false,"retrieved_on":1413041532,"author_flair_text":null,"thumbnail":"http://f.thumbs.redditmedia.com/Rpek3V5yudzyEu4q.jpg","is_self":false,"selftext_html":null,"mod_reports":[],"link_flair_text":null,"report_reasons":null,"title":"Machine learning resources for .NET developers","distinguished":null,"media":null,"id":"194mq1","secure_media":null,"downs":0,"ups":10,"author_flair_css_class":null,"subreddit":"MachineLearning","score":10,"secure_media_embed":{},"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/194mq1/machine_learning_resources_for_net_developers/","selftext":"","link_flair_css_class":null,"url":"http://www.refactorthis.net/post/2013/02/23/Machine-learning-resources-for-NET-developers.aspx","created_utc":1361702610,"banned_by":null,"author":"buddybjames","over_18":false,"media_embed":{},"num_comments":4,"gilded":0}
{"url":"http://www.reddit.com/r/MachineLearning/comments/197oq5/best_way_to_reduce_data_in_weka_so_algorithms_run/","created_utc":1361825963,"banned_by":null,"over_18":false,"author":"DarkSareon","gilded":0,"num_comments":10,"media_embed":{},"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/197oq5/best_way_to_reduce_data_in_weka_so_algorithms_run/","selftext":"I am trying a bunch of data against a bunch of different algorithms in Weka but some of these are so slow.  I have a large amount of data, 10000 items, represented by 5 classes and each item is represented in a BOW/TF-IDF.\n\nSome algorithms run slowly like NB (30 seconds to build a model).  Some run quickly (MNB, CNB) and some take 5+ min to build a model so I end up stopping it from running (JRip, J48, SMO).\n\nWhat are some good strategies to use to reduce the data so the classifiers can at least run in an acceptable amount of time?\n\nI am running 10-fold cross-validation in Weka... would be trying 5x2 cv in experimenter speed it up?\n\nThanks","link_flair_css_class":null,"subreddit":"MachineLearning","secure_media_embed":{},"score":4,"author_flair_css_class":null,"secure_media":null,"downs":0,"ups":4,"title":"Best way to reduce data in Weka so algorithms run in decent time","distinguished":null,"media":null,"id":"197oq5","is_self":true,"selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying a bunch of data against a bunch of different algorithms in Weka but some of these are so slow.  I have a large amount of data, 10000 items, represented by 5 classes and each item is represented in a BOW/TF-IDF.&lt;/p&gt;\n\n&lt;p&gt;Some algorithms run slowly like NB (30 seconds to build a model).  Some run quickly (MNB, CNB) and some take 5+ min to build a model so I end up stopping it from running (JRip, J48, SMO).&lt;/p&gt;\n\n&lt;p&gt;What are some good strategies to use to reduce the data so the classifiers can at least run in an acceptable amount of time?&lt;/p&gt;\n\n&lt;p&gt;I am running 10-fold cross-validation in Weka... would be trying 5x2 cv in experimenter speed it up?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","thumbnail":"self","mod_reports":[],"link_flair_text":null,"report_reasons":null,"domain":"self.MachineLearning","user_reports":[],"stickied":false,"edited":1361826365,"retrieved_on":1413037209,"author_flair_text":null}
{"subreddit":"MachineLearning","score":8,"secure_media_embed":{},"author_flair_css_class":null,"author":"machineVis","over_18":false,"num_comments":9,"gilded":0,"media_embed":{},"url":"http://www.reddit.com/r/MachineLearning/comments/197czf/detecting_a_specific_object_not_class_of_objects/","created_utc":1361816581,"banned_by":null,"selftext":"Hi all, I'm familiar with some of the state of the art methods for detecting classes of objects in an image (ie, Cars, humans, CIFAR-classes, etc...).\n\nHowever, if I am going to try to recognize a specific object in an image instead of a class of objects, it seems like a much simpler problem. Suppose I have an object in my room and I want my system to recognize this object when it is in an image (preferably with some invariance to rotation/lighting conditions), are there any algorithms that can take relatively few input examples of my object and then learn to recognize it in images? Unless I'm remembering wrong, I thought I had seen algorithms that could do this before...\n\nAny help pointing me in the right direction would be appreciated. Thanks!","link_flair_css_class":null,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/197czf/detecting_a_specific_object_not_class_of_objects/","report_reasons":null,"link_flair_text":null,"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m familiar with some of the state of the art methods for detecting classes of objects in an image (ie, Cars, humans, CIFAR-classes, etc...).&lt;/p&gt;\n\n&lt;p&gt;However, if I am going to try to recognize a specific object in an image instead of a class of objects, it seems like a much simpler problem. Suppose I have an object in my room and I want my system to recognize this object when it is in an image (preferably with some invariance to rotation/lighting conditions), are there any algorithms that can take relatively few input examples of my object and then learn to recognize it in images? Unless I&amp;#39;m remembering wrong, I thought I had seen algorithms that could do this before...&lt;/p&gt;\n\n&lt;p&gt;Any help pointing me in the right direction would be appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"edited":false,"retrieved_on":1413037695,"author_flair_text":null,"domain":"self.MachineLearning","user_reports":[],"stickied":false,"secure_media":null,"ups":8,"downs":0,"title":"Detecting A Specific Object (not class of objects)","distinguished":null,"media":null,"id":"197czf"}
{"author_flair_text":null,"retrieved_on":1413038789,"edited":false,"stickied":false,"user_reports":[],"domain":"refactorthis.net","report_reasons":null,"link_flair_text":null,"mod_reports":[],"thumbnail":"http://e.thumbs.redditmedia.com/xMAUKiKg0j5voTbR.jpg","is_self":false,"selftext_html":null,"id":"196m1k","distinguished":null,"media":null,"title":"Machine learning: bitly can do a lot more for you than shrink URLs.  Check out these awesome APIs for machine learning!","ups":1,"downs":0,"secure_media":null,"author_flair_css_class":null,"score":1,"secure_media_embed":{},"subreddit":"MachineLearning","link_flair_css_class":null,"selftext":"","permalink":"/r/MachineLearning/comments/196m1k/machine_learning_bitly_can_do_a_lot_more_for_you/","subreddit_id":"t5_2r3gv","media_embed":{},"num_comments":0,"gilded":0,"over_18":false,"author":"buddybjames","banned_by":null,"created_utc":1361780698,"url":"http://www.refactorthis.net/post/2013/02/25/Machine-learning-bitly-can-do-a-lot-more-for-you-than-shrink-your-URLs.aspx"}
{"stickied":false,"user_reports":[],"domain":"norvigaward.github.com","author_flair_text":null,"retrieved_on":1413038958,"edited":false,"mod_reports":[],"selftext_html":null,"is_self":false,"thumbnail":"http://e.thumbs.redditmedia.com/l09cLQ04TQiwjiM4.jpg","report_reasons":null,"link_flair_text":null,"id":"196hsc","media":null,"distinguished":null,"title":"Traitor - associating Concepts using the World Wide Web - Norvig Web Data Science Award Winner","ups":21,"downs":0,"secure_media":null,"author_flair_css_class":null,"secure_media_embed":{},"score":21,"subreddit":"MachineLearning","permalink":"/r/MachineLearning/comments/196hsc/traitor_associating_concepts_using_the_world_wide/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"","banned_by":null,"created_utc":1361774422,"url":"http://norvigaward.github.com/entries.html#naward13","gilded":0,"num_comments":4,"media_embed":{},"author":"rrenaud","over_18":false}
{"ups":13,"downs":0,"secure_media":null,"distinguished":null,"media":null,"id":"19a2wp","title":"5 Lessons Learned from the Event Recommendation Challenge","link_flair_text":null,"report_reasons":null,"selftext_html":null,"is_self":false,"thumbnail":"http://b.thumbs.redditmedia.com/QCyGG-UMghRboW-C.jpg","mod_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413033709,"stickied":false,"domain":"blog.kaggle.com","user_reports":[],"over_18":false,"author":"winkywooster","num_comments":0,"media_embed":{},"gilded":0,"created_utc":1361911028,"banned_by":null,"url":"http://blog.kaggle.com/2013/02/25/5-lessons-learned-for-the-event-recommendation-challenge/","link_flair_css_class":null,"selftext":"","permalink":"/r/MachineLearning/comments/19a2wp/5_lessons_learned_from_the_event_recommendation/","subreddit_id":"t5_2r3gv","score":13,"secure_media_embed":{},"subreddit":"MachineLearning","author_flair_css_class":null}
{"id":"199c6c","distinguished":null,"media":null,"title":"Efficient Estimation of Word Representations in Vector Space -- vec(\"King\") - vec(\"Man\") + vec(\"Woman\") ~= vec(\"Queen\")","downs":0,"ups":55,"secure_media":null,"stickied":false,"user_reports":[],"domain":"arxiv.org","author_flair_text":null,"retrieved_on":1413034786,"edited":false,"mod_reports":[],"thumbnail":"default","is_self":false,"selftext_html":null,"report_reasons":null,"link_flair_text":null,"permalink":"/r/MachineLearning/comments/199c6c/efficient_estimation_of_word_representations_in/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"","banned_by":null,"created_utc":1361888081,"url":"http://arxiv.org/pdf/1301.3781v1.pdf","gilded":0,"num_comments":2,"media_embed":{},"over_18":false,"author":"rrenaud","author_flair_css_class":null,"score":55,"secure_media_embed":{},"subreddit":"MachineLearning"}
{"secure_media":null,"downs":0,"ups":1,"title":"Fast clustering algorithms for massive datasets","distinguished":null,"media":null,"id":"19d043","is_self":false,"thumbnail":"http://f.thumbs.redditmedia.com/2ERXX8mL0ysdoZtA.jpg","selftext_html":null,"mod_reports":[],"report_reasons":null,"link_flair_text":null,"domain":"bigdatanews.com","user_reports":[],"stickied":false,"edited":false,"retrieved_on":1413029476,"author_flair_text":null,"url":"http://www.bigdatanews.com/profiles/blogs/fast-clustering-algorithms-for-massive-datasets","created_utc":1362008988,"banned_by":null,"over_18":false,"author":"winkywooster","media_embed":{},"num_comments":0,"gilded":0,"subreddit_id":"t5_2r3gv","permalink":"/r/MachineLearning/comments/19d043/fast_clustering_algorithms_for_massive_datasets/","selftext":"","link_flair_css_class":null,"subreddit":"MachineLearning","score":1,"secure_media_embed":{},"author_flair_css_class":null}
{"permalink":"/r/MachineLearning/comments/19c0lb/music_recommendations_at_spotify_machine_learning/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"","created_utc":1361982175,"banned_by":null,"url":"http://vimeo.com/57900625","author":"balthus1880","over_18":false,"gilded":0,"num_comments":10,"media_embed":{"scrolling":false,"width":600,"content":"&lt;iframe src=\"http://player.vimeo.com/video/57900625\" width=\"600\" height=\"340\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;","height":340},"author_flair_css_class":null,"score":36,"secure_media_embed":{},"subreddit":"MachineLearning","media":{"type":"vimeo.com","oembed":{"author_url":"http://vimeo.com/user5498254","width":600,"provider_name":"Vimeo","provider_url":"http://vimeo.com/","title":"Music recommendations at Spotify - Erik Bernhardsson","thumbnail_url":"http://b.vimeocdn.com/ts/401/595/401595736_295.jpg","height":340,"author_name":"xamdam","version":"1.0","html":"&lt;iframe src=\"http://player.vimeo.com/video/57900625\" width=\"600\" height=\"340\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;","description":"Spotify uses a range of large scale machine learning methods to find interesting music recommendations. Using large amounts of implicit data, collaborative filtering is behind features such as radio, related artists, and a number of soon to be released features.","type":"video","thumbnail_width":295,"thumbnail_height":166}},"distinguished":null,"id":"19c0lb","title":"Music recommendations at Spotify - Machine Learning (x/post from r/spotify)","ups":36,"downs":0,"secure_media":null,"stickied":false,"domain":"vimeo.com","user_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413030879,"is_self":false,"selftext_html":null,"thumbnail":"http://a.thumbs.redditmedia.com/lSuOWuZVM4Emezaf.jpg","mod_reports":[],"link_flair_text":null,"report_reasons":null}
{"id":"19bzni","distinguished":null,"media":null,"title":"Best resource for learning about the basics of ML (I am a non-programmer)","downs":0,"ups":1,"secure_media":null,"stickied":false,"user_reports":[],"domain":"self.MachineLearning","author_flair_text":null,"retrieved_on":1413030919,"edited":false,"mod_reports":[],"is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to begin thinking about ML and how it can help my company (music industry) to utilize user data. But I am not a programmer, nor do I really have access to talk to the programmers. But I want to learn! I will poke around on Kaggle. But any other resources would be great. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","report_reasons":null,"link_flair_text":null,"permalink":"/r/MachineLearning/comments/19bzni/best_resource_for_learning_about_the_basics_of_ml/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"I would like to begin thinking about ML and how it can help my company (music industry) to utilize user data. But I am not a programmer, nor do I really have access to talk to the programmers. But I want to learn! I will poke around on Kaggle. But any other resources would be great. Thanks","banned_by":null,"created_utc":1361981405,"url":"http://www.reddit.com/r/MachineLearning/comments/19bzni/best_resource_for_learning_about_the_basics_of_ml/","num_comments":1,"media_embed":{},"gilded":0,"over_18":false,"author":"balthus1880","author_flair_css_class":null,"secure_media_embed":{},"score":1,"subreddit":"MachineLearning"}
{"score":1,"secure_media_embed":{},"subreddit":"MachineLearning","author_flair_css_class":null,"created_utc":1361924691,"banned_by":null,"url":"http://www.reddit.com/r/MachineLearning/comments/19alds/trying_to_understand_an_equation_in_regularized/","over_18":false,"author":"zionsrogue","num_comments":4,"gilded":0,"media_embed":{},"permalink":"/r/MachineLearning/comments/19alds/trying_to_understand_an_equation_in_regularized/","subreddit_id":"t5_2r3gv","link_flair_css_class":null,"selftext":"I have been reading [Regularized Multi-Class Semi-Supervised Boosting](http://www.cs.washington.edu/research/insects/CVPR2009/optim_learning/multicls_semisup_boosting.pdf) and I can't seem to understand equation 2. From my understanding, the loss function \"l\" times the probability of \"p\" is the expected loss (i.e. how likely **x** is of class y). However, I have no idea what the \"d\" function is, the author never defines it.\n\nCan someone please explain this equation to me? I've been trying to wrap my head around it.","is_self":true,"thumbnail":"self","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been reading &lt;a href=\"http://www.cs.washington.edu/research/insects/CVPR2009/optim_learning/multicls_semisup_boosting.pdf\"&gt;Regularized Multi-Class Semi-Supervised Boosting&lt;/a&gt; and I can&amp;#39;t seem to understand equation 2. From my understanding, the loss function &amp;quot;l&amp;quot; times the probability of &amp;quot;p&amp;quot; is the expected loss (i.e. how likely &lt;strong&gt;x&lt;/strong&gt; is of class y). However, I have no idea what the &amp;quot;d&amp;quot; function is, the author never defines it.&lt;/p&gt;\n\n&lt;p&gt;Can someone please explain this equation to me? I&amp;#39;ve been trying to wrap my head around it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","mod_reports":[],"link_flair_text":null,"report_reasons":null,"stickied":false,"domain":"self.MachineLearning","user_reports":[],"author_flair_text":null,"edited":false,"retrieved_on":1413032975,"ups":1,"downs":0,"secure_media":null,"distinguished":null,"media":null,"id":"19alds","title":"Trying to understand an equation in \"Regularized Multi-Class Semi-Supervised Boosting\""}
